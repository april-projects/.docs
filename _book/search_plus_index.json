{"./":{"url":"./","title":"README","keywords":"","body":"April 项目组文档仓库 这是一个用于存储文档的仓库，可以方便地共享和管理各种文档。本仓库的文档类型不限，可以包括但不限于技术文档、设计文档、需求文档、用户手册等。 如何使用 你可以通过以下几种方式使用本仓库： 查看文档：在本仓库中找到你需要的文档，点击进入查看。 下载文档：在文档页面中点击下载按钮，即可下载文档。 提交文档：如果你想上传一个新文档或修改已有文档，可以先 Fork 本仓库，然后在你的仓库中进行修改，最后发起 Pull Request 即可。 贡献 如果你想为本仓库贡献文档，欢迎进行如下操作： Fork 本仓库 在你的仓库中添加或修改文档 发起 Pull Request 我们会及时审核并合并你的贡献。为了保证贡献质量，建议你在提交贡献前，仔细阅读贡献指南。 贡献指南 为了保证本仓库的贡献质量，我们制定了如下的贡献指南： 文档内容应当真实可靠，不得包含虚假信息。 文档格式应当规范，建议使用 Markdown 格式。 文档应当具有实用性和参考价值，不得过于简单或复杂。 代码示例应当可执行，并应当注明相关依赖库的版本号。 如有图片、视频等附件，建议使用外部链接或专门的存储仓库。 版权声明 本仓库的所有文档均属于原作者版权所有，未经授权不得进行商业使用。在 Fork 和提交贡献时，请务必尊重原作者的版权，并注明出处。 联系我们 如果你有任何问题或建议，可以通过以下方式联系我们： 邮箱：mobaijun8@163.com GitHub Issues：https://github.com/april-projects/.docs/issues window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/README.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/README.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"codesytel/":{"url":"codesytel/","title":"常用编程技巧和代码规范总结","keywords":"","body":"常用编程技巧和代码规范总结 一、前言 April（四月） 是以我的猫咪命名的一个开源团队，创立初衷是为了孵化一些项目到社区，意味着后续也会接受来自其他代码贡献者的代码，但是如果代码贡献者的编程风格与 April 的不一致，会给代码阅读者和其他代码提交者造成不小的困扰. April 因此总结了这份编程风格指南, 使所有提交代码的人都能获知 April 的编程风格. 二、Java 编码规范 Java 编程规范主要以阿里巴巴代码规约为主 ( GitHub 无法预览 PDF，可以 clone 本仓库，使用 typora 可以以 PDF 方式查看下面的文档) 三、编程技巧（补充） 一、注释规范 禁用行尾注释 方法或常量，成员变量，禁单行注释，应使用文档注释 类注释模板 /** *software：IntelliJ IDEA 2022.1 *class name: ${NAME} *class description： ${END} * *@author (作者名称) ${DATE} ${TIME} */ 枚举注释模板 /** *software：IntelliJ IDEA 2022.1 *enum name: ${NAME} *enum description： ${END} * *@author (作者名称) ${DATE} ${TIME} */ 接口注释模板 /** *software：IntelliJ IDEA 2022.1 *interface name: ${NAME} *interface description： ${END} *接口描述： ${END} * *@author (作者名称) ${DATE} ${TIME} */ 注解注释模板 /** *software：IntelliJ IDEA 2022.1 *annotation name: ${NAME} *annotation description： ${END} * *@author (作者名称) ${DATE} ${TIME} */ 二、建表规范 遵循三大范式 复杂字段之间用 （_） 下划线相隔，如（create_time，user_name） 禁止使用外键关联 主键字段使用（bigint）类型，Java 对应类型使用 Long 类型 日期类型字段是 （datetime），Java对应 LocalDateTime 类型 三、查询规范 列表查询 所有的列表查询都需要添加排序，已最后添加的数据显示在第一列，以 bigint 类型作为排序字段，如（主键 id ） 操作集合尽量使用 stream 和 lambda 表达式,工具类地址（com.mobaijun.common.util.stream） 四、返回规范 项目中定义了三个返回类，目录地址（com.mobaijun.common.result） AbstractTip 泛型父类，返回值 SuccessTip 成功返回 ErrorTip 异常返回 项目中返回只能在 controller 层进行操作，禁止在业务层（service）实行（AbstractTip/Success/Error）返回 业务层如果需要异常处理，使用 throw new Exception(\"\") 进行处理; 五、增删改查返回规范 新增：返回 boolean 类型或 int 类型 修改：返回 boolean 类型或 int 类型 删除：返回 int 类型 查询：返回 List 类型或 Entity 类型 批量：返回 int 类型 六、接口规范 类定义信息为 @Api(tags = {\"一级目录-二级目录-业务类型\"}, description = \"具体描述\") 查询使用：@GetMapping(value = \"/${methodName}\") 新增使用：@PostMapping(value = \"/${methodName}\") 修改使用：@PostMapping(value = \"/${methodName}\") 单个删除：@DeleteMapping(value = \"/${methodName}\") 批量删除：@DeleteMapping(value = \"/${methodName}\") 命名规则： 单个删除（singleDelete） 批量删除（batchDelete） 新增 （insert[Entity]） 修改 （update[Entity]） 查询 （select[Entity]List） 七、枚举定义规范 枚举如果没有set方法，属性需要使用 final 定义； 枚举每个字段需包含文档注释 枚举属性全部定义为大写，多个单纯之间以下划线分割 @Getter @AllArgsConstructor public enum NameType { /** * 名称 */ FACTORY_NAME(\"name\"); /** * 值 */ private final String value; } 八、编码技巧 成员变量 成员变量禁用 idea 告警关键字，例如 width、height 异常处理 如遇到多资源关闭应使用（try-with-resources）语法 参考链接传送地址 // 代码示例 public void readFile() throws FileNotFoundException { try (FileReader fr = new FileReader(\"d:/input.txt\");BufferedReader br = new BufferedReader(fr)) { String s = \"\"; while ((s = br.readLine()) != null) { System.out.println(s); } } catch (IOException e) { e.printStackTrace(); } } 工具类使用： 非必要不新增工具类，已 kjs-common 包工具类为准，内含 hutool 工具包，大多数场景已经可以完全应付 com.mobaijun kjs-common ${latest version} 依赖关系图 集合处理 集合处理使用 Java 8 新特性 lambda 结合 Stream 操作，例如： public static void writeWallpaper(List wallpaperDataList) throws IOException { if (!Files.exists(WALLPAPER_PATH)) { Files.createFile(WALLPAPER_PATH); } // 扫描本地文件 List data = readWallpaperData(); if (CollUtil.isNotEmpty(data)) { wallpaperDataList.addAll(data); } // 排序 List collect = wallpaperDataList.stream() // 倒序,最新日期排前面 .sorted(Comparator.comparing(WallpaperData::getCreatedAt).reversed()) .collect(Collectors.toList()); Files.write(WALLPAPER_PATH, \"## Wallpaper\".getBytes()); Files.write(WALLPAPER_PATH, System.lineSeparator().getBytes(), StandardOpenOption.APPEND); collect.forEach(wallpaperData -> { try { Files.write(WALLPAPER_PATH, wallpaperData.formatMarkdown().getBytes(), StandardOpenOption.APPEND); Files.write(WALLPAPER_PATH, System.lineSeparator().getBytes(), StandardOpenOption.APPEND); Files.write(WALLPAPER_PATH, System.lineSeparator().getBytes(), StandardOpenOption.APPEND); } catch (IOException e) { log.error(e.getMessage(), \"Failed to write wallpaper.md file\"); } }); } 上方代码来自 april-wallpaper 项目 对象实体转换 对象之间的属性赋值应该使用 mapstruct 进行转换，示例代码： @PostMapping(\"/insertMarketIndex\") public AbstractTip insertMarketIndex(@Validated MarketIndexDTO dto) { if (ObjectUtils.isEmpty(dto)) { return new ErrorTip<>(\"The data is null , abnormal, burst out NullPointerException\"); } return new SuccessTip<>(marketIndexService.insertMarketIndex(MarketIndexConverter.INSTANCE.toDto(dto))); } 四、代码提交规范 主要以 GitMoji 规范为主，gitmoji 是一个标准化和解释在GitHub提交消息上使用 emoji 的倡议。 gitmoji 是一个开源项目，专门规定了在 github 提交代码时应当遵循的 emoji 规范，在 git commit上使用 emoji 提供了一种简单的方法，仅通过查看所使用的表情符号来确定提交的目的或意图。 在执行 git commit 指令时使用 emoji 图标为本次提交添加一个特别的图标， 这个本次提交的记录很容易突出重点，或者说光看图标就知道本次提交的目的。这样就方便在日后查看历史提交日子记录中快速的查找到对于的提交版本。由于有很多不同的表情符号，表情库更新后，没有一个可以帮助更轻松地使用表情符号的中文表情库列表。 提交示例，图标地址传送门 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/codesytel/README.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/codesytel/README.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/jvm/JVM运行时区域详解.html":{"url":"Java/jvm/JVM运行时区域详解.html","title":"JVM运行时区域详解","keywords":"","body":"我们知道的JVM内存区域有：堆和栈，这是一种泛的分法，也是按运行时区域的一种分法，堆是所有线程共享的一块区域，而栈是线程隔离的，每个线程互不共享。 线程不共享区域 每个线程的数据区域包括程序计数器、虚拟机栈和本地方法栈，它们都是在新线程创建时才创建的。 程序计数器（Program Counter Rerister） 程序计数器区域一块内存较小的区域，它用于存储线程的每个执行指令，每个线程都有自己的程序计数器，此区域不会有内存溢出的情况。 虚拟机栈（VM Stack） 虚拟机栈描述的是Java方法执行的内存模型，每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 本地方法栈（Native Method Stack） 本地方法栈用于支持本地方法（native标识的方法，即非Java语言实现的方法）。 　 虚拟机栈和本地方法栈，当线程请求分配的栈容量超过JVM允许的最大容量时抛出StackOverflowError异常。 线程不共享区域如下图绿色背景所示。 线程共享区域 线程共享区域包含：堆和方法区。 堆（Heap） 堆是最常处理的区域，它存储在JVM启动时创建的数组和对象，JVM垃圾收集也主要是在堆上面工作。 如果实际所需的堆超过了自动内存管理系统能提供的最大容量时抛出OutOfMemoryError异常。 方法区（Method Area） 方法区是可供各条线程共享的运行时内存区域。存储了每一个类的结构信息，例如运行时常量池（Runtime Constant Pool）、字段和方法数据、构造函数和普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法。 当创建类和接口时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大内存空间后就会抛出OutOfMemoryError 运行时常量池（Runtime Constant Pool） 运行时常量池是方法区的一部分，每一个运行时常量池都分配在JVM的方法区中，在类和接口被加载到JVM后，对应的运行时常量池就被创建。运行时常量池是每一个类或接口的常量池（Constant_Pool）的运行时表现形式，它包括了若干种常量：编译器可知的数值字面量到必须运行期解析后才能获得的方法或字段的引用。 如果方法区的内存空间不能满足内存分配请求，那Java虚拟机将抛出一个OutOfMemoryError异常。 栈包含Frames，当调用方法时，Frame被推送到堆栈。一个Frame包含局部变量数组、操作数栈、常量池引用。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/jvm/JVM运行时区域详解.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/jvm/JVM运行时区域详解.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/JUC/":{"url":"Java/JUC/","title":"JUC","keywords":"","body":"April 项目组文档仓库 这是一个用于存储文档的仓库，可以方便地共享和管理各种文档。本仓库的文档类型不限，可以包括但不限于技术文档、设计文档、需求文档、用户手册等。 如何使用 你可以通过以下几种方式使用本仓库： 查看文档：在本仓库中找到你需要的文档，点击进入查看。 下载文档：在文档页面中点击下载按钮，即可下载文档。 提交文档：如果你想上传一个新文档或修改已有文档，可以先 Fork 本仓库，然后在你的仓库中进行修改，最后发起 Pull Request 即可。 贡献 如果你想为本仓库贡献文档，欢迎进行如下操作： Fork 本仓库 在你的仓库中添加或修改文档 发起 Pull Request 我们会及时审核并合并你的贡献。为了保证贡献质量，建议你在提交贡献前，仔细阅读贡献指南。 贡献指南 为了保证本仓库的贡献质量，我们制定了如下的贡献指南： 文档内容应当真实可靠，不得包含虚假信息。 文档格式应当规范，建议使用 Markdown 格式。 文档应当具有实用性和参考价值，不得过于简单或复杂。 代码示例应当可执行，并应当注明相关依赖库的版本号。 如有图片、视频等附件，建议使用外部链接或专门的存储仓库。 版权声明 本仓库的所有文档均属于原作者版权所有，未经授权不得进行商业使用。在 Fork 和提交贡献时，请务必尊重原作者的版权，并注明出处。 联系我们 如果你有任何问题或建议，可以通过以下方式联系我们： 邮箱：mobaijun8@163.com GitHub Issues：https://github.com/april-projects/.docs/issues window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/JUC/README.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/JUC/README.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/JUC/JUC（一）.html":{"url":"Java/JUC/JUC（一）.html","title":"JUC（一）","keywords":"","body":"再谈多线程 JUC相对于Java应用层的学习难度更大，开篇推荐掌握的预备知识：JavaSE多线程部分（必备）、操作系统、JVM（推荐）、计算机组成原理。掌握预备知识会让你的学习更加轻松，其中，JavaSE多线程部分要求必须掌握，否则无法继续学习本教程！我们不会再去重复教学JavaSE阶段的任何知识了。 各位小伙伴一定要点击收藏按钮（收藏 = 学会） 还记得我们在JavaSE中学习的多线程吗？让我们来回顾一下： 在我们的操作系统之上，可以同时运行很多个进程，并且每个进程之间相互隔离互不干扰。我们的CPU会通过时间片轮转算法，为每一个进程分配时间片，并在时间片使用结束后切换下一个进程继续执行，通过这种方式来实现宏观上的多个程序同时运行。 由于每个进程都有一个自己的内存空间，进程之间的通信就变得非常麻烦（比如要共享某些数据）而且执行不同进程会产生上下文切换，非常耗时，那么有没有一种更好地方案呢？ 后来，线程横空出世，一个进程可以有多个线程，线程是程序执行中一个单一的顺序控制流程，现在线程才是程序执行流的最小单元，各个线程之间共享程序的内存空间（也就是所在进程的内存空间），上下文切换速度也高于进程。 现在有这样一个问题： public static void main(String[] args) { int[] arr = new int[]{3, 1, 5, 2, 4}; //请将上面的数组按升序输出 } 按照正常思维，我们肯定是这样： public static void main(String[] args) { int[] arr = new int[]{3, 1, 5, 2, 4}; //直接排序吧 Arrays.sort(arr); for (int i : arr) { System.out.println(i); } } 而我们学习了多线程之后，可以换个思路来实现： public static void main(String[] args) { int[] arr = new int[]{3, 1, 5, 2, 4}; for (int i : arr) { new Thread(() -> { try { Thread.sleep(i * 1000); //越小的数休眠时间越短，优先被打印 System.out.println(i); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); } } 我们接触过的很多框架都在使用多线程，比如Tomcat服务器，所有用户的请求都是通过不同的线程来进行处理的，这样我们的网站才可以同时响应多个用户的请求，要是没有多线程，可想而知服务器的处理效率会有多低。 虽然多线程能够为我们解决很多问题，但是，如何才能正确地使用多线程，如何才能将多线程的资源合理使用，这都是我们需要关心的问题。 在Java 5的时候，新增了java.util.concurrent（JUC）包，其中包括大量用于多线程编程的工具类，目的是为了更好的支持高并发任务，让开发者进行多线程编程时减少竞争条件和死锁的问题！通过使用这些工具类，我们的程序会更加合理地使用多线程。而我们这一系列视频的主角，正是JUC。 但是我们先不着急去看这些内容，第一章，我们先来补点基础知识。 并发与并行 我们经常听到并发编程，那么这个并发代表的是什么意思呢？而与之相似的并行又是什么意思？它们之间有什么区别？ 比如现在一共有三个工作需要我们去完成。 顺序执行 顺序执行其实很好理解，就是我们依次去将这些任务完成了： 实际上就是我们同一时间只能处理一个任务，所以需要前一个任务完成之后，才能继续下一个任务，依次完成所有任务。 并发执行 并发执行也是我们同一时间只能处理一个任务，但是我们可以每个任务轮着做（时间片轮转）： 只要我们单次处理分配的时间足够的短，在宏观看来，就是三个任务在同时进行。 而我们Java中的线程，正是这种机制，当我们需要同时处理上百个上千个任务时，很明显CPU的数量是不可能赶得上我们的线程数的，所以说这时就要求我们的程序有良好的并发性能，来应对同一时间大量的任务处理。学习Java并发编程，能够让我们在以后的实际场景中，知道该如何应对高并发的情况。 并行执行 并行执行就突破了同一时间只能处理一个任务的限制，我们同一时间可以做多个任务： 比如我们要进行一些排序操作，就可以用到并行计算，只需要等待所有子任务完成，最后将结果汇总即可。包括分布式计算模型MapReduce，也是采用的并行计算思路。 再谈锁机制 谈到锁机制，相信各位应该并不陌生了，我们在JavaSE阶段，通过使用synchronized关键字来实现锁，这样就能够很好地解决线程之间争抢资源的情况。那么，synchronized底层到底是如何实现的呢？ 我们知道，使用synchronized，一定是和某个对象相关联的，比如我们要对某一段代码加锁，那么我们就需要提供一个对象来作为锁本身： public static void main(String[] args) { synchronized (Main.class) { //这里使用的是Main类的Class对象作为锁 } } 我们来看看，它变成字节码之后会用到哪些指令： 其中最关键的就是monitorenter指令了，可以看到之后也有monitorexit与之进行匹配（注意这里有2个），monitorenter和monitorexit分别对应加锁和释放锁，在执行monitorenter之前需要尝试获取锁，每个对象都有一个monitor监视器与之对应，而这里正是去获取对象监视器的所有权，一旦monitor所有权被某个线程持有，那么其他线程将无法获得（管程模型的一种实现）。 在代码执行完成之后，我们可以看到，一共有两个monitorexit在等着我们，那么为什么这里会有两个呢，按理说monitorenter和monitorexit不应该一一对应吗，这里为什么要释放锁两次呢？ 首先我们来看第一个，这里在释放锁之后，会马上进入到一个goto指令，跳转到15行，而我们的15行对应的指令就是方法的返回指令，其实正常情况下只会执行第一个monitorexit释放锁，在释放锁之后就接着同步代码块后面的内容继续向下执行了。而第二个，其实是用来处理异常的，可以看到，它的位置是在12行，如果程序运行发生异常，那么就会执行第二个monitorexit，并且会继续向下通过athrow指令抛出异常，而不是直接跳转到15行正常运行下去。 实际上synchronized使用的锁就是存储在Java对象头中的，我们知道，对象是存放在堆内存中的，而每个对象内部，都有一部分空间用于存储对象头信息，而对象头信息中，则包含了Mark Word用于存放hashCode和对象的锁信息，在不同状态下，它存储的数据结构有一些不同。 重量级锁 在JDK6之前，synchronized一直被称为重量级锁，monitor依赖于底层操作系统的Lock实现，Java的线程是映射到操作系统的原生线程上，切换成本较高。而在JDK6之后，锁的实现得到了改进。我们先从最原始的重量级锁开始： 我们说了，每个对象都有一个monitor与之关联，在Java虚拟机（HotSpot）中，monitor是由ObjectMonitor实现的： ObjectMonitor() { _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; } 每个等待锁的线程都会被封装成ObjectWaiter对象，进入到如下机制： ObjectWaiter首先会进入 Entry Set等着，当线程获取到对象的monitor后进入 The Owner 区域并把monitor中的owner变量设置为当前线程，同时monitor中的计数器count加1，若线程调用wait()方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSet集合中等待被唤醒。若当前线程执行完毕也将释放monitor并复位变量的值，以便其他线程进入获取对象的monitor。 虽然这样的设计思路非常合理，但是在大多数应用上，每一个线程占用同步代码块的时间并不是很长，我们完全没有必要将竞争中的线程挂起然后又唤醒，并且现代CPU基本都是多核心运行的，我们可以采用一种新的思路来实现锁。 在JDK1.4.2时，引入了自旋锁（JDK6之后默认开启），它不会将处于等待状态的线程挂起，而是通过无限循环的方式，不断检测是否能够获取锁，由于单个线程占用锁的时间非常短，所以说循环次数不会太多，可能很快就能够拿到锁并运行，这就是自旋锁。当然，仅仅是在等待时间非常短的情况下，自旋锁的表现会很好，但是如果等待时间太长，由于循环是需要处理器继续运算的，所以这样只会浪费处理器资源，因此自旋锁的等待时间是有限制的，默认情况下为10次，如果失败，那么会进而采用重量级锁机制。 在JDK6之后，自旋锁得到了一次优化，自旋的次数限制不再是固定的，而是自适应变化的，比如在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行，那么这次自旋也是有可能成功的，所以会允许自旋更多次。当然，如果某个锁经常都自旋失败，那么有可能会不再采用自旋策略，而是直接使用重量级锁。 轻量级锁 从JDK 1.6开始，为了减少获得锁和释放锁带来的性能消耗，就引入了轻量级锁。 轻量级锁的目标是，在无竞争情况下，减少重量级锁产生的性能消耗（并不是为了代替重量级锁，实际上就是赌一手同一时间只有一个线程在占用资源），包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。它不像是重量级锁那样，需要向操作系统申请互斥量。它的运作机制如下： 在即将开始执行同步代码块中的内容时，会首先检查对象的Mark Word，查看锁对象是否被其他线程占用，如果没有任何线程占用，那么会在当前线程中所处的栈帧中建立一个名为锁记录（Lock Record）的空间，用于复制并存储对象目前的Mark Word信息（官方称为Displaced Mark Word）。 接着，虚拟机将使用CAS操作将对象的Mark Word更新为轻量级锁状态（数据结构变为指向Lock Record的指针，指向的是当前的栈帧） CAS（Compare And Swap）是一种无锁算法（我们之前在Springboot阶段已经讲解过了），它并不会为对象加锁，而是在执行的时候，看看当前数据的值是不是我们预期的那样，如果是，那就正常进行替换，如果不是，那么就替换失败。比如有两个线程都需要修改变量i的值，默认为10，现在一个线程要将其修改为20，另一个要修改为30，如果他们都使用CAS算法，那么并不会加锁访问i，而是直接尝试修改i的值，但是在修改时，需要确认i是不是10，如果是，表示其他线程还没对其进行修改，如果不是，那么说明其他线程已经将其修改，此时不能完成修改任务，修改失败。 在CPU中，CAS操作使用的是cmpxchg指令，能够从最底层硬件层面得到效率的提升。 如果CAS操作失败了的话，那么说明可能这时有线程已经进入这个同步代码块了，这时虚拟机会再次检查对象的Mark Word，是否指向当前线程的栈帧，如果是，说明不是其他线程，而是当前线程已经有了这个对象的锁，直接放心大胆进同步代码块即可。如果不是，那确实是被其他线程占用了。 这时，轻量级锁一开始的想法就是错的（这时有对象在竞争资源，已经赌输了），所以说只能将锁膨胀为重量级锁，按照重量级锁的操作执行（注意锁的膨胀是不可逆的） 所以，轻量级锁 -> 失败 -> 自适应自旋锁 -> 失败 -> 重量级锁 解锁过程同样采用CAS算法，如果对象的MarkWord仍然指向线程的锁记录，那么就用CAS操作把对象的MarkWord和复制到栈帧中的Displaced Mark Word进行交换。如果替换失败，说明其他线程尝试过获取该锁，在释放锁的同时，需要唤醒被挂起的线程。 偏向锁 偏向锁相比轻量级锁更纯粹，干脆就把整个同步都消除掉，不需要再进行CAS操作了。它的出现主要是得益于人们发现某些情况下某个锁频繁地被同一个线程获取，这种情况下，我们可以对轻量级锁进一步优化。 偏向锁实际上就是专门为单个线程而生的，当某个线程第一次获得锁时，如果接下来都没有其他线程获取此锁，那么持有锁的线程将不再需要进行同步操作。 可以从之前的MarkWord结构中看到，偏向锁也会通过CAS操作记录线程的ID，如果一直都是同一个线程获取此锁，那么完全没有必要在进行额外的CAS操作。当然，如果有其他线程来抢了，那么偏向锁会根据当前状态，决定是否要恢复到未锁定或是膨胀为轻量级锁。 如果我们需要使用偏向锁，可以添加-XX:+UseBiased参数来开启。 所以，最终的锁等级为：未锁定 值得注意的是，如果对象通过调用hashCode()方法计算过对象的一致性哈希值，那么它是不支持偏向锁的，会直接进入到轻量级锁状态，因为Hash是需要被保存的，而偏向锁的Mark Word数据结构，无法保存Hash值；如果对象已经是偏向锁状态，再去调用hashCode()方法，那么会直接将锁升级为重量级锁，并将哈希值存放在monitor（有预留位置保存）中。 锁消除和锁粗化 锁消除和锁粗化都是在运行时的一些优化方案，比如我们某段代码虽然加了锁，但是在运行时根本不可能出现各个线程之间资源争夺的情况，这种情况下，完全不需要任何加锁机制，所以锁会被消除。锁粗化则是我们代码中频繁地出现互斥同步操作，比如在一个循环内部加锁，这样明显是非常消耗性能的，所以虚拟机一旦检测到这种操作，会将整个同步范围进行扩展。 JMM内存模型 注意这里提到的内存模型和我们在JVM中介绍的内存模型不在同一个层次，JVM中的内存模型是虚拟机规范对整个内存区域的规划，而Java内存模型，是在JVM内存模型之上的抽象模型，具体实现依然是基于JVM内存模型实现的，我们会在后面介绍。 Java内存模型 我们在计算机组成原理中学习过，在我们的CPU中，一般都会有高速缓存，而它的出现，是为了解决内存的速度跟不上处理器的处理速度的问题，所以CPU内部会添加一级或多级高速缓存来提高处理器的数据获取效率，但是这样也会导致一个很明显的问题，因为现在基本都是多核心处理器，每个处理器都有一个自己的高速缓存，那么又该怎么去保证每个处理器的高速缓存内容一致呢？ 为了解决缓存一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等。 而Java也采用了类似的模型来实现支持多线程的内存模型： JMM（Java Memory Model）内存模型规定如下： 所有的变量全部存储在主内存（注意这里包括下面提到的变量，指的都是会出现竞争的变量，包括成员变量、静态变量等，而局部变量这种属于线程私有，不包括在内） 每条线程有着自己的工作内存（可以类比CPU的高速缓存）线程对变量的所有操作，必须在工作内存中进行，不能直接操作主内存中的数据。 不同线程之间的工作内存相互隔离，如果需要在线程之间传递内容，只能通过主内存完成，无法直接访问对方的工作内存。 也就是说，每一条线程如果要操作主内存中的数据，那么得先拷贝到自己的工作内存中，并对工作内存中数据的副本进行操作，操作完成之后，也需要从工作副本中将结果拷贝回主内存中，具体的操作就是Save（保存）和Load（加载）操作。 那么各位肯定会好奇，这个内存模型，结合之前JVM所讲的内容，具体是怎么实现的呢？ 主内存：对应堆中存放对象的实例的部分。 工作内存：对应线程的虚拟机栈的部分区域，虚拟机可能会对这部分内存进行优化，将其放在CPU的寄存器或是高速缓存中。比如在访问数组时，由于数组是一段连续的内存空间，所以可以将一部分连续空间放入到CPU高速缓存中，那么之后如果我们顺序读取这个数组，那么大概率会直接缓存命中。 前面我们提到，在CPU中可能会遇到缓存不一致的问题，而Java中，也会遇到，比如下面这种情况： public class Main { private static int i = 0; public static void main(String[] args) throws InterruptedException { new Thread(() -> { for (int j = 0; j { for (int j = 0; j 可以看到这里是两个线程同时对变量i各自进行100000次自增操作，但是实际得到的结果并不是我们所期望的那样。 那么为什么会这样呢？在之前学习了JVM之后，相信各位应该已经知道，自增操作实际上并不是由一条指令完成的（注意一定不要理解为一行代码就是一个指令完成的）： 包括变量i的获取、修改、保存，都是被拆分为一个一个的操作完成的，那么这个时候就有可能出现在修改完保存之前，另一条线程也保存了，但是当前线程是毫不知情的。 所以说，我们当时在JavaSE阶段讲解这个问题的时候，是通过synchronized关键字添加同步代码块解决的，当然，我们后面还会讲解另外的解决方案（原子类） 重排序 在编译或执行时，为了优化程序的执行效率，编译器或处理器常常会对指令进行重排序，有以下情况： 编译器重排序：Java编译器通过对Java代码语义的理解，根据优化规则对代码指令进行重排序。 机器指令级别的重排序：现代处理器很高级，能够自主判断和变更机器指令的执行顺序。 指令重排序能够在不改变结果（单线程）的情况下，优化程序的运行效率，比如： public static void main(String[] args) { int a = 10; int b = 20; System.out.println(a + b); } 我们其实可以交换第一行和第二行： public static void main(String[] args) { int b = 10; int a = 20; System.out.println(a + b); } 即使发生交换，但是我们程序最后的运行结果是不会变的，当然这里只通过代码的形式演示，实际上JVM在执行字节码指令时也会进行优化，可能两个指令并不会按照原有的顺序进行。 虽然单线程下指令重排确实可以起到一定程度的优化作用，但是在多线程下，似乎会导致一些问题： public class Main { private static int a = 0; private static int b = 0; public static void main(String[] args) { new Thread(() -> { if(b == 1) { if(a == 0) { System.out.println(\"A\"); }else { System.out.println(\"B\"); } } }).start(); new Thread(() -> { a = 1; b = 1; }).start(); } } 上面这段代码，在正常情况下，按照我们的正常思维，是不可能输出A的，因为只要b等于1，那么a肯定也是1才对，因为a是在b之前完成的赋值。但是，如果进行了重排序，那么就有可能，a和b的赋值发生交换，b先被赋值为1，而恰巧这个时候，线程1开始判定b是不是1了，这时a还没来得及被赋值为1，可能线程1就已经走到打印那里去了，所以，是有可能输出A的。 volatile关键字 好久好久都没有认识新的关键字了，今天我们来看一个新的关键字volatile，开始之前我们先介绍三个词语： 原子性：其实之前讲过很多次了，就是要做什么事情要么做完，要么就不做，不存在做一半的情况。 可见性：指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性：即程序执行的顺序按照代码的先后顺序执行。 我们之前说了，如果多线程访问同一个变量，那么这个变量会被线程拷贝到自己的工作内存中进行操作，而不是直接对主内存中的变量本体进行操作，下面这个操作看起来是一个有限循环，但是是无限的： public class Main { private static int a = 0; public static void main(String[] args) throws InterruptedException { new Thread(() -> { while (a == 0); System.out.println(\"线程结束！\"); }).start(); Thread.sleep(1000); System.out.println(\"正在修改a的值...\"); a = 1; //很明显，按照我们的逻辑来说，a的值被修改那么另一个线程将不再循环 } } 实际上这就是我们之前说的，虽然我们主线程中修改了a的值，但是另一个线程并不知道a的值发生了改变，所以循环中依然是使用旧值在进行判断，因此，普通变量是不具有可见性的。 要解决这种问题，我们第一个想到的肯定是加锁，同一时间只能有一个线程使用，这样总行了吧，确实，这样的话肯定是可以解决问题的： public class Main { private static int a = 0; public static void main(String[] args) throws InterruptedException { new Thread(() -> { while (a == 0) { synchronized (Main.class){} } System.out.println(\"线程结束！\"); }).start(); Thread.sleep(1000); System.out.println(\"正在修改a的值...\"); synchronized (Main.class){ a = 1; } } } 但是，除了硬加一把锁的方案，我们也可以使用volatile关键字来解决，此关键字的第一个作用，就是保证变量的可见性。当写一个volatile变量时，JMM会把该线程本地内存中的变量强制刷新到主内存中去，并且这个写会操作会导致其他线程中的volatile变量缓存无效，这样，另一个线程修改了这个变时，当前线程会立即得知，并将工作内存中的变量更新为最新的版本。 那么我们就来试试看： public class Main { //添加volatile关键字 private static volatile int a = 0; public static void main(String[] args) throws InterruptedException { new Thread(() -> { while (a == 0); System.out.println(\"线程结束！\"); }).start(); Thread.sleep(1000); System.out.println(\"正在修改a的值...\"); a = 1; } } 结果还真的如我们所说的那样，当a发生改变时，循环立即结束。 当然，虽然说volatile能够保证可见性，但是不能保证原子性，要解决我们上面的i++的问题，以我们目前所学的知识，还是只能使用加锁来完成： public class Main { private static volatile int a = 0; public static void main(String[] args) throws InterruptedException { Runnable r = () -> { for (int i = 0; i 不对啊，volatile不是能在改变变量的时候其他线程可见吗，那为什么还是不能保证原子性呢？还是那句话，自增操作是被瓜分为了多个步骤完成的，虽然保证了可见性，但是只要手速够快，依然会出现两个线程同时写同一个值的问题（比如线程1刚刚将a的值更新为100，这时线程2可能也已经执行到更新a的值这条指令了，已经刹不住车了，所以依然会将a的值再更新为一次100） 那要是真的遇到这种情况，那么我们不可能都去写个锁吧？后面，我们会介绍原子类来专门解决这种问题。 最后一个功能就是volatile会禁止指令重排，也就是说，如果我们操作的是一个volatile变量，它将不会出现重排序的情况，也就解决了我们最上面的问题。那么它是怎么解决的重排序问题呢？若用volatile修饰共享变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序 内存屏障（Memory Barrier）又称内存栅栏，是一个CPU指令，它的作用有两个： 保证特定操作的顺序 保证某些变量的内存可见性（volatile的内存可见性，其实就是依靠这个实现的） 由于编译器和处理器都能执行指令重排的优化，如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序。 屏障类型 指令示例 说明 LoadLoad Load1;LoadLoad;Load2 保证Load1的读取操作在Load2及后续读取操作之前执行 StoreStore Store1;StoreStore;Store2 在Store2及其后的写操作执行前，保证Store1的写操作已刷新到主内存 LoadStore Load1;LoadStore;Store2 在Store2及其后的写操作执行前，保证Load1的读操作已读取结束 StoreLoad Store1;StoreLoad;Load2 保证load1的写操作已刷新到主内存之后，load2及其后的读操作才能执行 所以volatile能够保证，之前的指令一定全部执行，之后的指令一定都没有执行，并且前面语句的结果对后面的语句可见。 最后我们来总结一下volatile关键字的三个特性： 保证可见性 不保证原子性 防止指令重排 在之后我们的设计模式系列视频中，还会讲解单例模式下volatile的运用。 happens-before原则 经过我们前面的讲解，相信各位已经了解了JMM内存模型以及重排序等机制带来的优点和缺点，综上，JMM提出了happens-before（先行发生）原则，定义一些禁止编译优化的场景，来向各位程序员做一些保证，只要我们是按照原则进行编程，那么就能够保持并发编程的正确性。具体如下： 程序次序规则：同一个线程中，按照程序的顺序，前面的操作happens-before后续的任何操作。 同一个线程内，代码的执行结果是有序的。其实就是，可能会发生指令重排，但是保证代码的执行结果一定是和按照顺序执行得到的一致，程序前面对某一个变量的修改一定对后续操作可见的，不可能会出现前面才把a修改为1，接着读a居然是修改前的结果，这也是程序运行最基本的要求。 监视器锁规则：对一个锁的解锁操作，happens-before后续对这个锁的加锁操作。 就是无论是在单线程环境还是多线程环境，对于同一个锁来说，一个线程对这个锁解锁之后，另一个线程获取了这个锁都能看到前一个线程的操作结果。比如前一个线程将变量x的值修改为了12并解锁，之后另一个线程拿到了这把锁，对之前线程的操作是可见的，可以得到x是前一个线程修改后的结果12（所以synchronized是有happens-before规则的） volatile变量规则：对一个volatile变量的写操作happens-before后续对这个变量的读操作。 就是如果一个线程先去写一个volatile变量，紧接着另一个线程去读这个变量，那么这个写操作的结果一定对读的这个变量的线程可见。 线程启动规则：主线程A启动线程B，线程B中可以看到主线程启动B之前的操作。 在主线程A执行过程中，启动子线程B，那么线程A在启动子线程B之前对共享变量的修改结果对线程B可见。 线程加入规则：如果线程A执行操作join()线程B并成功返回，那么线程B中的任意操作happens-before线程Ajoin()操作成功返回。 传递性规则：如果A happens-before B，B happens-before C，那么A happens-before C。 那么我们来从happens-before原则的角度，来解释一下下面的程序结果： public class Main { private static int a = 0; private static int b = 0; public static void main(String[] args) { a = 10; b = a + 1; new Thread(() -> { if(b > 10) System.out.println(a); }).start(); } } 首先我们定义以上出现的操作： A：将变量a的值修改为10 B：将变量b的值修改为a + 1 C：主线程启动了一个新的线程，并在新的线程中获取b，进行判断，如果为true那么就打印a 首先我们来分析，由于是同一个线程，并且B是一个赋值操作且读取了A，那么按照程序次序规则，A happens-before B，接着在B之后，马上执行了C，按照线程启动规则，在新的线程启动之前，当前线程之前的所有操作对新的线程是可见的，所以 B happens-before C，最后根据传递性规则，由于A happens-before B，B happens-before C，所以A happens-before C，因此在新的线程中会输出a修改后的结果10。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/JUC/JUC（一）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/JUC/JUC（一）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/JUC/JUC（二）.html":{"url":"Java/JUC/JUC（二）.html","title":"JUC（二）","keywords":"","body":"多线程编程核心 在前面，我们了解了多线程的底层运作机制，我们终于知道，原来多线程环境下存在着如此之多的问题。在JDK5之前，我们只能选择synchronized关键字来实现锁，而JDK5之后，由于volatile关键字得到了升级（具体功能就是上一章所描述的），所以并发框架包便出现了，相比传统的synchronized关键字，我们对于锁的实现，有了更多的选择。 Doug Lea — JUC并发包的作者 如果IT的历史，是以人为主体串接起来的话，那么肯定少不了Doug Lea。这个鼻梁挂着眼镜，留着德王威廉二世的胡子，脸上永远挂着谦逊腼腆笑容，服务于纽约州立大学Oswego分校计算机科学系的老大爷。 说他是这个世界上对Java影响力最大的一个人，一点也不为过。因为两次Java历史上的大变革，他都间接或直接的扮演了举足轻重的角色。2004年所推出的Tiger。Tiger广纳了15项JSRs(Java Specification Requests)的语法及标准，其中一项便是JSR-166。JSR-166是来自于Doug编写的util.concurrent包。 那么，从这章开始，就让我们来感受一下，JUC为我们带来了什么。 锁框架 在JDK 5之后，并发包中新增了Lock接口（以及相关实现类）用来实现锁功能，Lock接口提供了与synchronized关键字类似的同步功能，但需要在使用时手动获取锁和释放锁。 Lock和Condition接口 使用并发包中的锁和我们传统的synchronized锁不太一样，这里的锁我们可以认为是一把真正意义上的锁，每个锁都是一个对应的锁对象，我只需要向锁对象获取锁或是释放锁即可。我们首先来看看，此接口中定义了什么： public interface Lock { //获取锁，拿不到锁会阻塞，等待其他线程释放锁，获取到锁后返回 void lock(); //同上，但是等待过程中会响应中断 void lockInterruptibly() throws InterruptedException; //尝试获取锁，但是不会阻塞，如果能获取到会返回true，不能返回false boolean tryLock(); //尝试获取锁，但是可以限定超时时间，如果超出时间还没拿到锁返回false，否则返回true，可以响应中断 boolean tryLock(long time, TimeUnit unit) throws InterruptedException; //释放锁 void unlock(); //暂时可以理解为替代传统的Object的wait()、notify()等操作的工具 Condition newCondition(); } 这里我们可以演示一下，如何使用Lock类来进行加锁和释放锁操作： public class Main { private static int i = 0; public static void main(String[] args) throws InterruptedException { Lock testLock = new ReentrantLock(); //可重入锁ReentrantLock类是Lock类的一个实现，我们后面会进行介绍 Runnable action = () -> { for (int j = 0; j 可以看到，和我们之前使用synchronized相比，我们这里是真正在操作一个\"锁\"对象，当我们需要加锁时，只需要调用lock()方法，而需要释放锁时，只需要调用unlock()方法。程序运行的最终结果和使用synchronized锁是一样的。 那么，我们如何像传统的加锁那样，调用对象的wait()和notify()方法呢，并发包提供了Condition接口： public interface Condition { //与调用锁对象的wait方法一样，会进入到等待状态，但是这里需要调用Condition的signal或signalAll方法进行唤醒（感觉就是和普通对象的wait和notify是对应的）同时，等待状态下是可以响应中断的 void await() throws InterruptedException; //同上，但不响应中断（看名字都能猜到） void awaitUninterruptibly(); //等待指定时间，如果在指定时间（纳秒）内被唤醒，会返回剩余时间，如果超时，会返回0或负数，可以响应中断 long awaitNanos(long nanosTimeout) throws InterruptedException; //等待指定时间（可以指定时间单位），如果等待时间内被唤醒，返回true，否则返回false，可以响应中断 boolean await(long time, TimeUnit unit) throws InterruptedException; //可以指定一个明确的时间点，如果在时间点之前被唤醒，返回true，否则返回false，可以响应中断 boolean awaitUntil(Date deadline) throws InterruptedException; //唤醒一个处于等待状态的线程，注意还得获得锁才能接着运行 void signal(); //同上，但是是唤醒所有等待线程 void signalAll(); } 这里我们通过一个简单的例子来演示一下： public static void main(String[] args) throws InterruptedException { Lock testLock = new ReentrantLock(); Condition condition = testLock.newCondition(); new Thread(() -> { testLock.lock(); //和synchronized一样，必须持有锁的情况下才能使用await System.out.println(\"线程1进入等待状态！\"); try { condition.await(); //进入等待状态 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"线程1等待结束！\"); testLock.unlock(); }).start(); Thread.sleep(100); //防止线程2先跑 new Thread(() -> { testLock.lock(); System.out.println(\"线程2开始唤醒其他等待线程\"); condition.signal(); //唤醒线程1，但是此时线程1还必须要拿到锁才能继续运行 System.out.println(\"线程2结束\"); testLock.unlock(); //这里释放锁之后，线程1就可以拿到锁继续运行了 }).start(); } 可以发现，Condition对象使用方法和传统的对象使用差别不是很大。 思考：下面这种情况跟上面有什么不同？ public static void main(String[] args) throws InterruptedException { Lock testLock = new ReentrantLock(); new Thread(() -> { testLock.lock(); System.out.println(\"线程1进入等待状态！\"); try { testLock.newCondition().await(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"线程1等待结束！\"); testLock.unlock(); }).start(); Thread.sleep(100); new Thread(() -> { testLock.lock(); System.out.println(\"线程2开始唤醒其他等待线程\"); testLock.newCondition().signal(); System.out.println(\"线程2结束\"); testLock.unlock(); }).start(); } 通过分析可以得到，在调用newCondition()后，会生成一个新的Condition对象，并且同一把锁内是可以存在多个Condition对象的（实际上原始的锁机制等待队列只能有一个，而这里可以创建很多个Condition来实现多等待队列），而上面的例子中，实际上使用的是不同的Condition对象，只有对同一个Condition对象进行等待和唤醒操作才会有效，而不同的Condition对象是分开计算的。 最后我们再来讲解一下时间单位，这是一个枚举类，也是位于java.util.concurrent包下： public enum TimeUnit { /** * Time unit representing one thousandth of a microsecond */ NANOSECONDS { public long toNanos(long d) { return d; } public long toMicros(long d) { return d/(C1/C0); } public long toMillis(long d) { return d/(C2/C0); } public long toSeconds(long d) { return d/(C3/C0); } public long toMinutes(long d) { return d/(C4/C0); } public long toHours(long d) { return d/(C5/C0); } public long toDays(long d) { return d/(C6/C0); } public long convert(long d, TimeUnit u) { return u.toNanos(d); } int excessNanos(long d, long m) { return (int)(d - (m*C2)); } }, //.... 可以看到时间单位有很多的，比如DAY、SECONDS、MINUTES等，我们可以直接将其作为时间单位，比如我们要让一个线程等待3秒钟，可以像下面这样编写： public static void main(String[] args) throws InterruptedException { Lock testLock = new ReentrantLock(); new Thread(() -> { testLock.lock(); try { System.out.println(\"等待是否未超时：\"+testLock.newCondition().await(1, TimeUnit.SECONDS)); } catch (InterruptedException e) { e.printStackTrace(); } testLock.unlock(); }).start(); } 当然，Lock类的tryLock方法也是支持使用时间单位的，各位可以自行进行测试。TimeUnit除了可以作为时间单位表示以外，还可以在不同单位之间相互转换： public static void main(String[] args) throws InterruptedException { System.out.println(\"60秒 = \"+TimeUnit.SECONDS.toMinutes(60) +\"分钟\"); System.out.println(\"365天 = \"+TimeUnit.DAYS.toSeconds(365) +\" 秒\"); } 也可以更加便捷地使用对象的wait()方法： public static void main(String[] args) throws InterruptedException { synchronized (Main.class) { System.out.println(\"开始等待\"); TimeUnit.SECONDS.timedWait(Main.class, 3); //直接等待3秒 System.out.println(\"等待结束\"); } } 我们也可以直接使用它来进行休眠操作： public static void main(String[] args) throws InterruptedException { TimeUnit.SECONDS.sleep(1); //休眠1秒钟 } 可重入锁 前面，我们讲解了锁框架的两个核心接口，那么我们接着来看看锁接口的具体实现类，我们前面用到了ReentrantLock，它其实是锁的一种，叫做可重入锁，那么这个可重入代表的是什么意思呢？简单来说，就是同一个线程，可以反复进行加锁操作： public static void main(String[] args) throws InterruptedException { ReentrantLock lock = new ReentrantLock(); lock.lock(); lock.lock(); //连续加锁2次 new Thread(() -> { System.out.println(\"线程2想要获取锁\"); lock.lock(); System.out.println(\"线程2成功获取到锁\"); }).start(); lock.unlock(); System.out.println(\"线程1释放了一次锁\"); TimeUnit.SECONDS.sleep(1); lock.unlock(); System.out.println(\"线程1再次释放了一次锁\"); //释放两次后其他线程才能加锁 } 可以看到，主线程连续进行了两次加锁操作（此操作是不会被阻塞的），在当前线程持有锁的情况下继续加锁不会被阻塞，并且，加锁几次，就必须要解锁几次，否则此线程依旧持有锁。我们可以使用getHoldCount()方法查看当前线程的加锁次数： public static void main(String[] args) throws InterruptedException { ReentrantLock lock = new ReentrantLock(); lock.lock(); lock.lock(); System.out.println(\"当前加锁次数：\"+lock.getHoldCount()+\"，是否被锁：\"+lock.isLocked()); TimeUnit.SECONDS.sleep(1); lock.unlock(); System.out.println(\"当前加锁次数：\"+lock.getHoldCount()+\"，是否被锁：\"+lock.isLocked()); TimeUnit.SECONDS.sleep(1); lock.unlock(); System.out.println(\"当前加锁次数：\"+lock.getHoldCount()+\"，是否被锁：\"+lock.isLocked()); } 可以看到，当锁不再被任何线程持有时，值为0，并且通过isLocked()方法查询结果为false。 实际上，如果存在线程持有当前的锁，那么其他线程在获取锁时，是会暂时进入到等待队列的，我们可以通过getQueueLength()方法获取等待中线程数量的预估值： public static void main(String[] args) throws InterruptedException { ReentrantLock lock = new ReentrantLock(); lock.lock(); Thread t1 = new Thread(lock::lock), t2 = new Thread(lock::lock);; t1.start(); t2.start(); TimeUnit.SECONDS.sleep(1); System.out.println(\"当前等待锁释放的线程数：\"+lock.getQueueLength()); System.out.println(\"线程1是否在等待队列中：\"+lock.hasQueuedThread(t1)); System.out.println(\"线程2是否在等待队列中：\"+lock.hasQueuedThread(t2)); System.out.println(\"当前线程是否在等待队列中：\"+lock.hasQueuedThread(Thread.currentThread())); } 我们可以通过hasQueuedThread()方法来判断某个线程是否正在等待获取锁状态。 同样的，Condition也可以进行判断： public static void main(String[] args) throws InterruptedException { ReentrantLock lock = new ReentrantLock(); Condition condition = lock.newCondition(); new Thread(() -> { lock.lock(); try { condition.await(); } catch (InterruptedException e) { e.printStackTrace(); } lock.unlock(); }).start(); TimeUnit.SECONDS.sleep(1); lock.lock(); System.out.println(\"当前Condition的等待线程数：\"+lock.getWaitQueueLength(condition)); condition.signal(); System.out.println(\"当前Condition的等待线程数：\"+lock.getWaitQueueLength(condition)); lock.unlock(); } 通过使用getWaitQueueLength()方法能够查看同一个Condition目前有多少线程处于等待状态。 公平锁与非公平锁 前面我们了解了如果线程之间争抢同一把锁，会暂时进入到等待队列中，那么多个线程获得锁的顺序是不是一定是根据线程调用lock()方法时间来定的呢，我们可以看到，ReentrantLock的构造方法中，是这样写的： public ReentrantLock() { sync = new NonfairSync(); //看名字貌似是非公平的 } 其实锁分为公平锁和非公平锁，默认我们创建出来的ReentrantLock是采用的非公平锁作为底层锁机制。那么什么是公平锁什么又是非公平锁呢？ 公平锁：多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到锁。 非公平锁：多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。 简单来说，公平锁不让插队，都老老实实排着；非公平锁让插队，但是排队的人让不让你插队就是另一回事了。 我们可以来测试一下公平锁和非公平锁的表现情况： public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 这里我们选择使用第二个构造方法，可以选择是否为公平锁实现： public static void main(String[] args) throws InterruptedException { ReentrantLock lock = new ReentrantLock(false); Runnable action = () -> { System.out.println(\"线程 \"+Thread.currentThread().getName()+\" 开始获取锁...\"); lock.lock(); System.out.println(\"线程 \"+Thread.currentThread().getName()+\" 成功获取锁！\"); lock.unlock(); }; for (int i = 0; i 这里我们只需要对比将在1秒后开始获取锁...和成功获取锁！的顺序是否一致即可，如果是一致，那说明所有的线程都是按顺序排队获取的锁，如果不是，那说明肯定是有线程插队了。 运行结果可以发现，在公平模式下，确实是按照顺序进行的，而在非公平模式下，一般会出现这种情况：线程刚开始获取锁马上就能抢到，并且此时之前早就开始的线程还在等待状态，很明显的插队行为。 那么，接着下一个问题，公平锁在任何情况下都一定是公平的吗？有关这个问题，我们会留到队列同步器中再进行讨论。 读写锁 除了可重入锁之外，还有一种类型的锁叫做读写锁，当然它并不是专门用作读写操作的锁，它和可重入锁不同的地方在于，可重入锁是一种排他锁，当一个线程得到锁之后，另一个线程必须等待其释放锁，否则一律不允许获取到锁。而读写锁在同一时间，是可以让多个线程获取到锁的，它其实就是针对于读写场景而出现的。 读写锁维护了一个读锁和一个写锁，这两个锁的机制是不同的。 读锁：在没有任何线程占用写锁的情况下，同一时间可以有多个线程加读锁。 写锁：在没有任何线程占用读锁的情况下，同一时间只能有一个线程加写锁。 读写锁也有一个专门的接口： public interface ReadWriteLock { //获取读锁 Lock readLock(); //获取写锁 Lock writeLock(); } 此接口有一个实现类ReentrantReadWriteLock（实现的是ReadWriteLock接口，不是Lock接口，它本身并不是锁），注意我们操作ReentrantReadWriteLock时，不能直接上锁，而是需要获取读锁或是写锁，再进行锁操作： public static void main(String[] args) throws InterruptedException { ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); lock.readLock().lock(); new Thread(lock.readLock()::lock).start(); } 这里我们对读锁加锁，可以看到可以多个线程同时对读锁加锁。 public static void main(String[] args) throws InterruptedException { ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); lock.readLock().lock(); new Thread(lock.writeLock()::lock).start(); } 有读锁状态下无法加写锁，反之亦然： public static void main(String[] args) throws InterruptedException { ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); lock.writeLock().lock(); new Thread(lock.readLock()::lock).start(); } 并且，ReentrantReadWriteLock不仅具有读写锁的功能，还保留了可重入锁和公平/非公平机制，比如同一个线程可以重复为写锁加锁，并且必须全部解锁才真正释放锁： public static void main(String[] args) throws InterruptedException { ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); lock.writeLock().lock(); lock.writeLock().lock(); new Thread(() -> { lock.writeLock().lock(); System.out.println(\"成功获取到写锁！\"); }).start(); System.out.println(\"释放第一层锁！\"); lock.writeLock().unlock(); TimeUnit.SECONDS.sleep(1); System.out.println(\"释放第二层锁！\"); lock.writeLock().unlock(); } 通过之前的例子来验证公平和非公平： public static void main(String[] args) throws InterruptedException { ReentrantReadWriteLock lock = new ReentrantReadWriteLock(true); Runnable action = () -> { System.out.println(\"线程 \"+Thread.currentThread().getName()+\" 将在1秒后开始获取锁...\"); lock.writeLock().lock(); System.out.println(\"线程 \"+Thread.currentThread().getName()+\" 成功获取锁！\"); lock.writeLock().unlock(); }; for (int i = 0; i 可以看到，结果是一致的。 锁降级和锁升级 锁降级指的是写锁降级为读锁。当一个线程持有写锁的情况下，虽然其他线程不能加读锁，但是线程自己是可以加读锁的： public static void main(String[] args) throws InterruptedException { ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); lock.writeLock().lock(); lock.readLock().lock(); System.out.println(\"成功加读锁！\"); } 那么，如果我们在同时加了写锁和读锁的情况下，释放写锁，是否其他的线程就可以一起加读锁了呢？ public static void main(String[] args) throws InterruptedException { ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); lock.writeLock().lock(); lock.readLock().lock(); new Thread(() -> { System.out.println(\"开始加读锁！\"); lock.readLock().lock(); System.out.println(\"读锁添加成功！\"); }).start(); TimeUnit.SECONDS.sleep(1); lock.writeLock().unlock(); //如果释放写锁，会怎么样？ } 可以看到，一旦写锁被释放，那么主线程就只剩下读锁了，因为读锁可以被多个线程共享，所以这时第二个线程也添加了读锁。而这种操作，就被称之为\"锁降级\"（注意不是先释放写锁再加读锁，而是持有写锁的情况下申请读锁再释放写锁） 注意在仅持有读锁的情况下去申请写锁，属于\"锁升级\"，ReentrantReadWriteLock是不支持的： public static void main(String[] args) throws InterruptedException { ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); lock.readLock().lock(); lock.writeLock().lock(); System.out.println(\"所升级成功！\"); } 可以看到线程直接卡在加写锁的那一句了。 队列同步器AQS 注意：难度巨大，如果对锁的使用不是很熟悉建议之后再来看！ 前面我们了解了可重入锁和读写锁，那么它们的底层实现原理到底是什么样的呢？又是大家看到就想跳过的套娃解析环节。 比如我们执行了ReentrantLock的lock()方法，那它的内部是怎么在执行的呢？ public void lock() { sync.lock(); } 可以看到，它的内部实际上啥都没做，而是交给了Sync对象在进行，并且，不只是这个方法，其他的很多方法都是依靠Sync对象在进行： public void unlock() { sync.release(1); } 那么这个Sync对象是干什么的呢？可以看到，公平锁和非公平锁都是继承自Sync，而Sync是继承自AbstractQueuedSynchronizer，简称队列同步器： abstract static class Sync extends AbstractQueuedSynchronizer { //... } static final class NonfairSync extends Sync {} static final class FairSync extends Sync {} 所以，要了解它的底层到底是如何进行操作的，还得看队列同步器，我们就先从这里下手吧！ 底层实现 AbstractQueuedSynchronizer（下面称为AQS）是实现锁机制的基础，它的内部封装了包括锁的获取、释放、以及等待队列。 一个锁（排他锁为例）的基本功能就是获取锁、释放锁、当锁被占用时，其他线程来争抢会进入等待队列，AQS已经将这些基本的功能封装完成了，其中等待队列是核心内容，等待队列是由双向链表数据结构实现的，每个等待状态下的线程都可以被封装进结点中并放入双向链表中，而对于双向链表是以队列的形式进行操作的，它像这样： AQS中有一个head字段和一个tail字段分别记录双向链表的头结点和尾结点，而之后的一系列操作都是围绕此队列来进行的。我们先来了解一下每个结点都包含了哪些内容： //每个处于等待状态的线程都可以是一个节点，并且每个节点是有很多状态的 static final class Node { //每个节点都可以被分为独占模式节点或是共享模式节点，分别适用于独占锁和共享锁 static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; //等待状态，这里都定义好了 //唯一一个大于0的状态，表示已失效，可能是由于超时或中断，此节点被取消。 static final int CANCELLED = 1; //此节点后面的节点被挂起（进入等待状态） static final int SIGNAL = -1; //在条件队列中的节点才是这个状态 static final int CONDITION = -2; //传播，一般用于共享锁 static final int PROPAGATE = -3; volatile int waitStatus; //等待状态值 volatile Node prev; //双向链表基操 volatile Node next; volatile Thread thread; //每一个线程都可以被封装进一个节点进入到等待队列 Node nextWaiter; //在等待队列中表示模式，条件队列中作为下一个结点的指针 final boolean isShared() { return nextWaiter == SHARED; } final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } Node() { } Node(Thread thread, Node mode) { this.nextWaiter = mode; this.thread = thread; } Node(Thread thread, int waitStatus) { this.waitStatus = waitStatus; this.thread = thread; } } 在一开始的时候，head和tail都是null，state为默认值0： private transient volatile Node head; private transient volatile Node tail; private volatile int state; 不用担心双向链表不会进行初始化，初始化是在实际使用时才开始的，先不管，我们接着来看其他的初始化内容： //直接使用Unsafe类进行操作 private static final Unsafe unsafe = Unsafe.getUnsafe(); //记录类中属性的在内存中的偏移地址，方便Unsafe类直接操作内存进行赋值等（直接修改对应地址的内存） private static final long stateOffset; //这里对应的就是AQS类中的state成员字段 private static final long headOffset; //这里对应的就是AQS类中的head头结点成员字段 private static final long tailOffset; private static final long waitStatusOffset; private static final long nextOffset; static { //静态代码块，在类加载的时候就会自动获取偏移地址 try { stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(\"state\")); headOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(\"head\")); tailOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(\"tail\")); waitStatusOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(\"waitStatus\")); nextOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(\"next\")); } catch (Exception ex) { throw new Error(ex); } } //通过CAS操作来修改头结点 private final boolean compareAndSetHead(Node update) { //调用的是Unsafe类的compareAndSwapObject方法，通过CAS算法比较对象并替换 return unsafe.compareAndSwapObject(this, headOffset, null, update); } //同上，省略部分代码 private final boolean compareAndSetTail(Node expect, Node update) { private static final boolean compareAndSetWaitStatus(Node node, int expect, int update) { private static final boolean compareAndSetNext(Node node, Node expect, Node update) { 可以发现，队列同步器由于要使用到CAS算法，所以，直接使用了Unsafe工具类，Unsafe类中提供了CAS操作的方法（Java无法实现，底层由C++实现）所有对AQS类中成员字段的修改，都有对应的CAS操作封装。 现在我们大致了解了一下它的底层运作机制，我们接着来看这个类是如何进行使用的，它提供了一些可重写的方法（根据不同的锁类型和机制，可以自由定制规则，并且为独占式和非独占式锁都提供了对应的方法），以及一些已经写好的模板方法（模板方法会调用这些可重写的方法），使用此类只需要将可重写的方法进行重写，并调用提供的模板方法，从而实现锁功能（学习过设计模式会比较好理解一些） 我们首先来看可重写方法： //独占式获取同步状态，查看同步状态是否和参数一致，如果返没有问题，那么会使用CAS操作设置同步状态并返回true protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } //独占式释放同步状态 protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); } //共享式获取同步状态，返回值大于0表示成功，否则失败 protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException(); } //共享式释放同步状态 protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException(); } //是否在独占模式下被当前线程占用（锁是否被当前线程持有） protected boolean isHeldExclusively() { throw new UnsupportedOperationException(); } 可以看到，这些需要重写的方法默认是直接抛出UnsupportedOperationException，也就是说根据不同的锁类型，我们需要去实现对应的方法，我们可以来看一下ReentrantLock（此类是全局独占式的）中的公平锁是如何借助AQS实现的： static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; //加锁操作调用了模板方法acquire //为了防止各位绕晕，请时刻记住，lock方法一定是在某个线程下为了加锁而调用的，并且同一时间可能会有其他线程也在调用此方法 final void lock() { acquire(1); } ... } 我们先看看加锁操作干了什么事情，这里直接调用了AQS提供的模板方法acquire()，我们来看看它在AQS类中的实现细节： @ReservedStackAccess //这个是JEP 270添加的新注解，它会保护被注解的方法，通过添加一些额外的空间，防止在多线程运行的时候出现栈溢出，下同 public final void acquire(int arg) { if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //节点为独占模式Node.EXCLUSIVE selfInterrupt(); } 首先会调用tryAcquire()方法（这里是由FairSync类实现的），如果尝试加独占锁失败（返回false了）说明可能这个时候有其他线程持有了此独占锁，所以当前线程得先等着，那么会调用addWaiter()方法将线程加入等待队列中： private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // 先尝试使用CAS直接入队，如果这个时候其他线程也在入队（就是不止一个线程在同一时间争抢这把锁）就进入enq() Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } //此方法是CAS快速入队失败时调用 enq(node); return node; } private Node enq(final Node node) { //自旋形式入队，可以看到这里是一个无限循环 for (;;) { Node t = tail; if (t == null) { //这种情况只能说明头结点和尾结点都还没初始化 if (compareAndSetHead(new Node())) //初始化头结点和尾结点 tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; //只有CAS成功的情况下，才算入队成功，如果CAS失败，那说明其他线程同一时间也在入队，并且手速还比当前线程快，刚好走到CAS操作的时候，其他线程就先入队了，那么这个时候node.prev就不是我们预期的节点了，而是另一个线程新入队的节点，所以说得进下一次循环再来一次CAS，这种形式就是自旋 } } } } 在了解了addWaiter()方法会将节点加入等待队列之后，我们接着来看，addWaiter()会返回已经加入的节点，acquireQueued()在得到返回的节点时，也会进入自旋状态，等待唤醒（也就是开始进入到拿锁的环节了）： @ReservedStackAccess final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head && tryAcquire(arg)) { //可以看到当此节点位于队首(node.prev == head)时，会再次调用tryAcquire方法获取锁，如果获取成功，会返回此过程中是否被中断的值 setHead(node); //新的头结点设置为当前结点 p.next = null; // 原有的头结点没有存在的意义了 failed = false; //没有失败 return interrupted; //直接返回等待过程中是否被中断 } //依然没获取成功， if (shouldParkAfterFailedAcquire(p, node) && //将当前节点的前驱节点等待状态设置为SIGNAL，如果失败将直接开启下一轮循环，直到成功为止，如果成功接着往下 parkAndCheckInterrupt()) //挂起线程进入等待状态，等待被唤醒，如果在等待状态下被中断，那么会返回true，直接将中断标志设为true，否则就是正常唤醒，继续自旋 interrupted = true; } } finally { if (failed) cancelAcquire(node); } } private final boolean parkAndCheckInterrupt() { LockSupport.park(this); //通过unsafe类操作底层挂起线程（会直接进入阻塞状态） return Thread.interrupted(); } private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) return true; //已经是SIGNAL，直接true if (ws > 0) { //不能是已经取消的节点，必须找到一个没被取消的 do { node.prev = pred = pred.prev; } while (pred.waitStatus > 0); pred.next = node; //直接抛弃被取消的节点 } else { //不是SIGNAL，先CAS设置为SIGNAL（这里没有返回true因为CAS不一定成功，需要下一轮再判断一次） compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; //返回false，马上开启下一轮循环 } 所以，acquire()中的if条件如果为true，那么只有一种情况，就是等待过程中被中断了，其他任何情况下都是成功获取到独占锁，所以当等待过程被中断时，会调用selfInterrupt()方法： static void selfInterrupt() { Thread.currentThread().interrupt(); } 这里就是直接向当前线程发送中断信号了。 上面提到了LockSupport类，它是一个工具类，我们也可以来玩一下这个park和unpark: public static void main(String[] args) throws InterruptedException { Thread t = Thread.currentThread(); //先拿到主线程的Thread对象 new Thread(() -> { try { TimeUnit.SECONDS.sleep(1); System.out.println(\"主线程可以继续运行了！\"); LockSupport.unpark(t); //t.interrupt(); 发送中断信号也可以恢复运行 } catch (InterruptedException e) { e.printStackTrace(); } }).start(); System.out.println(\"主线程被挂起！\"); LockSupport.park(); System.out.println(\"主线程继续运行！\"); } 这里我们就把公平锁的lock()方法实现讲解完毕了（让我猜猜，已经晕了对吧，越是到源码越考验个人的基础知识掌握，基础不牢地动山摇）接着我们来看公平锁的tryAcquire()方法： static final class FairSync extends Sync { //可重入独占锁的公平实现 @ReservedStackAccess protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); //先获取当前线程的Thread对象 int c = getState(); //获取当前AQS对象状态（独占模式下0为未占用，大于0表示已占用） if (c == 0) { //如果是0，那就表示没有占用，现在我们的线程就要来尝试占用它 if (!hasQueuedPredecessors() && //等待队列是否不为空且当前线程没有拿到锁，其实就是看看当前线程有没有必要进行排队，如果没必要排队，就说明可以直接获取锁 compareAndSetState(0, acquires)) { //CAS设置状态，如果成功则说明成功拿到了这把锁，失败则说明可能这个时候其他线程在争抢，并且还比你先抢到 setExclusiveOwnerThread(current); //成功拿到锁，会将独占模式所有者线程设定为当前线程（这个方法是父类AbstractOwnableSynchronizer中的，就表示当前这把锁已经是这个线程的了） return true; //占用锁成功，返回true } } else if (current == getExclusiveOwnerThread()) { //如果不是0，那就表示被线程占用了，这个时候看看是不是自己占用的，如果是，由于是可重入锁，可以继续加锁 int nextc = c + acquires; //多次加锁会将状态值进行增加，状态值就是加锁次数 if (nextc 在了解了公平锁的实现之后，是不是感觉有点恍然大悟的感觉，虽然整个过程非常复杂，但是只要理清思路，还是比较简单的。 加锁过程已经OK，我们接着来看，它的解锁过程，unlock()方法是在AQS中实现的： public void unlock() { sync.release(1); //直接调用了AQS中的release方法，参数为1表示解锁一次state值-1 } @ReservedStackAccess public final boolean release(int arg) { if (tryRelease(arg)) { //和tryAcquire一样，也得子类去重写，释放锁操作 Node h = head; //释放锁成功后，获取新的头结点 if (h != null && h.waitStatus != 0) //如果新的头结点不为空并且不是刚刚建立的结点（初始状态下status为默认值0，而上面在进行了shouldParkAfterFailedAcquire之后，会被设定为SIGNAL状态，值为-1） unparkSuccessor(h); //唤醒头节点下一个节点中的线程 return true; } return false; } private void unparkSuccessor(Node node) { // 将等待状态waitStatus设置为初始值0 int ws = node.waitStatus; if (ws 0) { //如果下一个结点为空或是等待状态是已取消，那肯定是不能通知unpark的，这时就要遍历所有节点再另外找一个符合unpark要求的节点了 s = null; for (Node t = tail; t != null && t != node; t = t.prev) //这里是从队尾向前，因为enq()方法中的t.next = node是在CAS之后进行的，而 node.prev = t 是CAS之前进行的，所以从后往前一定能够保证遍历所有节点 if (t.waitStatus 那么我们来看看tryRelease()方法是怎么实现的，具体实现在Sync中： @ReservedStackAccess protected final boolean tryRelease(int releases) { int c = getState() - releases; //先计算本次解锁之后的状态值 if (Thread.currentThread() != getExclusiveOwnerThread()) //因为是独占锁，那肯定这把锁得是当前线程持有才行 throw new IllegalMonitorStateException(); //否则直接抛异常 boolean free = false; if (c == 0) { //如果解锁之后的值为0，表示已经完全释放此锁 free = true; setExclusiveOwnerThread(null); //将独占锁持有线程设置为null } setState(c); //状态值设定为c return free; //如果不是0表示此锁还没完全释放，返回false，是0就返回true } 综上，我们来画一个完整的流程图： 这里我们只讲解了公平锁，有关非公平锁和读写锁，还请各位观众根据我们之前的思路，自行解读。 公平锁一定公平吗？ 前面我们讲解了公平锁的实现原理，那么，我们尝试分析一下，在并发的情况下，公平锁一定公平吗？ 我们再次来回顾一下tryAcquire()方法的实现： @ReservedStackAccess protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() && //注意这里，公平锁的机制是，一开始会查看是否有节点处于等待 compareAndSetState(0, acquires)) { //如果前面的方法执行后发现没有等待节点，就直接进入占锁环节了 setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc 所以hasQueuedPredecessors()这个环节容不得半点闪失，否则会直接破坏掉公平性，假如现在出现了这样的情况： 线程1已经持有锁了，这时线程2来争抢这把锁，走到hasQueuedPredecessors()，判断出为 false，线程2继续运行，然后线程2肯定获取锁失败（因为锁这时是被线程1占有的），因此就进入到等待队列中： private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // 线程2进来之后，肯定是要先走这里的，因为head和tail都是null if (compareAndSetHead(new Node())) tail = head; //这里就将tail直接等于head了，注意这里完了之后还没完，这里只是初始化过程 } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); Node pred = tail; if (pred != null) { //由于一开始head和tail都是null，所以线程2直接就进enq()了 node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); //请看上面 return node; } 而碰巧不巧，这个时候线程3也来抢锁了，按照正常流程走到了hasQueuedPredecessors()方法，而在此方法中： public final boolean hasQueuedPredecessors() { Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; //这里直接判断h != t，而此时线程2才刚刚执行完 tail = head，所以直接就返回false了 return h != t && ((s = h.next) == null || s.thread != Thread.currentThread()); } 因此，线程3这时就紧接着准备开始CAS操作了，又碰巧，这时线程1释放锁了，现在的情况就是，线程3直接开始CAS判断，而线程2还在插入节点状态，结果可想而知，居然是线程3先拿到了锁，这显然是违背了公平锁的公平机制。 一张图就是： 因此公不公平全看hasQueuedPredecessors()，而此方法只有在等待队列中存在节点时才能保证不会出现问题。所以公平锁，只有在等待队列存在节点时，才是真正公平的。 Condition实现原理 通过前面的学习，我们知道Condition类实际上就是用于代替传统对象的wait/notify操作的，同样可以实现等待/通知模式，并且同一把锁下可以创建多个Condition对象。那么我们接着来看看，它又是如何实现的呢，我们先从单个Condition对象进行分析： 在AQS中，Condition有一个实现类ConditionObject，而这里也是使用了链表实现了条件队列： public class ConditionObject implements Condition, java.io.Serializable { private static final long serialVersionUID = 1173984872572414699L; /** 条件队列的头结点 */ private transient Node firstWaiter; /** 条件队列的尾结点 */ private transient Node lastWaiter; //... 这里是直接使用了AQS中的Node类，但是使用的是Node类中的nextWaiter字段连接节点，并且Node的status为CONDITION： 我们知道，当一个线程调用await()方法时，会进入等待状态，直到其他线程调用signal()方法将其唤醒，而这里的条件队列，正是用于存储这些处于等待状态的线程。 我们先来看看最关键的await()方法是如何实现的，为了防止一会绕晕，在开始之前，我们先明确此方法的目标： 只有已经持有锁的线程才可以使用此方法 当调用此方法后，会直接释放锁，无论加了多少次锁 只有其他线程调用signal()或是被中断时才会唤醒等待中的线程 被唤醒后，需要等待其他线程释放锁，拿到锁之后才可以继续执行，并且会恢复到之前的状态（await之前加了几层锁唤醒后依然是几层锁） 好了，差不多可以上源码了： public final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); //如果在调用await之前就被添加了中断标记，那么会直接抛出中断异常 Node node = addConditionWaiter(); //为当前线程创建一个新的节点，并将其加入到条件队列中 int savedState = fullyRelease(node); //完全释放当前线程持有的锁，并且保存一下state值，因为唤醒之后还得恢复 int interruptMode = 0; //用于保存中断状态 while (!isOnSyncQueue(node)) { //循环判断是否位于同步队列中，如果等待状态下的线程被其他线程唤醒，那么会正常进入到AQS的等待队列中（之后我们会讲） LockSupport.park(this); //如果依然处于等待状态，那么继续挂起 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) //看看等待的时候是不是被中断了 break; } //出了循环之后，那线程肯定是已经醒了，这时就差拿到锁就可以恢复运行了 if (acquireQueued(node, savedState) && interruptMode != THROW_IE) //直接开始acquireQueued尝试拿锁（之前已经讲过了）从这里开始基本就和一个线程去抢锁是一样的了 interruptMode = REINTERRUPT; //已经拿到锁了，基本可以开始继续运行了，这里再进行一下后期清理工作 if (node.nextWaiter != null) unlinkCancelledWaiters(); //将等待队列中，不是Node.CONDITION状态的节点移除 if (interruptMode != 0) //依然是响应中断 reportInterruptAfterWait(interruptMode); //OK，接着该干嘛干嘛 } 实际上await()方法比较中规中矩，大部分操作也在我们的意料之中，那么我们接着来看signal()方法是如何实现的，同样的，为了防止各位绕晕，先明确signal的目标： 只有持有锁的线程才能唤醒锁所属的Condition等待的线程 优先唤醒条件队列中的第一个，如果唤醒过程中出现问题，接着找往下找，直到找到一个可以唤醒的 唤醒操作本质上是将条件队列中的结点直接丢进AQS等待队列中，让其参与到锁的竞争中 拿到锁之后，线程才能恢复运行 好了，上源码： public final void signal() { if (!isHeldExclusively()) //先看看当前线程是不是持有锁的状态 throw new IllegalMonitorStateException(); //不是？那你不配唤醒别人 Node first = firstWaiter; //获取条件队列的第一个结点 if (first != null) //如果队列不为空，获取到了，那么就可以开始唤醒操作 doSignal(first); } private void doSignal(Node first) { do { if ( (firstWaiter = first.nextWaiter) == null) //如果当前节点在本轮循环没有后继节点了，条件队列就为空了 lastWaiter = null; //所以这里相当于是直接清空 first.nextWaiter = null; //将给定节点的下一个结点设置为null，因为当前结点马上就会离开条件队列了 } while (!transferForSignal(first) && //接着往下看 (first = firstWaiter) != null); //能走到这里只能说明给定节点被设定为了取消状态，那就继续看下一个结点 } final boolean transferForSignal(Node node) { /* * 如果这里CAS失败，那有可能此节点被设定为了取消状态 */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; //CAS成功之后，结点的等待状态就变成了默认值0，接着通过enq方法直接将节点丢进AQS的等待队列中，相当于唤醒并且可以等待获取锁了 //这里enq方法返回的是加入之后等待队列队尾的前驱节点，就是原来的tail Node p = enq(node); int ws = p.waitStatus; //保存前驱结点的等待状态 //如果上一个节点的状态为取消, 或者尝试设置上一个节点的状态为SIGNAL失败（可能是在ws>0判断完之后马上变成了取消状态，导致CAS失败） if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); //直接唤醒线程 return true; } 其实最让人不理解的就是倒数第二行，明明上面都正常进入到AQS等待队列了，应该是可以开始走正常流程了，那么这里为什么还要提前来一次unpark呢？ 这里其实是为了进行优化而编写，直接unpark会有两种情况： 如果插入结点前，AQS等待队列的队尾节点就已经被取消，则满足wc > 0 如果插入node后，AQS内部等待队列的队尾节点已经稳定，满足tail.waitStatus == 0，但在执行ws > 0之后!compareAndSetWaitStatus(p, ws, Node.SIGNAL)之前被取消，则CAS也会失败，满足compareAndSetWaitStatus(p, ws, Node.SIGNAL) == false 如果这里被提前unpark，那么在await()方法中将可以被直接唤醒，并跳出while循环，直接开始争抢锁，因为前一个等待结点是被取消的状态，没有必要再等它了。 所以，大致流程下： 只要把整个流程理清楚，还是很好理解的。 自行实现锁类 既然前面了解了那么多AQS的功能，那么我就仿照着这些锁类来实现一个简单的锁： 要求：同一时间只能有一个线程持有锁，不要求可重入（反复加锁无视即可） public class Main { public static void main(String[] args) throws InterruptedException { } /** * 自行实现一个最普通的独占锁 * 要求：同一时间只能有一个线程持有锁，不要求可重入 */ private static class MyLock implements Lock { /** * 设计思路： * 1. 锁被占用，那么exclusiveOwnerThread应该被记录，并且state = 1 * 2. 锁没有被占用，那么exclusiveOwnerThread为null，并且state = 0 */ private static class Sync extends AbstractQueuedSynchronizer { @Override protected boolean tryAcquire(int arg) { if(isHeldExclusively()) return true; //无需可重入功能，如果是当前线程直接返回true if(compareAndSetState(0, arg)){ //CAS操作进行状态替换 setExclusiveOwnerThread(Thread.currentThread()); //成功后设置当前的所有者线程 return true; } return false; } @Override protected boolean tryRelease(int arg) { if(getState() == 0) throw new IllegalMonitorStateException(); //没加锁情况下是不能直接解锁的 if(isHeldExclusively()){ //只有持有锁的线程才能解锁 setExclusiveOwnerThread(null); //设置所有者线程为null setState(0); //状态变为0 return true; } return false; } @Override protected boolean isHeldExclusively() { return getExclusiveOwnerThread() == Thread.currentThread(); } protected Condition newCondition(){ return new ConditionObject(); //直接用现成的 } } private final Sync sync = new Sync(); @Override public void lock() { sync.acquire(1); } @Override public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } @Override public boolean tryLock() { return sync.tryAcquire(1); } @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(time)); } @Override public void unlock() { sync.release(1); } @Override public Condition newCondition() { return sync.newCondition(); } } } 到这里，我们对应队列同步器AQS的讲解就先到此为止了，当然，AQS的全部机制并非仅仅只有我们讲解的内容，一些我们没有提到的内容，还请各位观众自行探索，会有满满的成就感哦~ 原子类 前面我们讲解了锁框架的使用和实现原理，虽然比较复杂，但是收获还是很多的（主要是观摩大佬写的代码）这一部分我们就来讲一点轻松的。 前面我们说到，如果要保证i++的原子性，那么我们的唯一选择就是加锁，那么，除了加锁之外，还有没有其他更好的解决方法呢？JUC为我们提供了原子类，底层采用CAS算法，它是一种用法简单、性能高效、线程安全地更新变量的方式。 所有的原子类都位于java.util.concurrent.atomic包下。 原子类介绍 常用基本数据类，有对应的原子类封装： AtomicInteger：原子更新int AtomicLong：原子更新long AtomicBoolean：原子更新boolean 那么，原子类和普通的基本类在使用上有没有什么区别呢？我们先来看正常情况下使用一个基本类型： public class Main { public static void main(String[] args) { int i = 1; System.out.println(i++); } } 现在我们使用int类型对应的原子类，要实现同样的代码该如何编写： public class Main { public static void main(String[] args) { AtomicInteger i = new AtomicInteger(1); System.out.println(i.getAndIncrement()); //如果想实现i += 2这种操作，可以使用 addAndGet() 自由设置delta 值 } } 我们可以将int数值封装到此类中（注意必须调用构造方法，它不像Integer那样有装箱机制），并且通过调用此类提供的方法来获取或是对封装的int值进行自增，乍一看，这不就是基本类型包装类嘛，有啥高级的。确实，还真有包装类那味，但是它可不仅仅是简单的包装，它的自增操作是具有原子性的： public class Main { private static AtomicInteger i = new AtomicInteger(0); public static void main(String[] args) throws InterruptedException { Runnable r = () -> { for (int j = 0; j 同样是直接进行自增操作，我们发现，使用原子类是可以保证自增操作原子性的，就跟我们前面加锁一样。怎么会这么神奇？我们来看看它的底层是如何实现的，直接从构造方法点进去： private volatile int value; public AtomicInteger(int initialValue) { value = initialValue; } public AtomicInteger() { } 可以看到，它的底层是比较简单的，其实本质上就是封装了一个volatile类型的int值，这样能够保证可见性，在CAS操作的时候不会出现问题。 private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); } catch (Exception ex) { throw new Error(ex); } } 可以看到最上面是和AQS采用了类似的机制，因为要使用CAS算法更新value的值，所以得先计算出value字段在对象中的偏移地址，CAS直接修改对应位置的内存即可（可见Unsafe类的作用巨大，很多的底层操作都要靠它来完成） 接着我们来看自增操作是怎么在运行的： public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1); } 可以看到这里调用了unsafe.getAndAddInt()，套娃时间到，我们接着看看Unsafe里面写了什么： public final int getAndAddInt(Object o, long offset, int delta) { //delta就是变化的值，++操作就是自增1 int v; do { //volatile版本的getInt() //能够保证可见性 v = getIntVolatile(o, offset); } while (!compareAndSwapInt(o, offset, v, v + delta)); //这里是开始cas替换int的值，每次都去拿最新的值去进行替换，如果成功则离开循环，不成功说明这个时候其他线程先修改了值，就进下一次循环再获取最新的值然后再cas一次，直到成功为止 return v; } 可以看到这是一个do-while循环，那么这个循环在做一个什么事情呢？感觉就和我们之前讲解的AQS队列中的机制差不多，也是采用自旋形式，来不断进行CAS操作，直到成功。 可见，原子类底层也是采用了CAS算法来保证的原子性，包括getAndSet、getAndAdd等方法都是这样。原子类也直接提供了CAS操作方法，我们可以直接使用： public static void main(String[] args) throws InterruptedException { AtomicInteger integer = new AtomicInteger(10); System.out.println(integer.compareAndSet(30, 20)); System.out.println(integer.compareAndSet(10, 20)); System.out.println(integer); } 如果想以普通变量的方式来设定值，那么可以使用lazySet()方法，这样就不采用volatile的立即可见机制了。 AtomicInteger integer = new AtomicInteger(1); integer.lazySet(2); 除了基本类有原子类以外，基本类型的数组类型也有原子类： AtomicIntegerArray：原子更新int数组 AtomicLongArray：原子更新long数组 AtomicReferenceArray：原子更新引用数组 其实原子数组和原子类型一样的，不过我们可以对数组内的元素进行原子操作： public static void main(String[] args) throws InterruptedException { AtomicIntegerArray array = new AtomicIntegerArray(new int[]{0, 4, 1, 3, 5}); Runnable r = () -> { for (int i = 0; i 在JDK8之后，新增了DoubleAdder和LongAdder，在高并发情况下，LongAdder的性能比AtomicLong的性能更好，主要体现在自增上，它的大致原理如下：在低并发情况下，和AtomicLong是一样的，对value值进行CAS操作，但是出现高并发的情况时，AtomicLong会进行大量的循环操作来保证同步，而LongAdder会将对value值的CAS操作分散为对数组cells中多个元素的CAS操作（内部维护一个Cell[] as数组，每个Cell里面有一个初始值为0的long型变量，在高并发时会进行分散CAS，就是不同的线程可以对数组中不同的元素进行CAS自增，这样就避免了所有线程都对同一个值进行CAS），只需要最后再将结果加起来即可。 使用如下： public static void main(String[] args) throws InterruptedException { LongAdder adder = new LongAdder(); Runnable r = () -> { for (int i = 0; i 由于底层源码比较复杂，这里就不做讲解了。两者的性能对比（这里用到了CountDownLatch，建议学完之后再来看）： public class Main { public static void main(String[] args) throws InterruptedException { System.out.println(\"使用AtomicLong的时间消耗：\"+test2()+\"ms\"); System.out.println(\"使用LongAdder的时间消耗：\"+test1()+\"ms\"); } private static long test1() throws InterruptedException { CountDownLatch latch = new CountDownLatch(100); LongAdder adder = new LongAdder(); long timeStart = System.currentTimeMillis(); Runnable r = () -> { for (int i = 0; i { for (int i = 0; i 除了对基本数据类型支持原子操作外，对于引用类型，也是可以实现原子操作的： public static void main(String[] args) throws InterruptedException { String a = \"Hello\"; String b = \"World\"; AtomicReference reference = new AtomicReference<>(a); reference.compareAndSet(a, b); System.out.println(reference.get()); } JUC还提供了字段原子更新器，可以对类中的某个指定字段进行原子操作（注意字段必须添加volatile关键字）： public class Main { public static void main(String[] args) throws InterruptedException { Student student = new Student(); AtomicIntegerFieldUpdater fieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Student.class, \"age\"); System.out.println(fieldUpdater.incrementAndGet(student)); } public static class Student{ volatile int age; } } 了解了这么多原子类，是不是感觉要实现保证原子性的工作更加轻松了？ ABA问题及解决方案 我们来想象一下这种场景： 线程1和线程2同时开始对a的值进行CAS修改，但是线程1的速度比较快，将a的值修改为2之后紧接着又修改回1，这时线程2才开始进行判断，发现a的值是1，所以CAS操作成功。 很明显，这里的1已经不是一开始的那个1了，而是被重新赋值的1，这也是CAS操作存在的问题（无锁虽好，但是问题多多），它只会机械地比较当前值是不是预期值，但是并不会关心当前值是否被修改过，这种问题称之为ABA问题。 那么如何解决这种ABA问题呢，JUC提供了带版本号的引用类型，只要每次操作都记录一下版本号，并且版本号不会重复，那么就可以解决ABA问题了： public static void main(String[] args) throws InterruptedException { String a = \"Hello\"; String b = \"World\"; AtomicStampedReference reference = new AtomicStampedReference<>(a, 1); //在构造时需要指定初始值和对应的版本号 reference.attemptStamp(a, 2); //可以中途对版本号进行修改，注意要填写当前的引用对象 System.out.println(reference.compareAndSet(a, b, 2, 3)); //CAS操作时不仅需要提供预期值和修改值，还要提供预期版本号和新的版本号 } 至此，有关原子类的讲解就到这里。 并发容器 简单的讲完了，又该讲难一点的了。 注意：本版块的重点在于探究并发容器是如何利用锁机制和算法实现各种丰富功能的，我们会忽略一些常规功能的实现细节（比如链表如何插入元素删除元素），而更关注并发容器应对并发场景算法上的实现（比如在多线程环境下的插入操作是按照什么规则进行的） 在单线程模式下，集合类提供的容器可以说是非常方便了，几乎我们每个项目中都能或多或少的用到它们，我们在JavaSE阶段，为各位讲解了各个集合类的实现原理，我们了解了链表、顺序表、哈希表等数据结构，那么，在多线程环境下，这些数据结构还能正常工作吗？ 传统容器线程安全吗 我们来测试一下，100个线程同时向ArrayList中添加元素会怎么样： public class Main { public static void main(String[] args) { List list = new ArrayList<>(); Runnable r = () -> { for (int i = 0; i 不出意外的话，肯定是会报错的： Exception in thread \"Thread-0\" java.lang.ArrayIndexOutOfBoundsException: 73 at java.util.ArrayList.add(ArrayList.java:465) at com.test.Main.lambda$main$0(Main.java:13) at java.lang.Thread.run(Thread.java:750) Exception in thread \"Thread-19\" java.lang.ArrayIndexOutOfBoundsException: 1851 at java.util.ArrayList.add(ArrayList.java:465) at com.test.Main.lambda$main$0(Main.java:13) at java.lang.Thread.run(Thread.java:750) 9773 那么我们来看看报的什么错，从栈追踪信息可以看出，是add方法出现了问题： public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; //这一句出现了数组越界 return true; } 也就是说，同一时间其他线程也在疯狂向数组中添加元素，那么这个时候有可能在ensureCapacityInternal（确认容量足够）执行之后，elementData[size++] = e;执行之前，其他线程插入了元素，导致size的值超出了数组容量。这些在单线程的情况下不可能发生的问题，在多线程下就慢慢出现了。 我们再来看看比较常用的HashMap呢？ public static void main(String[] args) throws InterruptedException { Map map = new HashMap<>(); for (int i = 0; i { for (int j = 0; j 经过测试发现，虽然没有报错，但是最后的结果并不是我们期望的那样，实际上它还有可能导致Entry对象出现环状数据结构，引起死循环。 所以，在多线程环境下，要安全地使用集合类，我们得找找解决方案了。 并发容器介绍 怎么才能解决并发情况下的容器问题呢？我们首先想到的肯定是给方法前面加个synchronzed关键字，这样总不会抢了吧，在之前我们可以使用Vector或是Hashtable来解决，但是它们的效率实在是太低了，完全依靠锁来解决问题，因此现在已经很少再使它们了，这里也不会再去进行讲解。 JUC提供了专用于并发场景下的容器，比如我们刚刚使用的ArrayList，在多线程环境下是没办法使用的，我们可以将其替换为JUC提供的多线程专用集合类： public static void main(String[] args) throws InterruptedException { List list = new CopyOnWriteArrayList<>(); //这里使用CopyOnWriteArrayList来保证线程安全 Runnable r = () -> { for (int i = 0; i 我们发现，使用了CopyOnWriteArrayList之后，再没出现过上面的问题。 那么它是如何实现的呢，我们先来看看它是如何进行add()操作的： public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); //直接加锁，保证同一时间只有一个线程进行添加操作 try { Object[] elements = getArray(); //获取当前存储元素的数组 int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); //直接复制一份数组 newElements[len] = e; //修改复制出来的数组 setArray(newElements); //将元素数组设定为复制出来的数组 return true; } finally { lock.unlock(); } } 可以看到添加操作是直接上锁，并且会先拷贝一份当前存放元素的数组，然后对数组进行修改，再将此数组替换（CopyOnWrite）接着我们来看读操作： public E get(int index) { return get(getArray(), index); } 因此，CopyOnWriteArrayList对于读操作不加锁，而对于写操作是加锁的，类似于我们前面讲解的读写锁机制，这样就可以保证不丢失读性能的情况下，写操作不会出现问题。 接着我们来看对于HashMap的并发容器ConcurrentHashMap： public static void main(String[] args) throws InterruptedException { Map map = new ConcurrentHashMap<>(); for (int i = 0; i { for (int j = 0; j 可以看到这里的ConcurrentHashMap就没有出现之前HashMap的问题了。因为线程之间会争抢同一把锁，我们之前在讲解LongAdder的时候学习到了一种压力分散思想，既然每个线程都想抢锁，那我就干脆多搞几把锁，让你们每个人都能拿到，这样就不会存在等待的问题了，而JDK7之前，ConcurrentHashMap的原理也比较类似，它将所有数据分为一段一段地存储，先分很多段出来，每一段都给一把锁，当一个线程占锁访问时，只会占用其中一把锁，也就是仅仅锁了一小段数据，而其他段的数据依然可以被其他线程正常访问。 这里我们重点讲解JDK8之后它是怎么实现的，它采用了CAS算法配合锁机制实现，我们先来回顾一下JDK8下的HashMap是什么样的结构： HashMap就是利用了哈希表，哈希表的本质其实就是一个用于存放后续节点的头结点的数组，数组里面的每一个元素都是一个头结点（也可以说就是一个链表），当要新插入一个数据时，会先计算该数据的哈希值，找到数组下标，然后创建一个新的节点，添加到对应的链表后面。当链表的长度达到8时，会自动将链表转换为红黑树，这样能使得原有的查询效率大幅度降低！当使用红黑树之后，我们就可以利用二分搜索的思想，快速地去寻找我们想要的结果，而不是像链表一样挨个去看。 又是基础不牢地动山摇环节，由于ConcurrentHashMap的源码比较复杂，所以我们先从最简单的构造方法开始下手： 我们发现，它的构造方法和HashMap的构造方法有很大的出入，但是大体的结构和HashMap是差不多的，也是维护了一个哈希表，并且哈希表中存放的是链表或是红黑树，所以我们直接来看put()操作是如何实现的，只要看明白这个，基本上就懂了： public V put(K key, V value) { return putVal(key, value, false); } //有点小乱，如果看着太乱，可以在IDEA中折叠一下代码块，不然有点难受 final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); //键值不能为空，基操 int hash = spread(key.hashCode()); //计算键的hash值，用于确定在哈希表中的位置 int binCount = 0; //一会用来记录链表长度的，忽略 for (Node[] tab = table;;) { //无限循环，而且还是并发包中的类，盲猜一波CAS自旋锁 Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); //如果数组（哈希表）为空肯定是要进行初始化的，然后再重新进下一轮循环 else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { //如果哈希表该位置为null，直接CAS插入结点作为头结即可（注意这里会将f设置当前哈希表位置上的头结点） if (casTabAt(tab, i, null, new Node(hash, key, value, null))) break; // 如果CAS成功，直接break结束put方法，失败那就继续下一轮循环 } else if ((fh = f.hash) == MOVED) //头结点哈希值为-1，这里只需要知道是因为正在扩容即可 tab = helpTransfer(tab, f); //帮助进行迁移，完事之后再来下一次循环 else { //特殊情况都完了，这里就该是正常情况了， V oldVal = null; synchronized (f) { //在前面的循环中f肯定是被设定为了哈希表某个位置上的头结点，这里直接把它作为锁加锁了，防止同一时间其他线程也在操作哈希表中这个位置上的链表或是红黑树 if (tabAt(tab, i) == f) { if (fh >= 0) { //头结点的哈希值大于等于0说明是链表，下面就是针对链表的一些列操作 ...实现细节略 } else if (f instanceof TreeBin) { //肯定不大于0，肯定也不是-1，还判断是不是TreeBin，所以不用猜了，肯定是红黑树，下面就是针对红黑树的情况进行操作 //在ConcurrentHashMap并不是直接存储的TreeNode，而是TreeBin ...实现细节略 } } } //根据链表长度决定是否要进化为红黑树 if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); //注意这里只是可能会进化为红黑树，如果当前哈希表的长度小于64，它会优先考虑对哈希表进行扩容 if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null; } 怎么样，是不是感觉看着挺复杂，其实也还好，总结一下就是： 我们接着来看看get()操作： public V get(Object key) { Node[] tab; Node e, p; int n, eh; K ek; int h = spread(key.hashCode()); //计算哈希值 if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) { // 如果头结点就是我们要找的，那直接返回值就行了 if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null && key.equals(ek))) return e.val; } //要么是正在扩容，要么就是红黑树，负数只有这两种情况 else if (eh 综上，ConcurrentHashMap的put操作，实际上是对哈希表上的所有头结点元素分别加锁，理论上来说哈希表的长度很大程度上决定了ConcurrentHashMap在同一时间能够处理的线程数量，这也是为什么treeifyBin()会优先考虑为哈希表进行扩容的原因。显然，这种加锁方式比JDK7的分段锁机制性能更好。 其实这里也只是简单地介绍了一下它的运行机制，ConcurrentHashMap真正的难点在于扩容和迁移操作，我们主要了解的是他的并发执行机制，有关它的其他实现细节，这里暂时不进行讲解。 阻塞队列 除了我们常用的容器类之外，JUC还提供了各种各样的阻塞队列，用于不同的工作场景。 阻塞队列本身也是队列，但是它是适用于多线程环境下的，基于ReentrantLock实现的，它的接口定义如下： public interface BlockingQueue extends Queue { boolean add(E e); //入队，如果队列已满，返回false否则返回true（非阻塞） boolean offer(E e); //入队，如果队列已满，阻塞线程直到能入队为止 void put(E e) throws InterruptedException; //入队，如果队列已满，阻塞线程直到能入队或超时、中断为止，入队成功返回true否则false boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException; //出队，如果队列为空，阻塞线程直到能出队为止 E take() throws InterruptedException; //出队，如果队列为空，阻塞线程直到能出队超时、中断为止，出队成功正常返回，否则返回null E poll(long timeout, TimeUnit unit) throws InterruptedException; //返回此队列理想情况下（在没有内存或资源限制的情况下）可以不阻塞地入队的数量，如果没有限制，则返回 Integer.MAX_VALUE int remainingCapacity(); boolean remove(Object o); public boolean contains(Object o); //一次性从BlockingQueue中获取所有可用的数据对象（还可以指定获取数据的个数） int drainTo(Collection c); int drainTo(Collection c, int maxElements); 比如现在有一个容量为3的阻塞队列，这个时候一个线程put向其添加了三个元素，第二个线程接着put向其添加三个元素，那么这个时候由于容量已满，会直接被阻塞，而这时第三个线程从队列中取走2个元素，线程二停止阻塞，先丢两个进去，还有一个还是进不去，所以说继续阻塞。 利用阻塞队列，我们可以轻松地实现消费者和生产者模式，还记得我们在JavaSE中的实战吗？ 所谓的生产者消费者模型，是通过一个容器来解决生产者和消费者的强耦合问题。通俗的讲，就是生产者在不断的生产，消费者也在不断的消费，可是消费者消费的产品是生产者生产的，这就必然存在一个中间容器，我们可以把这个容器想象成是一个货架，当货架空的时候，生产者要生产产品，此时消费者在等待生产者往货架上生产产品，而当货架有货物的时候，消费者可以从货架上拿走商品，生产者此时等待货架出现空位，进而补货，这样不断的循环。 通过多线程编程，来模拟一个餐厅的2个厨师和3个顾客，假设厨师炒出一个菜的时间为3秒，顾客吃掉菜品的时间为4秒，窗口上只能放一个菜。 我们来看看，使用阻塞队列如何实现，这里我们就使用ArrayBlockingQueue实现类： public class Main { public static void main(String[] args) throws InterruptedException { BlockingQueue queue = new ArrayBlockingQueue<>(1); Runnable supplier = () -> { while (true){ try { String name = Thread.currentThread().getName(); System.err.println(time()+\"生产者 \"+name+\" 正在准备餐品...\"); TimeUnit.SECONDS.sleep(3); System.err.println(time()+\"生产者 \"+name+\" 已出餐！\"); queue.put(new Object()); } catch (InterruptedException e) { e.printStackTrace(); break; } } }; Runnable consumer = () -> { while (true){ try { String name = Thread.currentThread().getName(); System.out.println(time()+\"消费者 \"+name+\" 正在等待出餐...\"); queue.take(); System.out.println(time()+\"消费者 \"+name+\" 取到了餐品。\"); TimeUnit.SECONDS.sleep(4); System.out.println(time()+\"消费者 \"+name+\" 已经将饭菜吃完了！\"); } catch (InterruptedException e) { e.printStackTrace(); break; } } }; for (int i = 0; i 可以看到，阻塞队列在多线程环境下的作用是非常明显的，算上ArrayBlockingQueue，一共有三种常用的阻塞队列： ArrayBlockingQueue：有界带缓冲阻塞队列（就是队列是有容量限制的，装满了肯定是不能再装的，只能阻塞，数组实现） SynchronousQueue：无缓冲阻塞队列（相当于没有容量的ArrayBlockingQueue，因此只有阻塞的情况） LinkedBlockingQueue：无界带缓冲阻塞队列（没有容量限制，也可以限制容量，也会阻塞，链表实现） 这里我们以ArrayBlockingQueue为例进行源码解读，我们先来看看构造方法： final ReentrantLock lock; private final Condition notEmpty; private final Condition notFull; public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity 接着我们来看put和offer方法是如何实现的： public boolean offer(E e) { checkNotNull(e); final ReentrantLock lock = this.lock; //可以看到这里也是使用了类里面的ReentrantLock进行加锁操作 lock.lock(); //保证同一时间只有一个线程进入 try { if (count == items.length) //直接看看队列是否已满，如果没满则直接入队，如果已满则返回false return false; else { enqueue(e); return true; } } finally { lock.unlock(); } } public void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; //同样的，需要进行加锁操作 lock.lockInterruptibly(); //注意这里是可以响应中断的 try { while (count == items.length) notFull.await(); //可以看到当队列已满时会直接挂起当前线程，在其他线程出队操作时会被唤醒 enqueue(e); //直到队列有空位才将线程入队 } finally { lock.unlock(); } } private E dequeue() { // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(\"unchecked\") E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); notFull.signal(); //出队操作会调用notFull的signal方法唤醒被挂起处于等待状态的线程 return x; } 接着我们来看出队操作： public E poll() { final ReentrantLock lock = this.lock; lock.lock(); //出队同样进行加锁操作，保证同一时间只能有一个线程执行 try { return (count == 0) ? null : dequeue(); //如果队列不为空则出队，否则返回null } finally { lock.unlock(); } } public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); //可以响应中断进行加锁 try { while (count == 0) notEmpty.await(); //和入队相反，也是一直等直到队列中有元素之后才可以出队，在入队时会唤醒此线程 return dequeue(); } finally { lock.unlock(); } } private void enqueue(E x) { // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; notEmpty.signal(); //对notEmpty的signal唤醒操作 } 可见，如果各位对锁的使用非常熟悉的话，那么在阅读这些源码的时候，就会非常轻松了。 接着我们来看一个比较特殊的队列SynchronousQueue，它没有任何容量，也就是说正常情况下出队必须和入队操作成对出现，我们先来看它的内部，可以看到内部有一个抽象类Transferer，它定义了一个transfer方法： abstract static class Transferer { /** * 可以是put也可以是take操作 * * @param e 如果不是空，即作为生产者，那么表示会将传入参数元素e交给消费者 * 如果为空，即作为消费者，那么表示会从生产者那里得到一个元素e并返回 * @param 是否可以超时 * @param 超时时间 * @return 不为空就是从生产者那里返回的，为空表示要么被中断要么超时。 */ abstract E transfer(E e, boolean timed, long nanos); } 乍一看，有点迷惑，难不成还要靠这玩意去实现put和take操作吗？实际上它是直接以生产者消费者模式进行的，由于不需要依靠任何容器结构来暂时存放数据，所以我们可以直接通过transfer方法来对生产者和消费者之间的数据进行传递。 比如一个线程put一个新的元素进入，这时如果没有其他线程调用take方法获取元素，那么会持续被阻塞，直到有线程取出元素，而transfer正是需要等生产者消费者双方都到齐了才能进行交接工作，单独只有其中一方都需要进行等待。 public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); //判空 if (transferer.transfer(e, false, 0) == null) { //直接使用transfer方法进行数据传递 Thread.interrupted(); //为空表示要么被中断要么超时 throw new InterruptedException(); } } 它在公平和非公平模式下，有两个实现，这里我们来看公平模式下的SynchronousQueue是如何实现的： static final class TransferQueue extends Transferer { //头结点（头结点仅作为头结点，后续节点才是真正等待的线程节点） transient volatile QNode head; //尾结点 transient volatile QNode tail; /** 节点有生产者和消费者角色之分 */ static final class QNode { volatile QNode next; // 后继节点 volatile Object item; // 存储的元素 volatile Thread waiter; // 处于等待的线程，和之前的AQS一样的思路，每个线程等待的时候都会被封装为节点 final boolean isData; // 是生产者节点还是消费者节点 公平模式下，Transferer的实现是TransferQueue，是以先进先出的规则的进行的，内部有一个QNode类来保存等待的线程。 好了，我们直接上transfer()方法的实现（这里再次提醒各位，多线程环境下的源码分析和单线程的分析不同，我们需要时刻关注当前代码块的加锁状态，如果没有加锁，一定要具有多线程可能会同时运行的意识，这个意识在以后你自己处理多线程问题伴随着你，才能保证你的思路在多线程环境下是正确的）： E transfer(E e, boolean timed, long nanos) { //注意这里面没加锁，肯定会多个线程之间竞争 QNode s = null; boolean isData = (e != null); //e为空表示消费者，不为空表示生产者 for (;;) { QNode t = tail; QNode h = head; if (t == null || h == null) // 头结点尾结点任意为空（但是在构造的时候就已经不是空了） continue; // 自旋 if (h == t || t.isData == isData) { // 头结点等于尾结点表示队列中只有一个头结点，肯定是空，或者尾结点角色和当前节点一样，这两种情况下，都需要进行入队操作 QNode tn = t.next; if (t != tail) // 如果这段时间内t被其他线程修改了，如果是就进下一轮循环重新来 continue; if (tn != null) { // 继续校验是否为队尾，如果tn不为null，那肯定是其他线程改了队尾，可以进下一轮循环重新来了 advanceTail(t, tn); // CAS将新的队尾节点设置为tn，成不成功都无所谓，反正这一轮肯定没戏了 continue; } if (timed && nanos 所以，总结为以下流程： 对于非公平模式下的SynchronousQueue，则是采用的栈结构来存储等待节点，但是思路也是与这里的一致，需要等待并进行匹配操作，各位如果感兴趣可以继续了解一下非公平模式下的SynchronousQueue实现。 在JDK7的时候，基于SynchronousQueue产生了一个更强大的TransferQueue，它保留了SynchronousQueue的匹配交接机制，并且与等待队列进行融合。 我们知道，SynchronousQueue并没有使用锁，而是采用CAS操作保证生产者与消费者的协调，但是它没有容量，而LinkedBlockingQueue虽然是有容量且无界的，但是内部基本都是基于锁实现的，性能并不是很好，这时，我们就可以将它们各自的优点单独拿出来，揉在一起，就成了性能更高的LinkedTransferQueue public static void main(String[] args) throws InterruptedException { LinkedTransferQueue queue = new LinkedTransferQueue<>(); queue.put(\"1\"); //插入时，会先检查是否有其他线程等待获取，如果是，直接进行交接，否则插入到存储队列中 queue.put(\"2\"); //不会像SynchronousQueue那样必须等一个匹配的才可以 queue.forEach(System.out::println); //直接打印所有的元素，这在SynchronousQueue下只能是空，因为单独的入队或出队操作都会被阻塞 } 相比 SynchronousQueue ，它多了一个可以存储的队列，我们依然可以像阻塞队列那样获取队列中所有元素的值，简单来说，LinkedTransferQueue其实就是一个多了存储队列的SynchronousQueue。 接着我们来了解一些其他的队列： PriorityBlockingQueue - 是一个支持优先级的阻塞队列，元素的获取顺序按优先级决定。 DelayQueue - 它能够实现延迟获取元素，同样支持优先级。 我们先来看优先级阻塞队列： public static void main(String[] args) throws InterruptedException { PriorityBlockingQueue queue = new PriorityBlockingQueue<>(10, Integer::compare); //可以指定初始容量（可扩容）和优先级比较规则，这里我们使用升序 queue.add(3); queue.add(1); queue.add(2); System.out.println(queue); //注意保存顺序并不会按照优先级排列，所以可以看到结果并不是排序后的结果 System.out.println(queue.poll()); //但是出队顺序一定是按照优先级进行的 System.out.println(queue.poll()); System.out.println(queue.poll()); } 我们的重点是DelayQueue，它能实现延时出队，也就是说当一个元素插入后，如果没有超过一定时间，那么是无法让此元素出队的。 public class DelayQueue extends AbstractQueue implements BlockingQueue { 可以看到此类只接受Delayed的实现类作为元素： public interface Delayed extends Comparable { //注意这里继承了Comparable，它支持优先级 //获取剩余等待时间，正数表示还需要进行等待，0或负数表示等待结束 long getDelay(TimeUnit unit); } 这里我们手动实现一个： private static class Test implements Delayed { private final long time; //延迟时间，这里以毫秒为单位 private final int priority; private final long startTime; private final String data; private Test(long time, int priority, String data) { this.time = TimeUnit.SECONDS.toMillis(time); //秒转换为毫秒 this.priority = priority; this.startTime = System.currentTimeMillis(); //这里我们以毫秒为单位 this.data = data; } @Override public long getDelay(TimeUnit unit) { long leftTime = time - (System.currentTimeMillis() - startTime); //计算剩余时间 = 设定时间 - 已度过时间(= 当前时间 - 开始时间) return unit.convert(leftTime, TimeUnit.MILLISECONDS); //注意进行单位转换，单位由队列指定（默认是纳秒单位） } @Override public int compareTo(Delayed o) { if(o instanceof Test) return priority - ((Test) o).priority; //优先级越小越优先 return 0; } @Override public String toString() { return data; } } 接着我们在主方法中尝试使用： public static void main(String[] args) throws InterruptedException { DelayQueue queue = new DelayQueue<>(); queue.add(new Test(1, 2, \"2号\")); //1秒钟延时 queue.add(new Test(3, 1, \"1号\")); //1秒钟延时，优先级最高 System.out.println(queue.take()); //注意出队顺序是依照优先级来的，即使一个元素已经可以出队了，依然需要等待优先级更高的元素到期 System.out.println(queue.take()); } 我们来研究一下DelayQueue是如何实现的，首先来看add()方法： public boolean add(E e) { return offer(e); } public boolean offer(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { q.offer(e); //注意这里是向内部维护的一个优先级队列添加元素，并不是DelayQueue本身存储元素 if (q.peek() == e) { //如果入队后队首就是当前元素，那么直接进行一次唤醒操作（因为有可能之前就有其他线程等着take了） leader = null; available.signal(); } return true; } finally { lock.unlock(); } } public void put(E e) { offer(e); } 可以看到无论是哪种入队操作，都会加锁进行，属于常规操作。我们接着来看take()方法： public E take() throws InterruptedException { final ReentrantLock lock = this.lock; //出队也要先加锁，基操 lock.lockInterruptibly(); try { for (;;) { //无限循环，常规操作 E first = q.peek(); //获取队首元素 if (first == null) //如果为空那肯定队列为空，先等着吧，等有元素进来 available.await(); else { long delay = first.getDelay(NANOSECONDS); //获取延迟，这里传入的时间单位是纳秒 if (delay 到此，有关并发容器的讲解就到这里。 下一章我们会继续讲解线程池以及并发工具类。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/JUC/JUC（二）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/JUC/JUC（二）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/JUC/JUC（三）.html":{"url":"Java/JUC/JUC（三）.html","title":"JUC（三）","keywords":"","body":"并发编程进阶 欢迎来到JUC学习的最后一章，王炸当然是放在最后了。 线程池 在我们的程序中，多多少少都会用到多线程技术，而我们以往都是使用Thread类来创建一个新的线程： public static void main(String[] args) { Thread t = new Thread(() -> System.out.println(\"Hello World!\")); t.start(); } 利用多线程，我们的程序可以更加合理地使用CPU多核心资源，在同一时间完成更多的工作。但是，如果我们的程序频繁地创建线程，由于线程的创建和销毁也需要占用系统资源，因此这样会降低我们整个程序的性能，那么怎么做，才能更高效地使用多线程呢？ 我们其实可以将已创建的线程复用，利用池化技术，就像数据库连接池一样，我们也可以创建很多个线程，然后反复地使用这些线程，而不对它们进行销毁。 虽然听起来这个想法比较新颖，但是实际上线程池早已利用到各个地方，比如我们的Tomcat服务器，要在同一时间接受和处理大量的请求，那么就必须要在短时间内创建大量的线程，结束后又进行销毁，这显然会导致很大的开销，因此这种情况下使用线程池显然是更好的解决方案。 由于线程池可以反复利用已有线程执行多线程操作，所以它一般是有容量限制的，当所有的线程都处于工作状态时，那么新的多线程请求会被阻塞，直到有一个线程空闲出来为止，实际上这里就会用到我们之前讲解的阻塞队列。 所以我们可以暂时得到下面一个样子： 当然，JUC提供的线程池肯定没有这么简单，接下来就让我们深入进行了解。 线程池的使用 我们可以直接创建一个新的线程池对象，它已经提前帮助我们实现好了线程的调度机制，我们先来看它的构造方法： public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize 参数稍微有一点多，这里我们依次进行讲解： corePoolSize：核心线程池大小，我们每向线程池提交一个多线程任务时，都会创建一个新的核心线程，无论是否存在其他空闲线程，直到到达核心线程池大小为止，之后会尝试复用线程资源。当然也可以在一开始就全部初始化好，调用prestartAllCoreThreads()即可。 maximumPoolSize：最大线程池大小，当目前线程池中所有的线程都处于运行状态，并且等待队列已满，那么就会直接尝试继续创建新的非核心线程运行，但是不能超过最大线程池大小。 keepAliveTime：线程最大空闲时间，当一个非核心线程空闲超过一定时间，会自动销毁。 unit：线程最大空闲时间的时间单位 workQueue：线程等待队列，当线程池中核心线程数已满时，就会将任务暂时存到等待队列中，直到有线程资源可用为止，这里可以使用我们上一章学到的阻塞队列。 threadFactory：线程创建工厂，我们可以干涉线程池中线程的创建过程，进行自定义。 handler：拒绝策略，当等待队列和线程池都没有空间了，真的不能再来新的任务时，来了个新的多线程任务，那么只能拒绝了，这时就会根据当前设定的拒绝策略进行处理。 最为重要的就是线程池大小的限定了，这个也是很有学问的，合理地分配大小会使得线程池的执行效率事半功倍： 首先我们可以分析一下，线程池执行任务的特性，是CPU 密集型还是 IO 密集型 CPU密集型：主要是执行计算任务，响应时间很快，CPU一直在运行，这种任务CPU的利用率很高，那么线程数应该是根据 CPU 核心数来决定，CPU 核心数 = 最大同时执行线程数，以 i5-9400F 处理器为例，CPU 核心数为 6，那么最多就能同时执行 6 个线程。 IO密集型：主要是进行 IO 操作，因为执行 IO 操作的时间比较较长，比如从硬盘读取数据之类的，CPU就得等着IO操作，很容易出现空闲状态，导致 CPU 的利用率不高，这种情况下可以适当增加线程池的大小，让更多的线程可以一起进行IO操作，一般可以配置为CPU核心数的2倍。 这里我们手动创建一个新的线程池看看效果： public static void main(String[] args) throws InterruptedException { ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, //2个核心线程，最大线程数为4个 3, TimeUnit.SECONDS, //最大空闲时间为3秒钟 new ArrayBlockingQueue<>(2)); //这里使用容量为2的ArrayBlockingQueue队列 for (int i = 0; i { try { System.out.println(Thread.currentThread().getName()+\" 开始执行！（\"+ finalI); TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName()+\" 已结束！（\"+finalI); } catch (InterruptedException e) { e.printStackTrace(); } }); } TimeUnit.SECONDS.sleep(1); //看看当前线程池中的线程数量 System.out.println(\"线程池中线程数量：\"+executor.getPoolSize()); TimeUnit.SECONDS.sleep(5); //等到超过空闲时间 System.out.println(\"线程池中线程数量：\"+executor.getPoolSize()); executor.shutdownNow(); //使用完线程池记得关闭，不然程序不会结束，它会取消所有等待中的任务以及试图中断正在执行的任务，关闭后，无法再提交任务，一律拒绝 //executor.shutdown(); 同样可以关闭，但是会执行完等待队列中的任务再关闭 } 这里我们创建了一个核心容量为2，最大容量为4，等待队列长度为2，空闲时间为3秒的线程池，现在我们向其中执行6个任务，每个任务都会进行1秒钟休眠，那么当线程池中2个核心线程都被占用时，还有4个线程就只能进入到等待队列中了，但是等待队列中只有2个容量，这时紧接着的2个任务，线程池将直接尝试创建线程，由于不大于最大容量，因此可以成功创建。最后所有线程完成之后，在等待5秒后，超过了线程池的最大空闲时间，非核心线程被回收了，所以线程池中只有2个线程存在。 那么要是等待队列设定为没有容量的SynchronousQueue呢，这个时候会发生什么？ pool-1-thread-1 开始执行！（0 pool-1-thread-4 开始执行！（3 pool-1-thread-3 开始执行！（2 pool-1-thread-2 开始执行！（1 Exception in thread \"main\" java.util.concurrent.RejectedExecutionException: Task com.test.Main$$Lambda$1/1283928880@682a0b20 rejected from java.util.concurrent.ThreadPoolExecutor@3d075dc0[Running, pool size = 4, active threads = 4, queued tasks = 0, completed tasks = 0] at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063) at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379) at com.test.Main.main(Main.java:15) 可以看到，前4个任务都可以正常执行，但是到第五个任务时，直接抛出了异常，这其实就是因为等待队列的容量为0，相当于没有容量，那么这个时候，就只能拒绝任务了，拒绝的操作会根据拒绝策略决定。 线程池的拒绝策略默认有以下几个： AbortPolicy(默认)：像上面一样，直接抛异常。 CallerRunsPolicy：直接让提交任务的线程运行这个任务，比如在主线程向线程池提交了任务，那么就直接由主线程执行。 DiscardOldestPolicy：丢弃队列中最近的一个任务，替换为当前任务。 DiscardPolicy：什么也不用做。 这里我们进行一下测试： public static void main(String[] args) throws InterruptedException { ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, 3, TimeUnit.SECONDS, new SynchronousQueue<>(), new ThreadPoolExecutor.CallerRunsPolicy()); //使用另一个构造方法，最后一个参数传入策略，比如这里我们使用了CallerRunsPolicy策略 CallerRunsPolicy策略是谁提交的谁自己执行，所以： pool-1-thread-1 开始执行！（0 pool-1-thread-2 开始执行！（1 main 开始执行！（4 pool-1-thread-4 开始执行！（3 pool-1-thread-3 开始执行！（2 pool-1-thread-3 已结束！（2 pool-1-thread-2 已结束！（1 pool-1-thread-1 已结束！（0 main 已结束！（4 pool-1-thread-4 已结束！（3 pool-1-thread-1 开始执行！（5 pool-1-thread-1 已结束！（5 线程池中线程数量：4 线程池中线程数量：2 可以看到，当队列塞不下时，直接在主线程运行任务，运行完之后再继续向下执行。 我们吧策略修改为DiscardOldestPolicy试试看： public static void main(String[] args) throws InterruptedException { ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, 3, TimeUnit.SECONDS, new ArrayBlockingQueue<>(1), //这里设置为ArrayBlockingQueue，长度为1 new ThreadPoolExecutor.DiscardOldestPolicy()); 它会移除等待队列中的最近的一个任务，所以可以看到有一个任务实际上是被抛弃了的： pool-1-thread-1 开始执行！（0 pool-1-thread-4 开始执行！（4 pool-1-thread-3 开始执行！（3 pool-1-thread-2 开始执行！（1 pool-1-thread-1 已结束！（0 pool-1-thread-4 已结束！（4 pool-1-thread-1 开始执行！（5 线程池中线程数量：4 pool-1-thread-3 已结束！（3 pool-1-thread-2 已结束！（1 pool-1-thread-1 已结束！（5 线程池中线程数量：2 比较有意思的是，如果选择没有容量的SynchronousQueue作为等待队列会爆栈： pool-1-thread-1 开始执行！（0 pool-1-thread-3 开始执行！（2 pool-1-thread-2 开始执行！（1 pool-1-thread-4 开始执行！（3 Exception in thread \"main\" java.lang.StackOverflowError at java.util.concurrent.SynchronousQueue.offer(SynchronousQueue.java:912) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1371) ... pool-1-thread-1 已结束！（0 pool-1-thread-2 已结束！（1 pool-1-thread-4 已结束！（3 pool-1-thread-3 已结束！（2 这是为什么呢？我们来看看这个拒绝策略的源码： public static class DiscardOldestPolicy implements RejectedExecutionHandler { public DiscardOldestPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { e.getQueue().poll(); //会先执行一次出队操作，但是这对于SynchronousQueue来说毫无意义 e.execute(r); //这里会再次调用execute方法 } } } 可以看到，它会先对等待队列进行出队操作，但是由于SynchronousQueue压根没容量，所有这个操作毫无意义，然后就会递归执行execute方法，而进入之后，又发现没有容量不能插入，于是又重复上面的操作，这样就会无限的递归下去，最后就爆栈了。 当然，除了使用官方提供的4种策略之外，我们还可以使用自定义的策略： public static void main(String[] args) throws InterruptedException { ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, 3, TimeUnit.SECONDS, new SynchronousQueue<>(), (r, executor1) -> { //比如这里我们也来实现一个就在当前线程执行的策略 System.out.println(\"哎呀，线程池和等待队列都满了，你自己耗子尾汁吧\"); r.run(); //直接运行 }); 接着我们来看线程创建工厂，我们可以自己决定如何创建新的线程： public static void main(String[] args) throws InterruptedException { ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, 3, TimeUnit.SECONDS, new SynchronousQueue<>(), new ThreadFactory() { int counter = 0; @Override public Thread newThread(Runnable r) { return new Thread(r, \"我的自定义线程-\"+counter++); } }); for (int i = 0; i System.out.println(Thread.currentThread().getName()+\" 开始执行！\")); } } 这里传入的Runnable对象就是我们提交的任务，可以看到需要我们返回一个Thread对象，其实就是线程池创建线程的过程，而如何创建这个对象，以及它的一些属性，就都由我们来决定。 各位有没有想过这样一个情况，如果我们的任务在运行过程中出现异常了，那么是不是会导致线程池中的线程被销毁呢？ public static void main(String[] args) throws InterruptedException { ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 1, //最大容量和核心容量锁定为1 0, TimeUnit.MILLISECONDS, new LinkedBlockingDeque<>()); executor.execute(() -> { System.out.println(Thread.currentThread().getName()); throw new RuntimeException(\"我是异常！\"); }); TimeUnit.SECONDS.sleep(1); executor.execute(() -> { System.out.println(Thread.currentThread().getName()); }); } 可以看到，出现异常之后，再次提交新的任务，执行的线程是一个新的线程了。 除了我们自己创建线程池之外，官方也提供了很多的线程池定义，我们可以使用Executors工具类来快速创建线程池： public static void main(String[] args) throws InterruptedException { ExecutorService executor = Executors.newFixedThreadPool(2); //直接创建一个固定容量的线程池 } 可以看到它的内部实现为： public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()); } 这里直接将最大线程和核心线程数量设定为一样的，并且等待时间为0，因为压根不需要，并且采用的是一个无界的LinkedBlockingQueue作为等待队列。 使用newSingleThreadExecutor来创建只有一个线程的线程池： public static void main(String[] args) throws InterruptedException { ExecutorService executor = Executors.newSingleThreadExecutor(); //创建一个只有一个线程的线程池 } 原理如下： public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue())); } 可以看到这里并不是直接创建的一个ThreadPoolExecutor对象，而是套了一层FinalizableDelegatedExecutorService，那么这个又是什么东西呢？ static class FinalizableDelegatedExecutorService extends DelegatedExecutorService { FinalizableDelegatedExecutorService(ExecutorService executor) { super(executor); } protected void finalize() { //在GC时，会执行finalize方法，此方法中会关闭掉线程池，释放资源 super.shutdown(); } } static class DelegatedExecutorService extends AbstractExecutorService { private final ExecutorService e; //被委派对象 DelegatedExecutorService(ExecutorService executor) { e = executor; } //实际上所以的操作都是让委派对象执行的，有点像代理 public void execute(Runnable command) { e.execute(command); } public void shutdown() { e.shutdown(); } public List shutdownNow() { return e.shutdownNow(); } 所以，下面两种写法的区别在于： public static void main(String[] args) throws InterruptedException { ExecutorService executor1 = Executors.newSingleThreadExecutor(); ExecutorService executor2 = Executors.newFixedThreadPool(1); } 前者实际上是被代理了，我们没办法直接修改前者的相关属性，显然使用前者创建只有一个线程的线程池更加专业和安全（可以防止属性被修改）一些。 最后我们来看newCachedThreadPool方法： public static void main(String[] args) throws InterruptedException { ExecutorService executor = Executors.newCachedThreadPool(); //它是一个会根据需要无限制创建新线程的线程池 } 我们来看看它的实现： public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue()); } 可以看到，核心线程数为0，那么也就是说所有的线程都是非核心线程，也就是说线程空闲时间超过1秒钟，一律销毁。但是它的最大容量是Integer.MAX_VALUE，也就是说，它可以无限制地增长下去，所以这玩意一定要慎用。 执行带返回值的任务 一个多线程任务不仅仅可以是void无返回值任务，比如我们现在需要执行一个任务，但是我们需要在任务执行之后得到一个结果，这个时候怎么办呢？ 这里我们就可以使用到Future了，它可以返回任务的计算结果，我们可以通过它来获取任务的结果以及任务当前是否完成： public static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executor = Executors.newSingleThreadExecutor(); //直接用Executors创建，方便就完事了 Future future = executor.submit(() -> \"我是字符串!\"); //使用submit提交任务，会返回一个Future对象，注意提交的对象可以是Runable也可以是Callable，这里使用的是Callable能够自定义返回值 System.out.println(future.get()); //如果任务未完成，get会被阻塞，任务完成返回Callable执行结果返回值 executor.shutdown(); } 当然结果也可以一开始就定义好，然后等待Runnable执行完之后再返回： public static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executor = Executors.newSingleThreadExecutor(); Future future = executor.submit(() -> { try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } }, \"我是字符串！\"); System.out.println(future.get()); executor.shutdown(); } 还可以通过传入FutureTask对象的方式： public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService service = Executors.newSingleThreadExecutor(); FutureTask task = new FutureTask<>(() -> \"我是字符串！\"); service.submit(task); System.out.println(task.get()); executor.shutdown(); } 我们可以还通过Future对象获取当前任务的一些状态： public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService executor = Executors.newSingleThreadExecutor(); Future future = executor.submit(() -> \"都看到这里了，不赏UP主一个一键三连吗？\"); System.out.println(future.get()); System.out.println(\"任务是否执行完成：\"+future.isDone()); System.out.println(\"任务是否被取消：\"+future.isCancelled()); executor.shutdown(); } 我们来试试看在任务执行途中取消任务： public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService executor = Executors.newSingleThreadExecutor(); Future future = executor.submit(() -> { TimeUnit.SECONDS.sleep(10); return \"这次一定！\"; }); System.out.println(future.cancel(true)); System.out.println(future.isCancelled()); executor.shutdown(); } 执行定时任务 既然线程池怎么强大，那么线程池能不能执行定时任务呢？我们之前如果需要执行一个定时任务，那么肯定会用到Timer和TimerTask，但是它只会创建一个线程处理我们的定时任务，无法实现多线程调度，并且它无法处理异常情况一旦抛出未捕获异常那么会直接终止，显然我们需要一个更加强大的定时器。 JDK5之后，我们可以使用ScheduledThreadPoolExecutor来提交定时任务，它继承自ThreadPoolExecutor，并且所有的构造方法都必须要求最大线程池容量为Integer.MAX_VALUE，并且都是采用的DelayedWorkQueue作为等待队列。 public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); } public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory); } public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), handler); } public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler); } 我们来测试一下它的方法，这个方法可以提交一个延时任务，只有到达指定时间之后才会开始： public static void main(String[] args) throws ExecutionException, InterruptedException { //直接设定核心线程数为1 ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(1); //这里我们计划在3秒后执行 executor.schedule(() -> System.out.println(\"HelloWorld!\"), 3, TimeUnit.SECONDS); executor.shutdown(); } 我们也可以像之前一样，传入一个Callable对象，用于接收返回值： public static void main(String[] args) throws ExecutionException, InterruptedException { ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(2); //这里使用ScheduledFuture ScheduledFuture future = executor.schedule(() -> \"????\", 3, TimeUnit.SECONDS); System.out.println(\"任务剩余等待时间：\"+future.getDelay(TimeUnit.MILLISECONDS) / 1000.0 + \"s\"); System.out.println(\"任务执行结果：\"+future.get()); executor.shutdown(); } 可以看到schedule方法返回了一个ScheduledFuture对象，和Future一样，它也支持返回值的获取、包括对任务的取消同时还支持获取剩余等待时间。 那么如果我们希望按照一定的频率不断执行任务呢？ public static void main(String[] args) throws ExecutionException, InterruptedException { ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(2); executor.scheduleAtFixedRate(() -> System.out.println(\"Hello World!\"), 3, 1, TimeUnit.SECONDS); //三秒钟延迟开始，之后每隔一秒钟执行一次 } Executors也为我们预置了newScheduledThreadPool方法用于创建线程池： public static void main(String[] args) throws ExecutionException, InterruptedException { ScheduledExecutorService service = Executors.newScheduledThreadPool(1); service.schedule(() -> System.out.println(\"Hello World!\"), 1, TimeUnit.SECONDS); } 线程池实现原理 前面我们了解了线程池的使用，那么接着我们来看看它的详细实现过程，结构稍微有点复杂，坐稳，发车了。 这里需要首先介绍一下ctl变量： //这个变量比较关键，用到了原子AtomicInteger，用于同时保存线程池运行状态和线程数量（使用原子类是为了保证原子性） //它是通过拆分32个bit位来保存数据的，前3位保存状态，后29位保存工作线程数量（那要是工作线程数量29位装不下不就GG？） private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; //29位，线程数量位 private static final int CAPACITY = (1 我们先从最简单的入手，看看在调用execute方法之后，线程池会做些什么： //这个就是我们指定的阻塞队列 private final BlockingQueue workQueue; //再次提醒，这里没加锁！！该有什么意识不用我说了吧，所以说ctl才会使用原子类。 public void execute(Runnable command) { if (command == null) throw new NullPointerException(); //如果任务为null，那执行个寂寞，所以说直接空指针 int c = ctl.get(); //获取ctl的值，一会要读取信息的 if (workerCountOf(c) 是不是感觉思路还挺清晰的，我们接着来看addWorker是怎么创建和执行任务的，又是一大堆代码： private boolean addWorker(Runnable firstTask, boolean core) { //这里给最外层循环打了个标签，方便一会的跳转操作 retry: for (;;) { //无限循环，老套路了，注意这里全程没加锁 int c = ctl.get(); //获取ctl值 int rs = runStateOf(c); //解析当前的运行状态 // Check if queue empty only if necessary. if (rs >= SHUTDOWN && //判断线程池是否不是处于运行状态 ! (rs == SHUTDOWN && //如果不是运行状态，判断线程是SHUTDOWN状态并、任务不为null、等待队列不为空，只要有其中一者不满足，直接返回false，添加失败 firstTask == null && ! workQueue.isEmpty())) return false; for (;;) { //内层又一轮无限循环，这个循环是为了将线程计数增加，然后才可以真正地添加一个新的线程 int wc = workerCountOf(c); //解析当前的工作线程数量 if (wc >= CAPACITY || wc >= (core ? corePoolSize : maximumPoolSize)) //判断一下还装得下不，如果装得下，看看是核心线程还是非核心线程，如果是核心线程，不能大于核心线程数的限制，如果是非核心线程，不能大于最大线程数限制 return false; if (compareAndIncrementWorkerCount(c)) //CAS自增线程计数，如果增加成功，任务完成，直接跳出继续 break retry; //注意这里要直接跳出最外层循环，所以用到了标签（类似于goto语句） c = ctl.get(); // 如果CAS失败，更新一下c的值 if (runStateOf(c) != rs) //如果CAS失败的原因是因为线程池状态和一开始的不一样了，那么就重新从外层循环再来一次 continue retry; //注意这里要直接从最外层循环继续，所以用到了标签（类似于goto语句） // 如果是其他原因导致的CAS失败，那只可能是其他线程同时在自增，所以重新再来一次内层循环 } } //好了，线程计数自增也完了，接着就是添加新的工作线程了 boolean workerStarted = false; //工作线程是否已启动 boolean workerAdded = false; //工作线程是否已添加 Worker w = null; //暂时理解为工作线程，别急，我们之后会解读Worker类 try { w = new Worker(firstTask); //创建新的工作线程，传入我们提交的任务 final Thread t = w.thread; //拿到工作线程中封装的Thread对象 if (t != null) { //如果线程不为null，那就可以安排干活了 final ReentrantLock mainLock = this.mainLock; //又是ReentrantLock加锁环节，这里开始就是只有一个线程能进入了 mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); //获取当前线程的运行状态 if (rs largestPoolSize) //这里是记录线程池运行以来，历史上的最多线程数 largestPoolSize = s; workerAdded = true; //工作线程已添加 } } finally { mainLock.unlock(); //解锁 } if (workerAdded) { t.start(); //启动线程 workerStarted = true; //工作线程已启动 } } } finally { if (! workerStarted) //如果线程在上面的启动过程中失败了 addWorkerFailed(w); //将w移出workers并将计数器-1，最后如果线程池是终止状态，会尝试加速终止线程池 } return workerStarted; //返回是否成功 } 接着我们来看Worker类是如何实现的，它继承自AbstractQueuedSynchronizer，时隔两章，居然再次遇到AQS，那也就是说，它本身就是一把锁： private final class Worker extends AbstractQueuedSynchronizer implements Runnable { //用来干活的线程 final Thread thread; //要执行的第一个任务，构造时就确定了的 Runnable firstTask; //干活数量计数器，也就是这个线程完成了多少个任务 volatile long completedTasks; Worker(Runnable firstTask) { setState(-1); // 执行Task之前不让中断，将AQS的state设定为-1 this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); //通过预定义或是我们自定义的线程工厂创建线程 } public void run() { runWorker(this); //真正开始干活，包括当前活干完了又要等新的活来，就从这里开始，一会详细介绍 } //0就是没加锁，1就是已加锁 protected boolean isHeldExclusively() { return getState() != 0; } ... } 最后我们来看看一个Worker到底是怎么在进行任务的： final void runWorker(Worker w) { Thread wt = Thread.currentThread(); //获取当前线程 Runnable task = w.firstTask; //取出要执行的任务 w.firstTask = null; //然后把Worker中的任务设定为null w.unlock(); // 因为一开始为-1，这里是通过unlock操作将其修改回0，只有state大于等于0才能响应中断 boolean completedAbruptly = true; try { //只要任务不为null，或是任务为空但是可以从等待队列中取出任务不为空，那么就开始执行这个任务，注意这里是无限循环，也就是说如果当前没有任务了，那么会在getTask方法中卡住，因为要从阻塞队列中等着取任务 while (task != null || (task = getTask()) != null) { w.lock(); //对当前Worker加锁，这里其实并不是防其他线程，而是在shutdown时保护此任务的运行 //由于线程池在STOP状态及以上会禁止新线程加入并且中断正在进行的线程 if ((runStateAtLeast(ctl.get(), STOP) || //只要线程池是STOP及以上的状态，那肯定是不能开始新任务的 (Thread.interrupted() && //线程是否已经被打上中断标记并且线程一定是STOP及以上 runStateAtLeast(ctl.get(), STOP))) && !wt.isInterrupted()) //再次确保线程被没有打上中断标记 wt.interrupt(); //打中断标记 try { beforeExecute(wt, task); //开始之前的准备工作，这里暂时没有实现 Throwable thrown = null; try { task.run(); //OK，开始执行任务 } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); //执行之后的工作，也没实现 } } finally { task = null; //任务已完成，不需要了 w.completedTasks++; //任务完成数++ w.unlock(); //解锁 } } completedAbruptly = false; } finally { //如果能走到这一步，那说明上面的循环肯定是跳出了，也就是说这个Worker可以丢弃了 //所以这里会直接将 Worker 从 workers 里删除掉 processWorkerExit(w, completedAbruptly); } } 那么它是怎么从阻塞队列里面获取任务的呢： private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (;;) { //无限循环获取 int c = ctl.get(); //获取ctl int rs = runStateOf(c); //解析线程池运行状态 // Check if queue empty only if necessary. if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) { //判断是不是没有必要再执行等待队列中的任务了，也就是处于关闭线程池的状态了 decrementWorkerCount(); //直接减少一个工作线程数量 return null; //返回null，这样上面的runWorker就直接结束了，下同 } int wc = workerCountOf(c); //如果线程池运行正常，那就获取当前的工作线程数量 // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc > corePoolSize; //如果线程数大于核心线程数或是允许核心线程等待超时，那么就标记为可超时的 //超时或maximumPoolSize在运行期间被修改了，并且线程数大于1或等待队列为空，那也是不能获取到任务的 if ((wc > maximumPoolSize || (timed && timedOut)) && (wc > 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) //如果CAS减少工作线程成功 return null; //返回null continue; //否则开下一轮循环 } try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : //如果可超时，那么最多等到超时时间 workQueue.take(); //如果不可超时，那就一直等着拿任务 if (r != null) //如果成功拿到任务，ok，返回 return r; timedOut = true; //否则就是超时了，下一轮循环将直接返回null } catch (InterruptedException retry) { timedOut = false; } //开下一轮循环吧 } } 虽然我们的源码解读越来越深，但是只要各位的思路不断，依然是可以继续往下看的。到此，有关execute()方法的源码解读，就先到这里。 接着我们来看当线程池关闭时会做什么事情： //普通的shutdown会继续将等待队列中的线程执行完成后再关闭线程池 public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { //判断是否有权限终止 checkShutdownAccess(); //CAS将线程池运行状态改为SHUTDOWN状态，还算比较温柔，详细过程看下面 advanceRunState(SHUTDOWN); //让闲着的线程（比如正在等新的任务）中断，但是并不会影响正在运行的线程，详细过程请看下面 interruptIdleWorkers(); onShutdown(); //给ScheduledThreadPoolExecutor提供的钩子方法，就是等ScheduledThreadPoolExecutor去实现的，当前类没有实现 } finally { mainLock.unlock(); } tryTerminate(); //最后尝试终止线程池 } private void advanceRunState(int targetState) { for (;;) { int c = ctl.get(); //获取ctl if (runStateAtLeast(c, targetState) || //是否大于等于指定的状态 ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c)))) //CAS设置ctl的值 break; //任意一个条件OK就可以结束了 } } private void interruptIdleWorkers(boolean onlyOne) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) { Thread t = w.thread; //拿到Worker中的线程 if (!t.isInterrupted() && w.tryLock()) { //先判断一下线程是不是没有被中断然后尝试加锁，但是通过前面的runWorker()源代码我们得知，开始之后是让Worker加了锁的，所以如果线程还在执行任务，那么这里肯定会false try { t.interrupt(); //如果走到这里，那么说明线程肯定是一个闲着的线程，直接给中断吧 } catch (SecurityException ignore) { } finally { w.unlock(); //解锁 } } if (onlyOne) //如果只针对一个Worker，那么就结束循环 break; } } finally { mainLock.unlock(); } } 而shutdownNow()方法也差不多，但是这里会更直接一些： //shutdownNow开始后，不仅不允许新的任务到来，也不会再执行等待队列的线程，而且会终止正在执行的线程 public List shutdownNow() { List tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); //这里就是直接设定为STOP状态了，不再像shutdown那么温柔 advanceRunState(STOP); //直接中断所有工作线程，详细过程看下面 interruptWorkers(); //取出仍处于阻塞队列中的线程 tasks = drainQueue(); } finally { mainLock.unlock(); } tryTerminate(); return tasks; //最后返回还没开始的任务 } private void interruptWorkers() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) //遍历所有Worker w.interruptIfStarted(); //无差别对待，一律加中断标记 } finally { mainLock.unlock(); } } 最后的最后，我们再来看看tryTerminate()是怎么完完全全终止掉一个线程池的： final void tryTerminate() { for (;;) { //无限循环 int c = ctl.get(); //上来先获取一下ctl值 //只要是正在运行 或是 线程池基本上关闭了 或是 处于SHUTDOWN状态且工作队列不为空，那么这时还不能关闭线程池，返回 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty())) return; //走到这里，要么处于SHUTDOWN状态且等待队列为空或是STOP状态 if (workerCountOf(c) != 0) { // 如果工作线程数不是0，这里也会中断空闲状态下的线程 interruptIdleWorkers(ONLY_ONE); //这里最多只中断一个空闲线程，然后返回 return; } //走到这里，工作线程也为空了，可以终止线程池了 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { //先CAS将状态设定为TIDYING表示基本终止，正在做最后的操作 try { terminated(); //终止，暂时没有实现 } finally { ctl.set(ctlOf(TERMINATED, 0)); //最后将状态设定为TERMINATED，线程池结束了它年轻的生命 termination.signalAll(); //如果有线程调用了awaitTermination方法，会等待当前线程池终止，到这里差不多就可以唤醒了 } return; //结束 } //注意如果CAS失败会直接进下一轮循环重新判断 } finally { mainLock.unlock(); } // else retry on failed CAS } } OK，有关线程池的实现原理，我们就暂时先介绍到这里，关于更高级的定时任务线程池，这里就不做讲解了。 并发工具类 计数器锁 CountDownLatch 多任务同步神器。它允许一个或多个线程，等待其他线程完成工作，比如现在我们有这样的一个需求： 有20个计算任务，我们需要先将这些任务的结果全部计算出来，每个任务的执行时间未知 当所有任务结束之后，立即整合统计最终结果 要实现这个需求，那么有一个很麻烦的地方，我们不知道任务到底什么时候执行完毕，那么可否将最终统计延迟一定时间进行呢？但是最终统计无论延迟多久进行，要么不能保证所有任务都完成，要么可能所有任务都完成了而这里还在等。 所以说，我们需要一个能够实现子任务同步的工具。 public static void main(String[] args) throws InterruptedException { CountDownLatch latch = new CountDownLatch(20); //创建一个初始值为10的计数器锁 for (int i = 0; i { try { Thread.sleep((long) (2000 * new Random().nextDouble())); System.out.println(\"子任务\"+ finalI +\"执行完成！\"); } catch (InterruptedException e) { e.printStackTrace(); } latch.countDown(); //每执行一次计数器都会-1 }).start(); } //开始等待所有的线程完成，当计数器为0时，恢复运行 latch.await(); //这个操作可以同时被多个线程执行，一起等待，这里只演示了一个 System.out.println(\"所有子任务都完成！任务完成！！！\"); //注意这个计数器只能使用一次，用完只能重新创一个，没有重置的说法 } 我们在调用await()方法之后，实际上就是一个等待计数器衰减为0的过程，而进行自减操作则由各个子线程来完成，当子线程完成工作后，那么就将计数器-1，所有的子线程完成之后，计数器为0，结束等待。 那么它是如何实现的呢？实现 原理非常简单： public class CountDownLatch { //同样是通过内部类实现AbstractQueuedSynchronizer private static final class Sync extends AbstractQueuedSynchronizer { Sync(int count) { //这里直接使用AQS的state作为计数器（可见state能被玩出各种花样），也就是说一开始就加了count把共享锁，当线程调用countdown时，就解一层锁 setState(count); } int getCount() { return getState(); } //采用共享锁机制，因为可以被不同的线程countdown，所以实现的tryAcquireShared和tryReleaseShared //获取这把共享锁其实就是去等待state被其他线程减到0 protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1; } protected boolean tryReleaseShared(int releases) { // 每次执行都会将state值-1，直到为0 for (;;) { int c = getState(); if (c == 0) return false; //如果已经是0了，那就false int nextc = c-1; if (compareAndSetState(c, nextc)) //CAS设置state值，失败直接下一轮循环 return nextc == 0; //返回c-1之后，是不是0，如果是那就true，否则false，也就是说只有刚好减到0的时候才会返回true } } } private final Sync sync; public CountDownLatch(int count) { if (count 在深入讲解之前，我们先大致了解一下CountDownLatch的基本实现思路： 利用共享锁实现 在一开始的时候就是已经上了count层锁的状态，也就是state = count await()就是加共享锁，但是必须state为0才能加锁成功，否则按照AQS的机制，会进入等待队列阻塞，加锁成功后结束阻塞 countDown()就是解1层锁，也就是靠这个方法一点一点把state的值减到0 由于我们前面只对独占锁进行了讲解，没有对共享锁进行讲解，这里还是稍微提一下它： public final void acquireShared(int arg) { if (tryAcquireShared(arg) private void doAcquireShared(int arg) { final Node node = addWaiter(Node.SHARED); //向等待队列中添加一个新的共享模式结点 boolean failed = true; try { boolean interrupted = false; for (;;) { //无限循环 final Node p = node.predecessor(); //获取当前节点的前驱的结点 if (p == head) { //如果p就是头结点，那么说明当前结点就是第一个等待节点 int r = tryAcquireShared(arg); //会再次尝试获取共享锁 if (r >= 0) { //要是获取成功 setHeadAndPropagate(node, r); //那么就将当前节点设定为新的头结点，并且会继续唤醒后继节点 p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) && //和独占模式下一样的操作，这里不多说了 parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); //如果最后都还是没获取到，那么就cancel } } //其实感觉大体上和独占模式的获取有点像，但是它多了个传播机制，会继续唤醒后续节点 private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // 取出头结点并将当前节点设定为新的头结点 setHead(node); //因为一个线程成功获取到共享锁之后，有可能剩下的等待中的节点也有机会拿到共享锁 if (propagate > 0 || h == null || h.waitStatus 我们接着来看，它的countdown过程： public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { //直接尝试释放锁，如果成功返回true（在CountDownLatch中只有state减到0的那一次，会返回true） doReleaseShared(); //这里也会调用doReleaseShared继续唤醒后面的结点 return true; } return false; //其他情况false //不过这里countdown并没有用到这些返回值 } private void doReleaseShared() { for (;;) { //无限循环 Node h = head; //获取头结点 if (h != null && h != tail) { //如果头结点不为空且头结点不是尾结点，那么说明等待队列中存在节点 int ws = h.waitStatus; //取一下头结点的等待状态 if (ws == Node.SIGNAL) { //如果是SIGNAL，那么就CAS将头结点的状态设定为初始值 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; //失败就开下一轮循环重来 unparkSuccessor(h); //和独占模式一样，当锁被释放，都会唤醒头结点的后继节点，doAcquireShared循环继续，如果成功，那么根据setHeadAndPropagate，又会继续调用当前方法，不断地传播下去，让后面的线程一个一个地获取到共享锁，直到不能再继续获取为止 } else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) //如果等待状态是默认值0，那么说明后继节点已经被唤醒，直接将状态设定为PROPAGATE，它代表在后续获取资源的时候，够向后面传播 continue; //失败就开下一轮循环重来 } if (h == head) // 如果头结点发生了变化，不会break，而是继续循环，否则直接break退出 break; } } 可能看完之后还是有点乱，我们再来理一下： 共享锁是线程共享的，同一时刻能有多个线程拥有共享锁。 如果一个线程刚获取了共享锁，那么在其之后等待的线程也很有可能能够获取到锁，所以得传播下去继续尝试唤醒后面的结点，不像独占锁，独占的压根不需要考虑这些。 如果一个线程刚释放了锁，不管是独占锁还是共享锁，都需要唤醒后续等待结点的线程。 回到CountDownLatch，再结合整个AQS共享锁的实现机制，进行一次完整的推导，看明白还是比较简单的。 循环屏障 CyclicBarrier 好比一场游戏，我们必须等待房间内人数足够之后才能开始，并且游戏开始之后玩家需要同时进入游戏以保证公平性。 假如现在游戏房间内一共5人，但是游戏开始需要10人，所以我们必须等待剩下5人到来之后才能开始游戏，并且保证游戏开始时所有玩家都是同时进入，那么怎么实现这个功能呢？我们可以使用CyclicBarrier，翻译过来就是循环屏障，那么这个屏障正式为了解决这个问题而出现的。 public static void main(String[] args) { CyclicBarrier barrier = new CyclicBarrier(10, //创建一个初始值为10的循环屏障 () -> System.out.println(\"飞机马上就要起飞了，各位特种兵请准备！\")); //人等够之后执行的任务 for (int i = 0; i { try { Thread.sleep((long) (2000 * new Random().nextDouble())); System.out.println(\"玩家 \"+ finalI +\" 进入房间进行等待... (\"+barrier.getNumberWaiting()+\"/10)\"); barrier.await(); //调用await方法进行等待，直到等待的线程足够多为止 //开始游戏，所有玩家一起进入游戏 System.out.println(\"玩家 \"+ finalI +\" 进入游戏！\"); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } }).start(); } } 可以看到，循环屏障会不断阻挡线程，直到被阻挡的线程足够多时，才能一起冲破屏障，并且在冲破屏障时，我们也可以做一些其他的任务。这和人多力量大的道理是差不多的，当人足够多时方能冲破阻碍，到达美好的明天。当然，屏障由于是可循环的，所以它在被冲破后，会重新开始计数，继续阻挡后续的线程： public static void main(String[] args) { CyclicBarrier barrier = new CyclicBarrier(5); //创建一个初始值为5的循环屏障 for (int i = 0; i { try { Thread.sleep((long) (2000 * new Random().nextDouble())); System.out.println(\"玩家 \"+ finalI +\" 进入房间进行等待... (\"+barrier.getNumberWaiting()+\"/5)\"); barrier.await(); //调用await方法进行等待，直到等待线程到达5才会一起继续执行 //人数到齐之后，可以开始游戏了 System.out.println(\"玩家 \"+ finalI +\" 进入游戏！\"); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } }).start(); } } 可以看到，通过使用循环屏障，我们可以对线程进行一波一波地放行，每一波都放行5个线程，当然除了自动重置之外，我们也可以调用reset()方法来手动进行重置操作，同样会重新计数： public static void main(String[] args) throws InterruptedException { CyclicBarrier barrier = new CyclicBarrier(5); //创建一个初始值为10的计数器锁 for (int i = 0; i { try { barrier.await(); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } }).start(); Thread.sleep(500); //等一下上面的线程开始运行 System.out.println(\"当前屏障前的等待线程数：\"+barrier.getNumberWaiting()); barrier.reset(); System.out.println(\"重置后屏障前的等待线程数：\"+barrier.getNumberWaiting()); } 可以看到，在调用reset()之后，处于等待状态下的线程，全部被中断并且抛出BrokenBarrierException异常，循环屏障等待线程数归零。那么要是处于等待状态下的线程被中断了呢？屏障的线程等待数量会不会自动减少？ public static void main(String[] args) throws InterruptedException { CyclicBarrier barrier = new CyclicBarrier(10); Runnable r = () -> { try { barrier.await(); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } }; Thread t = new Thread(r); t.start(); t.interrupt(); new Thread(r).start(); } 可以看到，当await()状态下的线程被中断，那么屏障会直接变成损坏状态，一旦屏障损坏，那么这一轮就无法再做任何等待操作了。也就是说，本来大家计划一起合力冲破屏障，结果有一个人摆烂中途退出了，那么所有人的努力都前功尽弃，这一轮的屏障也不可能再被冲破了（所以CyclicBarrier告诉我们，不要做那个害群之马，要相信你的团队，不然没有好果汁吃），只能进行reset()重置操作进行重置才能恢复正常。 乍一看，怎么感觉和之前讲的CountDownLatch有点像，好了，这里就得区分一下了，千万别搞混： CountDownLatch： 它只能使用一次，是一个一次性的工具 它是一个或多个线程用于等待其他线程完成的同步工具 CyclicBarrier 它可以反复使用，允许自动或手动重置计数 它是让一定数量的线程在同一时间开始运行的同步工具 我们接着来看循环屏障的实现细节： public class CyclicBarrier { //内部类，存放broken标记，表示屏障是否损坏，损坏的屏障是无法正常工作的 private static class Generation { boolean broken = false; } /** 内部维护一个可重入锁 */ private final ReentrantLock lock = new ReentrantLock(); /** 再维护一个Condition */ private final Condition trip = lock.newCondition(); /** 这个就是屏障的最大阻挡容量，就是构造方法传入的初始值 */ private final int parties; /* 在屏障破裂时做的事情 */ private final Runnable barrierCommand; /** 当前这一轮的Generation对象，每一轮都有一个新的，用于保存broken标记 */ private Generation generation = new Generation(); //默认为最大阻挡容量，每来一个线程-1，和CountDownLatch挺像，当屏障破裂或是被重置时，都会将其重置为最大阻挡容量 private int count; //构造方法 public CyclicBarrier(int parties, Runnable barrierAction) { if (parties 0L) nanos = trip.awaitNanos(nanos); //否则最多等一段时间 } catch (InterruptedException ie) { //等的时候会判断是否被中断（依然是破坏屏障的第1种情况） if (g == generation && ! g.broken) { breakBarrier(); throw ie; } else { Thread.currentThread().interrupt(); } } if (g.broken) throw new BrokenBarrierException(); //如果线程被唤醒之后发现屏障已经被破坏，那么直接抛异常 if (g != generation) //成功冲破屏障开启下一轮，那么直接返回当前是第几个等待的线程。 return index; if (timed && nanos 看完了CyclicBarrier的源码之后，是不是感觉比CountDownLatch更简单一些？ 信号量 Semaphore 还记得我们在《操作系统》中学习的信号量机制吗？它在解决进程之间的同步问题中起着非常大的作用。 信号量(Semaphore)，有时被称为信号灯，是在多线程环境下使用的一种设施，是可以用来保证两个或多个关键代码段不被并发调用。在进入一个关键代码段之前，线程必须获取一个信号量；一旦该关键代码段完成了，那么该线程必须释放信号量。其它想进入该关键代码段的线程必须等待直到第一个线程释放信号量。 通过使用信号量，我们可以决定某个资源同一时间能够被访问的最大线程数，它相当于对某个资源的访问进行了流量控制。简单来说，它就是一个可以被N个线程占用的排它锁（因此也支持公平和非公平模式），我们可以在最开始设定Semaphore的许可证数量，每个线程都可以获得1个或n个许可证，当许可证耗尽或不足以供其他线程获取时，其他线程将被阻塞。 public static void main(String[] args) throws ExecutionException, InterruptedException { //每一个Semaphore都会在一开始获得指定的许可证数数量，也就是许可证配额 Semaphore semaphore = new Semaphore(2); //许可证配额设定为2 for (int i = 0; i { try { semaphore.acquire(); //申请一个许可证 System.out.println(\"许可证申请成功！\"); semaphore.release(); //归还一个许可证 } catch (InterruptedException e) { e.printStackTrace(); } }).start(); } } public static void main(String[] args) throws ExecutionException, InterruptedException { //每一个Semaphore都会在一开始获得指定的许可证数数量，也就是许可证配额 Semaphore semaphore = new Semaphore(3); //许可证配额设定为3 for (int i = 0; i { try { semaphore.acquire(2); //一次性申请两个许可证 System.out.println(\"许可证申请成功！\"); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); } 我们也可以通过Semaphore获取一些常规信息： public static void main(String[] args) throws InterruptedException { Semaphore semaphore = new Semaphore(3); //只配置一个许可证，5个线程进行争抢，不内卷还想要许可证？ for (int i = 0; i 我们可以手动回收掉所有的许可证： public static void main(String[] args) throws InterruptedException { Semaphore semaphore = new Semaphore(3); new Thread(semaphore::acquireUninterruptibly).start(); Thread.sleep(500); System.out.println(\"收回剩余许可数量：\"+semaphore.drainPermits()); //直接回收掉剩余的许可证 } 这里我们模拟一下，比如现在有10个线程同时进行任务，任务要求是执行某个方法，但是这个方法最多同时只能由5个线程执行，这里我们使用信号量就非常合适。 数据交换 Exchanger 线程之间的数据传递也可以这么简单。 使用Exchanger，它能够实现线程之间的数据交换： public static void main(String[] args) throws InterruptedException { Exchanger exchanger = new Exchanger<>(); new Thread(() -> { try { System.out.println(\"收到主线程传递的交换数据：\"+exchanger.exchange(\"AAAA\")); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); System.out.println(\"收到子线程传递的交换数据：\"+exchanger.exchange(\"BBBB\")); } 在调用exchange方法后，当前线程会等待其他线程调用同一个exchanger对象的exchange方法，当另一个线程也调用之后，方法会返回对方线程传入的参数。 可见功能还是比较简单的。 Fork/Join框架 在JDK7时，出现了一个新的框架用于并行执行任务，它的目的是为了把大型任务拆分为多个小任务，最后汇总多个小任务的结果，得到整大任务的结果，并且这些小任务都是同时在进行，大大提高运算效率。Fork就是拆分，Join就是合并。 我们来演示一下实际的情况，比如一个算式：18x7+36x8+9x77+8x53，可以拆分为四个小任务：18x7、36x8、9x77、8x53，最后我们只需要将这四个任务的结果加起来，就是我们原本算式的结果了，有点归并排序的味道。 它不仅仅只是拆分任务并使用多线程，而且还可以利用工作窃取算法，提高线程的利用率。 工作窃取算法：是指某个线程从其他队列里窃取任务来执行。一个大任务分割为若干个互不依赖的子任务，为了减少线程间的竞争，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务待处理。干完活的线程与其等着，不如帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。 现在我们来看看如何使用它，这里以计算1-1000的和为例，我们可以将其拆分为8个小段的数相加，比如1-125、126-250... ，最后再汇总即可，它也是依靠线程池来实现的： public class Main { public static void main(String[] args) throws InterruptedException, ExecutionException { ForkJoinPool pool = new ForkJoinPool(); System.out.println(pool.submit(new SubTask(1, 1000)).get()); } //继承RecursiveTask，这样才可以作为一个任务，泛型就是计算结果类型 private static class SubTask extends RecursiveTask { private final int start; //比如我们要计算一个范围内所有数的和，那么就需要限定一下范围，这里用了两个int存放 private final int end; public SubTask(int start, int end) { this.start = start; this.end = end; } @Override protected Integer compute() { if(end - start > 125) { //每个任务最多计算125个数的和，如果大于继续拆分，小于就可以开始算了 SubTask subTask1 = new SubTask(start, (end + start) / 2); subTask1.fork(); //会继续划分子任务执行 SubTask subTask2 = new SubTask((end + start) / 2 + 1, end); subTask2.fork(); //会继续划分子任务执行 return subTask1.join() + subTask2.join(); //越玩越有递归那味了 } else { System.out.println(Thread.currentThread().getName()+\" 开始计算 \"+start+\"-\"+end+\" 的值!\"); int res = 0; for (int i = start; i ForkJoinPool-1-worker-2 开始计算 1-125 的值! ForkJoinPool-1-worker-2 开始计算 126-250 的值! ForkJoinPool-1-worker-0 开始计算 376-500 的值! ForkJoinPool-1-worker-6 开始计算 751-875 的值! ForkJoinPool-1-worker-3 开始计算 626-750 的值! ForkJoinPool-1-worker-5 开始计算 501-625 的值! ForkJoinPool-1-worker-4 开始计算 251-375 的值! ForkJoinPool-1-worker-7 开始计算 876-1000 的值! 500500 可以看到，结果非常正确，但是整个计算任务实际上是拆分为了8个子任务同时完成的，结合多线程，原本的单线程任务，在多线程的加持下速度成倍提升。 包括Arrays工具类提供的并行排序也是利用了ForkJoinPool来实现： public static void parallelSort(byte[] a) { int n = a.length, p, g; if (n 并行排序的性能在多核心CPU环境下，肯定是优于普通排序的，并且排序规模越大优势越显著。 至此，并发编程篇完结。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/JUC/JUC（三）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/JUC/JUC（三）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/NIO/":{"url":"Java/NIO/","title":"NIO","keywords":"","body":"April 项目组文档仓库 这是一个用于存储文档的仓库，可以方便地共享和管理各种文档。本仓库的文档类型不限，可以包括但不限于技术文档、设计文档、需求文档、用户手册等。 如何使用 你可以通过以下几种方式使用本仓库： 查看文档：在本仓库中找到你需要的文档，点击进入查看。 下载文档：在文档页面中点击下载按钮，即可下载文档。 提交文档：如果你想上传一个新文档或修改已有文档，可以先 Fork 本仓库，然后在你的仓库中进行修改，最后发起 Pull Request 即可。 贡献 如果你想为本仓库贡献文档，欢迎进行如下操作： Fork 本仓库 在你的仓库中添加或修改文档 发起 Pull Request 我们会及时审核并合并你的贡献。为了保证贡献质量，建议你在提交贡献前，仔细阅读贡献指南。 贡献指南 为了保证本仓库的贡献质量，我们制定了如下的贡献指南： 文档内容应当真实可靠，不得包含虚假信息。 文档格式应当规范，建议使用 Markdown 格式。 文档应当具有实用性和参考价值，不得过于简单或复杂。 代码示例应当可执行，并应当注明相关依赖库的版本号。 如有图片、视频等附件，建议使用外部链接或专门的存储仓库。 版权声明 本仓库的所有文档均属于原作者版权所有，未经授权不得进行商业使用。在 Fork 和提交贡献时，请务必尊重原作者的版权，并注明出处。 联系我们 如果你有任何问题或建议，可以通过以下方式联系我们： 邮箱：mobaijun8@163.com GitHub Issues：https://github.com/april-projects/.docs/issues window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/NIO/README.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/NIO/README.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/NIO/Java NIO（一）.html":{"url":"Java/NIO/Java NIO（一）.html","title":"Java NIO（一）","keywords":"","body":" NIO基础 注意：推荐完成JavaSE篇、JavaWeb篇的学习再开启这一部分的学习，如果在这之前完成了JVM篇，那么看起来就会比较轻松了。 在JavaSE的学习中，我们了解了如何使用IO进行数据传输，Java IO是阻塞的，如果在一次读写数据调用时数据还没有准备好，或者目前不可写，那么读写操作就会被阻塞直到数据准备好或目标可写为止。Java NIO则是非阻塞的，每一次数据读写调用都会立即返回，并将目前可读（或可写）的内容写入缓冲区或者从缓冲区中输出，即使当前没有可用数据，调用仍然会立即返回并且不对缓冲区做任何操作。 NIO框架是在JDK1.4推出的，它的出现就是为了解决传统IO的不足，这一期视频，我们就将围绕着NIO开始讲解。 缓冲区 一切的一切还要从缓冲区开始讲起，包括源码在内，其实这个不是很难，只是需要理清思路。 Buffer类及其实现 Buffer类是缓冲区的实现，类似于Java中的数组，也是用于存放和获取数据的。但是Buffer相比Java中的数组，功能就非常强大了，它包含一系列对于数组的快捷操作。 Buffer是一个抽象类，它的核心内容： public abstract class Buffer { // 这四个变量的关系: mark 我们来看看Buffer类的子类，包括我们认识到的所有基本类型（除了boolean类型之外）： IntBuffer - int类型的缓冲区。 ShortBuffer - short类型的缓冲区。 LongBuffer - long类型的缓冲区。 FloatBuffer - float类型的缓冲区。 DoubleBuffer - double类型的缓冲区。 ByteBuffer - byte类型的缓冲区。 CharBuffer - char类型的缓冲区。 （注意我们之前在JavaSE中学习过的StringBuffer虽然也是这种命名方式，但是不属于Buffer体系，这里不会进行介绍） 这里我们以IntBuffer为例，我们来看看如何创建一个Buffer类： public static void main(String[] args) { //创建一个缓冲区不能直接new，而是需要使用静态方法去生成，有两种方式： //1. 申请一个容量为10的int缓冲区 IntBuffer buffer = IntBuffer.allocate(10); //2. 可以将现有的数组直接转换为缓冲区（包括数组中的数据） int[] arr = new int[]{1, 2, 3, 4, 5, 6}; IntBuffer buffer = IntBuffer.wrap(arr); } 那么它的内部是本质上如何进行操作的呢？我们来看看它的源码： public static IntBuffer allocate(int capacity) { if (capacity public static IntBuffer wrap(int[] array, int offset, int length) { try { //可以看到这个也是创建了一个新的HeapIntBuffer对象，并且给了初始数组以及截取的起始位置和长度 return new HeapIntBuffer(array, offset, length); } catch (IllegalArgumentException x) { throw new IndexOutOfBoundsException(); } } public static IntBuffer wrap(int[] array) { return wrap(array, 0, array.length); //调用的是上面的wrap方法 } 那么这个HeapIntBuffer又是如何实现的呢，我们接着来看： HeapIntBuffer(int[] buf, int off, int len) { // 注意这个构造方法不是public，是默认的访问权限 super(-1, off, off + len, buf.length, buf, 0); //你会发现这怎么又去调父类的构造方法了，绕来绕去 //mark是标记，off是当前起始下标位置，off+len是最大下标位置，buf.length是底层维护的数组真正长度，buf就是数组，最后一个0是起始偏移位置 } 我们又来看看IntBuffer中的构造方法是如何定义的： final int[] hb; // 只有在堆缓冲区实现时才会使用 final int offset; boolean isReadOnly; // 只有在堆缓冲区实现时才会使用 IntBuffer(int mark, int pos, int lim, int cap, // 注意这个构造方法不是public，是默认的访问权限 int[] hb, int offset) { super(mark, pos, lim, cap); //调用Buffer类的构造方法 this.hb = hb; //hb就是真正我们要存放数据的数组，堆缓冲区底层其实就是这么一个数组 this.offset = offset; //起始偏移位置 } 最后我们来看看Buffer中的构造方法： Buffer(int mark, int pos, int lim, int cap) { // 注意这个构造方法不是public，是默认的访问权限 if (cap = 0) { //如果起始标记大于等于0 if (mark > pos) //并且标记位置大于起始位置，那么就抛异常（至于为啥不能大于我们后面再说） throw new IllegalArgumentException(\"mark > position: (\" + mark + \" > \" + pos + \")\"); this.mark = mark; //否则设定mark位置（mark默认为-1） } } 通过对源码的观察，我们大致可以得到以下结构了： 现在我们来总结一下上面这些结构的各自职责划分： Buffer：缓冲区的一些基本变量定义，比如当前的位置（position）、容量 (capacity)、最大限制 (limit)、标记 (mark)等，你肯定会疑惑这些变量有啥用，别着急，这些变量会在后面的操作中用到，我们逐步讲解。 IntBuffer等子类：定义了存放数据的数组（只有堆缓冲区实现子类才会用到）、是否只读等，也就是说数据的存放位置、以及对于底层数组的相关操作都在这里已经定义好了，并且已经实现了Comparable接口。 HeapIntBuffer堆缓冲区实现子类：数据存放在堆中，实际上就是用的父类的数组在保存数据，并且将父类定义的所有底层操作全部实现了。 这样，我们对于Buffer类的基本结构就有了一个大致的认识。 缓冲区写操作 前面我们了解了Buffer类的基本操作，现在我们来看一下如何向缓冲区中存放数据以及获取数据，数据的存放包括以下四个方法： public abstract IntBuffer put(int i); - 在当前position位置插入数据，由具体子类实现 public abstract IntBuffer put(int index, int i); - 在指定位置存放数据，也是由具体子类实现 public final IntBuffer put(int[] src); - 直接存放所有数组中的内容（数组长度不能超出缓冲区大小） public IntBuffer put(int[] src, int offset, int length); - 直接存放数组中的内容，同上，但是可以指定存放一段范围 public IntBuffer put(IntBuffer src); - 直接存放另一个缓冲区中的内容 我们从最简的开始看，是在当前位置插入一个数据，那么这个当前位置是怎么定义的呢，我们来看看源码： public IntBuffer put(int x) { hb[ix(nextPutIndex())] = x; //这个ix和nextPutIndex()很灵性，我们来看看具体实现 return this; } protected int ix(int i) { return i + offset; //将i的值加上我们之前设定的offset偏移量值，但是默认是0（非0的情况后面会介绍） } final int nextPutIndex() { int p = position; //获取Buffer类中的position位置（一开始也是0） if (p >= limit) //位置肯定不能超过底层数组最大长度，否则越界 throw new BufferOverflowException(); position = p + 1; //获取之后会使得Buffer类中的position+1 return p; //返回当前的位置 } 所以put操作实际上是将底层数组hb在position位置上的数据进行设定。 设定完成后，position自动后移： 我们可以编写代码来看看： public static void main(String[] args) { IntBuffer buffer = IntBuffer.allocate(10); buffer .put(1) .put(2) .put(3); //我们依次存放三个数据试试看 System.out.println(buffer); } 通过断点调试，我们来看看实际的操作情况： 可以看到我们不断地put操作，position会一直向后移动，当然如果超出最大长度，那么会直接抛出异常： 接着我们来看看第二个put操作是如何进行，它能够在指定位置插入数据： public IntBuffer put(int i, int x) { hb[ix(checkIndex(i))] = x; //这里依然会使用ix，但是会检查位置是否合法 return this; } final int checkIndex(int i) { // package-private if ((i = limit)) //插入的位置不能小于0并且不能大于等于底层数组最大长度 throw new IndexOutOfBoundsException(); return i; //没有问题就把i返回 } 实际上这个比我们之前的要好理解一些，注意全程不会操作position的值，这里需要注意一下。 我们接着来看第三个put操作，它是直接在IntBuffer中实现的，是基于前两个put方法的子类实现来完成的： public IntBuffer put(int[] src, int offset, int length) { checkBounds(offset, length, src.length); //检查截取范围是否合法，给offset、调用者指定长度、数组实际长度 if (length > remaining()) //接着判断要插入的数据量在缓冲区是否容得下，装不下也不行 throw new BufferOverflowException(); int end = offset + length; //计算出最终读取位置，下面开始for for (int i = offset; i 0 ? rem : 0; //没容量就返回0 } static void checkBounds(int off, int len, int size) { // package-private if ((off | len | (off + len) | (size - (off + len))) 大致流程如下，首先来了一个数组要取一段数据全部丢进缓冲区： 在检查没有什么问题并且缓冲区有容量时，就可以开始插入了： 最后我们通过代码来看看： public static void main(String[] args) { IntBuffer buffer = IntBuffer.allocate(10); int[] arr = new int[]{1,2,3,4,5,6,7,8,9}; buffer.put(arr, 3, 4); //从下标3开始，截取4个元素 System.out.println(Arrays.toString(buffer.array())); //array方法可以直接获取到数组 } 可以看到最后结果为： 当然我们也可以将一个缓冲区的内容保存到另一个缓冲区： public IntBuffer put(IntBuffer src) { if (src == this) //不会吧不会吧，不会有人保存自己吧 throw new IllegalArgumentException(); if (isReadOnly()) //如果是只读的话，那么也是不允许插入操作的（我猜你们肯定会问为啥就这里会判断只读，前面四个呢） throw new ReadOnlyBufferException(); int n = src.remaining(); //给进来的src看看容量（注意这里不remaining的结果不是剩余容量，是转换后的，之后会说） if (n > remaining()) //这里判断当前剩余容量是否小于src容量 throw new BufferOverflowException(); for (int i = 0; i 我们来看看效果： public static void main(String[] args) { IntBuffer src = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); IntBuffer buffer = IntBuffer.allocate(10); buffer.put(src); System.out.println(Arrays.toString(buffer.array())); } 但是如果是这样的话，会出现问题： public static void main(String[] args) { IntBuffer src = IntBuffer.allocate(5); for (int i = 0; i 我们发现，结果和上面的不一样，并没有成功地将数据填到下面的IntBuffer中，这是为什么呢？实际上就是因为remaining()的计算问题，因为这个方法是直接计算postion的位置，但是由于我们在写操作完成之后，position跑到后面去了，也就导致remaining()结果最后算出来为0。 因为这里不是写操作，是接下来需要从头开始进行读操作，所以我们得想个办法把position给退回到一开始的位置，这样才可以从头开始读取，那么怎么做呢？一般我们在写入完成后需要进行读操作时（后面都是这样，不只是这里），会使用flip()方法进行翻转： public final Buffer flip() { limit = position; //修改limit值，当前写到哪里，下次读的最终位置就是这里，limit的作用开始慢慢体现了 position = 0; //position归零 mark = -1; //标记还原为-1，但是现在我们还没用到 return this; } 这样，再次计算remaining()的结果就是我们需要读取的数量了，这也是为什么put方法中要用remaining()来计算的原因，我们再来测试一下： public static void main(String[] args) { IntBuffer src = IntBuffer.allocate(5); for (int i = 0; i 翻转之后再次进行转移，就正常了。 缓冲区读操作 前面我们看完了写操作，现在我们接着来看看读操作。读操作有四个方法： public abstract int get(); - 直接获取当前position位置的数据，由子类实现 public abstract int get(int index); - 获取指定位置的数据，也是子类实现 public IntBuffer get(int[] dst) - 将数据读取到给定的数组中 public IntBuffer get(int[] dst, int offset, int length) - 同上，加了个范围 我们还是从最简单的开始看，第一个get方法的实现在IntBuffer类中： public int get() { return hb[ix(nextGetIndex())]; //直接从数组中取就完事 } final int nextGetIndex() { // 好家伙，这不跟前面那个一模一样吗 int p = position; if (p >= limit) throw new BufferUnderflowException(); position = p + 1; return p; } 可以看到每次读取操作之后，也会将postion+1，直到最后一个位置，如果还要继续读，那么就直接抛出异常。 我们来看看第二个： public int get(int i) { return hb[ix(checkIndex(i))]; //这里依然是使用checkIndex来检查位置是否非法 } 我们来看看第三个和第四个： public IntBuffer get(int[] dst, int offset, int length) { checkBounds(offset, length, dst.length); //跟put操作一样，也是需要检查是否越界 if (length > remaining()) //如果读取的长度比可以读的长度大，那肯定是不行的 throw new BufferUnderflowException(); int end = offset + length; //计算出最终读取位置 for (int i = offset; i 我们来看看效果： public static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); int[] arr = new int[10]; buffer.get(arr, 2, 5); System.out.println(Arrays.toString(arr)); } 可以看到成功地将数据读取到了数组中。 当然如果我们需要直接获取数组，也可以使用array()方法来拿到： public final int[] array() { if (hb == null) //为空那说明底层不是数组实现的，肯定就没法转换了 throw new UnsupportedOperationException(); if (isReadOnly) //只读也是不让直接取出的，因为一旦取出去岂不是就能被修改了 throw new ReadOnlyBufferException(); return hb; //直接返回hb } 我们来试试看： public static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); System.out.println(Arrays.toString(buffer.array())); } 当然，既然都已经拿到了底层的hb了，我们来看看如果直接修改之后是不是读取到的就是我们的修改之后的结果了： public static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); int[] arr = buffer.array(); arr[0] = 99999; //拿到数组对象直接改 System.out.println(buffer.get()); } 可以看到这种方式由于是直接拿到的底层数组，所有修改会直接生效在缓冲区中。 当然除了常规的读取方式之外，我们也可以通过mark()来实现跳转读取，这里需要介绍一下几个操作： public final Buffer mark() - 标记当前位置 public final Buffer reset() - 让当前的position位置跳转到mark当时标记的位置 我们首先来看标记方法： public final Buffer mark() { mark = position; //直接标记到当前位置，mark变量终于派上用场了，当然这里仅仅是标记 return this; } 我们再来看看重置方法： public final Buffer reset() { int m = mark; //存一下当前的mark位置 if (m 那比如我们在读取到1号位置时进行标记： 接着我们使用reset方法就可以直接回退回去了： 现在我们来测试一下： public static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); buffer.get(); //读取一位，那么position就变成1了 buffer.mark(); //这时标记，那么mark = 1 buffer.get(); //又读取一位，那么position就变成2了 buffer.reset(); //直接将position = mark，也就是变回1 System.out.println(buffer.get()); } 可以看到，读取的位置根据我们的操作进行了变化，有关缓冲区的读操作，就暂时讲到这里。 缓冲区其他操作 前面我们大致了解了一下缓冲区的读写操作，那么我们接着来看看，除了常规的读写操作之外，还有哪些其他的操作： public abstract IntBuffer compact() - 压缩缓冲区，由具体实现类实现 public IntBuffer duplicate() - 复制缓冲区，会直接创建一个新的数据相同的缓冲区 public abstract IntBuffer slice() - 划分缓冲区，会将原本的容量大小的缓冲区划分为更小的出来进行操作 public final Buffer rewind() - 重绕缓冲区，其实就是把position归零，然后mark变回-1 public final Buffer clear() - 将缓冲区清空，所有的变量变回最初的状态 我们先从压缩缓冲区开始看起，它会将整个缓冲区的大小和数据内容变成position位置到limit之间的数据，并移动到数组头部： public IntBuffer compact() { int pos = position(); //获取当前位置 int lim = limit(); //获取当前最大position位置 assert (pos 比如现在的状态是： 那么我们在执行compact()方法之后，会进行截取，此时limit - position = 6，那么就会截取第4、5、6、7、8、9这6个数据然后丢到最前面，接着position跑到7表示这是下一个继续的位置： 现在我们通过代码来检验一下： public static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}); for (int i = 0; i 可以看到最后的结果没有问题： 我们接着来看第二个方法，那么如果我们现在需要复制一个内容一模一样的的缓冲区，该怎么做？直接使用duplicate()方法就可以复制了： public IntBuffer duplicate() { //直接new一个新的，但是是吧hb给丢进去了，而不是拷贝一个新的 return new HeapIntBuffer(hb, this.markValue(), this.position(), this.limit(), this.capacity(), offset); } 那么各位猜想一下，如果通过这种方式创了一个新的IntBuffer，那么下面的例子会出现什么结果： public static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); IntBuffer duplicate = buffer.duplicate(); System.out.println(buffer == duplicate); System.out.println(buffer.array() == duplicate.array()); } 由于buffer是重新new的，所以第一个为false，而底层的数组由于在构造的时候没有进行任何的拷贝而是直接传递，因此实际上两个缓冲区的底层数组是同一个对象。所以，一个发生修改，那么另一个就跟着变了： public static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); IntBuffer duplicate = buffer.duplicate(); buffer.put(0, 66666); System.out.println(duplicate.get()); } 现在我们接着来看下一个方法，slice()方法会将缓冲区进行划分： public IntBuffer slice() { int pos = this.position(); //获取当前position int lim = this.limit(); //获取position最大位置 int rem = (pos 虽然现在底层依然使用的是之前的数组，但是由于设定了offset值，我们之前的操作似乎变得不太一样了： 回顾前面我们所讲解的内容，在读取和存放时，会被ix方法进行调整： protected int ix(int i) { return i + offset; //现在offset为4，那么也就是说逻辑上的i是0但是得到真实位置却是4 } public int get() { return hb[ix(nextGetIndex())]; //最后会经过ix方法转换为真正在数组中的位置 } 当然，在逻辑上我们可以认为是这样的： 现在我们来测试一下： public static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}); for (int i = 0; i 可以看到，最终结果： 最后两个方法就比较简单了，我们先来看rewind()，它相当于是对position和mark进行了一次重置： public final Buffer rewind() { position = 0; mark = -1; return this; } 接着是clear()，它相当于是将整个缓冲区回归到最初的状态了： public final Buffer clear() { position = 0; //同上 limit = capacity; //limit变回capacity mark = -1; return this; } 到这里，关于缓冲区的一些其他操作，我们就讲解到此。 缓冲区比较 缓冲区之间是可以进行比较的，我们可以看到equals方法和compareTo方法都是被重写了的，我们首先来看看equals方法，注意，它是判断两个缓冲区剩余的内容是否一致： public boolean equals(Object ob) { if (this == ob) //要是两个缓冲区是同一个对象，肯定一样 return true; if (!(ob instanceof IntBuffer)) //类型不是IntBuffer那也不用比了 return false; IntBuffer that = (IntBuffer)ob; //转换为IntBuffer int thisPos = this.position(); //获取当前缓冲区的相关信息 int thisLim = this.limit(); int thatPos = that.position(); //获取另一个缓冲区的相关信息 int thatLim = that.limit(); int thisRem = thisLim - thisPos; int thatRem = thatLim - thatPos; if (thisRem = thisPos; i--, j--) //从最后一个开始倒着往回比剩余的区域 if (!equals(this.get(i), that.get(j))) return false; //只要发现不一样的就不用继续了，直接false return true; //上面的比较都没问题，那么就true } private static boolean equals(int x, int y) { return x == y; } 那么我们按照它的思路来验证一下： public static void main(String[] args) { IntBuffer buffer1 = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}); IntBuffer buffer2 = IntBuffer.wrap(new int[]{6, 5, 4, 3, 2, 1, 7, 8, 9, 0}); System.out.println(buffer1.equals(buffer2)); //直接比较 buffer1.position(6); buffer2.position(6); System.out.println(buffer1.equals(buffer2)); //比较从下标6开始的剩余内容 } 可以看到结果就是我们所想的那样： 那么我们接着来看比较，compareTo方法，它实际上是Comparable接口提供的方法，它实际上比较的也是pos开始剩余的内容： public int compareTo(IntBuffer that) { int thisPos = this.position(); //获取并计算两个缓冲区的pos和remain int thisRem = this.limit() - thisPos; int thatPos = that.position(); int thatRem = that.limit() - thatPos; int length = Math.min(thisRem, thatRem); //选取一个剩余空间最小的出来 if (length 这里我们就不多做介绍了。 只读缓冲区 接着我们来看看只读缓冲区，只读缓冲区就像其名称一样，它只能进行读操作，而不允许进行写操作。 那么我们怎么创建只读缓冲区呢？ public abstract IntBuffer asReadOnlyBuffer(); - 基于当前缓冲区生成一个只读的缓冲区。 我们来看看此方法的具体实现： public IntBuffer asReadOnlyBuffer() { return new HeapIntBufferR(hb, //注意这里并不是直接创建了HeapIntBuffer，而是HeapIntBufferR，并且直接复制的hb数组 this.markValue(), this.position(), this.limit(), this.capacity(), offset); } 那么这个HeapIntBufferR类跟我们普通的HeapIntBuffer有什么不同之处呢？ 可以看到它是继承自HeapIntBuffer的，那么我们来看看它的实现有什么不同： protected HeapIntBufferR(int[] buf, int mark, int pos, int lim, int cap, int off) { super(buf, mark, pos, lim, cap, off); this.isReadOnly = true; } 可以看到在其构造方法中，除了直接调用父类的构造方法外，还会将isReadOnly标记修改为true，我们接着来看put操作有什么不同之处： public boolean isReadOnly() { return true; } public IntBuffer put(int x) { throw new ReadOnlyBufferException(); } public IntBuffer put(int i, int x) { throw new ReadOnlyBufferException(); } public IntBuffer put(int[] src, int offset, int length) { throw new ReadOnlyBufferException(); } public IntBuffer put(IntBuffer src) { throw new ReadOnlyBufferException(); } 可以看到所有的put方法全部凉凉，只要调用就会直接抛出ReadOnlyBufferException异常。但是其他get方法依然没有进行重写，也就是说get操作还是可以正常使用的，但是只要是写操作就都不行： public static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}); IntBuffer readBuffer = buffer.asReadOnlyBuffer(); System.out.println(readBuffer.isReadOnly()); System.out.println(readBuffer.get()); readBuffer.put(0, 666); } 可以看到结果为： 这就是只读状态下的缓冲区。 ByteBuffer和CharBuffer 通过前面的学习，我们基本上已经了解了缓冲区的使用，但是都是基于IntBuffer进行讲解，现在我们来看看另外两种基本类型的缓冲区ByteBuffer和CharBuffer，因为ByteBuffer底层存放的是很多单个byte字节，所以会有更多的玩法，同样CharBuffer是一系列字节，所以也有很多便捷操作。 我们先来看看ByteBuffer，我们可以直接点进去看： public abstract class ByteBuffer extends Buffer implements Comparable { final byte[] hb; // Non-null only for heap buffers final int offset; boolean isReadOnly; // Valid only for heap buffers .... 可以看到如果也是使用堆缓冲区子类实现，那么依然是一个byte[]的形式保存数据。我们来尝试使用一下： public static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(10); //除了直接丢byte进去之外，我们也可以丢其他的基本类型（注意容量消耗） buffer.putInt(Integer.MAX_VALUE); //丢个int的最大值进去，注意一个int占4字节 System.out.println(\"当前缓冲区剩余字节数：\"+buffer.remaining()); //只剩6个字节了 //我们来尝试读取一下，记得先翻转 buffer.flip(); while (buffer.hasRemaining()) { System.out.println(buffer.get()); //一共四个字节 } } 最后的结果为： 可以看到第一个byte为127、然后三个都是-1，我们来分析一下： 127 转换为二进制补码形式就是 01111111，而-1转换为二进制补码形式为11111111 那也就是说，第一个字节是01111111，而后续字节就是11111111，把它们拼接在一起： 二进制补码表示01111111 11111111 11111111 11111111 转换为十进制就是2147483647，也就是int的最大值。 那么根据我们上面的推导，各位能否计算得到下面的结果呢？ public static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(10); buffer.put((byte) 0); buffer.put((byte) 0); buffer.put((byte) 1); buffer.put((byte) -1); buffer.flip(); //翻转一下 System.out.println(buffer.getInt()); //以int形式获取，那么就是一次性获取4个字节 } 经过上面的计算，得到的结果就是： 上面的数据以二进制补码的形式表示为：00000000 00000000 00000001 11111111 将其转换为十进制那么就是：256 + 255 = 511 好吧，再来个魔鬼问题，把第一个换成1呢：10000000 00000000 00000001 11111111，自己算。 我们接着来看看CharBuffer，这种缓冲区实际上也是保存一大堆char类型的数据： public static void main(String[] args) { CharBuffer buffer = CharBuffer.allocate(10); buffer.put(\"lbwnb\"); //除了可以直接丢char之外，字符串也可以一次性丢进入 System.out.println(Arrays.toString(buffer.array())); } 但是正是得益于char数组，它包含了很多的字符串操作，可以一次性存放一整个字符串。我们甚至还可以将其当做一个String来进行处理： public static void main(String[] args) { CharBuffer buffer = CharBuffer.allocate(10); buffer.put(\"lbwnb\"); buffer.append(\"!\"); //可以像StringBuilder一样使用append来继续添加数据 System.out.println(\"剩余容量：\"+buffer.remaining()); //已经用了6个字符了 buffer.flip(); System.out.println(\"整个字符串为：\"+buffer); //直接将内容转换为字符串 System.out.println(\"第3个字符是：\"+buffer.charAt(2)); //直接像String一样charAt buffer //也可以转换为IntStream进行操作 .chars() .filter(i -> i System.out.print((char) i)); } 当然除了一些常规操作之外，我们还可以直接将一个字符串作为参数创建： public static void main(String[] args) { //可以直接使用wrap包装一个字符串，但是注意，包装出来之后是只读的 CharBuffer buffer = CharBuffer.wrap(\"收藏等于学会~\"); System.out.println(buffer); buffer.put(\"111\"); //这里尝试进行一下写操作 } 可以看到结果也是我们预料中的： 对于这两个比较特殊的缓冲区，我们就暂时讲解到这里。 直接缓冲区 注意：推荐学习完成JVM篇再来学习这一部分。 最后我们来看一下直接缓冲区，我们前面一直使用的都是堆缓冲区，也就是说实际上数据是保存在一个数组中的，如果你已经完成了JVM篇的学习，一定知道实际上占用的是堆内存，而我们也可以创建一个直接缓冲区，也就是申请堆外内存进行数据保存，采用操作系统本地的IO，相比堆缓冲区会快一些。 那么怎么使用直接缓冲区呢？我们可以通过allocateDirect方法来创建： public static void main(String[] args) { //这里我们申请一个直接缓冲区 ByteBuffer buffer = ByteBuffer.allocateDirect(10); //使用方式基本和之前是一样的 buffer.put((byte) 66); buffer.flip(); System.out.println(buffer.get()); } 我们来看看这个allocateDirect方法是如何创建一个直接缓冲区的： public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); } 这个方法直接创建了一个新的DirectByteBuffer对象，那么这个类又是怎么进行创建的呢？ 可以看到它并不是直接继承自ByteBuffer，而是MappedByteBuffer，并且实现了接口DirectBuffer，我们先来看看这个接口： public interface DirectBuffer { public long address(); //获取内存地址 public Object attachment(); //附加对象，这是为了保证某些情况下内存不被释放，我们后面细谈 public Cleaner cleaner(); //内存清理类 } public abstract class MappedByteBuffer extends ByteBuffer { //这三个方法目前暂时用不到，后面文件再说 public final MappedByteBuffer load(); public final boolean isLoaded(); public final MappedByteBuffer force(); } 接着我们来看看DirectByteBuffer类的成员变量： // 把Unsafe类取出来 protected static final Unsafe unsafe = Bits.unsafe(); // 在内存中直接创建的内存空间地址 private static final long arrayBaseOffset = (long)unsafe.arrayBaseOffset(byte[].class); // 是否具有非对齐访问能力，根据CPU架构而定，intel、AMD、AppleSilicon 都是支持的 protected static final boolean unaligned = Bits.unaligned(); // 直接缓冲区的内存地址，为了提升速度就放到Buffer类中去了 // protected long address; // 附加对象，一会有大作用 private final Object att; 接着我们来看看构造方法： DirectByteBuffer(int cap) { // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); //是否直接内存分页对齐，需要额外计算 int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); //计算出最终需要申请的大小 //判断堆外内存是否足够，够的话就作为保留内存 Bits.reserveMemory(size, cap); long base = 0; try { //通过Unsafe申请内存空间，并得到内存地址 base = unsafe.allocateMemory(size); } catch (OutOfMemoryError x) { //申请失败就取消一开始的保留内存 Bits.unreserveMemory(size, cap); throw x; } //批量将申请到的这一段内存每个字节都设定为0 unsafe.setMemory(base, size, (byte) 0); if (pa && (base % ps != 0)) { // Round up to page boundary address = base + ps - (base & (ps - 1)); } else { //将address变量（在Buffer中定义）设定为base的地址 address = base; } //创建一个针对于此缓冲区的Cleaner，由于是堆外内存，所以现在由它来进行内存清理 cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null; } 可以看到在构造方法中，是直接通过Unsafe类来申请足够的堆外内存保存数据，那么当我们不使用此缓冲区时，内存会被如何清理呢？我们来看看这个Cleaner： public class Cleaner extends PhantomReference{ //继承自鬼引用，也就是说此对象会存放一个没有任何引用的对象 //引用队列，PhantomReference构造方法需要 private static final ReferenceQueue dummyQueue = new ReferenceQueue<>(); //执行清理的具体流程 private final Runnable thunk; static private Cleaner first = null; //Cleaner双向链表，每创建一个Cleaner对象都会添加一个结点 private Cleaner next = null, prev = null; private static synchronized Cleaner add(Cleaner cl) { //添加操作会让新来的变成新的头结点 if (first != null) { cl.next = first; first.prev = cl; } first = cl; return cl; } //可以看到创建鬼引用的对象就是传进的缓冲区对象 private Cleaner(Object referent, Runnable thunk) { super(referent, dummyQueue); //清理流程实际上是外面的Deallocator this.thunk = thunk; } //通过此方法创建一个新的Cleaner public static Cleaner create(Object ob, Runnable thunk) { if (thunk == null) return null; return add(new Cleaner(ob, thunk)); //调用add方法将Cleaner添加到队列 } //清理操作 public void clean() { if (!remove(this)) return; //进行清理操作时会从双向队列中移除当前Cleaner，false说明已经移除过了，直接return try { thunk.run(); //这里就是直接执行具体清理流程 } catch (final Throwable x) { ... } } 那么我们先来看看具体的清理程序在做些什么，Deallocator是在直接缓冲区中声明的： private static class Deallocator implements Runnable { private static Unsafe unsafe = Unsafe.getUnsafe(); private long address; //内存地址 private long size; //大小 private int capacity; //申请的容量 private Deallocator(long address, long size, int capacity) { assert (address != 0); this.address = address; this.size = size; this.capacity = capacity; } public void run() { //具体的清理操作 if (address == 0) { // Paranoia return; } unsafe.freeMemory(address); //这里是直接调用了Unsafe进行内存释放操作 address = 0; //内存地址改为0，NULL Bits.unreserveMemory(size, capacity); //取消一开始的保留内存 } } 好了，现在我们可以明确在清理的时候实际上也是调用Unsafe类进行内存释放操作，那么，这个清理操作具体是在什么时候进行的呢？首先我们要明确，如果是普通的堆缓冲区，由于使用的数组，那么一旦此对象没有任何引用时，就随时都会被GC给回收掉，但是现在是堆外内存，只能我们手动进行内存回收，那么当DirectByteBuffer也失去引用时，会不会触发内存回收呢？ 答案是可以的，还记得我们刚刚看到Cleaner是PhantomReference的子类吗，而DirectByteBuffer是被鬼引用的对象，而具体的清理操作是Cleaner类的clean方法，莫非这两者有什么联系吗？ 你别说，还真有，我们直接看到PhantomReference的父类Reference，我们会发现这样一个类： private static class ReferenceHandler extends Thread { ... static { // 预加载并初始化 InterruptedException 和 Cleaner 类 // 以避免出现在循环运行过程中时由于内存不足而无法加载 ensureClassInitialized(InterruptedException.class); ensureClassInitialized(Cleaner.class); } public void run() { while (true) { tryHandlePending(true); //这里是一个无限循环调用tryHandlePending方法 } } } private T referent; /* 会被GC回收的对象，也就是我们给过来被引用的对象 */ volatile ReferenceQueue queue; //引用队列，可以和下面的next搭配使用，形成链表 //Reference对象也是一个一个连起来的节点，这样才能放到ReferenceQueue中形成链表 volatile Reference next; //即将被GC的引用链表 transient private Reference discovered; /* 由虚拟机操作 */ //pending与discovered一起构成了一个pending单向链表，标记为static类所有，pending为链表的头节点，discovered为链表当前 //Reference节点指向下一个节点的引用，这个队列是由JVM构建的，当对象除了被reference引用之外没有其它强引用了，JVM就会将指向 //需要回收的对象的Reference对象都放入到这个队列里面，这个队列会由下面的 Reference Hander 线程来处理。 private static Reference pending = null; static { //Reference类的静态代码块 ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread handler = new ReferenceHandler(tg, \"Reference Handler\"); //在一开始的时候就会创建 handler.setPriority(Thread.MAX_PRIORITY); //以最高优先级启动 handler.setDaemon(true); //此线程直接作为一个守护线程 handler.start(); //也就是说在一开始的时候这个守护线程就会启动 ... } 那么也就是说Reference Handler线程是在一开始就启动了，那么我们的关注点可以放在tryHandlePending方法上，看看这玩意到底在做个啥： static boolean tryHandlePending(boolean waitForNotify) { Reference r; Cleaner c; try { synchronized (lock) { //加锁办事 //当Cleaner引用的DirectByteBuffer对象即将被回收时，pending会变成此Cleaner对象 //这里判断到pending不为null时就需要处理一下对象销毁了 if (pending != null) { r = pending; // 'instanceof' 有时会导致内存溢出，所以将r从链表中移除之前就进行类型判断 // 如果是Cleaner类型就给到c c = r instanceof Cleaner ? (Cleaner) r : null; // 将pending更新为链表下一个待回收元素 pending = r.discovered; r.discovered = null; //r不再引用下一个节点 } else { //否则就进入等待 if (waitForNotify) { lock.wait(); } return waitForNotify; } } } catch (OutOfMemoryError x) { Thread.yield(); return true; } catch (InterruptedException x) { return true; } // 如果元素是Cleaner类型，c在上面就会被赋值，这里就会执行其clean方法（破案了） if (c != null) { c.clean(); return true; } ReferenceQueue q = r.queue; if (q != ReferenceQueue.NULL) q.enqueue(r); //这个是引用队列，实际上就是我们之前在JVM篇中讲解的入队机制 return true; } 通过对源码的解读，我们就了解了直接缓冲区的内存加载释放整个流程。和堆缓冲区一样，当直接缓冲区没有任何强引用时，就有机会被GC正常回收掉并自动释放申请的内存。 我们接着来看看直接缓冲区的读写操作是如何进行的： public byte get() { return ((unsafe.getByte(ix(nextGetIndex())))); //直接通过Unsafe类读取对应地址上的byte数据 } private long ix(int i) { return address + ((long)i 我们接着来看看写操作： public ByteBuffer put(byte x) { unsafe.putByte(ix(nextPutIndex()), ((x))); return this; } 可以看到无论是读取还是写入操作都是通过Unsafe类操作对应的内存地址完成的。 那么它的复制操作是如何实现的呢？ public ByteBuffer duplicate() { return new DirectByteBuffer(this, this.markValue(), this.position(), this.limit(), this.capacity(), 0); } DirectByteBuffer(DirectBuffer db, // 这里给的db是进行复制操作的DirectByteBuffer对象 int mark, int pos, int lim, int cap, int off) { super(mark, pos, lim, cap); address = db.address() + off; //直接继续使用之前申请的内存空间 cleaner = null; //因为用的是之前的内存空间，已经有对应的Cleaner了，这里不需要再搞一个 att = db; //将att设定为此对象 } 可以看到，如果是进行复制操作，那么会直接会继续使用执行复制操作的DirectByteBuffer申请的内存空间。不知道各位是否能够马上联想到一个问题，我们知道，如果执行复制操作的DirectByteBuffer对象失去了强引用被回收，那么就会触发Cleaner并进行内存释放，但是有个问题就是，这段内存空间可能复制出来的DirectByteBuffer对象还需要继续使用，这时肯定是不能进行回收的，所以说这里使用了att变量将之前的DirectByteBuffer对象进行引用，以防止其失去强引用被垃圾回收，所以只要不是原来的DirectByteBuffer对象和复制出来的DirectByteBuffer对象都失去强引用时，就不会导致这段内存空间被回收。 这样，我们之前的未解之谜为啥有个att也就得到答案了，有关直接缓冲区的介绍，就到这里为止。 通道 前面我们学习了NIO的基石——缓冲区，那么缓冲区具体用在什么地方呢，在本板块我们学习通道之后，相信各位就能知道了。那么，什么是通道呢？ 在传统IO中，我们都是通过流进行传输，数据会源源不断从流中传出；而在NIO中，数据是放在缓冲区中进行管理，再使用通道将缓冲区中的数据传输到目的地。 通道接口层次 通道的根基接口是Channel，所以的派生接口和类都是从这里开始的，我们来看看它定义了哪些基本功能： public interface Channel extends Closeable { //通道是否处于开启状态 public boolean isOpen(); //因为通道开启也需要关闭，所以实现了Closeable接口，所以这个方法懂的都懂 public void close() throws IOException; } 我们接着来看看它的一些子接口，首先是最基本的读写操作： public interface ReadableByteChannel extends Channel { //将通道中的数据读取到给定的缓冲区中 public int read(ByteBuffer dst) throws IOException; } public interface WritableByteChannel extends Channel { //将给定缓冲区中的数据写入到通道中 public int write(ByteBuffer src) throws IOException; } 有了读写功能后，最后整合为了一个ByteChannel接口： public interface ByteChannel extends ReadableByteChannel, WritableByteChannel{ } 在ByteChannel之下，还有更多的派生接口： //允许保留position和更改position的通道，以及对通道连接实体的相关操作 public interface SeekableByteChannel extends ByteChannel { ... //获取当前的position long position() throws IOException; //修改当前的position SeekableByteChannel position(long newPosition) throws IOException; //返回此通道连接到的实体（比如文件）的当前大小 long size() throws IOException; //将此通道连接到的实体截断（比如文件，截断之后，文件后面一半就没了）为给定大小 SeekableByteChannel truncate(long size) throws IOException; } 接着我们来看，除了读写之外，Channel还可以具有响应中断的能力： public interface InterruptibleChannel extends Channel { //当其他线程调用此方法时，在此通道上处于阻塞状态的线程会直接抛出 AsynchronousCloseException 异常 public void close() throws IOException; } //这是InterruptibleChannel的抽象实现，完成了一部分功能 public abstract class AbstractInterruptibleChannel implements Channel, InterruptibleChannel { //加锁关闭操作用到 private final Object closeLock = new Object(); //当前Channel的开启状态 private volatile boolean open = true; protected AbstractInterruptibleChannel() { } //关闭操作实现 public final void close() throws IOException { synchronized (closeLock) { //同时只能有一个线程进行此操作，加锁 if (!open) //如果已经关闭了，那么就不用继续了 return; open = false; //开启状态变成false implCloseChannel(); //开始关闭通道 } } //该方法由 close 方法调用，以执行关闭通道的具体操作，仅当通道尚未关闭时才调用此方法，不会多次调用。 protected abstract void implCloseChannel() throws IOException; public final boolean isOpen() { return open; } //开始阻塞（有可能一直阻塞下去）操作之前，需要调用此方法进行标记， protected final void begin() { ... } //阻塞操作结束之后，也需要需要调用此方法，为了防止异常情况导致此方法没有被调用，建议放在finally中 protected final void end(boolean completed) ... } ... } 而之后的一些实现类，都是基于这些接口定义的方法去进行实现的，比如FileChannel： 这样，我们就大致了解了一下通道相关的接口定义，那么我来看看具体是如何如何使用的。 比如现在我们要实现从输入流中读取数据然后打印出来，那么之前传统IO的写法： public static void main(String[] args) throws IOException { //数组创建好，一会用来存放从流中读取到的数据 byte[] data = new byte[10]; //直接使用输入流 InputStream in = System.in; while (true) { int len; while ((len = in.read(data)) >= 0) { //将输入流中的数据一次性读取到数组中 System.out.print(\"读取到一批数据：\"+new String(data, 0, len)); //读取了多少打印多少 } } } 而现在我们使用通道之后： public static void main(String[] args) throws IOException { //缓冲区创建好，一会就靠它来传输数据 ByteBuffer buffer = ByteBuffer.allocate(10); //将System.in作为输入源，一会Channel就可以从这里读取数据，然后通过缓冲区装载一次性传递数据 ReadableByteChannel readChannel = Channels.newChannel(System.in); while (true) { //将通道中的数据写到缓冲区中，缓冲区最多一次装10个 readChannel.read(buffer); //写入操作结束之后，需要进行翻转，以便接下来的读取操作 buffer.flip(); //最后转换成String打印出来康康 System.out.println(\"读取到一批数据：\"+new String(buffer.array(), 0, buffer.remaining())); //回到最开始的状态 buffer.clear(); } } 乍一看，好像感觉也没啥区别，不就是把数组换成缓冲区了吗，效果都是一样的，数据也是从Channel中读取得到，并且通过缓冲区进行数据装载然后得到结果，但是，Channel不像流那样是单向的，它就像它的名字一样，一个通道可以从一端走到另一端，也可以从另一端走到这一端，我们后面进行介绍。 文件传输FileChannel 前面我们介绍了通道的基本情况，这里我们就来尝试实现一下文件的读取和写入，在传统IO中，文件的写入和输出都是依靠FileOutputStream和FileInputStream来完成的： public static void main(String[] args) throws IOException { try(FileOutputStream out = new FileOutputStream(\"test.txt\"); FileInputStream in = new FileInputStream(\"test.txt\")){ String data = \"伞兵一号卢本伟准备就绪！\"; out.write(data.getBytes()); //向文件的输出流中写入数据，也就是把数据写到文件中 out.flush(); byte[] bytes = new byte[in.available()]; in.read(bytes); //从文件的输入流中读取文件的信息 System.out.println(new String(bytes)); } } 而现在，我们只需要通过一个FileChannel就可以完成这两者的操作，获取文件通道的方式有以下几种： public static void main(String[] args) throws IOException { //1. 直接通过输入或输出流获取对应的通道 FileInputStream in = new FileInputStream(\"test.txt\"); //但是这里的通道只支持读取或是写入操作 FileChannel channel = in.getChannel(); //创建一个容量为128的缓冲区 ByteBuffer buffer = ByteBuffer.allocate(128); //从通道中将数据读取到缓冲区中 channel.read(buffer); //翻转一下，接下来要读取了 buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.remaining())); } 可以看到通过输入流获取的文件通道读取是没有任何问题的，但是写入操作： public static void main(String[] args) throws IOException { //1. 直接通过输入或输出流获取对应的通道 FileInputStream in = new FileInputStream(\"test.txt\"); //但是这里的通道只支持读取或是写入操作 FileChannel channel = in.getChannel(); //尝试写入一下 channel.write(ByteBuffer.wrap(\"伞兵一号卢本伟准备就绪！\".getBytes())); } 直接报错，说明只支持读取操作，那么输出流呢？ public static void main(String[] args) throws IOException { //1. 直接通过输入或输出流获取对应的通道 FileOutputStream out = new FileOutputStream(\"test.txt\"); //但是这里的通道只支持读取或是写入操作 FileChannel channel = out.getChannel(); //尝试写入一下 channel.write(ByteBuffer.wrap(\"伞兵一号卢本伟准备就绪！\".getBytes())); } 可以看到能够正常进行写入，但是读取呢？ public static void main(String[] args) throws IOException { //1. 直接通过输入或输出流获取对应的通道 FileOutputStream out = new FileOutputStream(\"test.txt\"); //但是这里的通道只支持读取或是写入操作 FileChannel channel = out.getChannel(); ByteBuffer buffer = ByteBuffer.allocate(128); //从通道中将数据读取到缓冲区中 channel.read(buffer); //翻转一下，接下来要读取了 buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.remaining())); } 可以看到输出流生成的Channel又不支持读取，所以说本质上还是保持着输入输出流的特性，但是之前不是说Channel又可以输入又可以输出吗？这里我们来看看第二种方式： //RandomAccessFile能够支持文件的随机访问，并且实现了数据流 public class RandomAccessFile implements DataOutput, DataInput, Closeable { 我们可以通过RandomAccessFile来创建通道： public static void main(String[] args) throws IOException { /* 通过RandomAccessFile进行创建，注意后面的mode有几种： r 以只读的方式使用 rw 读操作和写操作都可以 rws 每当进行写操作，同步的刷新到磁盘，刷新内容和元数据 rwd 每当进行写操作，同步的刷新到磁盘，刷新内容 */ try(RandomAccessFile f = new RandomAccessFile(\"test.txt\", \"\")){ } } 现在我们来测试一下它的读写操作： public static void main(String[] args) throws IOException { /* 通过RandomAccessFile进行创建，注意后面的mode有几种： r 以只读的方式使用 rw 读操作和写操作都可以 rws 每当进行写操作，同步的刷新到磁盘，刷新内容和元数据 rwd 每当进行写操作，同步的刷新到磁盘，刷新内容 */ try(RandomAccessFile f = new RandomAccessFile(\"test.txt\", \"rw\"); //这里设定为支持读写，这样创建的通道才能具有这些功能 FileChannel channel = f.getChannel()){ //通过RandomAccessFile创建一个通道 channel.write(ByteBuffer.wrap(\"伞兵二号马飞飞准备就绪！\".getBytes())); System.out.println(\"写操作完成之后文件访问位置：\"+channel.position()); //注意读取也是从现在的位置开始 channel.position(0); //需要将位置变回到最前面，这样下面才能从文件的最开始进行读取 ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.remaining())); } } 可以看到，一个FileChannel既可以完成文件读取，也可以完成文件的写入。 除了基本的读写操作，我们也可以直接对文件进行截断： public static void main(String[] args) throws IOException { try(RandomAccessFile f = new RandomAccessFile(\"test.txt\", \"rw\"); FileChannel channel = f.getChannel()){ //截断文件，只留前20个字节 channel.truncate(20); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.remaining())); } } 可以看到文件的内容直接被截断了，文件内容就只剩一半了。 当然，如果我们要进行文件的拷贝，也是很方便的，只需要使用通道就可以，比如我们现在需要将一个通道的数据写入到另一个通道，就可以直接使用transferTo方法： public static void main(String[] args) throws IOException { try(FileOutputStream out = new FileOutputStream(\"test2.txt\"); FileInputStream in = new FileInputStream(\"test.txt\")){ FileChannel inChannel = in.getChannel(); //获取到test文件的通道 inChannel.transferTo(0, inChannel.size(), out.getChannel()); //直接将test文件通道中的数据转到test2文件的通道中 } } 可以看到执行后，文件的内容全部被复制到另一个文件了。 当然，反向操作也是可以的： public static void main(String[] args) throws IOException { try(FileOutputStream out = new FileOutputStream(\"test2.txt\"); FileInputStream in = new FileInputStream(\"test.txt\")){ FileChannel inChannel = in.getChannel(); //获取到test文件的通道 out.getChannel().transferFrom(inChannel, 0, inChannel.size()); //直接将从test文件通道中传来的数据转给test2文件的通道 } } 当我们要编辑某个文件时，通过使用MappedByteBuffer类，可以将其映射到内存中进行编辑，编辑的内容会同步更新到文件中： //注意一定要是可写的，不然无法进行修改操作 try(RandomAccessFile f = new RandomAccessFile(\"test.txt\", \"rw\"); FileChannel channel = f.getChannel()){ //通过map方法映射文件的某一段内容，创建MappedByteBuffer对象 //比如这里就是从第四个字节开始，映射10字节内容到内存中 //注意这里需要使用MapMode.READ_WRITE模式，其他模式无法保存数据到文件 MappedByteBuffer buffer = channel.map(FileChannel.MapMode.READ_WRITE, 4, 10); //我们可以直接对在内存中的数据进行编辑，也就是编辑Buffer中的内容 //注意这里写入也是从pos位置开始的，默认是从0开始，相对于文件就是从第四个字节开始写 //注意我们只映射了10个字节，也就是写的内容不能超出10字节了 buffer.put(\"yyds\".getBytes()); //编辑完成后，通过force方法将数据写回文件的映射区域 buffer.force(); } 可以看到，文件的某一个区域已经被我们修改了，并且这里实际上使用的就是DirectByteBuffer直接缓冲区，效率还是很高的。 文件锁FileLock 我们可以创建一个跨进程文件锁来防止多个进程之间的文件争抢操作（注意这里是进程，不是线程）FileLock是文件锁，它能保证同一时间只有一个进程（程序）能够修改它，或者都只可以读，这样就解决了多进程间的同步文件，保证了安全性。但是需要注意的是，它进程级别的，不是线程级别的，他可以解决多个进程并发访问同一个文件的问题，但是它不适用于控制同一个进程中多个线程对一个文件的访问。 那么我们来看看如何使用文件锁： public static void main(String[] args) throws IOException, InterruptedException { //创建RandomAccessFile对象，并拿到Channel RandomAccessFile f = new RandomAccessFile(\"test.txt\", \"rw\"); FileChannel channel = f.getChannel(); System.out.println(new Date() + \" 正在尝试获取文件锁...\"); //接着我们直接使用lock方法进行加锁操作（如果其他进程已经加锁，那么会一直阻塞在这里） //加锁操作支持对文件的某一段进行加锁，比如这里就是从0开始后的6个字节加锁，false代表这是一把独占锁 //范围锁甚至可以提前加到一个还未写入的位置上 FileLock lock = channel.lock(0, 6, false); System.out.println(new Date() + \" 已获取到文件锁！\"); Thread.sleep(5000); //假设要处理5秒钟 System.out.println(new Date() + \" 操作完毕，释放文件锁！\"); //操作完成之后使用release方法进行锁释放 lock.release(); } 有关共享锁和独占锁： 进程对文件加独占锁后，当前进程对文件可读可写，独占此文件，其它进程是不能读该文件进行读写操作的。 进程对文件加共享锁后，进程可以对文件进行读操作，但是无法进行写操作，共享锁可以被多个进程添加，但是只要存在共享锁，就不能添加独占锁。 现在我们来启动两个进程试试看，我们需要在IDEA中配置一下两个启动项： 现在我们依次启动它们： 可以看到确实是两个进程同一时间只能有一个进行访问，而另一个需要等待锁释放。 那么如果我们申请的是文件的不同部分呢？ //其中一个进程锁 0 - 5 FileLock lock = channel.lock(0, 6, false); //另一个进程锁 6 - 11 FileLock lock = channel.lock(6, 6, false); 可以看到，两个进程这时就可以同时进行加锁操作了，因为它们锁的是不同的段落。 那么要是交叉呢？ //其中一个进程锁 0 - 5 FileLock lock = channel.lock(0, 6, false); //另一个进程锁 3 - 8 FileLock lock = channel.lock(3, 6, false); 可以看到交叉的情况下也是会出现阻塞的。 接着我们来看看共享锁，共享锁允许多个进程同时加锁，但是不能进行写操作： public static void main(String[] args) throws IOException, InterruptedException { RandomAccessFile f = new RandomAccessFile(\"test.txt\", \"rw\"); FileChannel channel = f.getChannel(); System.out.println(new Date() + \" 正在尝试获取文件锁...\"); //现在使用共享锁 FileLock lock = channel.lock(0, Long.MAX_VALUE, true); System.out.println(new Date() + \" 已获取到文件锁！\"); //进行写操作 channel.write(ByteBuffer.wrap(new Date().toString().getBytes())); System.out.println(new Date() + \" 操作完毕，释放文件锁！\"); //操作完成之后使用release方法进行锁释放 lock.release(); } 当我们进行写操作时： 可以看到直接抛出异常，说另一个程序已锁定文件的一部分，进程无法访问（某些系统或是环境实测无效，比如UP主的arm架构MacOS就不生效，这个异常是在Windows环境下运行得到的） 当然，我们也可以测试一下多个进行同时加共享锁： public static void main(String[] args) throws IOException, InterruptedException { RandomAccessFile f = new RandomAccessFile(\"test.txt\", \"rw\"); FileChannel channel = f.getChannel(); System.out.println(new Date() + \" 正在尝试获取文件锁...\"); FileLock lock = channel.lock(0, Long.MAX_VALUE, true); System.out.println(new Date() + \" 已获取到文件锁！\"); Thread.sleep(5000); //假设要处理5秒钟 System.out.println(new Date() + \" 操作完毕，释放文件锁！\"); lock.release(); } 可以看到结果是多个进程都能加共享锁： 当然，除了直接使用lock()方法进行加锁之外，我们也可以使用tryLock()方法以非阻塞方式获取文件锁，但是如果获取锁失败会得到null： public static void main(String[] args) throws IOException, InterruptedException { RandomAccessFile f = new RandomAccessFile(\"test.txt\", \"rw\"); FileChannel channel = f.getChannel(); System.out.println(new Date() + \" 正在尝试获取文件锁...\"); FileLock lock = channel.tryLock(0, Long.MAX_VALUE, false); System.out.println(lock); Thread.sleep(5000); //假设要处理5秒钟 lock.release(); } 可以看到，两个进程都去尝试获取独占锁： 第一个成功加锁的进程获得了对应的锁对象，而第二个进程直接得到的是null。 到这里，有关文件锁的相关内容就差不多了。 多路复用网络通信 前面我们已经介绍了NIO框架的两大核心：Buffer和Channel，我们接着来看看最后一个内容。 传统阻塞I/O网络通信 说起网络通信，相信各位并不陌生，正是因为网络的存在我们才能走进现代化的社会，在JavaWeb阶段，我们学习了如何使用Socket建立TCP连接进行网络通信： public static void main(String[] args) { try(ServerSocket server = new ServerSocket(8080)){ //将服务端创建在端口8080上 System.out.println(\"正在等待客户端连接...\"); Socket socket = server.accept(); System.out.println(\"客户端已连接，IP地址为：\"+socket.getInetAddress().getHostAddress()); BufferedReader reader = new BufferedReader(new InputStreamReader(socket.getInputStream())); //通过 System.out.print(\"接收到客户端数据：\"); System.out.println(reader.readLine()); OutputStreamWriter writer = new OutputStreamWriter(socket.getOutputStream()); writer.write(\"已收到！\"); writer.flush(); }catch (IOException e){ e.printStackTrace(); } } public static void main(String[] args) { try (Socket socket = new Socket(\"localhost\", 8080); Scanner scanner = new Scanner(System.in)){ System.out.println(\"已连接到服务端！\"); OutputStream stream = socket.getOutputStream(); OutputStreamWriter writer = new OutputStreamWriter(stream); //通过转换流来帮助我们快速写入内容 System.out.println(\"请输入要发送给服务端的内容：\"); String text = scanner.nextLine(); writer.write(text+'\\n'); //因为对方是readLine()这里加个换行符 writer.flush(); System.out.println(\"数据已发送：\"+text); BufferedReader reader = new BufferedReader(new InputStreamReader(socket.getInputStream())); System.out.println(\"收到服务器返回：\"+reader.readLine()); }catch (IOException e){ System.out.println(\"服务端连接失败！\"); e.printStackTrace(); }finally { System.out.println(\"客户端断开连接！\"); } } 当然，我们也可以使用前面讲解的通道来进行通信： public static void main(String[] args) { //创建一个新的ServerSocketChannel，一会直接使用SocketChannel进行网络IO操作 try (ServerSocketChannel serverChannel = ServerSocketChannel.open()){ //依然是将其绑定到8080端口 serverChannel.bind(new InetSocketAddress(8080)); //同样是调用accept()方法，阻塞等待新的连接到来 SocketChannel socket = serverChannel.accept(); //因为是通道，两端的信息都是可以明确的，这里获取远端地址，当然也可以获取本地地址 System.out.println(\"客户端已连接，IP地址为：\"+socket.getRemoteAddress()); //使用缓冲区进行数据接收 ByteBuffer buffer = ByteBuffer.allocate(128); socket.read(buffer); //SocketChannel同时实现了读写通道接口，所以可以直接进行双向操作 buffer.flip(); System.out.print(\"接收到客户端数据：\"+new String(buffer.array(), 0, buffer.remaining())); //直接向通道中写入数据就行 socket.write(ByteBuffer.wrap(\"已收到！\".getBytes())); //记得关 socket.close(); } catch (IOException e) { throw new RuntimeException(e); } } public static void main(String[] args) { //创建一个新的SocketChannel，一会通过通道进行通信 try (SocketChannel channel = SocketChannel.open(new InetSocketAddress(\"localhost\", 8080)); Scanner scanner = new Scanner(System.in)){ System.out.println(\"已连接到服务端！\"); System.out.println(\"请输入要发送给服务端的内容：\"); String text = scanner.nextLine(); //直接向通道中写入数据，真舒服 channel.write(ByteBuffer.wrap(text.getBytes())); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); //直接从通道中读取数据 buffer.flip(); System.out.println(\"收到服务器返回：\"+new String(buffer.array(), 0, buffer.remaining())); } catch (IOException e) { throw new RuntimeException(e); } } 虽然可以通过传统的Socket进行网络通信，但是我们发现，如果要进行IO操作，我们需要单独创建一个线程来进行处理，比如现在有很多个客户端，服务端需要同时进行处理，那么如果我们要处理这些客户端的请求，那么我们就只能单独为其创建一个线程来进行处理： 虽然这样看起来比较合理，但是随着客户端数量的增加，如果要保持持续通信，那么就不能摧毁这些线程，而是需要一直保留（但是实际上很多时候只是保持连接，一直在阻塞等待客户端的读写操作，IO操作的频率很低，这样就白白占用了一条线程，很多时候都是站着茅坑不拉屎），但是我们的线程不可能无限制的进行创建，总有一天会耗尽服务端的资源，那么现在怎么办呢，关键是现在又有很多客户端源源不断地连接并进行操作，这时，我们就可以利用NIO为我们提供的多路复用编程模型。 我们来看看NIO为我们提供的模型： 服务端不再是一个单纯通过accept()方法来创建连接的机制了，而是根据客户端不同的状态，Selector会不断轮询，只有客户端在对应的状态时，比如真正开始读写操作时，才会创建线程或进行处理（这样就不会一直阻塞等待某个客户端的IO操作了），而不是创建之后需要一直保持连接，即使没有任何的读写操作。这样就不会因为占着茅坑不拉屎导致线程无限制地创建下去了。 通过这种方式，甚至单线程都能做到高效的复用，最典型的例子就是Redis了，因为内存的速度非常快，多线程上下文的开销就会显得有些拖后腿，还不如直接单线程简单高效，这也是为什么Redis单线程也能这么快的原因。 因此，我们就从NIO框架的第三个核心内容：Selector，开始讲起。 选择器与I/O多路复用 前面我们大概了解了一下选择器，我们知道，选择器是当具体有某一个状态（比如读、写、请求）已经就绪时，才会进行处理，而不是让我们的程序主动地进行等待。 既然我们现在需要实现IO多路复用，那么我们来看看常见的IO多路复用模型，也就是Selector的实现方案，比如现在有很多个用户连接到我们的服务器： select：当这些连接出现具体的某个状态时，只是知道已经就绪了，但是不知道详具体是哪一个连接已经就绪，每次调用都进行线性遍历所有连接，时间复杂度为O(n)，并且存在最大连接数限制。 poll：同上，但是由于底层采用链表，所以没有最大连接数限制。 epoll：采用事件通知方式，当某个连接就绪，能够直接进行精准通知（这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的，只要就绪会会直接回调callback函数，实现精准通知，但是只有Linux支持这种方式），时间复杂度O(1)，Java在Linux环境下正是采用的这种模式进行实现的。 好了，既然多路复用模型了解完毕了，那么我们就来看看如何让我们的网络通信实现多路复用： public static void main(String[] args) { try (ServerSocketChannel serverChannel = ServerSocketChannel.open(); Selector selector = Selector.open()){ //开启一个新的Selector，这玩意也是要关闭释放资源的 serverChannel.bind(new InetSocketAddress(8080)); //要使用选择器进行操作，必须使用非阻塞的方式，这样才不会像阻塞IO那样卡在accept()，而是直接通过，让选择器去进行下一步操作 serverChannel.configureBlocking(false); //将选择器注册到ServerSocketChannel中，后面是选择需要监听的时间，只有发生对应事件时才会进行选择，多个事件用 | 连接，注意，并不是所有的Channel都支持以下全部四个事件，可能只支持部分 //因为是ServerSocketChannel这里我们就监听accept就可以了，等待客户端连接 //SelectionKey.OP_CONNECT --- 连接就绪事件，表示客户端与服务器的连接已经建立成功 //SelectionKey.OP_ACCEPT --- 接收连接事件，表示服务器监听到了客户连接，服务器可以接收这个连接了 //SelectionKey.OP_READ --- 读 就绪事件，表示通道中已经有了可读的数据，可以执行读操作了 //SelectionKey.OP_WRITE --- 写 就绪事件，表示已经可以向通道写数据了（这玩意比较特殊，一般情况下因为都是可以写入的，所以可能会无限循环） serverChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { //无限循环等待新的用户网络操作 //每次选择都可能会选出多个已经就绪的网络操作，没有操作时会暂时阻塞 int count = selector.select(); System.out.println(\"监听到 \"+count+\" 个事件\"); Set selectionKeys = selector.selectedKeys(); Iterator iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); //根据不同的事件类型，执行不同的操作即可 if(key.isAcceptable()) { //如果当前ServerSocketChannel已经做好准备处理Accept SocketChannel channel = serverChannel.accept(); System.out.println(\"客户端已连接，IP地址为：\"+channel.getRemoteAddress()); //现在连接就建立好了，接着我们需要将连接也注册选择器，比如我们需要当这个连接有内容可读时就进行处理 channel.configureBlocking(false); channel.register(selector, SelectionKey.OP_READ); //这样就在连接建立时完成了注册 } else if(key.isReadable()) { //如果当前连接有可读的数据并且可以写，那么就开始处理 SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); buffer.flip(); System.out.println(\"接收到客户端数据：\"+new String(buffer.array(), 0, buffer.remaining())); //直接向通道中写入数据就行 channel.write(ByteBuffer.wrap(\"已收到！\".getBytes())); //别关，说不定用户还要继续通信呢 } //处理完成后，一定记得移出迭代器，不然下次还有 iterator.remove(); } } } catch (IOException e) { throw new RuntimeException(e); } } 接着我们来编写一下客户客户端： public static void main(String[] args) { //创建一个新的SocketChannel，一会通过通道进行通信 try (SocketChannel channel = SocketChannel.open(new InetSocketAddress(\"localhost\", 8080)); Scanner scanner = new Scanner(System.in)){ System.out.println(\"已连接到服务端！\"); while (true) { //咱给它套个无限循环，这样就能一直发消息了 System.out.println(\"请输入要发送给服务端的内容：\"); String text = scanner.nextLine(); //直接向通道中写入数据，真舒服 channel.write(ByteBuffer.wrap(text.getBytes())); System.out.println(\"已发送！\"); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); //直接从通道中读取数据 buffer.flip(); System.out.println(\"收到服务器返回：\"+new String(buffer.array(), 0, buffer.remaining())); } } catch (IOException e) { throw new RuntimeException(e); } } 我们来看看效果： 可以看到成功实现了，当然各位也可以跟自己的室友一起开客户端进行测试，现在，我们只用了一个线程，就能够同时处理多个请求，可见多路复用是多么重要。 实现Reactor模式 前面我们简单实现了多路复用网络通信，我们接着来了解一下Reactor模式，对我们的服务端进行优化。 现在我们来看看如何进行优化，我们首先抽象出两个组件，Reactor线程和Handler处理器： Reactor线程：负责响应IO事件，并分发到Handler处理器。新的事件包含连接建立就绪、读就绪、写就绪等。 Handler处理器：执行非阻塞的操作。 实际上我们之前编写的算是一种单线程Reactor的朴素模型（面向过程的写法），我们来看看标准的写法： 客户端还是按照我们上面的方式连接到Reactor，并通过选择器走到Acceptor或是Handler，Acceptor主要负责客户端连接的建立，Handler负责读写操作，代码如下，首先是Handler： public class Handler implements Runnable{ private final SocketChannel channel; public Handler(SocketChannel channel) { this.channel = channel; } @Override public void run() { try { ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); buffer.flip(); System.out.println(\"接收到客户端数据：\"+new String(buffer.array(), 0, buffer.remaining())); channel.write(ByteBuffer.wrap(\"已收到！\".getBytes())); }catch (IOException e){ e.printStackTrace(); } } } 接着是Acceptor，实际上就是把上面的业务代码搬个位置罢了： /** * Acceptor主要用于处理连接操作 */ public class Acceptor implements Runnable{ private final ServerSocketChannel serverChannel; private final Selector selector; public Acceptor(ServerSocketChannel serverChannel, Selector selector) { this.serverChannel = serverChannel; this.selector = selector; } @Override public void run() { try{ SocketChannel channel = serverChannel.accept(); System.out.println(\"客户端已连接，IP地址为：\"+channel.getRemoteAddress()); channel.configureBlocking(false); //这里在注册时，创建好对应的Handler，这样在Reactor中分发的时候就可以直接调用Handler了 channel.register(selector, SelectionKey.OP_READ, new Handler(channel)); }catch (IOException e){ e.printStackTrace(); } } } 这里我们在注册时丢了一个附加对象进去，这个附加对象会在选择器选择到此通道上时，可以通过attachment()方法进行获取，对于我们简化代码有大作用，一会展示，我们接着来看看Reactor： public class Reactor implements Closeable, Runnable{ private final ServerSocketChannel serverChannel; private final Selector selector; public Reactor() throws IOException{ serverChannel = ServerSocketChannel.open(); selector = Selector.open(); } @Override public void run() { try { serverChannel.bind(new InetSocketAddress(8080)); serverChannel.configureBlocking(false); //注册时，将Acceptor作为附加对象存放，当选择器选择后也可以获取到 serverChannel.register(selector, SelectionKey.OP_ACCEPT, new Acceptor(serverChannel, selector)); while (true) { int count = selector.select(); System.out.println(\"监听到 \"+count+\" 个事件\"); Set selectionKeys = selector.selectedKeys(); Iterator iterator = selectionKeys.iterator(); while (iterator.hasNext()) { this.dispatch(iterator.next()); //通过dispatch方法进行分发 iterator.remove(); } } }catch (IOException e) { e.printStackTrace(); } } //通过此方法进行分发 private void dispatch(SelectionKey key){ Object att = key.attachment(); //获取attachment，ServerSocketChannel和对应的客户端Channel都添加了的 if(att instanceof Runnable) { ((Runnable) att).run(); //由于Handler和Acceptor都实现自Runnable接口，这里就统一调用一下 } //这样就实现了对应的时候调用对应的Handler或是Acceptor了 } //用了记得关，保持好习惯，就像看完视频要三连一样 @Override public void close() throws IOException { serverChannel.close(); selector.close(); } } 最后我们编写一下主类： public static void main(String[] args) { //创建Reactor对象，启动，完事 try (Reactor reactor = new Reactor()){ reactor.run(); }catch (IOException e) { e.printStackTrace(); } } 这样，我们就实现了单线程Reactor模式，注意全程使用到的都只是一个线程，没有创建新的线程来处理任何事情。 但是单线程始终没办法应对大量的请求，如果请求量上去了，单线程还是很不够用，接着我们来看看多线程Reactor模式，它创建了多个线程处理，我们可以将数据读取完成之后的操作交给线程池来执行： 其实我们只需要稍微修改一下Handler就行了： public class Handler implements Runnable{ //把线程池给安排了，10个线程 private static final ExecutorService POOL = Executors.newFixedThreadPool(10); private final SocketChannel channel; public Handler(SocketChannel channel) { this.channel = channel; } @Override public void run() { try { ByteBuffer buffer = ByteBuffer.allocate(1024); channel.read(buffer); buffer.flip(); POOL.submit(() -> { try { System.out.println(\"接收到客户端数据：\"+new String(buffer.array(), 0, buffer.remaining())); channel.write(ByteBuffer.wrap(\"已收到！\".getBytes())); }catch (IOException e){ e.printStackTrace(); } }); } catch (IOException e) { throw new RuntimeException(e); } } } 这样，在数据读出之后，就可以将数据处理交给线程池执行。 但是这样感觉还是划分的不够，一个Reactor需要同时处理来自客户端的所有操作请求，显得有些乏力，那么不妨我们将Reactor做成一主多从的模式，让主Reactor只负责Accept操作，而其他的Reactor进行各自的其他操作： 现在我们来重新设计一下我们的代码，Reactor类就作为主节点，不进行任何修改，我们来修改一下其他的： //SubReactor作为从Reactor public class SubReactor implements Runnable, Closeable { //每个从Reactor也有一个Selector private final Selector selector; //创建一个4线程的线程池，也就是四个从Reactor工作 private static final ExecutorService POOL = Executors.newFixedThreadPool(4); private static final SubReactor[] reactors = new SubReactor[4]; private static int selectedIndex = 0; //采用轮询机制，每接受一个新的连接，就轮询分配给四个从Reactor static { //在一开始的时候就让4个从Reactor跑起来 for (int i = 0; i > 监听到 \"+count+\" 个事件\"); Set selectionKeys = selector.selectedKeys(); Iterator iterator = selectionKeys.iterator(); while (iterator.hasNext()) { this.dispatch(iterator.next()); iterator.remove(); } } }catch (IOException e) { e.printStackTrace(); } } private void dispatch(SelectionKey key){ Object att = key.attachment(); if(att instanceof Runnable) { ((Runnable) att).run(); } } @Override public void close() throws IOException { selector.close(); } } 我们接着来修改一下Acceptor类： public class Acceptor implements Runnable{ private final ServerSocketChannel serverChannel; //只需要一个ServerSocketChannel就行了 public Acceptor(ServerSocketChannel serverChannel) { this.serverChannel = serverChannel; } @Override public void run() { try{ SocketChannel channel = serverChannel.accept(); //还是正常进行Accept操作，得到SocketChannel System.out.println(Thread.currentThread().getName()+\" >> 客户端已连接，IP地址为：\"+channel.getRemoteAddress()); channel.configureBlocking(false); Selector selector = SubReactor.nextSelector(); //选取下一个从Reactor的Selector selector.wakeup(); //在注册之前唤醒一下防止卡死 channel.register(selector, SelectionKey.OP_READ, new Handler(channel)); //注意现在注册的是从Reactor的Selector }catch (IOException e){ e.printStackTrace(); } } } 现在，SocketChannel相关的操作就由从Reactor进行处理了，而不是一律交给主Reactor进行操作。 至此，我们已经了解了NIO的三大组件：Buffer、Channel、Selector，有关NIO基础相关的内容，就讲解到这里。下一章我们将继续讲解基于NIO实现的高性能网络通信框架Netty。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/NIO/Java NIO（一）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/NIO/Java NIO（一）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/NIO/Java NIO（二）.html":{"url":"Java/NIO/Java NIO（二）.html","title":"Java NIO（二）","keywords":"","body":"Netty框架 前面我们学习了Java为我们提供的NIO框架，提供使用NIO提供的三大组件，我们就可以编写更加高性能的客户端/服务端网络程序了，甚至还可以自行规定一种通信协议进行通信。 NIO框架存在的问题 但是之前我们在使用NIO框架的时候，还是发现了一些问题，我们先来盘点一下。 客户端关闭导致服务端空轮询 可能在之前的实验中，你发现了这样一个问题： 当我们的客户端主动与服务端断开连接时，会导致READ事件一直被触发，也就是说selector.select()会直接通过，并且是可读的状态，但是我们发现实际上读到是数据是一个空的（上面的图中在空轮询两次后抛出异常了，也有可能是无限的循环下去）所以这里我们得稍微处理一下： } else if(key.isReadable()) { SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(128); //这里我们需要判断一下，如果read操作得到的结果是-1，那么说明服务端已经断开连接了 if(channel.read(buffer) 这样，我们就可以在客户端主动断开时关闭连接了： 当然，除了这种情况可能会导致空轮询之外，实际上还有一种可能，这种情况是NIO框架本身的BUG： while (true) { int count = selector.select(); //由于底层epoll机制的问题，导致select方法可能会一直返回0，造成无限循环的情况。 System.out.println(\"监听到 \"+count+\" 个事件\"); Set selectionKeys = selector.selectedKeys(); Iterator iterator = selectionKeys.iterator(); 详细请看JDK官方BUG反馈： JDK-6670302 : (se) NIO selector wakes up with 0 selected keys infinitely JDK-6403933 : (se) Selector doesn't block on Selector.select(timeout) (lnx) 本质原因也是因为客户端的主动断开导致： This is an issue with poll (and epoll) on Linux. If a file descriptor for a connected socket is polled with a request event mask of 0, and if the connection is abruptly terminated (RST) then the poll wakes up with the POLLHUP (and maybe POLLERR) bit set in the returned event set. The implication of this behaviour is that Selector will wakeup and as the interest set for the SocketChannel is 0 it means there aren't any selected events and the select method returns 0. 这个问题本质是与操作系统有关的，所以JDK一直都认为是操作系统的问题，不应该由自己来处理，所以这个问题在当时的好几个JDK版本都是存在的，这是一个很严重的空转问题，无限制地进行空转操作会导致CPU资源被疯狂消耗。 不过，这个问题，却被Netty框架巧妙解决了，我们后面再说。 粘包/拆包问题 除了上面的问题之外，我们接着来看下一个问题。 我们在计算机网络这门课程中学习过，操作系统通过TCP协议发送数据的时候，也会先将数据存放在缓冲区中，而至于什么时候真正地发出这些数据，是由TCP协议来决定的，这是我们无法控制的事情。 也就是说，比如现在我们要发送两个数据包（P1/P2），理想情况下，这两个包应该是依次到达服务端，并由服务端正确读取两次数据出来，但是由于上面的机制，可能会出现下面的情况： 可能P1和P2被合在一起发送给了服务端（粘包现象） 可能P1和P2的前半部分合在一起发送给了服务端（拆包现象） 可能P1的前半部分就被单独作为一个部分发给了服务端，后面的和P2一起发给服务端（也是拆包现象） 当然，对于这种问题，也有一些比较常见的解决方案： 消息定长，发送方和接收方规定固定大小的消息长度，例如每个数据包大小固定为200字节，如果不够，空位补空格，只有接收了200个字节之后，作为一个完整的数据包进行处理。 在每个包的末尾使用固定的分隔符，比如每个数据包末尾都是\\r\\n，这样就一定需要读取到这样的分隔符才能将前面所有的数据作为一个完整的数据包进行处理。 将消息分为头部和本体，在头部中保存有当前整个数据包的长度，只有在读到足够长度之后才算是读到了一个完整的数据包。 这里我们就来演示一下第一种解决方案： public static void main(String[] args) { try (ServerSocketChannel serverChannel = ServerSocketChannel.open(); Selector selector = Selector.open()){ serverChannel.bind(new InetSocketAddress(8080)); serverChannel.configureBlocking(false); serverChannel.register(selector, SelectionKey.OP_ACCEPT); //一个数据包要求必须塞满30个字节 ByteBuffer buffer = ByteBuffer.allocate(30); while (true) { int count = selector.select(); Set selectionKeys = selector.selectedKeys(); Iterator iterator = selectionKeys.iterator(); while (iterator.hasNext()) { ... if(buffer.remaining() == 0) { buffer.flip(); System.out.println(\"接收到客户端数据：\"+new String(buffer.array(), 0, buffer.remaining())); buffer.clear(); } channel.write(ByteBuffer.wrap((\"已收到 \"+size+\" 字节的数据！\").getBytes())); } ... 现在，当我们的客户端发送消息时，如果没有达到30个字节，那么会暂时存储起来，等有30个之后再一次性得到，当然如果数据量超过了30，那么最多也只会读取30个字节，其他的放在下一批： 这样就可以在一定程度上解决粘包/拆包问题了。 走进Netty框架 前面我们盘点了一下NIO存在的一些问题，而在Netty框架中，这些问题都被巧妙的解决了。 Netty是由JBOSS提供的一个开源的java网络编程框架，主要是对java的nio包进行了再次封装。Netty比java原生的nio包提供了更加强大、稳定的功能和易于使用的api。 netty的作者是Trustin Lee，这是一个韩国人，他还开发了另外一个著名的网络编程框架，mina。二者在很多方面都十分相似，它们的线程模型也是基本一致 。不过netty社区的活跃程度要mina高得多。 Netty实际上应用场景非常多，比如我们的Minecraft游戏服务器： Java版本的Minecraft服务器就是使用Netty框架作为网络通信的基础，正是得益于Netty框架的高性能，我们才能愉快地和其他的小伙伴一起在服务器里面炸服。 学习了Netty框架后，说不定你也可以摸索到部分Minecraft插件/模组开发的底层细节（太折磨了，UP主高中搞了大半年这玩意） 当然除了游戏服务器之外，我们微服务之间的远程调用也可以使用Netty来完成，比如Dubbo的RPC框架，包括最新的SpringWebFlux框架，也抛弃了内嵌Tomcat而使用Netty作为通信框架。既然Netty这么强大，那么现在我们就开始Netty的学习吧！ 导包先： io.netty netty-all 4.1.76.Final ByteBuf介绍 Netty并没有使用NIO中提供的ByteBuffer来进行数据装载，而是自行定义了一个ByteBuf类。 那么这个类相比NIO中的ByteBuffer有什么不同之处呢？ 写操作完成后无需进行flip()翻转。 具有比ByteBuffer更快的响应速度。 动态扩容。 首先我们来看看它的内部结构： public abstract class AbstractByteBuf extends ByteBuf { ... int readerIndex; //index被分为了读和写，是两个指针在同时工作 int writerIndex; private int markedReaderIndex; //mark操作也分两种 private int markedWriterIndex; private int maxCapacity; //最大容量，没错，这玩意能动态扩容 可以看到，读操作和写操作分别由两个指针在进行维护，每写入一次，writerIndex向后移动一位，每读取一次，也是readerIndex向后移动一位，当然readerIndex不能大于writerIndex，这样就不会像NIO中的ByteBuffer那样还需要进行翻转了。 其中readerIndex和writerIndex之间的部分就是是可读的内容，而writerIndex之后到capacity都是可写的部分。 我们来实际使用一下看看： public static void main(String[] args) { //创建一个初始容量为10的ByteBuf缓冲区，这里的Unpooled是用于快速生成ByteBuf的工具类 //至于为啥叫Unpooled是池化的意思，ByteBuf有池化和非池化两种，区别在于对内存的复用，我们之后再讨论 ByteBuf buf = Unpooled.buffer(10); System.out.println(\"初始状态：\"+Arrays.toString(buf.array())); buf.writeInt(-888888888); //写入一个Int数据 System.out.println(\"写入Int后：\"+Arrays.toString(buf.array())); buf.readShort(); //无需翻转，直接读取一个short数据出来 System.out.println(\"读取Short后：\"+Arrays.toString(buf.array())); buf.discardReadBytes(); //丢弃操作，会将当前的可读部分内容丢到最前面，并且读写指针向前移动丢弃的距离 System.out.println(\"丢弃之后：\"+Arrays.toString(buf.array())); buf.clear(); //清空操作，清空之后读写指针都归零 System.out.println(\"清空之后：\"+Arrays.toString(buf.array())); } 通过结合断点调试，我们可以观察读写指针的移动情况，更加清楚的认识一下ByteBuf的底层操作。 我们再来看看划分操作是不是和之前一样的： public static void main(String[] args) { //我们也可以将一个byte[]直接包装进缓冲区（和NIO是一样的）不过写指针的值一开始就跑到最后去了，但是这玩意是不是只读的 ByteBuf buf = Unpooled.wrappedBuffer(\"abcdefg\".getBytes()); //除了包装，也可以复制数据，copiedBuffer()会完完整整将数据拷贝到一个新的缓冲区中 buf.readByte(); //读取一个字节 ByteBuf slice = buf.slice(); //现在读指针位于1，然后进行划分 System.out.println(slice.arrayOffset()); //得到划分出来的ByteBuf的偏移地址 System.out.println(Arrays.toString(slice.array())); } 可以看到，划分也是根据当前读取的位置来进行的。 我们继续来看看它的另一个特性，动态扩容，比如我们申请一个容量为10的缓冲区： public static void main(String[] args) { ByteBuf buf = Unpooled.buffer(10); //容量只有10字节 System.out.println(buf.capacity()); //直接写一个字符串 buf.writeCharSequence(\"卢本伟牛逼！\", StandardCharsets.UTF_8); //很明显这么多字已经超过10字节了 System.out.println(buf.capacity()); } 通过结果我们发现，在写入一个超出当前容量的数据时，会进行动态扩容，扩容会从64开始，之后每次触发扩容都会x2，当然如果我们不希望它扩容，可以指定最大容量： public static void main(String[] args) { //在生成时指定maxCapacity也为10 ByteBuf buf = Unpooled.buffer(10, 10); System.out.println(buf.capacity()); buf.writeCharSequence(\"卢本伟牛逼！\", StandardCharsets.UTF_8); System.out.println(buf.capacity()); } 可以看到现在无法再动态扩容了： 我们接着来看一下缓冲区的三种实现模式：堆缓冲区模式、直接缓冲区模式、复合缓冲区模式。 堆缓冲区（数组实现）和直接缓冲区（堆外内存实现）不用多说，前面我们在NIO中已经了解过了，我们要创建一个直接缓冲区也很简单，直接调用： public static void main(String[] args) { ByteBuf buf = Unpooled.directBuffer(10); System.out.println(Arrays.toString(buf.array())); } 同样的不能直接拿到数组，因为底层压根不是数组实现的： 我们来看看复合模式，复合模式可以任意地拼凑组合其他缓冲区，比如我们可以： 这样，如果我们想要对两个缓冲区组合的内容进行操作，我们就不用再单独创建一个新的缓冲区了，而是直接将其进行拼接操作，相当于是作为多个缓冲区组合的视图。 //创建一个复合缓冲区 CompositeByteBuf buf = Unpooled.compositeBuffer(); buf.addComponent(Unpooled.copiedBuffer(\"abc\".getBytes())); buf.addComponent(Unpooled.copiedBuffer(\"def\".getBytes())); for (int i = 0; i 可以看到我们也可以正常操作组合后的缓冲区。 最后我们来看看，池化缓冲区和非池化缓冲区的区别。 我们研究一下Unpooled工具类中具体是如何创建buffer的： public final class Unpooled { private static final ByteBufAllocator ALLOC; //实际上内部是有一个ByteBufAllocator对象的 public static final ByteOrder BIG_ENDIAN; public static final ByteOrder LITTLE_ENDIAN; public static final ByteBuf EMPTY_BUFFER; public static ByteBuf buffer() { return ALLOC.heapBuffer(); //缓冲区的创建操作实际上是依靠ByteBufAllocator来进行的 } ... static { //ALLOC在静态代码块中进行指定，实际上真正的实现类是UnpooledByteBufAllocator ALLOC = UnpooledByteBufAllocator.DEFAULT; BIG_ENDIAN = ByteOrder.BIG_ENDIAN; LITTLE_ENDIAN = ByteOrder.LITTLE_ENDIAN; EMPTY_BUFFER = ALLOC.buffer(0, 0); //空缓冲区容量和最大容量都是0 assert EMPTY_BUFFER instanceof EmptyByteBuf : \"EMPTY_BUFFER must be an EmptyByteBuf.\"; } } 那么我们来看看，这个ByteBufAllocator又是个啥，顾名思义，其实就是负责分配缓冲区的。 它有两个具体实现类：UnpooledByteBufAllocator和PooledByteBufAllocator，一个是非池化缓冲区生成器，还有一个是池化缓冲区生成器，那么池化和非池化有啥区别呢？ 实际上池化缓冲区利用了池化思想，将缓冲区通过设置内存池来进行内存块复用，这样就不用频繁地进行内存的申请，尤其是在使用堆外内存的时候，避免多次重复通过底层malloc()函数系统调用申请内存造成的性能损失。Netty的内存管理机制主要是借鉴Jemalloc内存分配策略，感兴趣的小伙伴可以深入了解一下。 所以，由于是复用内存空间，我们来看个例子： public static void main(String[] args) { ByteBufAllocator allocator = PooledByteBufAllocator.DEFAULT; ByteBuf buf = allocator.directBuffer(10); //申请一个容量为10的直接缓冲区 buf.writeChar('T'); //随便操作操作 System.out.println(buf.readChar()); buf.release(); //释放此缓冲区 ByteBuf buf2 = allocator.directBuffer(10); //重新再申请一个同样大小的直接缓冲区 System.out.println(buf2 == buf); } 可以看到，在我们使用完一个缓冲区之后，我们将其进行资源释放，当我们再次申请一个同样大小的缓冲区时，会直接得到之前已经申请好的缓冲区，所以，PooledByteBufAllocator实际上是将ByteBuf实例放入池中在进行复用。 零拷贝简介 注意：此小节作为选学内容，需要掌握操作系统和计算机组成原理才能学习。 零拷贝是一种I/O操作优化技术，可以快速高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间，首先第一个问题，什么是内核空间，什么又是用户空间呢？ 其实早期操作系统是不区分内核空间和用户空间的，但是应用程序能访问任意内存空间，程序很容易不稳定，常常把系统搞崩溃，比如清除操作系统的内存数据。实际上让应用程序随便访问内存真的太危险了，于是就按照CPU 指令的重要程度对指令进行了分级，指令分为四个级别：Ring0 ~ Ring3，Linux 下只使用了 Ring0 和 Ring3 两个运行级别，进程运行在 Ring3 级别时运行在用户态，指令只访问用户空间，而运行在 Ring0 级别时被称为运行在内核态，可以访问任意内存空间。 比如我们Java中创建一个新的线程，实际上最终是要交给操作系统来为我们进行分配的，而需要操作系统帮助我们完成任务则需要进行系统调用，是内核在进行处理，不是我们自己的程序在处理，这时就相当于我们的程序处于了内核态，而当操作系统底层分配完成，最后到我们Java代码中返回得到线程对象时，又继续由我们的程序进行操作，所以从内核态转换回了用户态。 而我们的文件操作也是这样，我们实际上也是需要让操作系统帮助我们从磁盘上读取文件数据或是向网络发送数据，比如使用传统IO的情况下，我们要从磁盘上读取文件然后发送到网络上，就会经历以下流程： 可以看到整个过程中是经历了2次CPU拷贝+2次DMA拷贝，一共四次拷贝，虽然逻辑比较清晰，但是数据老是这样来回进行复制，是不是太浪费时间了点？所以我们就需要寻找一种更好的方式，来实现零拷贝。 实现零拷贝我们这里演示三种方案： 使用虚拟内存 现在的操作系统基本都是支持虚拟内存的，我们可以让内核空间和用户空间的虚拟地址指向同一个物理地址，这样就相当于是直接共用了这一块区域，也就谈不上拷贝操作了： 使用mmap/write内存映射 实际上这种方式就是将内核空间中的缓存直接映射到用户空间缓存，比如我们之前在学习NIO中使用的MappedByteBuffer，就是直接作为映射存在，当我们需要将数据发送到Socket缓冲区时，直接在内核空间中进行操作就行了： 不过这样还是会出现用户态和内核态的切换，我们得再优化优化。 使用sendfile方式 在Linux2.1开始，引入了sendfile方式来简化操作，我们可以直接告诉内核要把哪个文件数据拷贝拷贝到Socket上，直接在内核空间中一步到位： 比如我们之前在NIO中使用的transferTo()方法，就是利用了这种机制来实现零拷贝的。 Netty工作模型 前面我们了解了Netty为我们提供的更高级的缓冲区类，我们接着来看看Netty是如何工作的，上一章我们介绍了Reactor模式，而Netty正是以主从Reactor多线程模型为基础，构建出了一套高效的工作模型。 大致工作模型图如下： 可以看到，和我们之前介绍的主从Reactor多线程模型非常类似： 所有的客户端需要连接到主Reactor完成Accept操作后，其他的操作由从Reactor去完成，这里也是差不多的思想，但是它进行了一些改进，我们来看一下它的设计： Netty 抽象出两组线程池BossGroup和WorkerGroup，BossGroup专门负责接受客户端的连接, WorkerGroup专门负读写，就像我们前面说的主从Reactor一样。 无论是BossGroup还是WorkerGroup，都是使用EventLoop（事件循环，很多系统都采用了事件循环机制，比如前端框架Node.js，事件循环顾名思义，就是一个循环，不断地进行事件通知）来进行事件监听的，整个Netty也是使用事件驱动来运作的，比如当客户端已经准备好读写、连接建立时，都会进行事件通知，说白了就像我们之前写NIO多路复用那样，只不过这里换成EventLoop了而已，它已经帮助我们封装好了一些常用操作，而且我们可以自己添加一些额外的任务，如果有多个EventLoop，会存放在EventLoopGroup中，EventLoopGroup就是BossGroup和WorkerGroup的具体实现。 在BossGroup之后，会正常将SocketChannel绑定到WorkerGroup中的其中一个EventLoop上，进行后续的读写操作监听。 前面我们大致了解了一下Netty的工作模型，接着我们来尝试创建一个Netty服务器： public static void main(String[] args) { //这里我们使用NioEventLoopGroup实现类即可，创建BossGroup和WorkerGroup //当然还有EpollEventLoopGroup，但是仅支持Linux，这是Netty基于Linux底层Epoll单独编写的一套本地实现，没有使用NIO那套 EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(); //创建服务端启动引导类 ServerBootstrap bootstrap = new ServerBootstrap(); //可链式，就很棒 bootstrap .group(bossGroup, workerGroup) //指定事件循环组 .channel(NioServerSocketChannel.class) //指定为NIO的ServerSocketChannel .childHandler(new ChannelInitializer() { //注意，这里的SocketChannel不是我们NIO里面的，是Netty的 @Override protected void initChannel(SocketChannel channel) { //获取流水线，当我们需要处理客户端的数据时，实际上是像流水线一样在处理，这个流水线上可以有很多Handler channel.pipeline().addLast(new ChannelInboundHandlerAdapter(){ //添加一个Handler，这里使用ChannelInboundHandlerAdapter @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { //ctx是上下文，msg是收到的消息，默认以ByteBuf形式（也可以是其他形式，后面再说） ByteBuf buf = (ByteBuf) msg; //类型转换一下 System.out.println(Thread.currentThread().getName()+\" >> 接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); //通过上下文可以直接发送数据回去，注意要writeAndFlush才能让客户端立即收到 ctx.writeAndFlush(Unpooled.wrappedBuffer(\"已收到！\".getBytes())); } }); } }); //最后绑定端口，启动 bootstrap.bind(8080); } 可以看到上面写了很多东西，但是你一定会懵逼，这些新来的东西，都是什么跟什么啊，怎么一个也没看明白？没关系，我们可以暂时先将代码写在这里，具体的各个部分，还请听后面细细道来。 我们接着编写一个客户端，客户端可以直接使用我们之前的： public static void main(String[] args) { //创建一个新的SocketChannel，一会通过通道进行通信 try (SocketChannel channel = SocketChannel.open(new InetSocketAddress(\"localhost\", 8080)); Scanner scanner = new Scanner(System.in)){ System.out.println(\"已连接到服务端！\"); while (true) { //咱给它套个无限循环，这样就能一直发消息了 System.out.println(\"请输入要发送给服务端的内容：\"); String text = scanner.nextLine(); if(text.isEmpty()) continue; //直接向通道中写入数据，真舒服 channel.write(ByteBuffer.wrap(text.getBytes())); System.out.println(\"已发送！\"); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); //直接从通道中读取数据 buffer.flip(); System.out.println(\"收到服务器返回：\"+new String(buffer.array(), 0, buffer.remaining())); } } catch (IOException e) { throw new RuntimeException(e); } } 通过通道正常收发数据即可，这样我们就成功搭建好了一个Netty服务器。 Channel详解 在学习NIO时，我们就已经接触到Channel了，我们可以通过通道来进行数据的传输，并且通道支持双向传输。 而在Netty中，也有对应的Channel类型： public interface Channel extends AttributeMap, ChannelOutboundInvoker, Comparable { ChannelId id(); //通道ID EventLoop eventLoop(); //获取此通道所属的EventLoop，因为一个Channel在它的生命周期内只能注册到一个EventLoop中 Channel parent(); //Channel是具有层级关系的，这里是返回父Channel ChannelConfig config(); boolean isOpen(); //通道当前的相关状态 boolean isRegistered(); boolean isActive(); ChannelMetadata metadata(); //通道相关信息 SocketAddress localAddress(); SocketAddress remoteAddress(); ChannelFuture closeFuture(); //关闭通道，但是会用到ChannelFuture，后面说 boolean isWritable(); long bytesBeforeUnwritable(); long bytesBeforeWritable(); Unsafe unsafe(); ChannelPipeline pipeline(); //流水线，之后也会说 ByteBufAllocator alloc(); //可以直接从Channel拿到ByteBufAllocator的实例，来分配ByteBuf Channel read(); Channel flush(); //刷新，基操 } 可以看到，Netty中的Channel相比NIO功能就多得多了。Netty中的Channel主要特点如下： 所有的IO操作都是异步的，并不是在当前线程同步运行，方法调用之后就直接返回了，那怎么获取操作的结果呢？还记得我们在前面JUC篇教程中学习的Future吗，没错，这里的ChannelFuture也是干这事的。 我们可以来看一下Channel接口的父接口ChannelOutboundInvoker接口，这里面定义了大量的I/O操作： public interface ChannelOutboundInvoker { //通道出站调用（包含大量的网络出站操作，比如写） ChannelFuture bind(SocketAddress var1); //Socket绑定、连接、断开、关闭等操作 ChannelFuture connect(SocketAddress var1); ChannelFuture connect(SocketAddress var1, SocketAddress var2); ChannelFuture disconnect(); ChannelFuture close(); ChannelFuture deregister(); ChannelFuture bind(SocketAddress var1, ChannelPromise var2); //下面这一系列还有附带ChannelPromise的，ChannelPromise我们后面再说，其实就是ChannelFuture的增强版 ChannelFuture connect(SocketAddress var1, ChannelPromise var2); ChannelFuture connect(SocketAddress var1, SocketAddress var2, ChannelPromise var3); ChannelFuture disconnect(ChannelPromise var1); ChannelFuture close(ChannelPromise var1); ChannelFuture deregister(ChannelPromise var1); ChannelOutboundInvoker read(); ChannelFuture write(Object var1); //可以看到这些常见的写操作，都是返回的ChannelFuture，而不是直接给结果 ChannelFuture write(Object var1, ChannelPromise var2); ChannelOutboundInvoker flush(); ChannelFuture writeAndFlush(Object var1, ChannelPromise var2); ChannelFuture writeAndFlush(Object var1); ChannelPromise newPromise(); //其他的暂时不提 ChannelProgressivePromise newProgressivePromise(); ChannelFuture newSucceededFuture(); ChannelFuture newFailedFuture(Throwable var1); ChannelPromise voidPromise(); } 当然它还实现了AttributeMap接口，其实有点类似于Session那种感觉，我们可以添加一些属性之类的： public interface AttributeMap { Attribute attr(AttributeKey var1); boolean hasAttr(AttributeKey var1); } 我们了解了Netty底层的Channel之后，我们接着来看ChannelHandler，既然现在有了通道，那么怎么进行操作呢？我们可以将需要处理的事情放在ChannelHandler中，ChannelHandler充当了所有入站和出站数据的应用程序逻辑的容器，实际上就是我们之前Reactor模式中的Handler，全靠它来处理读写操作。 不过这里不仅仅是一个简单的ChannelHandler在进行处理，而是一整套流水线，我们之后会介绍ChannelPipeline。 比如我们上面就是使用了ChannelInboundHandlerAdapter抽象类，它是ChannelInboundHandler接口的实现，用于处理入站数据，可以看到我们实际上就是通过重写对应的方法来进行处理，这些方法会在合适的时间被调用： channel.pipeline().addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { //ctx是上下文，msg是收到的消息，以ByteBuf形式 ByteBuf buf = (ByteBuf) msg; //类型转换一下 System.out.println(Thread.currentThread().getName()+\" >> 接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); //通过上下文可以直接发送数据回去，注意要writeAndFlush才能让客户端立即收到 ctx.writeAndFlush(Unpooled.wrappedBuffer(\"已收到！\".getBytes())); } }); 我们先从顶层接口开始看起： public interface ChannelHandler { //当ChannelHandler被添加到流水线中时调用 void handlerAdded(ChannelHandlerContext var1) throws Exception; //当ChannelHandler从流水线中移除时调用 void handlerRemoved(ChannelHandlerContext var1) throws Exception; /** @deprecated 已过时那咱就不管了 */ @Deprecated void exceptionCaught(ChannelHandlerContext var1, Throwable var2) throws Exception; @Inherited @Documented @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) public @interface Sharable { } } 顶层接口的定义比较简单，就只有一些流水线相关的回调方法，我们接着来看下一级： //ChannelInboundHandler用于处理入站相关事件 public interface ChannelInboundHandler extends ChannelHandler { //当Channel已经注册到自己的EventLoop上时调用，前面我们说了，一个Channel只会注册到一个EventLoop上，注册到EventLoop后，这样才会在发生对应事件时被通知。 void channelRegistered(ChannelHandlerContext var1) throws Exception; //从EventLoop上取消注册时 void channelUnregistered(ChannelHandlerContext var1) throws Exception; //当Channel已经处于活跃状态时被调用，此时Channel已经连接/绑定，并且已经就绪 void channelActive(ChannelHandlerContext var1) throws Exception; //跟上面相反，不再活跃了，并且不在连接它的远程节点 void channelInactive(ChannelHandlerContext var1) throws Exception; //当从Channel读取数据时被调用，可以看到数据被自动包装成了一个Object（默认是ByteBuf） void channelRead(ChannelHandlerContext var1, Object var2) throws Exception; //上一个读取操作完成后调用 void channelReadComplete(ChannelHandlerContext var1) throws Exception; //暂时不介绍 void userEventTriggered(ChannelHandlerContext var1, Object var2) throws Exception; //当Channel的可写状态发生改变时被调用 void channelWritabilityChanged(ChannelHandlerContext var1) throws Exception; //出现异常时被调用 void exceptionCaught(ChannelHandlerContext var1, Throwable var2) throws Exception; } 而我们上面用到的ChannelInboundHandlerAdapter实际上就是对这些方法实现的抽象类，相比直接用接口，我们可以只重写我们需要的方法，没有重写的方法会默认向流水线下一个ChannelHandler发送。 我们来测试一下吧： public class TestChannelHandler extends ChannelInboundHandlerAdapter { public void channelRegistered(ChannelHandlerContext ctx) throws Exception { System.out.println(\"channelRegistered\"); } public void channelUnregistered(ChannelHandlerContext ctx) throws Exception { System.out.println(\"channelUnregistered\"); } public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(\"channelActive\"); } public void channelInactive(ChannelHandlerContext ctx) throws Exception { System.out.println(\"channelInactive\"); } public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(Thread.currentThread().getName()+\" >> 接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); //这次我们就直接使用ctx.alloc()来生成缓冲区 ByteBuf back = ctx.alloc().buffer(); back.writeCharSequence(\"已收到！\", StandardCharsets.UTF_8); ctx.writeAndFlush(back); System.out.println(\"channelRead\"); } public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { System.out.println(\"channelReadComplete\"); } public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { System.out.println(\"userEventTriggered\"); } public void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception { System.out.println(\"channelWritabilityChanged\"); } public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { System.out.println(\"exceptionCaught\"+cause); } } public static void main(String[] args) { EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap .group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) //ChannelInitializer是一个特殊的ChannelHandler，它本身不处理任何出站/入站事件，它的目的仅仅是完成Channel的初始化 .childHandler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel channel) { //将我们自定义的ChannelHandler添加到流水线 channel.pipeline().addLast(new TestChannelHandler()); } }); bootstrap.bind(8080); } 现在我们启动服务器，让客户端来连接并发送一下数据试试看： 可以看到ChannelInboundHandler的整个生命周期，首先是Channel注册成功，然后才会变成可用状态，接着就差不多可以等待客户端来数据了，当客户端主动断开连接时，会再次触发一次channelReadComplete，然后不可用，最后取消注册。 我们来测试一下出现异常的情况呢？ public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(Thread.currentThread().getName()+\" >> 接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); ByteBuf back = ctx.alloc().buffer(); back.writeCharSequence(\"已收到！\", StandardCharsets.UTF_8); ctx.writeAndFlush(back); System.out.println(\"channelRead\"); throw new RuntimeException(\"我是自定义异常1\"); //弄点异常上去 } public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { System.out.println(\"channelReadComplete\"); throw new RuntimeException(\"我是自定义异常2\"); //弄点异常上去 } ... public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { System.out.println(\"exceptionCaught\"+cause); } 可以看到发生异常时，会接着调用exceptionCaught方法： 与ChannelInboundHandler对应的还有ChannelOutboundHandler用于处理出站相关的操作，这里就不进行演示了。 我们接着来看看ChannelPipeline，每一个Channel都对应一个ChannelPipeline（在Channel初始化时就被创建了） 它就像是一条流水线一样，整条流水线上可能会有很多个Handler（包括入站和出站），整条流水线上的两端还有两个默认的处理器（用于一些预置操作和后续操作，比如释放资源等），我们只需要关心如何安排这些自定义的Handler即可，比如我们现在希望创建两个入站ChannelHandler，一个用于接收请求并处理，还有一个用于处理当前接收请求过程中出现的异常： .childHandler(new ChannelInitializer() { //注意，这里的SocketChannel不是我们NIO里面的，是Netty的 @Override protected void initChannel(SocketChannel channel) { channel.pipeline() //直接获取pipeline，然后添加两个Handler，注意顺序 .addLast(new ChannelInboundHandlerAdapter(){ //第一个用于处理消息接收 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); throw new RuntimeException(\"我是异常\"); } }) .addLast(new ChannelInboundHandlerAdapter(){ //第二个用于处理异常 @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { System.out.println(\"我是异常处理：\"+cause); } }); } }); 那么它是如何运作的呢？实际上如果我们不在ChannelInboundHandlerAdapter中重写对应的方法，它会默认传播到流水线的下一个ChannelInboundHandlerAdapter进行处理，比如： public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.fireExceptionCaught(cause); //通过ChannelHandlerContext来向下传递，ChannelHandlerContext是在Handler添加进Pipeline中时就被自动创建的 } 比如我们现在需要将一个消息在两个Handler中进行处理： @Override protected void initChannel(SocketChannel channel) { channel.pipeline() //直接获取pipeline，然后添加两个Handler .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"1接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); ctx.fireChannelRead(msg); //通过ChannelHandlerContext } }) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"2接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); } }); } 我们接着来看看出站相关操作，我们可以使用ChannelOutboundHandlerAdapter来完成： @Override protected void initChannel(SocketChannel channel) { channel.pipeline() .addLast(new ChannelOutboundHandlerAdapter(){ //注意出栈站操作应该在入站操作的前面，当我们使用ChannelHandlerContext的write方法时，是从流水线的当前位置倒着往前找下一个ChannelOutboundHandlerAdapter，而我们之前使用的ChannelInboundHandlerAdapter是从前往后找下一个，如果我们使用的是Channel的write方法，那么会从整个流水线的最后开始倒着往前找ChannelOutboundHandlerAdapter，一定要注意顺序。 @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { //当执行write操作时，会 System.out.println(msg); //write的是啥，这里就是是啥 //我们将其转换为ByteBuf，这样才能发送回客户端 ctx.writeAndFlush(Unpooled.wrappedBuffer(msg.toString().getBytes())); } }) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"1接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); ctx.fireChannelRead(msg); } }) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"2接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); ctx.writeAndFlush(\"不会吧不会吧，不会还有人都看到这里了还没三连吧\"); //这里可以write任何对象 //ctx.channel().writeAndFlush(\"啊对对对\"); 或是通过Channel进行write也可以 } }); } 现在我们来试试看，搞两个出站的Handler，验证一下是不是上面的样子： @Override protected void initChannel(SocketChannel channel) { channel.pipeline() //直接获取pipeline，然后添加两个Handler .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"1接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); ctx.fireChannelRead(msg); } }) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"2接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); ctx.channel().writeAndFlush(\"伞兵一号卢本伟\"); //这里我们使用channel的write } }) .addLast(new ChannelOutboundHandlerAdapter(){ @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { System.out.println(\"1号出站：\"+msg); } }) .addLast(new ChannelOutboundHandlerAdapter(){ @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { System.out.println(\"2号出站：\"+msg); ctx.write(msg); //继续write给其他的出站Handler，不然到这里就断了 } }); } 所以，出站操作在流水线上是反着来的，整个流水线操作大概流程如下: 有关Channel及其处理相关操作，就先讲到这里。 EventLoop和任务调度 前面我们讲解了Channel，那么在EventLoop中具体是如何进行调度的呢？实际上我们之前在编写NIO的时候，就是一个while循环在源源不断地等待新的事件，而EventLoop也正是这种思想，它本质就是一个事件等待/处理线程。 我们上面使用的就是EventLoopGroup，包含很多个EventLoop，我们每创建一个连接，就需要绑定到一个EventLoop上，之后EventLoop就会开始监听这个连接（只要连接不关闭，一直都是这个EventLoop负责此Channel），而一个EventLoop可以同时监听很多个Channel，实际上就是我们之前学习的Selector罢了。 当然，EventLoop并不只是用于网络操作的，我们前面所说的EventLoop其实都是NioEventLoop，它是专用于网络通信的，除了网络通信之外，我们也可以使用普通的EventLoop来处理一些其他的事件。 比如我们现在编写的服务端，虽然结构上和主从Reactor多线程模型差不多，但是我们发现，Handler似乎是和读写操作在一起进行的，而我们之前所说的模型中，Handler是在读写之外的单独线程中进行的： public static void main(String[] args) { EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(1); //线程数先限制一下 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap .group(bossGroup, workerGroup) //指定事件循环组 .channel(NioServerSocketChannel.class) //指定为NIO的ServerSocketChannel .childHandler(new ChannelInitializer() { //注意，这里的SocketChannel不是我们NIO里面的，是Netty的 @Override protected void initChannel(SocketChannel channel) { channel.pipeline() .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); Thread.sleep(10000); //这里我们直接卡10秒假装在处理任务 ctx.writeAndFlush(Unpooled.wrappedBuffer(\"已收到！\".getBytes())); } }); } }); bootstrap.bind(8080); } 可以看到，如果在这里卡住了，那么就没办法处理EventLoop绑定的其他Channel了，所以我们这里就创建一个普通的EventLoop来专门处理读写之外的任务： public static void main(String[] args) { EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(1); //线程数先限制一下 EventLoopGroup handlerGroup = new DefaultEventLoopGroup(); //使用DefaultEventLoop来处理其他任务 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap .group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel channel) { channel.pipeline() .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); handlerGroup.submit(() -> { //由于继承自ScheduledExecutorService，我们直接提交任务就行了，是不是感觉贼方便 try { Thread.sleep(10000); } catch (InterruptedException e) { throw new RuntimeException(e); } ctx.writeAndFlush(Unpooled.wrappedBuffer(\"已收到！\".getBytes())); }); } }); } }); bootstrap.bind(8080); } 当然我们也可以写成一条流水线： public static void main(String[] args) { EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(1); //线程数先限制一下 EventLoopGroup handlerGroup = new DefaultEventLoopGroup(); //使用DefaultEventLoop来处理其他任务 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap .group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel channel) { channel.pipeline() .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); ctx.fireChannelRead(msg); } }).addLast(handlerGroup, new ChannelInboundHandlerAdapter(){ //在添加时，可以直接指定使用哪个EventLoopGroup @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { try { Thread.sleep(10000); } catch (InterruptedException e) { throw new RuntimeException(e); } ctx.writeAndFlush(Unpooled.wrappedBuffer(\"已收到！\".getBytes())); } }); } }); bootstrap.bind(8080); } 这样，我们就进一步地将EventLoop利用起来了。 按照前面服务端的方式，我们来把Netty版本的客户端也给写了： public static void main(String[] args) { Bootstrap bootstrap = new Bootstrap(); //客户端也是使用Bootstrap来启动 bootstrap .group(new NioEventLoopGroup()) //客户端就没那么麻烦了，直接一个EventLoop就行，用于处理发回来的数据 .channel(NioSocketChannel.class) //客户端肯定就是使用SocketChannel了 .handler(new ChannelInitializer() { //这里的数据处理方式和服务端是一样的 @Override protected void initChannel(SocketChannel channel) throws Exception { channel.pipeline().addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\">> 接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); } }); } }); Channel channel = bootstrap.connect(\"localhost\", 8080).channel(); //连接后拿到对应的Channel对象 //注意上面连接操作是异步的，调用之后会继续往下走，下面我们就正式编写客户端的数据发送代码了 try(Scanner scanner = new Scanner(System.in)){ //还是和之前一样，扫了就发 while (true) { System.out.println(\" 我们来测试一下吧： Future和Promise 我们接着来看ChannelFuture，前面我们提到，Netty中Channel的相关操作都是异步进行的，并不是在当前线程同步执行，我们不能立即得到执行结果，如果需要得到结果，那么我们就必须要利用到Future。 我们先来看看ChannelFutuer接口怎么定义的： public interface ChannelFuture extends Future { Channel channel(); //我们可以直接获取此任务的Channel ChannelFuture addListener(GenericFutureListener> var1); //当任务完成时，会直接执行GenericFutureListener的任务，注意执行的位置也是在EventLoop中 ChannelFuture addListeners(GenericFutureListener>... var1); ChannelFuture removeListener(GenericFutureListener> var1); ChannelFuture removeListeners(GenericFutureListener>... var1); ChannelFuture sync() throws InterruptedException; //在当前线程同步等待异步任务完成，任务失败会抛出异常 ChannelFuture syncUninterruptibly(); //同上，但是无法响应中断 ChannelFuture await() throws InterruptedException; //同上，但是任务中断不会抛出异常，需要手动判断 ChannelFuture awaitUninterruptibly(); //不用我说了吧？ boolean isVoid(); //返回类型是否为void } 此接口是继承自Netty中的Future接口的（不是JDK的那个）： public interface Future extends java.util.concurrent.Future { //再往上才是JDK的Future boolean isSuccess(); //用于判断任务是否执行成功的 boolean isCancellable(); Throwable cause(); //获取导致任务失败的异常 ... V getNow(); //立即获取结果，如果还未产生结果，得到null，不过ChannelFuture定义V为Void，就算完成了获取也是null boolean cancel(boolean var1); //取消任务 } Channel的很多操作都是异步完成的，直接返回一个ChannelFuture，比如Channel的write操作，返回的就是一个ChannelFuture对象： .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\"接收到客户端发送的数据：\"+buf.toString(StandardCharsets.UTF_8)); ChannelFuture future = ctx.writeAndFlush(Unpooled.wrappedBuffer(\"已收到！\".getBytes())); System.out.println(\"任务完成状态：\"+future.isDone()); //通过ChannelFuture来获取相关信息 } }); 包括我们的服务端启动也是返回的ChannelFuture： ... } }); ChannelFuture future = bootstrap.bind(8080); System.out.println(\"服务端启动状态：\"+future.isDone()); System.out.println(\"我是服务端启动完成之后要做的事情！\"); } 可以看到，服务端的启动就比较慢了，所以在一开始直接获取状态会返回false，但是这个时候我们又需要等到服务端启动完成之后做一些事情，这个时候该怎么办呢？现在我们就有两种方案了： } }); ChannelFuture future = bootstrap.bind(8080); future.sync(); //让当前线程同步等待任务完成 System.out.println(\"服务端启动状态：\"+future.isDone()); System.out.println(\"我是服务端启动完成之后要做的事情！\"); } 第一种方案是直接让当前线程同步等待异步任务完成，我们可以使用sync()方法，这样当前线程会一直阻塞直到任务结束。第二种方案是添加一个监听器，等待任务完成时通知： } }); ChannelFuture future = bootstrap.bind(8080); //直接添加监听器，当任务完成时自动执行，但是注意执行也是异步的，不是在当前线程 future.addListener(f -> System.out.println(\"我是服务端启动完成之后要做的事情！\")); } 包括客户端的关闭，也是异步进行的： try(Scanner scanner = new Scanner(System.in)){ while (true) { System.out.println(\" 我们接着来看看Promise接口，它支持手动设定成功和失败的结果： //此接口也是继承自Netty中的Future接口 public interface Promise extends Future { Promise setSuccess(V var1); //手动设定成功 boolean trySuccess(V var1); Promise setFailure(Throwable var1); //手动设定失败 boolean tryFailure(Throwable var1); boolean setUncancellable(); //这些就和之前的Future是一样的了 Promise addListener(GenericFutureListener> var1); Promise addListeners(GenericFutureListener>... var1); Promise removeListener(GenericFutureListener> var1); Promise removeListeners(GenericFutureListener>... var1); Promise await() throws InterruptedException; Promise awaitUninterruptibly(); Promise sync() throws InterruptedException; Promise syncUninterruptibly(); } 比如我们来测试一下： public static void main(String[] args) throws ExecutionException, InterruptedException { Promise promise = new DefaultPromise<>(new DefaultEventLoop()); System.out.println(promise.isSuccess()); //在一开始肯定不是成功的 promise.setSuccess(\"lbwnb\"); //设定成功 System.out.println(promise.isSuccess()); //再次获取，可以发现确实成功了 System.out.println(promise.get()); //获取结果，就是我们刚刚给进去的 } 可以看到我们可以手动指定成功状态，包括ChannelOutboundInvoker中的一些基本操作，都是支持ChannelPromise的： .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; String text = buf.toString(StandardCharsets.UTF_8); System.out.println(\"接收到客户端发送的数据：\"+text); ChannelPromise promise = new DefaultChannelPromise(channel); System.out.println(promise.isSuccess()); ctx.writeAndFlush(Unpooled.wrappedBuffer(\"已收到！\".getBytes()), promise); promise.sync(); //同步等待一下 System.out.println(promise.isSuccess()); } }); 最后结果就是我们想要的了，当然我们也可以像Future那样添加监听器，当成功时自动通知： public static void main(String[] args) throws ExecutionException, InterruptedException { Promise promise = new DefaultPromise<>(new DefaultEventLoop()); promise.addListener(f -> System.out.println(promise.get())); //注意是在上面的DefaultEventLoop执行的 System.out.println(promise.isSuccess()); promise.setSuccess(\"lbwnb\"); System.out.println(promise.isSuccess()); } 有关Future和Promise就暂时讲解到这里。 编码器和解码器 前面我们已经了解了Netty的大部分基础内容，我们接着来看看Netty内置的一些编码器和解码器。 在前面的学习中，我们的数据发送和接收都是需要以ByteBuf形式传输，但是这样是不是有点太不方便了，咱们能不能参考一下JavaWeb那种搞个Filter，在我们开始处理数据之前，过过滤一次，并在过滤的途中将数据转换成我们想要的类型，也可以将发出的数据进行转换，这就要用到编码解码器了。 我们先来看看最简的，字符串，如果我们要直接在客户端或是服务端处理字符串，可以直接添加一个字符串解码器到我们的流水线中： @Override protected void initChannel(SocketChannel channel) { channel.pipeline() //解码器本质上也算是一种ChannelInboundHandlerAdapter，用于处理入站请求 .addLast(new StringDecoder()) //当客户端发送来的数据只是简单的字符串转换的ByteBuf时，我们直接使用内置的StringDecoder即可转换 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //经过StringDecoder转换后，msg直接就是一个字符串，所以打印就行了 System.out.println(msg); } }); } 可以看到，使用起来还是非常方便的，我们只需要将其添加到流水线即可，实际上器本质就是一个ChannelInboundHandlerAdapter： 我们看到它是继承自MessageToMessageDecoder，用于将传入的Message转换为另一种类型，我们也可以自行编写一个实现： /** * 我们也来搞一个自定义的 */ public class TestDecoder extends MessageToMessageDecoder { @Override protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf buf, List list) throws Exception { System.out.println(\"数据已收到，正在进行解码...\"); String text = buf.toString(StandardCharsets.UTF_8); //直接转换为UTF8字符串 list.add(text); //解码后需要将解析后的数据丢进List中，如果丢进去多个数据，相当于数据被分成了多个，后面的Handler就需要每个都处理一次 } } 运行，可以看到： 当然如果我们在List里面丢很多个数据的话： public class TestDecoder extends MessageToMessageDecoder { @Override protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf buf, List list) throws Exception { System.out.println(\"数据已收到，正在进行解码...\"); String text = buf.toString(StandardCharsets.UTF_8); //直接转换为UTF8字符串 list.add(text); list.add(text+\"2\"); list.add(text+'3'); //一条消息被解码成三条消息 } } 可以看到，后面的Handler会依次对三条数据都进行处理，当然，除了MessageToMessageDecoder之外，还有其他类型的解码器，比如ByteToMessageDecoder等，这里就不一一介绍了，Netty内置了很多的解码器实现来方便我们开发，比如HTTP（下一节介绍），SMTP、MQTT等，以及我们常用的Redis、Memcached、JSON等数据包。 当然，有了解码器处理发来的数据，那发出去的数据肯定也是需要被处理的，所以编码器就出现了： channel.pipeline() //解码器本质上也算是一种ChannelInboundHandlerAdapter，用于处理入站请求 .addLast(new StringDecoder()) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\"收到客户端的数据：\"+msg); ctx.channel().writeAndFlush(\"可以，不跟你多BB\"); //直接发字符串回去 } }) .addLast(new StringEncoder()); //使用内置的StringEncoder可以直接将出站的字符串数据编码成ByteBuf 和上面的StringDecoder一样，StringEncoder本质上就是一个ChannelOutboundHandlerAdapter： 是不是感觉前面学习的Handler和Pipeline突然就变得有用了，直接一条线把数据处理安排得明明白白啊。 现在我们把客户端也改成使用编码、解码器的样子： public static void main(String[] args) { Bootstrap bootstrap = new Bootstrap(); bootstrap .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer() { @Override protected void initChannel(SocketChannel channel) throws Exception { channel.pipeline() .addLast(new StringDecoder()) //解码器安排 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\">> 接收到客户端发送的数据：\" + msg); //直接接收字符串 } }) .addLast(new StringEncoder()); //编码器安排 } }); Channel channel = bootstrap.connect(\"localhost\", 8080).channel(); try(Scanner scanner = new Scanner(System.in)){ while (true) { System.out.println(\" 这样我们的代码量又蹭蹭的减少了很多： 当然，除了编码器和解码器之外，还有编解码器。？？缝合怪？？ 可以看到它是既继承了ChannelInboundHandlerAdapter也实现了ChannelOutboundHandler接口，又能处理出站也能处理入站请求，实际上就是将之前的给组合到一起了，比如我们也可以实现一个缝合在一起的StringCodec类： //需要指定两个泛型，第一个是入站的消息类型，还有一个是出站的消息类型，出站是String类型，我们要转成ByteBuf public class StringCodec extends MessageToMessageCodec { @Override protected void encode(ChannelHandlerContext channelHandlerContext, String buf, List list) throws Exception { System.out.println(\"正在处理出站数据...\"); list.add(Unpooled.wrappedBuffer(buf.getBytes())); //同样的，添加的数量就是出站的消息数量 } @Override protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf buf, List list) throws Exception { System.out.println(\"正在处理入站数据...\"); list.add(buf.toString(StandardCharsets.UTF_8)); //和之前一样，直接一行解决 } } 可以看到实际上就是需要我们同时去实现编码和解码方法，继承MessageToMessageCodec类即可。 当然，如果整条流水线上有很多个解码器或是编码器，那么也可以多次进行编码或是解码，比如： public class StringToStringEncoder extends MessageToMessageEncoder { @Override protected void encode(ChannelHandlerContext channelHandlerContext, String s, List list) throws Exception { System.out.println(\"我是预处理编码器，就要皮这一下。\"); list.add(\"[已处理] \"+s); } } channel.pipeline() //解码器本质上也算是一种ChannelInboundHandlerAdapter，用于处理入站请求 .addLast(new StringDecoder()) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\"收到客户端的数据：\"+msg); ctx.channel().writeAndFlush(\"可以，不跟你多BB\"); //直接发字符串回去 } }) .addLast(new StringEncoder()) //最后再转成ByteBuf .addLast(new StringToStringEncoder()); //先从我们自定义的开始 可以看到，数据在流水线上一层一层处理最后再回到的客户端： 我们在一开始提到的粘包/拆包问题，也可以使用一个解码器解决： channel.pipeline() .addLast(new FixedLengthFrameDecoder(10)) //第一种解决方案，使用定长数据包，每个数据包都要是指定长度 ... channel.pipeline() .addLast(new DelimiterBasedFrameDecoder(1024, Unpooled.wrappedBuffer(\"!\".getBytes()))) //第二种，就是指定一个特定的分隔符，比如我们这里以感叹号为分隔符 //在收到分隔符之前的所有数据，都作为同一个数据包的内容 channel.pipeline() .addLast(new LengthFieldBasedFrameDecoder(1024, 0, 4)) //第三种方案，就是在头部添加长度信息，来确定当前发送的数据包具体长度是多少 //offset是从哪里开始，length是长度信息占多少字节，这里是从0开始读4个字节表示数据包长度 .addLast(new StringDecoder()) channel.pipeline() .addLast(new StringDecoder()) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\">> 接收到客户端发送的数据：\" + msg); } }) .addLast(new LengthFieldPrepender(4)) //客户端在发送时也需要将长度拼到前面去 .addLast(new StringEncoder()); 有关编码器和解码器的内容就先介绍到这里。 实现HTTP协议通信 前面我们介绍了Netty为我们提供的编码器和解码器，这里我们就来使用一下支持HTTP协议的编码器和解码器。 channel.pipeline() .addLast(new HttpRequestDecoder()) //Http请求解码器 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\"收到客户端的数据：\"+msg.getClass()); //看看是个啥类型 //收到浏览器请求后，我们需要给一个响应回去 FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); //HTTP版本为1.1，状态码就OK（200）即可 //直接向响应内容中写入数据 response.content().writeCharSequence(\"Hello World!\", StandardCharsets.UTF_8); ctx.channel().writeAndFlush(response); //发送响应 ctx.channel().close(); //HTTP请求是一次性的，所以记得关闭 } }) .addLast(new HttpResponseEncoder()); //响应记得也要编码后发送哦 现在我们用浏览器访问一下我们的服务器吧： 可以看到浏览器成功接收到服务器响应，然后控制台打印了以下类型： 可以看到一次请求是一个DefaultHttpRequest+LastHttpContent$1，这里有两组是因为浏览器请求了一个地址之后紧接着请求了我们网站的favicon图标。 这样把数据分开处理肯定是不行的，要是直接整合成一个多好，安排： channel.pipeline() .addLast(new HttpRequestDecoder()) //Http请求解码器 .addLast(new HttpObjectAggregator(Integer.MAX_VALUE)) //搞一个聚合器，将内容聚合为一个FullHttpRequest，参数是最大内容长度 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { FullHttpRequest request = (FullHttpRequest) msg; System.out.println(\"浏览器请求路径：\"+request.uri()); //直接获取请求相关信息 FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); response.content().writeCharSequence(\"Hello World!\", StandardCharsets.UTF_8); ctx.channel().writeAndFlush(response); ctx.channel().close(); } }) .addLast(new HttpResponseEncoder()); 再次访问，我们发现可以正常读取请求路径了： 我们来试试看搞个静态页面代理玩玩，拿出我们的陈年老模板： 全部放进Resource文件夹，一会根据浏览器的请求路径，我们就可以返回对应的页面了，先安排一个解析器，用于解析路径然后将静态页面的内容返回： public class PageResolver { //直接单例模式 private static final PageResolver INSTANCE = new PageResolver(); private PageResolver(){} public static PageResolver getInstance(){ return INSTANCE; } //请求路径给进来，接着我们需要将页面拿到，然后转换成响应数据包发回去 public FullHttpResponse resolveResource(String path){ if(path.startsWith(\"/\")) { //判断一下是不是正常的路径请求 path = path.equals(\"/\") ? \"index.html\" : path.substring(1); //如果是直接请求根路径，那就默认返回index页面，否则就该返回什么路径的文件就返回什么 try(InputStream stream = this.getClass().getClassLoader().getResourceAsStream(path)) { if(stream != null) { //拿到文件输入流之后，才可以返回页面 byte[] bytes = new byte[stream.available()]; stream.read(bytes); return this.packet(HttpResponseStatus.OK, bytes); //数据先读出来，然后交给下面的方法打包 } } catch (IOException e){ e.printStackTrace(); } } //其他情况一律返回404 return this.packet(HttpResponseStatus.NOT_FOUND, \"404 Not Found!\".getBytes()); } //包装成FullHttpResponse，把状态码和数据写进去 private FullHttpResponse packet(HttpResponseStatus status, byte[] data){ FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, status); response.content().writeBytes(data); return response; } } 现在我们的静态资源解析就写好了，接着： channel.pipeline() .addLast(new HttpRequestDecoder()) //Http请求解码器 .addLast(new HttpObjectAggregator(Integer.MAX_VALUE)) //搞一个聚合器，将内容聚合为一个FullHttpRequest，参数是最大内容长度 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { FullHttpRequest request = (FullHttpRequest) msg; //请求进来了直接走解析 PageResolver resolver = PageResolver.getInstance(); ctx.channel().writeAndFlush(resolver.resolveResource(request.uri())); ctx.channel().close(); } }) .addLast(new HttpResponseEncoder()); 现在我们启动服务器来试试看吧： 可以看到页面可以正常展示了，是不是有Tomcat哪味了。 其他内置Handler介绍 Netty也为我们内置了一些其他比较好用的Handler，比如我们要打印日志： channel.pipeline() .addLast(new HttpRequestDecoder()) .addLast(new HttpObjectAggregator(Integer.MAX_VALUE)) .addLast(new LoggingHandler(LogLevel.INFO)) //添加一个日志Handler，在请求到来时会自动打印相关日志 ... 日志级别我们选择INFO，现在我们用浏览器访问一下： 可以看到每次请求的内容和详细信息都会在日志中出现，包括详细的数据包解析过程，请求头信息都是完整地打印在控制台上的。 我们也可以使用Handler对IP地址进行过滤，比如我们不希望某些IP地址连接我们的服务器： channel.pipeline() .addLast(new HttpRequestDecoder()) .addLast(new HttpObjectAggregator(Integer.MAX_VALUE)) .addLast(new RuleBasedIpFilter(new IpFilterRule() { @Override public boolean matches(InetSocketAddress inetSocketAddress) { return !inetSocketAddress.getHostName().equals(\"127.0.0.1\"); //进行匹配，返回false表示匹配失败 //如果匹配失败，那么会根据下面的类型决定该干什么，比如我们这里判断是不是本地访问的，如果是那就拒绝 } @Override public IpFilterRuleType ruleType() { return IpFilterRuleType.REJECT; //类型，REJECT表示拒绝连接，ACCEPT表示允许连接 } })) 现在我们浏览器访问一下看看： 我们也可以对那些长期处于空闲的进行处理： channel.pipeline() .addLast(new StringDecoder()) .addLast(new IdleStateHandler(10, 10, 0)) //IdleStateHandler能够侦测连接空闲状态 //第一个参数表示连接多少秒没有读操作时触发事件，第二个是写操作，第三个是读写操作都算，0表示禁用 //事件需要在ChannelInboundHandlerAdapter中进行监听处理 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\"收到客户端数据：\"+msg); ctx.channel().writeAndFlush(\"已收到！\"); } @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { //没想到吧，这个方法原来是在这个时候用的 if(evt instanceof IdleStateEvent) { IdleStateEvent event = (IdleStateEvent) evt; if(event.state() == IdleState.WRITER_IDLE) { System.out.println(\"好久都没写了，看视频的你真的有认真在跟着敲吗\"); } else if(event.state() == IdleState.READER_IDLE) { System.out.println(\"已经很久很久没有读事件发生了，好寂寞\"); } } } }) .addLast(new StringEncoder()); 可以看到，当我们超过一段时间不发送数据时，就会这样： 通过这种机制，我们就可以直接关掉那些占着茅坑不拉屎的连接。 启动流程源码解读 前面我们完成了对Netty基本功能的讲解，我们最后就来看一下，Netty到底是如何启动以及进行数据处理的。 首先我们知道，整个服务端是在bind之后启动的，那么我们就从这里开始下手，不多BB直接上源码： public ChannelFuture bind(int inetPort) { return this.bind(new InetSocketAddress(inetPort)); //转换成InetSocketAddress对象 } 进来之后发现是调用的其他绑定方法，继续： public ChannelFuture bind(SocketAddress localAddress) { this.validate(); //再次验证一下，看看EventLoopGroup和Channel指定了没 return this.doBind((SocketAddress)ObjectUtil.checkNotNull(localAddress, \"localAddress\")); } 我们继续往下看： private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = this.initAndRegister(); //上来第一句初始化然后注册 ... } 我们看看是怎么注册的： final ChannelFuture initAndRegister() { Channel channel = null; try { channel = this.channelFactory.newChannel(); //通过channelFactory创建新的Channel，实际上就是我们在一开始设定的NioServerSocketChannel this.init(channel); //接着对创建好的NioServerSocketChannel进行初始化 ... ChannelFuture regFuture = this.config().group().register(channel); //将通道注册到bossGroup中的一个EventLoop中 ... return regFuture; } 我们来看看是如何对创建好的ServerSocketChannel进行初始化的： void init(Channel channel) { setChannelOptions(channel, this.newOptionsArray(), logger); setAttributes(channel, this.newAttributesArray()); ChannelPipeline p = channel.pipeline(); ... //在流水线上添加一个Handler，在Handler初始化的时候向EventLoop中提交一个任务，将ServerBootstrapAcceptor添加到流水线上 //这样我们的ServerSocketChannel在客户端连接时就能Accept了 p.addLast(new ChannelHandler[]{new ChannelInitializer() { public void initChannel(final Channel ch) { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = ServerBootstrap.this.config.handler(); if (handler != null) { pipeline.addLast(new ChannelHandler[]{handler}); } ch.eventLoop().execute(new Runnable() { public void run() { //这里提交一个任务，将ServerBootstrapAcceptor添加到ServerSocketChannel的pipeline中 pipeline.addLast(new ChannelHandler[]{new ServerBootstrapAcceptor(ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)}); } }); } }}); } 我们来看一下，ServerBootstrapAcceptor怎么处理的，直接看到它的channelRead方法： //当底层NIO的ServerSocketChannel的Selector有OP_ACCEPT事件到达时，NioEventLoop会接收客户端连接，创建SocketChannel，并触发channelRead回调 public void channelRead(ChannelHandlerContext ctx, Object msg) { //此时msg就是Accept连接创建之后的Channel对象 final Channel child = (Channel)msg; //这里直接将我们之前编写的childHandler添加到新创建的客户端连接的流水线中（是不是感觉突然就通了） child.pipeline().addLast(new ChannelHandler[]{this.childHandler}); AbstractBootstrap.setChannelOptions(child, this.childOptions, ServerBootstrap.logger); AbstractBootstrap.setAttributes(child, this.childAttrs); try { //直接向workGroup中的一个EventLoop注册新创建好的客户端连接Channel，等待读写事件 this.childGroup.register(child).addListener(new ChannelFutureListener() { //异步操作完成后，如果没有注册成功，就强制关闭这个Channel public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { ServerBootstrap.ServerBootstrapAcceptor.forceClose(child, future.cause()); ... 所以，实际上就是我们之前讲解的主从Reactor多线程模型，只要前面理解了，这里其实很好推断。 初始化完成之后，我们来看看注册，在之前NIO阶段我们也是需要将Channel注册到对应的Selector才可以开始选择： public ChannelFuture register(Channel channel) { return this.register((ChannelPromise)(new DefaultChannelPromise(channel, this))); //转换成ChannelPromise继续 } public ChannelFuture register(ChannelPromise promise) { ObjectUtil.checkNotNull(promise, \"promise\"); promise.channel().unsafe().register(this, promise); //调用Channel的Unsafe接口实现进行注册 return promise; } 继续向下： public final void register(EventLoop eventLoop, final ChannelPromise promise) { ... AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) { this.register0(promise); //这里是继续调用register0方法在进行注册 } ... } } 继续： private void register0(ChannelPromise promise) { try { ... boolean firstRegistration = this.neverRegistered; AbstractChannel.this.doRegister(); //这里开始执行AbstractNioChannel中的doRegister方法进行注册 AbstractChannel.this.registered = true; AbstractChannel.this.pipeline.invokeHandlerAddedIfNeeded(); this.safeSetSuccess(promise); if (AbstractChannel.this.isActive()) { if (firstRegistration) { AbstractChannel.this.pipeline.fireChannelActive(); //这里是关键 } else if (AbstractChannel.this.config().isAutoRead()) { this.beginRead(); } } ... } 来到最后一级： protected void doRegister() throws Exception { boolean selected = false; while(true) { try { //可以看到在这里终于是真正的进行了注册，javaChannel()得到NIO的Channel对象，然后调用register方法 //这里就和我们之前NIO一样了，将Channel注册到Selector中，可以看到Selector也是EventLoop中的 //但是注意，这里的ops参数是0，也就是不监听任何事件 this.selectionKey = this.javaChannel().register(this.eventLoop().unwrappedSelector(), 0, this); return; ... } } 我们回到上一级，在doRegister完成之后，会拿到selectionKey，但是注意这时还没有监听任何事件，我们接着看到下面的fireChannelActive方法： public final ChannelPipeline fireChannelActive() { AbstractChannelHandlerContext.invokeChannelActive(this.head); //传的是流水线上的默认头结点 return this; } static void invokeChannelActive(final AbstractChannelHandlerContext next) { EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeChannelActive(); //继续向下 } else { executor.execute(new Runnable() { public void run() { next.invokeChannelActive(); } }); } } private void invokeChannelActive() { if (this.invokeHandler()) { try { ((ChannelInboundHandler)this.handler()).channelActive(this); //依然是调用的头结点的channelActive方法进行处理 } catch (Throwable var2) { this.invokeExceptionCaught(var2); } } else { this.fireChannelActive(); } } public void channelActive(ChannelHandlerContext ctx) { //这里是头结点的 ctx.fireChannelActive(); this.readIfIsAutoRead(); //继续向下 } private void readIfIsAutoRead() { if (DefaultChannelPipeline.this.channel.config().isAutoRead()) { DefaultChannelPipeline.this.channel.read(); //继续不断向下 } } public void read(ChannelHandlerContext ctx) { this.unsafe.beginRead(); //最后这里会调用beginRead方法 } public final void beginRead() { this.assertEventLoop(); try { AbstractChannel.this.doBeginRead(); //这里就是调用AbstractNioChannel的doBeginRead方法了 } catch (final Exception var2) { this.invokeLater(new Runnable() { public void run() { AbstractChannel.this.pipeline.fireExceptionCaught(var2); } }); this.close(this.voidPromise()); } } protected void doBeginRead() throws Exception { SelectionKey selectionKey = this.selectionKey; //先拿到之前注册好的selectionKey if (selectionKey.isValid()) { this.readPending = true; int interestOps = selectionKey.interestOps(); //把监听的操作取出来 if ((interestOps & this.readInterestOp) == 0) { //如果没有监听任何操作 selectionKey.interestOps(interestOps | this.readInterestOp); //那就把readInterestOp事件进行监听，这里的readInterestOp实际上就是OP_ACCEPT } } } 这样，Channel在初始化完成之后也完成了底层的注册，已经可以开始等待事件了。 我们现在回到之前的doBind方法的注册位置，现在注册完成之后，基本上整个主从Reactor结构就已经出来了，我们来看看还要做些什么： private ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = this.initAndRegister(); //目前初始化和注册都已经成功了 final Channel channel = regFuture.channel(); //由于是异步操作，我们通过ChannelFuture拿到对应的ServerSocketChannel对象 if (regFuture.cause() != null) { return regFuture; } else if (regFuture.isDone()) { //如果说初始化已经完成了 ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); //直接开始进行进一步的绑定 return promise; } else { //如果还没搞完，那就创Promis继续等待任务完成 final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { promise.setFailure(cause); } else { promise.registered(); AbstractBootstrap.doBind0(regFuture, channel, localAddress, promise); } } }); return promise; } } 可以看到最后都会走到doBind0方法： private static void doBind0(final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) { //最后会向Channel已经注册到的EventLoop中提交一个新的任务 channel.eventLoop().execute(new Runnable() { public void run() { if (regFuture.isSuccess()) { //这里才是真正调用Channel底层进行绑定操作 channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } }); } 至此，服务端的启动流程结束。我们前面还提到了NIO的空轮询问题，这里我们来看看Netty是如何解决的，我们直接定位到NioEventLoop中： //由于代码太多，这里省略大部分代码 while(true) { boolean var34; try { ... try { if (!this.hasTasks()) { strategy = this.select(curDeadlineNanos); //首先会在这里进行Selector.select()操作，跟NIO是一样的 } ... ++selectCnt; //每次唤醒都会让selectCnt自增 this.cancelledKeys = 0; ... if (!ranTasks && strategy 我们来看看是怎么进行判断的： private boolean unexpectedSelectorWakeup(int selectCnt) { if (Thread.interrupted()) { if (logger.isDebugEnabled()) { logger.debug(\"Selector.select() returned prematurely because Thread.currentThread().interrupt() was called. Use NioEventLoop.shutdownGracefully() to shutdown the NioEventLoop.\"); } return true; //如果selectCnt大于等于SELECTOR_AUTO_REBUILD_THRESHOLD（默认为512）那么会直接重建Selector } else if (SELECTOR_AUTO_REBUILD_THRESHOLD > 0 && selectCnt >= SELECTOR_AUTO_REBUILD_THRESHOLD) { logger.warn(\"Selector.select() returned prematurely {} times in a row; rebuilding Selector {}.\", selectCnt, this.selector); this.rebuildSelector(); //当前的Selector出现BUG了，得重建一个Selector return true; } else { return false; } } 实际上，当每次空轮询发生时会有专门的计数器+1，如果空轮询的次数超过了512次，就认为其触发了空轮询bug，触发bug后，Netty直接重建一个Selector，将原来的Channel重新注册到新的 Selector上，将旧的 Selector关掉，这样就防止了无限循环。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/NIO/Java NIO（二）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/NIO/Java NIO（二）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/SpringCloud/":{"url":"Java/SpringCloud/","title":"SpringCloud","keywords":"","body":"April 项目组文档仓库 这是一个用于存储文档的仓库，可以方便地共享和管理各种文档。本仓库的文档类型不限，可以包括但不限于技术文档、设计文档、需求文档、用户手册等。 如何使用 你可以通过以下几种方式使用本仓库： 查看文档：在本仓库中找到你需要的文档，点击进入查看。 下载文档：在文档页面中点击下载按钮，即可下载文档。 提交文档：如果你想上传一个新文档或修改已有文档，可以先 Fork 本仓库，然后在你的仓库中进行修改，最后发起 Pull Request 即可。 贡献 如果你想为本仓库贡献文档，欢迎进行如下操作： Fork 本仓库 在你的仓库中添加或修改文档 发起 Pull Request 我们会及时审核并合并你的贡献。为了保证贡献质量，建议你在提交贡献前，仔细阅读贡献指南。 贡献指南 为了保证本仓库的贡献质量，我们制定了如下的贡献指南： 文档内容应当真实可靠，不得包含虚假信息。 文档格式应当规范，建议使用 Markdown 格式。 文档应当具有实用性和参考价值，不得过于简单或复杂。 代码示例应当可执行，并应当注明相关依赖库的版本号。 如有图片、视频等附件，建议使用外部链接或专门的存储仓库。 版权声明 本仓库的所有文档均属于原作者版权所有，未经授权不得进行商业使用。在 Fork 和提交贡献时，请务必尊重原作者的版权，并注明出处。 联系我们 如果你有任何问题或建议，可以通过以下方式联系我们： 邮箱：mobaijun8@163.com GitHub Issues：https://github.com/april-projects/.docs/issues window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/README.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/README.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/SpringCloud/SpringCloud（一）.html":{"url":"Java/SpringCloud/SpringCloud（一）.html","title":"SpringCloud（一）","keywords":"","body":" 微服务基础 注意：此阶段学习推荐的电脑配置，至少配备4核心CPU（主频3.0Ghz以上）+16GB内存，否则卡到你怀疑人生。 前面我们讲解了SpringBoot框架，通过使用SpringBoot框架，我们的项目开发速度可以说是得到了质的提升。同时，我们对于项目的维护和理解，也会更加的轻松。可见，SpringBoot为我们的开发带来了巨大便捷。而这一部分，我们将基于SpringBoot，继续深入到企业实际场景，探讨微服务架构下的SpringCloud。这个部分我们会更加注重于架构设计上的讲解，弱化实现原理方面的研究。 传统项目转型 要说近几年最火热的话题，那还得是微服务，那么什么是微服务呢？ 我们可以先从技术的演变开始看起，在我们学习JavaWeb之后，一般的网站开发模式为Servlet+JSP，但是实际上我们在学习了SSM之后，会发现这种模式已经远远落后了，第一，一个公司不可能去招那么多同时会前端+后端的开发人员，就算招到，也并不一定能保证两个方面都比较擅长，相比前后端分开学习的开发人员，显然后者的学习成本更低，专注度更高。因此前后端分离成为了一种新的趋势。通过使用SpringBoot，我们几乎可以很快速地开发一个高性能的单体应用，只需要启动一个服务端，我们整个项目就开始运行了，各项功能融于一体，开发起来也更加轻松。 但是随着我们项目的不断扩大，单体应用似乎显得有点乏力了。 随着越来越多的功能不断地加入到一个SpringBoot项目中，随着接口不断增加，整个系统就要在同一时间内响应更多类型的请求，显然，这种扩展方式是不可能无限使用下去的，总有一天，这个SpringBoot项目会庞大到运行缓慢。并且所有的功能如果都集成在单端上，那么所有的请求都会全部汇集到一台服务器上，对此服务器造成巨大压力。 可以试想一下，如果我们的电脑已经升级到i9-12900K，但是依然在运行项目的时候缓慢，无法同一时间响应成千上万的请求，那么这个问题就已经不是单纯升级机器配置可以解决的了。 传统单体架构应用随着项目规模的扩大，实际上会暴露越来越多的问题，尤其是一台服务器无法承受庞大的单体应用部署，并且单体应用的维护也会越来越困难，我们得寻找一种新的开发架构来解决这些问题了。 In short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. Martin Fowler在2014年提出了“微服务”架构，它是一种全新的架构风格。 微服务把一个庞大的单体应用拆分为一个个的小型服务，比如我们原来的图书管理项目中，有登录、注册、添加、删除、搜索等功能，那么我们可以将这些功能单独做成一个个小型的SpringBoot项目，独立运行。 每个小型的微服务，都可以独立部署和升级，这样，就算整个系统崩溃，那么也只会影响一个服务的运行。 微服务之间使用HTTP进行数据交互，不再是单体应用内部交互了，虽然这样会显得更麻烦，但是带来的好处也是很直接的，甚至能突破语言限制，使用不同的编程语言进行微服务开发，只需要使用HTTP进行数据交互即可。 我们可以同时购买多台主机来分别部署这些微服务，这样，单机的压力就被分散到多台机器，并且每台机器的配置不一定需要太高，这样就能节省大量的成本，同时安全性也得到很大的保证。 甚至同一个微服务可以同时存在多个，这样当其中一个服务器出现问题时，其他服务器也在运行同样的微服务，这样就可以保证一个微服务的高可用。 当然，这里只是简单的演示一下微服务架构，实际开发中肯定是比这个复杂得多的。 可见，采用微服务架构，更加能够应对当今时代下的种种考验，传统项目的开发模式，需要进行架构上的升级。 走进SpringCloud 前面我们介绍了微服务架构的优点，那么同样的，这些优点的背后也存在着诸多的问题： 要实现微服务并不是说只需要简单地将项目进行拆分，我们还需要考虑对各个微服务进行管理、监控等，这样我们才能够及时地寻找和排查问题。因此微服务往往需要的是一整套解决方案，包括服务注册和发现、容灾处理、负载均衡、配置管理等。 它不像单体架构那种方便维护，由于部署在多个服务器，我们不得不去保证各个微服务能够稳定运行，在管理难度上肯定是高于传统单体应用的。 在分布式的环境下，单体应用的某些功能可能会变得比较麻烦，比如分布式事务。 所以，为了更好地解决这些问题，SpringCloud正式登场。 SpringCloud是Spring提供的一套分布式解决方案，集合了一些大型互联网公司的开源产品，包括诸多组件，共同组成SpringCloud框架。并且，它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、熔断机制、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。 由于中小型公司没有独立开发自己的分布式基础设施的能力，使用SpringCloud解决方案能够以最低的成本应对当前时代的业务发展。 可以看到，SpringCloud整体架构的亮点是非常明显的，分布式架构下的各个场景，都有对应的组件来处理，比如基于Netflix（奈飞）的开源分布式解决方案提供的组件： Eureka - 实现服务治理（服务注册与发现），我们可以对所有的微服务进行集中管理，包括他们的运行状态、信息等。 Ribbon - 为服务之间相互调用提供负载均衡算法（现在被SpringCloudLoadBalancer取代） Hystrix - 断路器，保护系统，控制故障范围。暂时可以跟家里电闸的保险丝类比，当触电危险发生时能够防止进一步的发展。 Zuul - api网关，路由，负载均衡等多种作用，就像我们的路由器，可能有很多个设备都连接了路由器，但是数据包要转发给谁则是由路由器在进行（已经被SpringCloudGateway取代） Config - 配置管理，可以实现配置文件集中管理 当然，这里只是进行简单的了解即可，实际上微服务的玩法非常多，我们后面的学习中将会逐步进行探索。 那么首先，我们就从注册中心开始说起。 Eureka 注册中心 官方文档：https://docs.spring.io/spring-cloud-netflix/docs/current/reference/html/ 小贴士：各位小伙伴在学习的过程中觉得有什么疑惑的可以直接查阅官方文档，我们会在每一个技术开始之前贴上官方文档的地址，方便各位进行查阅，同时在我们的课程中并不一定会完完整整地讲完整个框架的内容，有关详细的功能和使用方法文档中也是写的非常清楚的，感兴趣的可以深入学习哦。 微服务项目结构 现在我们重新设计一下之前的图书管理系统项目，将原有的大型（也许 项目进行拆分，注意项目拆分一定要尽可能保证单一职责，相同的业务不要在多个微服务中重复出现，如果出现需要借助其他业务完成的服务，那么可以使用服务之间相互调用的形式来实现（之后会介绍）： 登录验证服务：用于处理用户注册、登录、密码重置等，反正就是一切与账户相关的内容，包括用户信息获取等。 图书管理服务：用于进行图书添加、删除、更新等操作，图书管理相关的服务，包括图书的存储等和信息获取。 图书借阅服务：交互性比较强的服务，需要和登陆验证服务和图书管理服务进行交互。 那么既然要将单体应用拆分为多个小型服务，我们就需要重新设计一下整个项目目录结构，这里我们就创建多个子项目，每一个子项目都是一个服务，这样由父项目统一管理依赖，就无需每个子项目都去单独管理依赖了，也更方便一点。 我们首先创建一个普通的SpringBoot项目： 然后不需要勾选任何依赖，直接创建即可，项目创建完成并初始化后，我们删除父工程的无用文件，只保留必要文件，像下面这样： 接着我们就可以按照我们划分的服务，进行子工程创建了，创建一个新的Maven项目，注意父项目要指定为我们一开始创建的的项目，子项目命名随意： 子项目创建好之后，接着我们在子项目中创建SpringBoot的启动主类： 接着我们点击运行，即可启动子项目了，实际上这个子项目就一个最简单的SpringBoot web项目，注意启动之后最下方有弹窗，我们点击\"使用 服务\"，这样我们就可以实时查看当前整个大项目中有哪些微服务了： 接着我们以同样的方法，创建其他的子项目，注意我们最好将其他子项目的端口设置得不一样，不然会导致端口占用，我们分别为它们创建application.yml文件： 接着我们来尝试启动一下这三个服务，正常情况下都是可以直接启动的： 可以看到它们分别运行在不同的端口上，这样，就方便不同的程序员编写不同的服务了，提交当前项目代码时的冲突率也会降低。 接着我们来创建一下数据库，这里还是老样子，创建三个表即可，当然实际上每个微服务单独使用一个数据库服务器也是可以的，因为按照单一职责服务只会操作自己对应的表，这里UP主比较穷，就只用一个数据库演示了： 创建好之后，结果如下，一共三张表，各位可以自行添加一些数据到里面，这就不贴出来了： 如果各位嫌麻烦的话可以下载.sql文件自行导入。 接着我们来稍微写一点业务，比如用户信息查询业务，我们先把数据库相关的依赖进行导入，这里依然使用Mybatis框架，首先在父项目中添加MySQL驱动和Lombok依赖： mysql mysql-connector-java org.projectlombok lombok 由于不是所有的子项目都需要用到Mybatis，我们在父项目中只进行版本管理即可： org.mybatis.spring.boot mybatis-spring-boot-starter 2.2.0 接着我们就可以在用户服务子项目中添加此依赖了： org.mybatis.spring.boot mybatis-spring-boot-starter 接着添加数据源信息（UP用到是阿里云的MySQL云数据库，各位注意修改一下数据库地址）： spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://cloudstudy.mysql.cn-chengdu.rds.aliyuncs.com:3306/cloudstudy username: test password: 123456 接着我们来写用户查询相关的业务： @Data public class User { int uid; String name; String sex; } @Mapper public interface UserMapper { @Select(\"select * from DB_USER where uid = #{uid}\") User getUserById(int uid); } public interface UserService { User getUserById(int uid); } @Service public class UserServiceImpl implements UserService { @Resource UserMapper mapper; @Override public User getUserById(int uid) { return mapper.getUserById(uid); } } @RestController public class UserController { @Resource UserService service; //这里以RESTFul风格为例 @RequestMapping(\"/user/{uid}\") public User findUserById(@PathVariable(\"uid\") int uid){ return service.getUserById(uid); } } 现在我们访问即可拿到数据： 同样的方式，我们完成一下图书查询业务，注意现在是在图书管理微服务中编写（别忘了导入Mybatis依赖以及配置数据源）： @Data public class Book { int bid; String title; String desc; } @Mapper public interface BookMapper { @Select(\"select * from DB_BOOK where bid = #{bid}\") Book getBookById(int bid); } public interface BookService { Book getBookById(int bid); } @Service public class BookServiceImpl implements BookService { @Resource BookMapper mapper; @Override public Book getBookById(int bid) { return mapper.getBookById(bid); } } @RestController public class BookController { @Resource BookService service; @RequestMapping(\"/book/{bid}\") Book findBookById(@PathVariable(\"bid\") int bid){ return service.getBookById(bid); } } 同样进行一下测试： 这样，我们一个完整项目的就拆分成了多个微服务，不同微服务之间是独立进行开发和部署的。 服务间调用 前面我们完成了用户信息查询和图书信息查询，现在我们来接着完成借阅服务。 借阅服务是一个关联性比较强的服务，它不仅仅需要查询借阅信息，同时可能还需要获取借阅信息下的详细信息，比如具体那个用户借阅了哪本书，并且用户和书籍的详情也需要同时出现，那么这种情况下，我们就需要去访问除了借阅表以外的用户表和图书表。 但是这显然是违反我们之前所说的单一职责的，相同的业务功能不应该重复出现，但是现在由需要在此服务中查询用户的信息和图书信息，那怎么办呢？我们可以让一个服务去调用另一个服务来获取信息。 这样，图书管理微服务和用户管理微服务相对于借阅记录，就形成了一个生产者和消费者的关系，前者是生产者，后者便是消费者。 现在我们先将借阅关联信息查询完善了： @Data public class Borrow { int id; int uid; int bid; } @Mapper public interface BorrowMapper { @Select(\"select * from DB_BORROW where uid = #{uid}\") List getBorrowsByUid(int uid); @Select(\"select * from DB_BORROW where bid = #{bid}\") List getBorrowsByBid(int bid); @Select(\"select * from DB_BORROW where bid = #{bid} and uid = #{uid}\") Borrow getBorrow(int uid, int bid); } 现在有一个需求，需要查询用户的借阅详细信息，也就是说需要查询某个用户具体借了那些书，并且需要此用户的信息和所有已借阅的书籍信息一起返回，那么我们先来设计一下返回实体： @Data @AllArgsConstructor public class UserBorrowDetail { User user; List bookList; } 但是有一个问题，我们发现User和Book实体实际上是在另外两个微服务中定义的，相当于当前项目并没有定义这些实体类，那么怎么解决呢？ 因此，我们可以将所有服务需要用到的实体类单独放入另一个一个项目中，然后让这些项目引用集中存放实体类的那个项目，这样就可以保证每个微服务的实体类信息都可以共用了： 然后只需要在对应的类中引用此项目作为依赖即可： com.example commons 0.0.1-SNAPSHOT 之后新的公共实体类都可以在commons项目中进行定义了，现在我们接着来完成刚刚的需求，先定义接口： public interface BorrowService { UserBorrowDetail getUserBorrowDetailByUid(int uid); } @Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); //那么问题来了，现在拿到借阅关联信息了，怎么调用其他服务获取信息呢？ } } 需要进行服务远程调用我们需要用到RestTemplate来进行： @Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); //RestTemplate支持多种方式的远程调用 RestTemplate template = new RestTemplate(); //这里通过调用getForObject来请求其他服务，并将结果自动进行封装 //获取User信息 User user = template.getForObject(\"http://localhost:8082/user/\"+uid, User.class); //获取每一本书的详细信息 List bookList = borrow .stream() .map(b -> template.getForObject(\"http://localhost:8080/book/\"+b.getBid(), Book.class)) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 现在我们再最后完善一下Controller： @RestController public class BorrowController { @Resource BorrowService service; @RequestMapping(\"/borrow/{uid}\") UserBorrowDetail findUserBorrows(@PathVariable(\"uid\") int uid){ return service.getUserBorrowDetailByUid(uid); } } 在数据库中添加一点借阅信息，测试看看能不能正常获取（注意一定要保证三个服务都处于开启状态，否则远程调用会失败）： 可以看到，结果正常，没有问题，远程调用成功。 这样，一个简易的图书管理系统的分布式项目就搭建完成了，这里记得把整个项目压缩打包备份一下，下一章学习SpringCloud Alibaba也需要进行配置。 服务注册与发现 前面我们了解了如何对单体应用进行拆分，并且也学习了如何进行服务之间的相互调用，但是存在一个问题，就是虽然服务拆分完成，但是没有一个比较合理的管理机制，如果单纯只是这样编写，在部署和维护起来，肯定是很麻烦的。可以想象一下，如果某一天这些微服务的端口或是地址大规模地发生改变，我们就不得不将服务之间的调用路径大规模的同步进行修改，这是多么可怕的事情。我们需要削弱这种服务之间的强关联性，因此我们需要一个集中管理微服务的平台，这时就要借助我们这一部分的主角了。 Eureka能够自动注册并发现微服务，然后对服务的状态、信息进行集中管理，这样当我们需要获取其他服务的信息时，我们只需要向Eureka进行查询就可以了。 像这样的话，服务之间的强关联性就会被进一步削弱。 那么现在我们就来搭建一个Eureka服务器，只需要创建一个新的Maven项目即可，然后我们需要在父工程中添加一下SpringCloud的依赖，这里选用2021.0.1版本（Spring Cloud 最新的版本命名方式变更了，现在是 YEAR.x 这种命名方式，具体可以在官网查看：https://spring.io/projects/spring-cloud#learn）： org.springframework.cloud spring-cloud-dependencies 2021.0.1 pom import 接着我们为新创建的项目添加依赖： org.springframework.cloud spring-cloud-starter-netflix-eureka-server 下载内容有点多，首次导入请耐心等待一下。 接着我们来创建主类，还是一样的操作： @EnableEurekaServer @SpringBootApplication public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } 别着急启动！！！接着我们需要修改一下配置文件： server: port: 8888 eureka: # 开启之前需要修改一下客户端设置（虽然是服务端 client: # 由于我们是作为服务端角色，所以不需要获取服务端，改为false，默认为true fetch-registry: false # 暂时不需要将自己也注册到Eureka register-with-eureka: false # 将eureka服务端指向自己 service-url: defaultZone: http://localhost:8888/eureka 好了，现在差不多可以启动了，启动完成后，直接输入地址+端口即可访问Eureka的管理后台： 可以看到目前还没有任何的服务注册到Eureka，我们接着来配置一下我们的三个微服务，首先还是需要导入Eureka依赖（注意别导错了，名称里面有个starter的才是）： org.springframework.cloud spring-cloud-starter-netflix-eureka-client 然后修改配置文件： eureka: client: # 跟上面一样，需要指向Eureka服务端地址，这样才能进行注册 service-url: defaultZone: http://localhost:8888/eureka OK，无需在启动类添加注解，直接启动就可以了，然后打开Eureka的服务管理页面，可以看到我们刚刚开启的服务： 可以看到8082端口上的服务器，已经成功注册到Eureka了，但是这个服务名称怎么会显示为UNKNOWN，我们需要修改一下： spring: application: name: userservice 当我们的服务启动之后，会每隔一段时间跟Eureka发送一次心跳包，这样Eureka就能够感知到我们的服务是否处于正常运行状态。 现在我们用同样的方法，将另外两个微服务也注册进来： 那么，现在我们怎么实现服务发现呢？ 也就是说，我们之前如果需要对其他微服务进行远程调用，那么就必须要知道其他服务的地址： User user = template.getForObject(\"http://localhost:8082/user/\"+uid, User.class); 而现在有了Eureka之后，我们可以直接向其进行查询，得到对应的微服务地址，这里直接将服务名称替换即可： @Service public class BorrowServiceImpl implements BorrowService { @Resource BorrowMapper mapper; @Resource RestTemplate template; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); //这里不用再写IP，直接写服务名称userservice User user = template.getForObject(\"http://userservice/user/\"+uid, User.class); //这里不用再写IP，直接写服务名称bookservice List bookList = borrow .stream() .map(b -> template.getForObject(\"http://bookservice/book/\"+b.getBid(), Book.class)) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 接着我们手动将RestTemplate声明为一个Bean，然后添加@LoadBalanced注解，这样Eureka就会对服务的调用进行自动发现，并提供负载均衡： @Configuration public class BeanConfig { @Bean @LoadBalanced RestTemplate template(){ return new RestTemplate(); } } 现在我们就可以正常调用了： 不对啊，不是说有负载均衡的能力吗，怎么个负载均衡呢？ 我们先来看看，同一个服务器实际上是可以注册很多个的，但是它们的端口不同，比如我们这里创建多个用户查询服务，我们现在将原有的端口配置修改一下，由IDEA中设定启动参数来决定，这样就可以多创建几个不同端口的启动项了： 可以看到，在Eureka中，同一个服务出现了两个实例： 现在我们稍微修改一下用户查询，然后进行远程调用，看看请求是不是均匀地分配到这两个服务端： @RestController public class UserController { @Resource UserService service; @RequestMapping(\"/user/{uid}\") public User findUserById(@PathVariable(\"uid\") int uid){ System.out.println(\"我被调用拉！\"); return service.getUserById(uid); } } 可以看到，两个实例都能够均匀地被分配请求： 这样，服务自动发现以及简单的负载均衡就实现完成了，并且，如果某个微服务挂掉了，只要存在其他同样的微服务实例在运行，那么就不会导致整个微服务不可用，极大地保证了安全性。 注册中心高可用 各位可否想过这样的一个问题？虽然Eureka能够实现服务注册和发现，但是如果Eureka服务器崩溃了，岂不是所有需要用到服务发现的微服务就GG了？ 为了避免，这种问题，我们也可以像上面那样，搭建Eureka集群，存在多个Eureka服务器，这样就算挂掉其中一个，其他的也还在正常运行，就不会使得服务注册与发现不可用。当然，要是物理黑客直接炸了整个机房，那还是算了吧。 我们来看看如何搭建Eureka集群，这里由于机器配置不高，就搭建两个Eureka服务器组成集群。 首先我们需要修改一下Eureka服务端的配置文件，这里我们创建两个配置文件，： server: port: 8801 spring: application: name: eurekaserver eureka: instance: # 由于不支持多个localhost的Eureka服务器，但是又只有本地测试环境，所以就只能自定义主机名称了 # 主机名称改为eureka01 hostname: eureka01 client: fetch-registry: false # 去掉register-with-eureka选项，让Eureka服务器自己注册到其他Eureka服务器，这样才能相互启用 service-url: # 注意这里填写其他Eureka服务器的地址，不用写自己的 defaultZone: http://eureka01:8801/eureka server: port: 8802 spring: application: name: eurekaserver eureka: instance: hostname: eureka02 client: fetch-registry: false service-url: defaultZone: http://eureka01:8801/eureka 这里由于我们修改成自定义的地址，需要在hosts文件中将其解析到172.0.0.1才能回到localhost，Mac下文件路径为/etc/hosts，Windows下为C:\\Windows\\system32\\drivers\\etc\\hosts： 对创建的两个配置文件分别添加启动配置，直接使用spring.profiles.active指定启用的配置文件即可： 接着启动这两个注册中心，这两个Eureka管理页面都可以被访问，我们访问其中一个： 可以看到下方replicas中已经包含了另一个Eureka服务器的地址，并且是可用状态。 接着我们需要将我们的微服务配置也进行修改： eureka: client: service-url: # 将两个Eureka的地址都加入，这样就算有一个Eureka挂掉，也能完成注册 defaultZone: http://localhost:8801/eureka, http://localhost:8802/eureka 可以看到，服务全部成功注册，并且两个Eureka服务端都显示为已注册： 接着我们模拟一下，将其中一个Eureka服务器关闭掉，可以看到它会直接变成不可用状态： 当然，如果这个时候我们重启刚刚关闭的Eureka服务器，会自动同步其他Eureka服务器的数据。 LoadBalancer 负载均衡 前面我们讲解了如何对服务进行拆分、如何通过Eureka服务器进行服务注册与发现，那么现在我们来看看，它的负载均衡到底是如何实现的，实际上之前演示的负载均衡是依靠LoadBalancer实现的。 在2020年前的SpringCloud版本是采用Ribbon作为负载均衡实现，但是2020年的版本之后SpringCloud把Ribbon移除了，进而用自己编写的LoadBalancer替代。 那么，负载均衡是如何进行的呢？ 负载均衡 实际上，在添加@LoadBalanced注解之后，会启用拦截器对我们发起的服务调用请求进行拦截（注意这里是针对我们发起的请求进行拦截），叫做LoadBalancerInterceptor，它实现ClientHttpRequestInterceptor接口： @FunctionalInterface public interface ClientHttpRequestInterceptor { ClientHttpResponse intercept(HttpRequest request, byte[] body, ClientHttpRequestExecution execution) throws IOException; } 主要是对intercept方法的实现： public ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException { URI originalUri = request.getURI(); String serviceName = originalUri.getHost(); Assert.state(serviceName != null, \"Request URI does not contain a valid hostname: \" + originalUri); return (ClientHttpResponse)this.loadBalancer.execute(serviceName, this.requestFactory.createRequest(request, body, execution)); } 我们可以打个断点看看实际是怎么在执行的，可以看到： 服务端会在发起请求时执行这些拦截器。 那么这个拦截器做了什么事情呢，首先我们要明确，我们给过来的请求地址，并不是一个有效的主机名称，而是服务名称，那么怎么才能得到真正需要访问的主机名称呢，肯定是得找Eureka获取的。 我们来看看loadBalancer.execute()做了什么，它的具体实现为BlockingLoadBalancerClient： //从上面给进来了服务的名称和具体的请求实体 public T execute(String serviceId, LoadBalancerRequest request) throws IOException { String hint = this.getHint(serviceId); LoadBalancerRequestAdapter lbRequest = new LoadBalancerRequestAdapter(request, new DefaultRequestContext(request, hint)); Set supportedLifecycleProcessors = this.getSupportedLifecycleProcessors(serviceId); supportedLifecycleProcessors.forEach((lifecycle) -> { lifecycle.onStart(lbRequest); }); //可以看到在这里会调用choose方法自动获取对应的服务实例信息 ServiceInstance serviceInstance = this.choose(serviceId, lbRequest); if (serviceInstance == null) { supportedLifecycleProcessors.forEach((lifecycle) -> { lifecycle.onComplete(new CompletionContext(Status.DISCARD, lbRequest, new EmptyResponse())); }); //没有发现任何此服务的实例就抛异常（之前的测试中可能已经遇到了） throw new IllegalStateException(\"No instances available for \" + serviceId); } else { //成功获取到对应服务的实例，这时就可以发起HTTP请求获取信息了 return this.execute(serviceId, serviceInstance, lbRequest); } } 所以，实际上在进行负载均衡的时候，会向Eureka发起请求，选择一个可用的对应服务，然后会返回此服务的主机地址等信息： 自定义负载均衡策略 LoadBalancer默认提供了两种负载均衡策略： RandomLoadBalancer - 随机分配策略 (默认) RoundRobinLoadBalancer - 轮询分配策略 现在我们希望修改默认的负载均衡策略，可以进行指定，比如我们现在希望用户服务采用随机分配策略，我们需要先创建随机分配策略的配置类（不用加@Configuration）： public class LoadBalancerConfig { //将官方提供的 RandomLoadBalancer 注册为Bean @Bean public ReactorLoadBalancer randomLoadBalancer(Environment environment, LoadBalancerClientFactory loadBalancerClientFactory){ String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME); return new RandomLoadBalancer(loadBalancerClientFactory.getLazyProvider(name, ServiceInstanceListSupplier.class), name); } } 接着我们需要为对应的服务指定负载均衡策略，直接使用注解即可： @Configuration @LoadBalancerClient(value = \"userservice\", //指定为 userservice 服务，只要是调用此服务都会使用我们指定的策略 configuration = LoadBalancerConfig.class) //指定我们刚刚定义好的配置类 public class BeanConfig { @Bean @LoadBalanced RestTemplate template(){ return new RestTemplate(); } } 接着我们在BlockingLoadBalancerClient中添加断点，观察是否采用我们指定的策略进行请求： 发现访问userservice服务的策略已经更改为我们指定的策略了。 OpenFeign实现负载均衡 官方文档：https://docs.spring.io/spring-cloud-openfeign/docs/current/reference/html/ Feign和RestTemplate一样，也是HTTP客户端请求工具，但是它的使用方式更加便捷。首先是依赖： org.springframework.cloud spring-cloud-starter-openfeign 接着在启动类添加@EnableFeignClients注解： @SpringBootApplication @EnableFeignClients public class BorrowApplication { public static void main(String[] args) { SpringApplication.run(BorrowApplication.class, args); } } 那么现在我们需要调用其他微服务提供的接口，该怎么做呢？我们直接创建一个对应服务的接口类即可： @FeignClient(\"userservice\") //声明为userservice服务的HTTP请求客户端 public interface UserClient { } 接着我们直接创建所需类型的方法，比如我们之前的： RestTemplate template = new RestTemplate(); User user = template.getForObject(\"http://userservice/user/\"+uid, User.class); 现在可以直接写成这样： @FeignClient(\"userservice\") public interface UserClient { //路径保证和其他微服务提供的一致即可 @RequestMapping(\"/user/{uid}\") User getUserById(@PathVariable(\"uid\") int uid); //参数和返回值也保持一致 } 接着我们直接注入使用（有Mybatis那味了）： @Resource UserClient userClient; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); //这里不用再写IP，直接写服务名称bookservice List bookList = borrow .stream() .map(b -> template.getForObject(\"http://bookservice/book/\"+b.getBid(), Book.class)) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } 访问，可以看到结果依然是正确的： 并且我们可以观察一下两个用户微服务的调用情况，也是以负载均衡的形式进行的。 按照同样的方法，我们接着将图书管理服务的调用也改成接口形式： 最后我们的Service代码就变成了： @Service public class BorrowServiceImpl implements BorrowService { @Resource BorrowMapper mapper; @Resource UserClient userClient; @Resource BookClient bookClient; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List bookList = borrow .stream() .map(b -> bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 继续访问进行测试： OK，正常。 当然，Feign也有很多的其他配置选项，这里就不多做介绍了，详细请查阅官方文档。 Hystrix 服务熔断 官方文档：https://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/1.3.5.RELEASE/single/spring-cloud-netflix.html#_circuit_breaker_hystrix_clients 我们知道，微服务之间是可以进行相互调用的，那么如果出现了下面的情况会导致什么问题？ 由于位于最底端的服务提供者E发生故障，那么此时会直接导致服务ABCD全线崩溃，就像雪崩了一样。 这种问题实际上是不可避免的，由于多种因素，比如网络卡顿、系统故障、硬件问题等，都存在一定可能，会导致这种极端的情况发生。因此，我们需要寻找一个应对这种极端情况的解决方案。 为了解决分布式系统的雪崩问题，SpringCloud提供了Hystrix熔断器组件，他就像我们家中的保险丝一样，当电流过载就会直接熔断，防止危险进一步发生，从而保证家庭用电安全。可以想象一下，如果整条链路上的服务已经全线崩溃，这时还在不断地有大量的请求到达，需要各个服务进行处理，肯定是会使得情况越来越糟糕的。 我们来详细看看它的工作机制。 服务降级 首先我们来看看服务降级，注意一定要区分开服务降级和服务熔断的区别，服务降级并不会直接返回错误，而是可以提供一个补救措施，正常响应给请求者。这样相当于服务依然可用，但是服务能力肯定是下降了的。 我们就基于借阅管理服务来进行讲解，我们不开启用户服务和图书服务，表示用户服务和图书服务已经挂掉了。 这里我们导入Hystrix的依赖（此项目已经停止维护，SpringCloud依赖中已经不自带了，所以说需要自己单独导入）： org.springframework.cloud spring-cloud-starter-netflix-hystrix 2.2.10.RELEASE 接着我们需要在启动类添加注解开启： @SpringBootApplication @EnableHystrix //启用Hystrix public class BorrowApplication { public static void main(String[] args) { SpringApplication.run(BorrowApplication.class, args); } } 那么现在，由于用户服务和图书服务不可用，所以查询借阅信息的请求肯定是没办法正常响应的，这时我们可以提供一个备选方案，也就是说当服务出现异常时，返回我们的备选方案： @RestController public class BorrowController { @Resource BorrowService service; @HystrixCommand(fallbackMethod = \"onError\") //使用@HystrixCommand来指定备选方案 @RequestMapping(\"/borrow/{uid}\") UserBorrowDetail findUserBorrows(@PathVariable(\"uid\") int uid){ return service.getUserBorrowDetailByUid(uid); } //备选方案，这里直接返回空列表了 //注意参数和返回值要和上面的一致 UserBorrowDetail onError(int uid){ return new UserBorrowDetail(null, Collections.emptyList()); } } 可以看到，虽然我们的服务无法正常运行了，但是依然可以给浏览器正常返回响应数据： 服务降级是一种比较温柔的解决方案，虽然服务本身的不可用，但是能够保证正常响应数据。 服务熔断 熔断机制是应对雪崩效应的一种微服务链路保护机制，当检测出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回”错误”的响应信息。当检测到该节点微服务响应正常后恢复调用链路。 实际上，熔断就是在降级的基础上进一步升级形成的，也就是说，在一段时间内多次调用失败，那么就直接升级为熔断。 我们可以添加两条输出语句： @RestController public class BorrowController { @Resource BorrowService service; @HystrixCommand(fallbackMethod = \"onError\") @RequestMapping(\"/borrow/{uid}\") UserBorrowDetail findUserBorrows(@PathVariable(\"uid\") int uid){ System.out.println(\"开始向其他服务获取信息\"); return service.getUserBorrowDetailByUid(uid); } UserBorrowDetail onError(int uid){ System.out.println(\"服务错误，进入备选方法！\"); return new UserBorrowDetail(null, Collections.emptyList()); } } 接着，我们在浏览器中疯狂点击刷新按钮，对此服务疯狂发起请求，可以看到后台： 一开始的时候，会正常地去调用Controller对应的方法findUserBorrows，发现失败然后进入备选方法，但是我们发现在持续请求一段时间之后，没有再调用这个方法，而是直接调用备选方案，这便是升级到了熔断状态。 我们可以继续不断点击，继续不断地发起请求： 可以看到，过了一段时间之后，会尝试正常执行一次findUserBorrows，但是依然是失败状态，所以继续保持熔断状态。 所以得到结论，它能够对一段时间内出现的错误进行侦测，当侦测到出错次数过多时，熔断器会打开，所有的请求会直接响应失败，一段时间后，只执行一定数量的请求，如果还是出现错误，那么则继续保持打开状态，否则说明服务恢复正常运行，关闭熔断器。 我们可以测试一下，开启另外两个服务之后，继续点击： 可以看到，当另外两个服务正常运行之后，当再次尝试调用findUserBorrows之后会成功，于是熔断机制就关闭了，服务恢复运行。 总结一下： OpenFeign实现降级 Hystrix也可以配合Feign进行降级，我们可以对应接口中定义的远程调用单独进行降级操作。 比如我们还是以用户服务挂掉为例，那么这个时候肯定是会远程调用失败的，也就是说我们的Controller中的方法在执行过程中会直接抛出异常，进而被Hystrix监控到并进行服务降级。 而实际上导致方法执行异常的根源就是远程调用失败，所以我们换个思路，既然用户服务调用失败，那么我就给这个远程调用添加一个替代方案，如果此远程调用失败，那么就直接上替代方案。那么怎么实现替代方案呢？我们知道Feign都是以接口的形式来声明远程调用，那么既然远程调用已经失效，我们就自行对其进行实现，创建一个实现类，对原有的接口方法进行替代方案实现： @Component //注意，需要将其注册为Bean，Feign才能自动注入 public class UserFallbackClient implements UserClient{ @Override public User getUserById(int uid) { //这里我们自行对其进行实现，并返回我们的替代方案 User user = new User(); user.setName(\"我是替代方案\"); return user; } } 实现完成后，我们只需要在原有的接口中指定失败替代实现即可： //fallback参数指定为我们刚刚编写的实现类 @FeignClient(value = \"userservice\", fallback = UserFallbackClient.class) public interface UserClient { @RequestMapping(\"/user/{uid}\") User getUserById(@PathVariable(\"uid\") int uid); } 现在去掉BorrowController的@HystrixCommand注解和备选方法： @RestController public class BorrowController { @Resource BorrowService service; @RequestMapping(\"/borrow/{uid}\") UserBorrowDetail findUserBorrows(@PathVariable(\"uid\") int uid){ return service.getUserBorrowDetailByUid(uid); } } 最后我们在配置文件中开启熔断支持： feign: circuitbreaker: enabled: true 启动服务，调用接口试试看： 可以看到，现在已经采用我们的替代方案作为结果。 监控页面部署 除了对服务的降级和熔断处理，我们也可以对其进行实时监控，只需要安装监控页面即可，这里我们创建一个新的项目，导入依赖： org.springframework.cloud spring-cloud-starter-netflix-hystrix-dashboard 2.2.10.RELEASE 接着添加配置文件： server: port: 8900 hystrix: dashboard: # 将localhost添加到白名单，默认是不允许的 proxy-stream-allow-list: \"localhost\" 接着创建主类，注意需要添加@EnableHystrixDashboard注解开启管理页面： @SpringBootApplication @EnableHystrixDashboard public class HystrixDashBoardApplication { public static void main(String[] args) { SpringApplication.run(HystrixDashBoardApplication.class, args); } } 启动Hystrix管理页面服务，然后我们需要在要进行监控的服务中添加Actuator依赖： org.springframework.boot spring-boot-starter-actuator Actuator是SpringBoot程序的监控系统，可以实现健康检查，记录信息等。在使用之前需要引入spring-boot-starter-actuator，并做简单的配置即可。 添加此依赖后，我们可以在IDEA中查看运行情况： 然后在配置文件中配置Actuator添加暴露： management: endpoints: web: exposure: include: '*' 接着我们打开刚刚启动的管理页面，地址为：http://localhost:8900/hystrix/ 在中间填写要监控的服务：比如借阅服务：http://localhost:8301/actuator/hystrix.stream，注意后面要添加`/actuator/hystrix.stream`，然后点击Monitor Stream即可进入监控页面： 可以看到现在都是Loading状态，这是因为还没有开始统计，我们现在尝试调用几次我们的服务： 可以看到，在调用之后，监控页面出现了信息： 可以看到5次访问都是正常的，所以显示为绿色，接着我们来尝试将图书服务关闭，这样就会导致服务降级甚至熔断，然后再多次访问此服务看看监控会如何变化： 可以看到，错误率直接飙升到100%，并且一段时间内持续出现错误，中心的圆圈也变成了红色，我们继续进行访问： 在出现大量错误的情况下保持持续访问，可以看到此时已经将服务熔断，Circuit更改为Open状态，并且图中的圆圈也变得更大，表示压力在持续上升。 Gateway 路由网关 官网地址：https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/ 说到路由，想必各位一定最先想到的就是家里的路由器了，那么我们家里的路由器充当的是一个什么角色呢？ 我们知道，如果我们需要连接互联网，那么就需要将手机或是电脑连接到家里的路由器才可以，而路由器则连接光猫，光猫再通过光纤连接到互联网，也就是说，互联网方向发送过来的数据，需要经过路由器才能到达我们的设备。而路由器充当的就是数据包中转站，所有的局域网设备都无法直接与互联网连接，而是需要经过路由器进行中转，我们一般说路由器下的网络是内网，而互联网那一端是外网。 我们的局域网设备，无法被互联网上的其他设备直接访问，肯定是能够保证到安全性的。并互联网发送过来的数据，需要经过路由器进行解析，识别到底是哪一个设备的数据包，然后再发送给对应的设备。 而我们的微服务也是这样，一般情况下，可能并不是所有的微服务都需要直接暴露给外部调用，这时我们就可以使用路由机制，添加一层防护，让所有的请求全部通过路由来转发到各个微服务，并且转发给多个相同微服务实例也可以实现负载均衡。 在之前，路由的实现一般使用Zuul，但是已经停更，而现在新出现了由SpringCloud官方开发的Gateway路由，它相比Zuul不仅性能上得到了一定的提升，并且是官方推出，契合性也会更好，所以我们这里就主要讲解Gateway。 部署网关 现在我们来创建一个新的项目，作为我们的网关，这里需要添加两个依赖： org.springframework.cloud spring-cloud-starter-gateway org.springframework.cloud spring-cloud-starter-netflix-eureka-client 第一个依赖就是网关的依赖，而第二个则跟其他微服务一样，需要注册到Eureka才能生效，注意别添加Web依赖，使用的是WebFlux框架。 然后我们来完善一下配置文件： server: port: 8500 eureka: client: service-url: defaultZone: http://localhost:8801/eureka, http://localhost:8802/eureka spring: application: name: gateway 现在就可以启动了： 但是现在还没有配置任何的路由功能，我们接着将路由功能进行配置： spring: cloud: gateway: # 配置路由，注意这里是个列表，每一项都包含了很多信息 routes: - id: borrow-service # 路由名称 uri: lb://borrowservice # 路由的地址，lb表示使用负载均衡到微服务，也可以使用http正常转发 predicates: # 路由规则，断言什么请求会被路由 - Path=/borrow/** # 只要是访问的这个路径，一律都被路由到上面指定的服务 路由规则的详细列表（断言工厂列表）在这里：https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/#gateway-request-predicates-factories，可以指定多种类型，包括指定时间段、Cookie携带情况、Header携带情况、访问的域名地址、访问的方法、路径、参数、访问者IP等。也可以使用配置类进行配置，但是还是推荐直接配置文件，省事。 接着启动网关，搭载Arm架构芯片的Mac电脑可能会遇到这个问题： 这是因为没有找到适用于此架构的动态链接库，不影响使用，无视即可，希望以后的版本能修复吧。 可以看到，我们现在可以直接通过路由来访问我们的服务了： 注意此时依然可以通过原有的服务地址进行访问： 这样我们就可以将不需要外网直接访问的微服务全部放到内网环境下，而只依靠网关来对外进行交涉。 路由过滤器 路由过滤器支持以某种方式修改传入的 HTTP 请求或传出的 HTTP 响应，路由过滤器的范围是某一个路由，跟之前的断言一样，Spring Cloud Gateway 也包含许多内置的路由过滤器工厂，详细列表：https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/#gatewayfilter-factories 比如我们现在希望在请求到达时，在请求头中添加一些信息再转发给我们的服务，那么这个时候就可以使用路由过滤器来完成，我们只需要对配置文件进行修改： spring: application: name: gateway cloud: gateway: routes: - id: borrow-service uri: lb://borrowservice predicates: - Path=/borrow/** # 继续添加新的路由配置，这里就以书籍管理服务为例 # 注意-要对齐routes: - id: book-service uri: lb://bookservice predicates: - Path=/book/** filters: # 添加过滤器 - AddRequestHeader=Test, HelloWorld! # AddRequestHeader 就是添加请求头信息，其他工厂请查阅官网 接着我们在BookController中获取并输出一下，看看是不是成功添加了： @RestController public class BookController { @Resource BookService service; @RequestMapping(\"/book/{bid}\") Book findBookById(@PathVariable(\"bid\") int bid, HttpServletRequest request){ System.out.println(request.getHeader(\"Test\")); return service.getBookById(bid); } } 现在我们通过Gateway访问我们的图书管理服务： 可以看到这里成功获取到由网关添加的请求头信息了。 除了针对于某一个路由配置过滤器之外，我们也可以自定义全局过滤器，它能够作用于全局。但是我们需要通过代码的方式进行编写，比如我们要实现拦截没有携带指定请求参数的请求： @Component //需要注册为Bean public class TestFilter implements GlobalFilter { @Override public Mono filter(ServerWebExchange exchange, GatewayFilterChain chain) { //只需要实现此方法 return null; } } 接着我们编写判断： @Override public Mono filter(ServerWebExchange exchange, GatewayFilterChain chain) { //先获取ServerHttpRequest对象，注意不是HttpServletRequest ServerHttpRequest request = exchange.getRequest(); //打印一下所有的请求参数 System.out.println(request.getQueryParams()); //判断是否包含test参数，且参数值为1 List value = request.getQueryParams().get(\"test\"); if(value != null && value.contains(\"1\")) { //将ServerWebExchange向过滤链的下一级传递（跟JavaWeb中介绍的过滤器其实是差不多的） return chain.filter(exchange); }else { //直接在这里不再向下传递，然后返回响应 return exchange.getResponse().setComplete(); } } 可以看到结果： 成功实现规则判断和拦截操作。 当然，过滤器肯定是可以存在很多个的，所以我们可以手动指定过滤器之间的顺序： @Component public class TestFilter implements GlobalFilter, Ordered { //实现Ordered接口 @Override public int getOrder() { return 0; } 注意Order的值越小优先级越高，并且无论是在配置文件中编写的单个路由过滤器还是全局路由过滤器，都会受到Order值影响（单个路由的过滤器Order值按从上往下的顺序从1开始递增），最终是按照Order值决定哪个过滤器优先执行，当Order值一样时 全局路由过滤器执行 优于 单独的路由过滤器执行。 Config 配置中心 官方文档：https://docs.spring.io/spring-cloud-config/docs/current/reference/html/ 经过前面的学习，我们对于一个分布式应用的技术选型和搭建已经了解得比较多了，但是各位有没有发现一个问题，如果我们的微服务项目需要部署很多个实例，那么配置文件我们岂不是得一个一个去改，可能十几个实例还好，要是有几十个上百个呢？那我们一个一个去配置，岂不直接猝死在工位上。 所以，我们需要一种更加高级的集中化地配置文件管理工具，集中地对配置文件进行配置。 Spring Cloud Config 为分布式系统中的外部配置提供服务器端和客户端支持。使用 Config Server，您可以集中管理所有环境中应用程序的外部配置。 实际上Spring Cloud Config就是一个配置中心，所有的服务都可以从配置中心取出配置，而配置中心又可以从GitHub远程仓库中获取云端的配置文件，这样我们只需要修改GitHub中的配置即可对所有的服务进行配置管理了。 部署配置中心 这里我们接着创建一个新的项目，并导入依赖： org.springframework.cloud spring-cloud-config-server org.springframework.cloud spring-cloud-starter-netflix-eureka-client 老规矩，启动类： @SpringBootApplication @EnableConfigServer public class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class, args); } } 接着就是配置文件： server: port: 8700 spring: application: name: configserver eureka: client: service-url: defaultZone: http://localhost:8801/eureka, http://localhost:8802/eureka 先启动一次看看，能不能成功： 这里我们以本地仓库为例（就不用GitHub了，卡到怀疑人生了），首先在项目目录下创建一个本地Git仓库，打开终端，在桌面上创建一个新的本地仓库： 然后我们在文件夹中随便创建一些配置文件，注意名称最好是{服务名称}-{环境}.yml： 然后我们在配置文件中，添加本地仓库的一些信息（远程仓库同理），详细使用教程：https://docs.spring.io/spring-cloud-config/docs/current/reference/html/#_git_backend spring: cloud: config: server: git: # 这里填写的是本地仓库地址，远程仓库直接填写远程仓库地址 http://git... uri: file://${user.home}/Desktop/config-repo # 默认分支设定为你自己本地或是远程分支的名称 default-label: main 然后启动我们的配置服务器，通过以下格式进行访问： http://localhost:8700/{服务名称}/{环境}/{Git分支} http://localhost:8700/{Git分支}/{服务名称}-{环境}.yml 比如我们要访问图书服务的生产环境代码，可以使用 http://localhost:8700/bookservice/prod/main 链接，它会显示详细信息： 也可以使用 http://localhost:8700/main/bookservice-prod.yml 链接，它仅显示配置文件原文： 当然，除了使用Git来保存之外，还支持一些其他的方式，详细情况请查阅官网。 客户端配置 服务端配置完成之后，我们接着来配置一下客户端，那么现在我们的服务既然需要从服务器读取配置文件，那么就需要进行一些配置，我们删除原来的application.yml文件（也可以保留，最后无论是远端配置还是本地配置都会被加载），改用bootstrap.yml（在application.yml之前加载，可以实现配置文件远程获取）： org.springframework.cloud spring-cloud-starter-config org.springframework.cloud spring-cloud-starter-bootstrap spring: cloud: config: # 名称，其实就是文件名称 name: bookservice # 配置服务器的地址 uri: http://localhost:8700 # 环境 profile: prod # 分支 label: main 配置完成之后，启动图书服务： 可以看到已经从远端获取到了配置，并进行启动。 微服务CAP原则 经过前面的学习，我们对SpringCloud Netflix以及SpringCloud官方整个生态下的组件认识也差不多了，入门教学就到此为止，下一章将开启真正精彩的正片部分，本章的最后我们还是来了解一些理论上的知识。 CAP原则又称CAP定理，指的是在一个分布式系统中，存在Consistency（一致性）、Availability（可用性）、Partition tolerance（分区容错性），三者不可同时保证，最多只能保证其中的两者。 一致性（C）：在分布式系统中的所有数据备份，在同一时刻都是同样的值（所有的节点无论何时访问都能拿到最新的值） 可用性（A）：系统中非故障节点收到的每个请求都必须得到响应（比如我们之前使用的服务降级和熔断，其实就是一种维持可用性的措施，虽然服务返回的是没有什么意义的数据，但是不至于用户的请求会被服务器忽略） 分区容错性（P）：一个分布式系统里面，节点之间组成的网络本来应该是连通的，然而可能因为一些故障（比如网络丢包等，这是很难避免的），使得有些节点之间不连通了，整个网络就分成了几块区域，数据就散布在了这些不连通的区域中（这样就可能出现某些被分区节点存放的数据访问失败，我们需要来容忍这些不可靠的情况） 总的来说，数据存放的节点数越多，分区容忍性就越高，但是要复制更新的次数就越多，一致性就越难保证。同时为了保证一致性，更新所有节点数据所需要的时间就越长，那么可用性就会降低。 所以说，只能存在以下三种方案： AC 可用性+一致性 要同时保证可用性和一致性，代表着某个节点数据更新之后，需要立即将结果通知给其他节点，并且要尽可能的快，这样才能及时响应保证可用性，这就对网络的稳定性要求非常高，但是实际情况下，网络很容易出现丢包等情况，并不是一个可靠的传输，如果需要避免这种问题，就只能将节点全部放在一起，但是这显然违背了分布式系统的概念，所以对于我们的分布式系统来说，很难接受。 CP 一致性+分区容错性 为了保证一致性，那么就得将某个节点的最新数据发送给其他节点，并且需要等到所有节点都得到数据才能进行响应，同时有了分区容错性，那么代表我们可以容忍网络的不可靠问题，所以就算网络出现卡顿，那么也必须等待所有节点完成数据同步，才能进行响应，因此就会导致服务在一段时间内完全失效，所以可用性是无法得到保证的。 AP 可用性+分区容错性 既然CP可能会导致一段时间内服务得不到任何响应，那么要保证可用性，就只能放弃节点之间数据的高度统一，也就是说可以在数据不统一的情况下，进行响应，因此就无法保证一致性了。虽然这样会导致拿不到最新的数据，但是只要数据同步操作在后台继续运行，一定能够在某一时刻完成所有节点数据的同步，那么就能实现最终一致性，所以AP实际上是最能接受的一种方案。 比如我们实现的Eureka集群，它使用的就是AP方案，Eureka各个节点都是平等的，少数节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka客户端在向某个Eureka服务端注册时如果发现连接失败，则会自动切换至其他节点。只要有一台Eureka服务器正常运行，那么就能保证服务可用（A），只不过查询到的信息可能不是最新的（C） 在之后的章节，我们还会继续了解这些理论的其他实际应用。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/SpringCloud（一）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/SpringCloud（一）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/SpringCloud/SpringCloud（二）.html":{"url":"Java/SpringCloud/SpringCloud（二）.html","title":"SpringCloud（二）","keywords":"","body":" 微服务进阶 前面我们了解了微服务的一套解决方案，但是它是基于Netflix的解决方案，实际上我们发现，很多框架都已经停止维护了，来看看目前我们所认识到的SpringCloud各大组件的维护情况： 注册中心：Eureka（属于Netflix，2.x版本不再开源，1.x版本仍在更新） 服务调用：Ribbon（属于Netflix，停止更新，已经彻底被移除）、SpringCloud Loadbalancer（属于SpringCloud官方，目前的默认方案） 服务降级：Hystrix（属于Netflix，停止更新，已经彻底被移除） 路由网关：Zuul（属于Netflix，停止更新，已经彻底被移除）、Gateway（属于SpringCloud官方，推荐方案） 配置中心：Config（属于SpringCloud官方） 可见，我们之前使用的整套解决方案中，超过半数的组件都已经处于不可用状态，并且部分组件都是SpringCloud官方出手提供框架进行解决，因此，寻找一套更好的解决方案势在必行，也就引出了我们本章的主角：SpringCloud Alibaba 阿里巴巴作为业界的互联网大厂，给出了一套全新的解决方案，官方网站（中文）：https://spring-cloud-alibaba-group.github.io/github-pages/2021/zh-cn/index.html Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。 依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里分布式应用解决方案，通过阿里中间件来迅速搭建分布式应用系统。 目前 Spring Cloud Alibaba 提供了如下功能: 服务限流降级：支持 WebServlet、WebFlux, OpenFeign、RestTemplate、Dubbo 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。 分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新。 Rpc服务：扩展 Spring Cloud 客户端 RestTemplate 和 OpenFeign，支持调用 Dubbo RPC 服务 消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。 分布式事务：使用 @GlobalTransactional 注解， 高效并且对业务零侵入地解决分布式事务问题。 阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。 分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。 阿里云短信服务：覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。 可以看到，SpringCloudAlibaba实际上是对我们的SpringCloud组件增强功能，是SpringCloud的增强框架，可以兼容SpringCloud原生组件和SpringCloudAlibaba的组件。 开始学习之前，把我们之前打包好的拆分项目解压，我们将基于它进行讲解。 Nacos 更加全能的注册中心 Nacos（Naming Configuration Service）是一款阿里巴巴开源的服务注册与发现、配置管理的组件，相当于是Eureka+Config的组合形态。 安装与部署 Nacos服务器是独立安装部署的，因此我们需要下载最新的Nacos服务端程序，下载地址：https://github.com/alibaba/nacos，连不上可以到视频下方云盘中下载。 可以看到目前最新的版本是1.4.3版本（2022年2月27日发布的），我们直接下载zip文件即可。 接着我们将文件进行解压，得到以下内容： 我们直接将其拖入到项目文件夹下，便于我们一会在IDEA内部启动，接着添加运行配置： 其中-m standalone表示单节点模式，Mac和Linux下记得将解释器设定为/bin/bash，由于Nacos在Mac/Linux默认是后台启动模式，我们修改一下它的bash文件，让它变成前台启动，这样IDEA关闭了Nacos就自动关闭了，否则开发环境下很容易忘记关： # 注释掉 nohup $JAVA ${JAVA_OPT} nacos.nacos >> ${BASE_DIR}/logs/start.out 2>&1 & # 替换成下面的 $JAVA ${JAVA_OPT} nacos.nacos 接着我们点击启动： OK，启动成功，可以看到它的管理页面地址也是给我们贴出来了： http://localhost:8848/nacos/index.html，访问这个地址： 默认的用户名和管理员密码都是nacos，直接登陆即可，可以看到进入管理页面之后功能也是相当丰富： 至此，Nacos的安装与部署完成。 服务注册与发现 现在我们要实现基于Nacos的服务注册与发现，那么就需要导入SpringCloudAlibaba相关的依赖，我们在父工程将依赖进行管理： org.mybatis.spring.boot mybatis-spring-boot-starter 2.2.0 org.springframework.cloud spring-cloud-dependencies 2021.0.1 pom import com.alibaba.cloud spring-cloud-alibaba-dependencies 2021.0.1.0 pom import 接着我们就可以在子项目中添加服务发现依赖了，比如我们以图书服务为例： com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery 和注册到Eureka一样，我们也需要在配置文件中配置Nacos注册中心的地址： server: # 之后所有的图书服务节点就81XX端口 port: 8101 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://cloudstudy.mysql.cn-chengdu.rds.aliyuncs.com:3306/cloudstudy username: test password: 123456 # 应用名称 bookservice application: name: bookservice cloud: nacos: discovery: # 配置Nacos注册中心地址 server-addr: localhost:8848 接着启动我们的图书服务，可以在Nacos的服务列表中找到： 按照同样的方法，我们接着将另外两个服务也注册到Nacos中： 接着我们使用OpenFeign，实现服务发现远程调用以及负载均衡，导入依赖： org.springframework.cloud spring-cloud-starter-openfeign org.springframework.cloud spring-cloud-starter-loadbalancer 编写接口： @FeignClient(\"userservice\") public interface UserClient { @RequestMapping(\"/user/{uid}\") User getUserById(@PathVariable(\"uid\") int uid); } @FeignClient(\"bookservice\") public interface BookClient { @RequestMapping(\"/book/{bid}\") Book getBookById(@PathVariable(\"bid\") int bid); } @Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Resource UserClient userClient; @Resource BookClient bookClient; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List bookList = borrow .stream() .map(b -> bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } @EnableFeignClients @SpringBootApplication public class BorrowApplication { public static void main(String[] args) { SpringApplication.run(BorrowApplication.class, args); } } 接着我们进行测试： 测试正常，可以自动发现服务，接着我们来多配置几个实例，去掉图书服务和用户服务的端口配置： 然后我们在图书服务和用户服务中添加一句打印方便之后查看： @RequestMapping(\"/user/{uid}\") public User findUserById(@PathVariable(\"uid\") int uid){ System.out.println(\"调用用户服务\"); return service.getUserById(uid); } 现在将全部服务启动： 可以看到Nacos中的实例数量已经显示为2： 接着我们调用借阅服务，看看能否负载均衡远程调用： OK，负载均衡远程调用没有问题，这样我们就实现了基于Nacos的服务的注册与发现，实际上大致流程与Eureka一致。 值得注意的是，Nacos区分了临时实例和非临时实例： 那么临时和非临时有什么区别呢？ 临时实例：和Eureka一样，采用心跳机制向Nacos发送请求保持在线状态，一旦心跳停止，代表实例下线，不保留实例信息。 非临时实例：由Nacos主动进行联系，如果连接失败，那么不会移除实例信息，而是将健康状态设定为false，相当于会对某个实例状态持续地进行监控。 我们可以通过配置文件进行修改临时实例： spring: application: name: borrowservice cloud: nacos: discovery: server-addr: localhost:8848 # 将ephemeral修改为false，表示非临时实例 ephemeral: false 接着我们在Nacos中查看，可以发现实例已经不是临时的了： 如果这时我们关闭此实例，那么会变成这样： 只是将健康状态变为false，而不会删除实例的信息。 集群分区 实际上集群分区概念在之前的Eureka中也有出现，比如： eureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://localhost:8888/eureka # 这个defaultZone是个啥玩意，为什么要用这个名称？为什么要要用这样的形式来声明注册中心？ 在一个分布式应用中，相同服务的实例可能会在不同的机器、位置上启动，比如我们的用户管理服务，可能在成都有1台服务器部署、重庆有一台服务器部署，而这时，我们在成都的服务器上启动了借阅服务，那么如果我们的借阅服务现在要调用用户服务，就应该优先选择同一个区域的用户服务进行调用，这样会使得响应速度更快。 因此，我们可以对部署在不同机房的服务进行分区，可以看到实例的分区是默认： 我们可以直接在配置文件中进行修改： spring: application: name: borrowservice cloud: nacos: discovery: server-addr: localhost:8848 # 修改为重庆地区的集群 cluster-name: Chongqing 当然由于我们这里使用的是不同的启动配置，直接在启动配置中添加环境变量spring.cloud.nacos.discovery.cluster-name也行，这里我们将用户服务和图书服务两个区域都分配一个，借阅服务就配置为成都地区： 修改完成之后，我们来尝试重新启动一下（Nacos也要重启），观察Nacos中集群分布情况： 可以看到现在有两个集群，并且都有一个实例正在运行。我们接着去调用借阅服务，但是发现并没有按照区域进行优先调用，而依然使用的是轮询模式的负载均衡调用。 我们必须要提供Nacos的负载均衡实现才能开启区域优先调用机制，只需要在配制文件中进行修改即可： spring: application: name: borrowservice cloud: nacos: discovery: server-addr: localhost:8848 cluster-name: Chengdu # 将loadbalancer的nacos支持开启，集成Nacos负载均衡 loadbalancer: nacos: enabled: true 现在我们重启借阅服务，会发现优先调用的是同区域的用户和图书服务，现在我们可以将成都地区的服务下线： 可以看到，在下线之后，由于本区域内没有可用服务了，借阅服务将会调用重庆区域的用户服务。 除了根据区域优先调用之外，同一个区域内的实例也可以单独设置权重，Nacos会优先选择权重更大的实例进行调用，我们可以直接在管理页面中进行配置： 或是在配置文件中进行配置： spring: application: name: borrowservice cloud: nacos: discovery: server-addr: localhost:8848 cluster-name: Chengdu # 权重大小，越大越优先调用，默认为1 weight: 0.5 通过配置权重，某些性能不太好的机器就能够更少地被使用，而更多的使用那些网络良好性能更高的主机上的实例。 配置中心 前面我们学习了SpringCloud Config，我们可以通过配置服务来加载远程配置，这样我们就可以在远端集中管理配置文件。 实际上我们可以在bootstrap.yml中配置远程配置文件获取，然后再进入到配置文件加载环节，而Nacos也支持这样的操作，使用方式也比较类似，比如我们现在想要将借阅服务的配置文件放到Nacos进行管理，那么这个时候就需要在Nacos中创建配置文件： 将借阅服务的配置文件全部（当然正常情况下是不会全部CV的，只会复制那些需要经常修改的部分，这里为了省事就直接全部CV了）复制过来，注意Data ID的格式跟我们之前一样，应用名称-环境.yml，如果只编写应用名称，那么代表此配置文件无论在什么环境下都会使用，然后每个配置文件都可以进行分组，也算是一种分类方式： 完成之后点击发布即可： 然后在项目中导入依赖： org.springframework.cloud spring-cloud-starter-bootstrap com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config 接着我们在借阅服务中添加bootstrap.yml文件： spring: application: # 服务名称和配置文件保持一致 name: borrowservice profiles: # 环境也是和配置文件保持一致 active: dev cloud: nacos: config: # 配置文件后缀名 file-extension: yml # 配置中心服务器地址，也就是Nacos地址 server-addr: localhost:8848 现在我们启动服务试试看： 可以看到成功读取配置文件并启动了，实际上使用上来说跟之前的Config是基本一致的。 Nacos还支持配置文件的热更新，比如我们在配置文件中添加了一个属性，而这个时候可能需要实时修改，并在后端实时更新，那么这种该怎么实现呢？我们创建一个新的Controller： @RestController public class TestController { @Value(\"${test.txt}\") //我们从配置文件中读取test.txt的字符串值，作为test接口的返回值 String txt; @RequestMapping(\"/test\") public String test(){ return txt; } } 我们修改一下配置文件，然后重启服务器： 可以看到已经可以正常读取了： 现在我们将配置文件的值进行修改： 再次访问接口，会发现没有发生变化： 但是后台是成功检测到值更新了，但是值却没改变： 那么如何才能实现配置热更新呢？我们可以像下面这样： @RestController @RefreshScope //添加此注解就能实现自动刷新了 public class TestController { @Value(\"${test.txt}\") String txt; @RequestMapping(\"/test\") public String test(){ return txt; } } 重启服务器，再次重复上述实验，成功。 命名空间 我们还可以将配置文件或是服务实例划分到不同的命名空间中，其实就是区分开发、生产环境或是引用归属之类的： 这里我们创建一个新的命名空间： 可以看到在dev命名空间下，没有任何配置文件和服务： 我们在不同的命名空间下，实例和配置都是相互之间隔离的，我们也可以在配置文件中指定当前的命名空间。 实现高可用 由于Nacos暂不支持Arm架构芯片的Mac集群搭建，本小节用Linxu云主机（Nacos比较吃内存，2个Nacos服务器集群，至少2G内存）环境演示。 通过前面的学习，我们已经了解了如何使用Nacos以及Nacos的功能等，最后我们来看看，如果像之前Eureka一样，搭建Nacos集群，实现高可用。 官方方案：https://nacos.io/zh-cn/docs/cluster-mode-quick-start.html http://ip1:port/openAPI 直连ip模式，机器挂则需要修改ip才可以使用。 http://SLB:port/openAPI 挂载SLB模式(内网SLB，不可暴露到公网，以免带来安全风险)，直连SLB即可，下面挂server真实ip，可读性不好。 http://nacos.com:port/openAPI 域名 + SLB模式(内网SLB，不可暴露到公网，以免带来安全风险)，可读性好，而且换ip方便，推荐模式 我们来看看它的架构设计，它推荐我们在所有的Nacos服务端之前建立一个负载均衡，我们通过访问负载均衡服务器来间接访问到各个Nacos服务器。实际上就，是比如有三个Nacos服务器做集群，但是每个服务不可能把每个Nacos都去访问一次进行注册，实际上只需要在任意一台Nacos服务器上注册即可，Nacos服务器之间会自动同步信息，但是如果我们随便指定一台Nacos服务器进行注册，如果这台Nacos服务器挂了，但是其他Nacos服务器没挂，这样就没办法完成注册了，但是实际上整个集群还是可用的状态。 所以这里就需要在所有Nacos服务器之前搭建一个SLB（服务器负载均衡），这样就可以避免上面的问题了。但是我们知道，如果要实现外界对服务访问的负载均衡，我们就得用比如之前说到的Gateway来实现，而这里实际上我们可以用一个更加方便的工具：Nginx，来实现（之前我们没讲过，但是使用起来很简单，放心后面会带着大家使用） 关于SLB最上方还有一个DNS（我们在计算机网络这门课程中学习过），这个是因为SLB是裸IP，如果SLB服务器修改了地址，那么所有微服务注册的地址也得改，所以这里是通过加域名，通过域名来访问，让DNS去解析真实IP，这样就算改变IP，只需要修改域名解析记录即可，域名地址是不会变化的。 最后就是Nacos的数据存储模式，在单节点的情况下，Nacos实际上是将数据存放在自带的一个嵌入式数据库中： 而这种模式只适用于单节点，在多节点集群模式下，肯定是不能各存各的，所以，Nacos提供了MySQL统一存储支持，我们只需要让所有的Nacos服务器连接MySQL进行数据存储即可，官方也提供好了SQL文件。 现在就可以开始了，第一步，我们直接导入数据库即可，文件在conf目录中： 我们来将其导入到数据库，可以看到生成了很多的表： 然后我们来创建两个Nacos服务器，做一个迷你的集群，这里使用scp命令将nacos服务端上传到Linux服务器（注意需要提前安装好JRE 8或更高版本的环境）： 解压之后，我们对其配置文件进行修改，首先是application.properties配置文件，修改以下内容，包括MySQL服务器的信息： ### Default web server port: server.port=8801 #*************** Config Module Related Configurations ***************# ### If use MySQL as datasource: spring.datasource.platform=mysql ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://cloudstudy.mysql.cn-chengdu.rds.aliyuncs.com:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC db.user.0=nacos db.password.0=nacos 然后修改集群配置，这里需要重命名一下： 端口记得使用内网IP地址： 最后我们修改一下Nacos的内存分配以及前台启动，直接修改startup.sh文件（内存有限，玩不起高的）： 保存之后，将nacos复制一份，并将端口修改为8802，接着启动这两个Nacos服务器。 然后我们打开管理面板，可以看到两个节点都已经启动了： 这样，我们第二步就完成了，接着我们需要添加一个SLB，这里我们用Nginx做反向代理： Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。它相当于在内网与外网之间形成一个网关，所有的请求都可以由Nginx服务器转交给内网的其他服务器。 这里我们直接安装： sudo apt install nginx 可以看到直接请求80端口之后得到，表示安装成功： 现在我们需要让其代理我们刚刚启动的两个Nacos服务器，我们需要对其进行一些配置。配置文件位于/etc/nginx/nginx.conf，添加以下内容： #添加我们在上游刚刚创建好的两个nacos服务器 upstream nacos-server { server 10.0.0.12:8801; server 10.0.0.12:8802; } server { listen 80; server_name 1.14.121.107; location /nacos { proxy_pass http://nacos-server; } } 重启Nginx服务器，成功连接： 然后我们将所有的服务全部修改为云服务器上Nacos的地址，启动试试看。 这样，我们就搭建好了Nacos集群。 Sentinel 流量防卫兵 注意：这一章有点小绕，思路理清。 经过之前的学习，我们了解了微服务存在的雪崩问题，也就是说一个微服务出现问题，有可能导致整个链路直接不可用，这种时候我们就需要进行及时的熔断和降级，这些策略，我们之前通过使用Hystrix来实现。 SpringCloud Alibaba也有自己的微服务容错组件，但是它相比Hystrix更加的强大。 随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Sentinel 具有以下特征: 丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。 完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Apache Dubbo、gRPC、Quarkus 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。同时 Sentinel 提供 Java/Go/C++ 等多语言的原生实现。 完善的 SPI 扩展机制：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。 安装与部署 和Nacos一样，它是独立安装和部署的，下载地址：https://github.com/alibaba/Sentinel/releases 注意下载下来之后是一个jar文件（其实就是个SpringBoot项目），我们需要在IDEA中添加一些运行配置： 接着就可以直接启动啦，当然默认端口占用8080，如果需要修改，可以添加环境变量： 启动之后，就可以访问到Sentinel的监控页面了，用户名和密码都是sentinel，地址：http://localhost:8858/#/dashboard 这样就成功开启监控页面了，接着我们需要让我们的服务连接到Sentinel控制台，老规矩，导入依赖： com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 然后在配置文件中添加Sentinel相关信息（实际上Sentinel是本地在进行管理，但是我们可以连接到监控页面，这样就可以图形化操作了）： spring: application: name: userservice cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: # 添加监控页面地址即可 dashboard: localhost:8858 现在启动我们的服务，然后访问一次服务，这样Sentinel中就会存在信息了（懒加载机制，不会一上来就加载）： 现在我们就可以在Sentinel控制台中对我们的服务运行情况进行实时监控了，可以看到监控的内容非常的多，包括时间点、QPS(每秒查询率)、响应时间等数据。 按照上面的方式，我们将所有的服务全部连接到Sentinel管理面板中。 流量控制 前面我们完成了对Sentinel的搭建与连接，接着我们来看看Sentinel的第一个功能，流量控制。 我们的机器不可能无限制的接受和处理客户端的请求，如果不加以限制，当发生高并发情况时，系统资源将很快被耗尽。为了避免这种情况，我们就可以添加流量控制（也可以说是限流）当一段时间内的流量到达一定的阈值的时候，新的请求将不再进行处理，这样不仅可以合理地应对高并发请求，同时也能在一定程度上保护服务器不受到外界的恶意攻击。 那么要实现限流，正常情况下，我们该采取什么样的策略呢？ 方案一：快速拒绝，既然不再接受新的请求，那么我们可以直接返回一个拒绝信息，告诉用户访问频率过高。 方案二：预热，依然基于方案一，但是由于某些情况下高并发请求是在某一时刻突然到来，我们可以缓慢地将阈值提高到指定阈值，形成一个缓冲保护。 方案三：排队等待，不接受新的请求，但是也不直接拒绝，而是进队列先等一下，如果规定时间内能够执行，那么就执行，要是超时就算了。 针对于是否超过流量阈值的判断，这里我们提4种算法： 漏桶算法 顾名思义，就像一个桶开了一个小孔，水流进桶中的速度肯定是远大于水流出桶的速度的，这也是最简单的一种限流思路： 我们知道，桶是有容量的，所以当桶的容量已满时，就装不下水了，这时就只有丢弃请求了。 利用这种思想，我们就可以写出一个简单的限流算法。 令牌桶算法 只能说有点像信号量机制。现在有一个令牌桶，这个桶是专门存放令牌的，每隔一段时间就向桶中丢入一个令牌（速度由我们指定）当新的请求到达时，将从桶中删除令牌，接着请求就可以通过并给到服务，但是如果桶中的令牌数量不足，那么不会删除令牌，而是让此数据包等待。 可以试想一下，当流量下降时，令牌桶中的令牌会逐渐积累，这样如果突然出现高并发，那么就能在短时间内拿到大量的令牌。 固定时间窗口算法 我们可以对某一个时间段内的请求进行统计和计数，比如在14:15到14:16这一分钟内，请求量不能超过100，也就是一分钟之内不能超过100次请求，那么就可以像下面这样进行划分： 虽然这种模式看似比较合理，但是试想一下这种情况： 14:15:59的时候来了100个请求 14:16:01的时候又来了100个请求 出现上面这种情况，符合固定时间窗口算法的规则，所以这200个请求都能正常接受，但是，如果你反应比较快，应该发现了，我们其实希望的是60秒内只有100个请求，但是这种情况却是在3秒内出现了200个请求，很明显已经违背了我们的初衷。 因此，当遇到临界点时，固定时间窗口算法存在安全隐患。 滑动时间窗口算法 相对于固定窗口算法，滑动时间窗口算法更加灵活，它会动态移动窗口，重新进行计算： 虽然这样能够避免固定时间窗口的临界问题，但是这样显然是比固定窗口更加耗时的。 好了，了解完了我们的限流策略和判定方法之后，我们在Sentinel中进行实际测试一下，打开管理页面的簇点链路模块： 这里演示对我们的借阅接口进行限流，点击流控，会看到让我们添加流控规则： 阈值类型：QPS就是每秒钟的请求数量，并发线程数是按服务当前使用的线程数据进行统计的。 流控模式：当达到阈值时，流控的对象，这里暂时只用直接。 流控效果：就是我们上面所说的三种方案。 这里我们选择QPS、阈值设定为1，流控模式选择直接、流控效果选择快速失败，可以看到，当我们快速地进行请求时，会直接返回失败信息： 这里各位最好自行尝试一下其他的流控效果，熟悉和加深印象。 最后我们来看看这些流控模式有什么区别： 直接：只针对于当前接口。 关联：当其他接口超过阈值时，会导致当前接口被限流。 链路：更细粒度的限流，能精确到具体的方法。 我们首先来看看关联，比如现在我们对自带的/error接口进行限流： 注意限流是作用于关联资源的，一旦发现关联资源超过阈值，那么就会对当前的资源进行限流，我们现在来测试一下，这里使用PostMan的Runner连续对关联资源发起请求： 开启Postman，然后我们会发现借阅服务已经凉凉： 当我们关闭掉Postman的任务后，恢复正常。 最后我们来讲解一下链路模式，它能够更加精准的进行流量控制，链路流控模式指的是，当从指定接口过来的资源请求达到限流条件时，开启限流，这里得先讲解一下@SentinelResource的使用。 我们可以对某一个方法进行限流控制，无论是谁在何处调用了它，这里需要使用到@SentinelResource，一旦方法被标注，那么就会进行监控，比如我们这里创建两个请求映射，都来调用Service的被监控方法： @RestController public class BorrowController { @Resource BorrowService service; @RequestMapping(\"/borrow/{uid}\") UserBorrowDetail findUserBorrows(@PathVariable(\"uid\") int uid){ return service.getUserBorrowDetailByUid(uid); } @RequestMapping(\"/borrow2/{uid}\") UserBorrowDetail findUserBorrows2(@PathVariable(\"uid\") int uid){ return service.getUserBorrowDetailByUid(uid); } } @Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Resource UserClient userClient; @Resource BookClient bookClient; @Override @SentinelResource(\"getBorrow\") //监控此方法，无论被谁执行都在监控范围内，这里给的value是自定义名称，这个注解可以加在任何方法上，包括Controller中的请求映射方法，跟HystrixCommand贼像 public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List bookList = borrow .stream() .map(b -> bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 接着添加配置： spring: application: name: borrowservice cloud: sentinel: transport: dashboard: localhost:8858 # 关闭Context收敛，这样被监控方法可以进行不同链路的单独控制 web-context-unify: false 然后我们在Sentinel控制台中添加流控规则，注意是针对此方法，可以看到已经自动识别到borrow接口下调用了这个方法： 最后我们在浏览器中对这两个接口都进行测试，会发现，无论请求哪个接口，只要调用了Service中的getUserBorrowDetailByUid这个方法，都会被限流。注意限流的形式是后台直接抛出异常，至于怎么处理我们后面再说。 那么这个链路选项实际上就是决定只限流从哪个方向来的调用，比如我们只对borrow2这个接口对getUserBorrowDetailByUid方法的调用进行限流，那么我们就可以为其指定链路： 然后我们会发现，限流效果只对我们配置的链路接口有效，而其他链路是不会被限流的。 除了直接对接口进行限流规则控制之外，我们也可以根据当前系统的资源使用情况，决定是否进行限流： 系统规则支持以下的模式： Load 自适应（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。 CPU usage（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。 平均 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 并发线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 这里就不进行演示了。 限流和异常处理 现在我们已经了解了如何进行限流操作，那么限流状态下的返回结果该怎么修改呢，我们看到被限流之后返回的是Sentinel默认的数据，现在我们希望自定义改如何操作？ 这里我们先创建好被限流状态下需要返回的内容，定义一个请求映射： @RequestMapping(\"/blocked\") JSONObject blocked(){ JSONObject object = new JSONObject(); object.put(\"code\", 403); object.put(\"success\", false); object.put(\"massage\", \"您的请求频率过快，请稍后再试！\"); return object; } 接着我们在配置文件中将此页面设定为限流页面： spring: cloud: sentinel: transport: dashboard: localhost:8858 # 将刚刚编写的请求映射设定为限流页面 block-page: /blocked 这样，当被限流时，就会被重定向到指定页面： 那么，对于方法级别的限流呢？经过前面的学习我们知道，当某个方法被限流时，会直接在后台抛出异常，那么这种情况我们该怎么处理呢，比如我们之前在Hystrix中可以直接添加一个替代方案，这样当出现异常时会直接执行我们的替代方法并返回，Sentinel也可以。 比如我们还是在getUserBorrowDetailByUid方法上进行配置： @Override @SentinelResource(value = \"getBorrow\", blockHandler = \"blocked\") //指定blockHandler，也就是被限流之后的替代解决方案，这样就不会使用默认的抛出异常的形式了 public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List bookList = borrow .stream() .map(b -> bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } //替代方案，注意参数和返回值需要保持一致，并且参数最后还需要额外添加一个BlockException public UserBorrowDetail blocked(int uid, BlockException e) { return new UserBorrowDetail(null, Collections.emptyList()); } 可以看到，一旦被限流将执行替代方案，最后返回的结果就是： 注意blockHandler只能处理限流情况下抛出的异常，包括下面即将要介绍的热点参数限流也是同理，如果是方法本身抛出的其他类型异常，不在管控范围内，但是可以通过其他参数进行处理： @RequestMapping(\"/test\") @SentinelResource(value = \"test\", fallback = \"except\", //fallback指定出现异常时的替代方案 exceptionsToIgnore = IOException.class) //忽略那些异常，也就是说这些异常出现时不使用替代方案 String test(){ throw new RuntimeException(\"HelloWorld！\"); } //替代方法必须和原方法返回值和参数一致，最后可以添加一个Throwable作为参数接受异常 String except(Throwable t){ return t.getMessage(); } 这样，其他的异常也可以有替代方案了： 特别注意这种方式会在没有配置blockHandler的情况下，将Sentinel机制内（也就是限流的异常）的异常也一并处理了，如果配置了blockHandler，那么在出现限流时，依然只会执行blockHandler指定的替代方案（因为限流是在方法执行之前进行的） 热点参数限流 我们还可以对某一热点数据进行精准限流，比如在某一时刻，不同参数被携带访问的频率是不一样的： http://localhost:8301/test?a=10 访问100次 http://localhost:8301/test?b=10 访问0次 http://localhost:8301/test?c=10 访问3次 由于携带参数a的请求比较多，我们就可以只对携带参数a的请求进行限流。 这里我们创建一个新的测试请求映射： @RequestMapping(\"/test\") @SentinelResource(\"test\") //注意这里需要添加@SentinelResource才可以，用户资源名称就使用这里定义的资源名称 String findUserBorrows2(@RequestParam(value = \"a\", required = false) int a, @RequestParam(value = \"b\", required = false) int b, @RequestParam(value = \"c\",required = false) int c) { return \"请求成功！a = \"+a+\", b = \"+b+\", c = \"+c; } 启动之后，我们在Sentinel里面进行热点配置： 然后开始访问我们的测试接口，可以看到在携带参数a时，当访问频率超过设定值，就会直接被限流，这里是直接在后台抛出异常： 而我们使用其他参数或是不带a参数，那么就不会出现这种问题了： 除了直接对某个参数精准限流外，我们还可以对参数携带的指定值单独设定阈值，比如我们现在不仅希望对参数a限流，而且还希望当参数a的值为10时，QPS达到5再进行限流，那么就可以设定例外： 这样，当请求携带参数a，且参数a的值为10时，阈值将按照我们指定的特例进行计算。 服务熔断和降级 还记得我们前所说的服务降级吗，也就是说我们需要在整个微服务调用链路出现问题的时候，及时对服务进行降级，以防止问题进一步恶化。 那么，各位是否有思考过，如果在某一时刻，服务B出现故障（可能就卡在那里了），而这时服务A依然有大量的请求，在调用服务B，那么，由于服务A没办法再短时间内完成处理，新来的请求就会导致线程数不断地增加，这样，CPU的资源很快就会被耗尽。 那么要防止这种情况，就只能进行隔离了，这里我们提两种隔离方案： 线程池隔离 线程池隔离实际上就是对每个服务的远程调用单独开放线程池，比如服务A要调用服务B，那么只基于固定数量的线程池，这样即使在短时间内出现大量请求，由于没有线程可以分配，所以就不会导致资源耗尽了。 信号量隔离 信号量隔离是使用Semaphore类实现的（如果不了解，可以观看本系列 并发编程篇 视频教程），思想基本上与上面是相同的，也是限定指定的线程数量能够同时进行服务调用，但是它相对于线程池隔离，开销会更小一些，使用效果同样优秀，也支持超时等。 Sentinel也正是采用的这种方案实现隔离的。 好了，说回我们的熔断和降级，当下游服务因为某种原因变得不可用或响应过慢时，上游服务为了保证自己整体服务的可用性，不再继续调用目标服务而是快速返回或是执行自己的替代方案，这便是服务降级。 整个过程分为三个状态： 关闭：熔断器不工作，所有请求全部该干嘛干嘛。 打开：熔断器工作，所有请求一律降级处理。 半开：尝试进行一下下正常流程，要是还不行继续保持打开状态，否则关闭。 那么我们来看看Sentinel中如何进行熔断和降级操作，打开管理页面，我们可以自由新增熔断规则： 其中，熔断策略有三种模式： 慢调用比例：如果出现那种半天都处理不完的调用，有可能就是服务出现故障，导致卡顿，这个选项是按照最大响应时间（RT）进行判定，如果一次请求的处理时间超过了指定的RT，那么就被判定为慢调用，在一个统计时长内，如果请求数目大于最小请求数目，并且被判定为慢调用的请求比例已经超过阈值，将触发熔断。经过熔断时长之后，将会进入到半开状态进行试探（这里和Hystrix一致） 然后修改一下接口的执行，我们模拟一下慢调用： @RequestMapping(\"/borrow2/{uid}\") UserBorrowDetail findUserBorrows2(@PathVariable(\"uid\") int uid) throws InterruptedException { Thread.sleep(1000); return null; } 重启，然后我们创建一个新的熔断规则： 可以看到，超时直接触发了熔断，进入到阻止页面： 异常比例：这个与慢调用比例类似，不过这里判断的是出现异常的次数，与上面一样，我们也来进行一些小测试： @RequestMapping(\"/borrow2/{uid}\") UserBorrowDetail findUserBorrows2(@PathVariable(\"uid\") int uid) { throw new RuntimeException(); } 启动服务器，接着添加我们的熔断规则： 现在我们进行访问，会发现后台疯狂报错，然后就熔断了： 异常数：这个和上面的唯一区别就是，只要达到指定的异常数量，就熔断，这里我们修改一下熔断规则： 现在我们再次不断访问此接口，可以发现，效果跟之前其实是差不多的，只是判断的策略稍微不同罢了： 那么熔断规则如何设定我们了解了，那么，如何自定义服务降级呢？之前在使用Hystrix的时候，如果出现异常，可以执行我们的替代方案，Sentinel也是可以的。 同样的，我们只需要在@SentinelResource中配置blockHandler参数（那这里跟前面那个方法限流的配置不是一毛一样吗？没错，因为如果添加了@SentinelResource注解，那么这里会进行方法级别细粒度的限制，和之前方法级别限流一样，会在降级之后直接抛出异常，如果不添加则返回默认的限流页面，blockHandler的目的就是处理这种Sentinel机制上的异常，所以这里其实和之前的限流配置是一个道理，因此下面熔断配置也应该对value自定义名称的资源进行配置，才能作用到此方法上）： @RequestMapping(\"/borrow2/{uid}\") @SentinelResource(value = \"findUserBorrows2\", blockHandler = \"test\") UserBorrowDetail findUserBorrows2(@PathVariable(\"uid\") int uid) { throw new RuntimeException(); } UserBorrowDetail test(int uid, BlockException e){ return new UserBorrowDetail(new User(), Collections.emptyList()); } 接着我们对进行熔断配置，注意是对我们添加的@SentinelResource中指定名称的findUserBorrows2进行配置： OK，可以看到熔断之后，服务降级之后的效果： 最后我们来看一下如何让Feign的也支持Sentinel，前面我们使用Hystrix的时候，就可以直接对Feign的每个接口调用单独进行服务降级，而使用Sentinel，也是可以的，首先我们需要在配置文件中开启支持： feign: sentinel: enabled: true 之后的步骤其实和之前是一模一样的，首先创建实现类： @Component public class UserClientFallback implements UserClient{ @Override public User getUserById(int uid) { User user = new User(); user.setName(\"我是替代方案\"); return user; } } 然后直接启动就可以了，中途的时候我们吧用户服务全部下掉，可以看到正常使用替代方案： 这样Feign的配置就OK了，那么传统的RestTemplate呢？我们可以使用@SentinelRestTemplate注解实现： @Bean @LoadBalanced @SentinelRestTemplate(blockHandler = \"handleException\", blockHandlerClass = ExceptionUtil.class, fallback = \"fallback\", fallbackClass = ExceptionUtil.class) //这里同样可以设定fallback等参数 public RestTemplate restTemplate() { return new RestTemplate(); } 这里就不多做赘述了。 Seata与分布式事务 重难点内容，坑也多得离谱，最好保持跟UP一样的版本，官方文档：https://seata.io/zh-cn/docs/overview/what-is-seata.html 在前面的阶段中，我们学习过事务，还记得我们之前谈到的数据库事务的特性吗？ 原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读已提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 那么各位试想一下，在分布式环境下，有可能出现这样一个问题，比如我们下单购物，那么整个流程可能是这样的：先调用库存服务对库存进行减扣 -> 然后订单服务开始下单 -> 最后用户账户服务进行扣款，虽然看似是一个很简单的一个流程，但是如果没有事务的加持，很有可能会由于中途出错，比如整个流程中订单服务出现问题，那么就会导致库存扣了，但是实际上这个订单并没有生成，用户也没有付款。 上面这种情况时间就是一种多服务多数据源的分布式事务模型（比较常见），因此，为了解决这种情况，我们就得实现分布式事务，让这整个流程保证原子性。 SpringCloud Alibaba为我们提供了用于处理分布式事务的组件Seata。 Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。 实际上，就是多了一个中间人来协调所有服务的事务。 项目环境搭建 这里我们对我们之前的图书管理系统进行升级： 每个用户最多只能同时借阅2本不同的书。 图书馆中所有的书都有3本。 用户借书流程：先调用图书服务书籍数量-1 -> 添加借阅记录 -> 调用用户服务用户可借阅数量-1 那么首先我们对数据库进行修改，这里为了简便，就直接在用户表中添加一个字段用于存储用户能够借阅的书籍数量： 然后修改书籍信息，也是直接添加一个字段用于记录剩余数量： 接着我们去编写一下对应的服务吧，首先是用户服务： @Mapper public interface UserMapper { @Select(\"select * from DB_USER where uid = #{uid}\") User getUserById(int uid); @Select(\"select book_count from DB_USER where uid = #{uid}\") int getUserBookRemain(int uid); @Update(\"update DB_USER set book_count = #{count} where uid = #{uid}\") int updateBookCount(int uid, int count); } @Service public class UserServiceImpl implements UserService { @Resource UserMapper mapper; @Override public User getUserById(int uid) { return mapper.getUserById(uid); } @Override public int getRemain(int uid) { return mapper.getUserBookRemain(uid); } @Override public boolean setRemain(int uid, int count) { return mapper.updateBookCount(uid, count) > 0; } } @RestController public class UserController { @Resource UserService service; @RequestMapping(\"/user/{uid}\") public User findUserById(@PathVariable(\"uid\") int uid){ return service.getUserById(uid); } @RequestMapping(\"/user/remain/{uid}\") public int userRemain(@PathVariable(\"uid\") int uid){ return service.getRemain(uid); } @RequestMapping(\"/user/borrow/{uid}\") public boolean userBorrow(@PathVariable(\"uid\") int uid){ int remain = service.getRemain(uid); return service.setRemain(uid, remain - 1); } } 然后是图书服务，其实跟用户服务差不多： @Mapper public interface BookMapper { @Select(\"select * from DB_BOOK where bid = #{bid}\") Book getBookById(int bid); @Select(\"select count from DB_BOOK where bid = #{bid}\") int getRemain(int bid); @Update(\"update DB_BOOK set count = #{count} where bid = #{bid}\") int setRemain(int bid, int count); } @Service public class BookServiceImpl implements BookService { @Resource BookMapper mapper; @Override public Book getBookById(int bid) { return mapper.getBookById(bid); } @Override public boolean setRemain(int bid, int count) { return mapper.setRemain(bid, count) > 0; } @Override public int getRemain(int bid) { return mapper.getRemain(bid); } } @RestController public class BookController { @Resource BookService service; @RequestMapping(\"/book/{bid}\") Book findBookById(@PathVariable(\"bid\") int bid){ return service.getBookById(bid); } @RequestMapping(\"/book/remain/{bid}\") public int bookRemain(@PathVariable(\"bid\") int uid){ return service.getRemain(uid); } @RequestMapping(\"/book/borrow/{bid}\") public boolean bookBorrow(@PathVariable(\"bid\") int uid){ int remain = service.getRemain(uid); return service.setRemain(uid, remain - 1); } } 最后完善我们的借阅服务： @FeignClient(value = \"userservice\") public interface UserClient { @RequestMapping(\"/user/{uid}\") User getUserById(@PathVariable(\"uid\") int uid); @RequestMapping(\"/user/borrow/{uid}\") boolean userBorrow(@PathVariable(\"uid\") int uid); @RequestMapping(\"/user/remain/{uid}\") int userRemain(@PathVariable(\"uid\") int uid); } @FeignClient(\"bookservice\") public interface BookClient { @RequestMapping(\"/book/{bid}\") Book getBookById(@PathVariable(\"bid\") int bid); @RequestMapping(\"/book/borrow/{bid}\") boolean bookBorrow(@PathVariable(\"bid\") int bid); @RequestMapping(\"/book/remain/{bid}\") int bookRemain(@PathVariable(\"bid\") int bid); } @RestController public class BorrowController { @Resource BorrowService service; @RequestMapping(\"/borrow/{uid}\") UserBorrowDetail findUserBorrows(@PathVariable(\"uid\") int uid){ return service.getUserBorrowDetailByUid(uid); } @RequestMapping(\"/borrow/take/{uid}/{bid}\") JSONObject borrow(@PathVariable(\"uid\") int uid, @PathVariable(\"bid\") int bid){ service.doBorrow(uid, bid); JSONObject object = new JSONObject(); object.put(\"code\", \"200\"); object.put(\"success\", false); object.put(\"message\", \"借阅成功！\"); return object; } } @Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Resource UserClient userClient; @Resource BookClient bookClient; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List bookList = borrow .stream() .map(b -> bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } @Override public boolean doBorrow(int uid, int bid) { //1. 判断图书和用户是否都支持借阅 if(bookClient.bookRemain(bid) 这样，只要我们的图书借阅过程中任何一步出现问题，都会抛出异常。 我们来测试一下： 再次尝试借阅，后台会直接报错： 抛出异常，但是我们发现一个问题，借阅信息添加失败了，但是图书的数量依然被-1，也就是说正常情况下，我们是希望中途出现异常之后，之前的操作全部回滚的： 而这里由于是在另一个服务中进行的数据库操作，所以传统的@Transactional注解无效，这时就得借助Seata提供分布式事务了。 分布式事务解决方案 要开始实现分布式事务，我们得先从理论上开始下手，我们来了解一下常用的分布式事务解决方案。 XA分布式事务协议 - 2PC（两阶段提交实现） 这里的PC实际上指的是Prepare和Commit，也就是说它分为两个阶段，一个是准备一个是提交，整个过程的参与者一共有两个角色，一个是事务的执行者，一个是事务的协调者，实际上整个分布式事务的运作都需要依靠协调者来维持： 在准备和提交阶段，会进行： 准备阶段： 一个分布式事务是由协调者来开启的，首先协调者会向所有的事务执行者发送事务内容，等待所有的事务执行者答复。 各个事务执行者开始执行事务操作，但是不进行提交，并将undo和redo信息记录到事务日志中。 如果事务执行者执行事务成功，那么就告诉协调者成功Yes，否则告诉协调者失败No，不能提交事务。 提交阶段： 当所有的执行者都反馈完成之后，进入第二阶段。 协调者会检查各个执行者的反馈内容，如果所有的执行者都返回成功，那么就告诉所有的执行者可以提交事务了，最后再释放锁资源。 如果有至少一个执行者返回失败或是超时，那么就让所有的执行者都回滚，分布式事务执行失败。 虽然这种方式看起来比较简单，但是存在以下几个问题： 事务协调者是非常核心的角色，一旦出现问题，将导致整个分布式事务不能正常运行。 如果提交阶段发生网络问题，导致某些事务执行者没有收到协调者发来的提交命令，将导致某些执行者提交某些执行者没提交，这样肯定是不行的。 XA分布式事务协议 - 3PC（三阶段提交实现） 三阶段提交是在二阶段提交基础上的改进版本，主要是加入了超时机制，同时在协调者和执行者中都引入了超时机制。 三个阶段分别进行： CanCommit阶段： 协调者向执行者发送CanCommit请求，询问是否可以执行事务提交操作，然后开始等待执行者的响应。 执行者接收到请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态，否则返回No PreCommit阶段： 协调者根据执行者的反应情况来决定是否可以进入第二阶段事务的PreCommit操作。 如果所有的执行者都返回Yes，则协调者向所有执行者发送PreCommit请求，并进入Prepared阶段，执行者接收到请求后，会执行事务操作，并将undo和redo信息记录到事务日志中，如果成功执行，则返回成功响应。 如果所有的执行者至少有一个返回No，则协调者向所有执行者发送abort请求，所有的执行者在收到请求或是超过一段时间没有收到任何请求时，会直接中断事务。 DoCommit阶段： 该阶段进行真正的事务提交。 协调者接收到所有执行者发送的成功响应，那么他将从PreCommit状态进入到DoCommit状态，并向所有执行者发送doCommit请求，执行者接收到doCommit请求之后，开始执行事务提交，并在完成事务提交之后释放所有事务资源，并最后向协调者发送确认响应，协调者接收到所有执行者的确认响应之后，完成事务（如果因为网络问题导致执行者没有收到doCommit请求，执行者会在超时之后直接提交事务，虽然执行者只是猜测协调者返回的是doCommit请求，但是因为前面的两个流程都正常执行，所以能够在一定程度上认为本次事务是成功的，因此会直接提交） 协调者没有接收至少一个执行者发送的成功响应（也可能是响应超时），那么就会执行中断事务，协调者会向所有执行者发送abort请求，执行者接收到abort请求之后，利用其在PreCommit阶段记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源，执行者完成事务回滚之后，向协调者发送确认消息， 协调者接收到参与者反馈的确认消息之后，执行事务的中断。 相比两阶段提交，三阶段提交的优势是显而易见的，当然也有缺点： 3PC在2PC的第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的。 一旦参与者无法及时收到来自协调者的信息之后，会默认执行Commit，这样就不会因为协调者单方面的故障导致全局出现问题。 但是我们知道，实际上超时之后的Commit决策本质上就是一个赌注罢了，如果此时协调者发送的是abort请求但是超时未接收，那么就会直接导致数据一致性问题。 TCC（补偿事务） 补偿事务TCC就是Try、Confirm、Cancel，它对业务有侵入性，一共分为三个阶段，我们依次来解读一下。 Try阶段： 比如我们需要在借书时，将书籍的库存-1，并且用户的借阅量也-1，但是这个操作，除了直接对库存和借阅量进行修改之外，还需要将减去的值，单独存放到冻结表中，但是此时不会创建借阅信息，也就是说只是预先把关键的东西给处理了，预留业务资源出来。 Confirm阶段： 如果Try执行成功无误，那么就进入到Confirm阶段，接着之前，我们就该创建借阅信息了，只能使用Try阶段预留的业务资源，如果创建成功，那么就对Try阶段冻结的值，进行解冻，整个流程就完成了。当然，如果失败了，那么进入到Cancel阶段。 Cancel阶段： 不用猜了，那肯定是把冻结的东西还给人家，因为整个借阅操作压根就没成功。就像你付了款买了东西但是网络问题，导致交易失败，钱不可能不还给你吧。 跟XA协议相比，TCC就没有协调者这一角色的参与了，而是自主通过上一阶段的执行情况来确保正常，充分利用了集群的优势，性能也是有很大的提升。但是缺点也很明显，它与业务具有一定的关联性，需要开发者去编写更多的补偿代码，同时并不一定所有的业务流程都适用于这种形式。 Seata机制简介 前面我们了解了一些分布式事务的解决方案，那么我们来看一下Seata是如何进行分布式事务的处理的。 官网给出的是这样的一个架构图，那么图中的RM、TM、TC代表着什么意思呢？ RM（Resource Manager）：用于直接执行本地事务的提交和回滚。 TM（Transaction Manager）：TM是分布式事务的核心管理者。比如现在我们需要在借阅服务中开启全局事务，来让其自身、图书服务、用户服务都参与进来，也就是说一般全局事务发起者就是TM。 TC（Transaction Manager）这个就是我们的Seata服务器，用于全局控制，比如在XA模式下就是一个协调者的角色，而一个分布式事务的启动就是由TM向TC发起请求，TC再来与其他的RM进行协调操作。 TM请求TC开启一个全局事务，TC会生成一个XID作为该全局事务的编号，XID会在微服务的调用链路中传播，保证将多个微服务的子事务关联在一起；RM请求TC将本地事务注册为全局事务的分支事务，通过全局事务的XID进行关联；TM请求TC告诉XID对应的全局事务是进行提交还是回滚；TC驱动RM将XID对应的自己的本地事务进行提交还是回滚； Seata支持4种事务模式，官网文档：https://seata.io/zh-cn/docs/overview/what-is-seata.html AT：本质上就是2PC的升级版，在 AT 模式下，用户只需关心自己的 “业务SQL” 一阶段，Seata 会拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。 二阶段如果确认提交的话，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可，当然如果需要回滚，那么就用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。 TCC：和我们上面讲解的思路是一样的。 XA：同上，但是要求数据库本身支持这种模式才可以。 Saga：用于处理长事务，每个执行者需要实现事务的正向操作和补偿操作： 那么，以AT模式为例，我们的程序如何才能做到不对业务进行侵入的情况下实现分布式事务呢？实际上，Seata客户端，是通过对数据源进行代理实现的，使用的是DataSourceProxy类，所以在程序这边，我们只需要将对应的代理类注册为Bean即可（0.9版本之后支持自动进行代理，不用我们手动操作） 接下来，我们就以AT模式为例进行讲解。 使用file模式部署 Seata也是以服务端形式进行部署的，然后每个服务都是客户端，服务端下载地址：https://github.com/seata/seata/releases/download/v1.4.2/seata-server-1.4.2.zip 把源码也下载一下：https://github.com/seata/seata/archive/refs/heads/develop.zip 下载完成之后，放入到IDEA项目目录中，添加启动配置，这里端口使用8868： Seata服务端支持本地部署或是基于注册发现中心部署（比如Nacos、Eureka等），这里我们首先演示一下最简单的本地部署，不需要对Seata的配置文件做任何修改。 Seata存在着事务分组机制： 事务分组：seata的资源逻辑，可以按微服务的需要，在应用程序（客户端）对自行定义事务分组，每组取一个名字。 集群：seata-server服务端一个或多个节点组成的集群cluster。 应用程序（客户端）使用时需要指定事务逻辑分组与Seata服务端集群（默认为default）的映射关系。 为啥要设计成通过事务分组再直接映射到集群？干嘛不直接指定集群呢？获取事务分组到映射集群的配置。这样设计后，事务分组可以作为资源的逻辑隔离单位，出现某集群故障时可以快速failover，只切换对应分组，可以把故障缩减到服务级别，但前提也是你有足够server集群。 接着我们需要将我们的各个服务作为Seate的客户端，只需要导入依赖即可： com.alibaba.cloud spring-cloud-starter-alibaba-seata 然后添加配置： seata: service: vgroup-mapping: # 这里需要对事务组做映射，默认的分组名为 应用名称-seata-service-group，将其映射到default集群 # 这个很关键，一定要配置对，不然会找不到服务 bookservice-seata-service-group: default grouplist: default: localhost:8868 这样就可以直接启动了，但是注意现在只是单纯地连接上，并没有开启任何的分布式事务。 现在我们接着来配置开启分布式事务，首先在启动类添加注解，此注解会添加一个后置处理器将数据源封装为支持分布式事务的代理数据源（虽然官方表示配置文件中已经默认开启了自动代理，但是UP主实测1.4.2版本下只能打注解的方式才能生效）： @EnableAutoDataSourceProxy @SpringBootApplication public class BookApplication { public static void main(String[] args) { SpringApplication.run(BookApplication.class, args); } } 接着我们需要在开启分布式事务的方法上添加@GlobalTransactional注解： @GlobalTransactional @Override public boolean doBorrow(int uid, int bid) { //这里打印一下XID看看，其他的服务业添加这样一个打印，如果一会都打印的是同一个XID，表示使用的就是同一个事务 System.out.println(RootContext.getXID()); if(bookClient.bookRemain(bid) 还没结束，我们前面说了，Seata会分析修改数据的sql，同时生成对应的反向回滚SQL，这个回滚记录会存放在undo_log 表中。所以要求每一个Client 都有一个对应的undo_log表（也就是说每个服务连接的数据库都需要创建这样一个表，这里由于我们三个服务都用的同一个数据库，所以说就只用在这个数据库中创建undo_log表即可），表SQL定义如下： CREATE TABLE `undo_log` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `branch_id` BIGINT(20) NOT NULL, `xid` VARCHAR(100) NOT NULL, `context` VARCHAR(128) NOT NULL, `rollback_info` LONGBLOB NOT NULL, `log_status` INT(11) NOT NULL, `log_created` DATETIME NOT NULL, `log_modified` DATETIME NOT NULL, `ext` VARCHAR(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8; 创建完成之后，我们现在就可以启动三个服务了，我们来测试一下当出现异常的时候是不是会正常回滚： 首先第一次肯定是正常完成借阅操作的，接着我们再次进行请求，肯定会出现异常： 如果能在栈追踪信息中看到seata相关的包，那么说明分布式事务已经开始工作了，通过日志我们可以看到，出现了回滚操作： 并且数据库中确实是回滚了扣除操作： 这样，我们就通过Seata简单地实现了分布式事务。 使用nacos模式部署 前面我们实现了本地Seata服务的file模式部署，现在我们来看看如何让其配合Nacos进行部署，利用Nacos的配置管理和服务发现机制，Seata能够更好地工作。 我们先单独为Seata配置一个命名空间： 我们打开conf目录中的registry.conf配置文件： registry { # 注册配置 # 可以看到这里可以选择类型，默认情况下是普通的file类型，也就是本地文件的形式进行注册配置 # 支持的类型如下，对应的类型在下面都有对应的配置 # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" # 采用nacos方式会将seata服务端也注册到nacos中，这样客户端就可以利用服务发现自动找到seata服务 # 就不需要我们手动指定IP和端口了，不过看似方便，坑倒是不少，后面再说 nacos { # 应用名称，这里默认就行 application = \"seata-server\" # Nacos服务器地址 serverAddr = \"localhost:8848\" # 这里使用的是SEATA_GROUP组，一会注册到Nacos中就是这个组 group = \"SEATA_GROUP\" # 这里就使用我们上面单独为seata配置的命名空间，注意填的是ID namespace = \"89fc2145-4676-48b8-9edd-29e867879bcb\" # 集群名称，这里还是使用default cluster = \"default\" # Nacos的用户名和密码 username = \"nacos\" password = \"nacos\" } #... 注册信息配置完成之后，接着我们需要将配置文件也放到Nacos中，让Nacos管理配置，这样我们就可以对配置进行热更新了，一旦环境需要变化，只需要直接在Nacos中修改即可。 config { # 这里我们也使用nacos # file、nacos 、apollo、zk、consul、etcd3 type = \"nacos\" nacos { # 跟上面一样的配法 serverAddr = \"127.0.0.1:8848\" namespace = \"89fc2145-4676-48b8-9edd-29e867879bcb\" group = \"SEATA_GROUP\" username = \"nacos\" password = \"nacos\" # 这个不用改，默认就行 dataId = \"seataServer.properties\" } 接着，我们需要将配置导入到Nacos中，我们打开一开始下载的源码script/config-center/nacos目录，这是官方提供的上传脚本，我们直接运行即可（windows下没对应的bat就很蛋疼，可以使用git命令行来运行一下），这里我们使用这个可交互的版本： 按照提示输入就可以了，不输入就使用的默认值，不知道为啥最新版本有四个因为参数过长还导入失败了，就离谱，不过不影响。 导入成功之后，可以在对应的命名空间下看到对应的配置（为啥非要一个一个配置项单独搞，就不能写一起吗）： 注意，还没完，我们还需要将对应的事务组映射配置也添加上，DataId格式为service.vgroupMapping.事务组名称，比如我们就使用默认的名称，值全部依然使用default即可： 现在我们就完成了服务端的Nacos配置，接着我们需要对客户端也进行Nacos配置： seata: # 注册 registry: # 使用Nacos type: nacos nacos: # 使用Seata的命名空间，这样才能正确找到Seata服务，由于组使用的是SEATA_GROUP，配置默认值就是，就不用配了 namespace: 89fc2145-4676-48b8-9edd-29e867879bcb username: nacos password: nacos # 配置 config: type: nacos nacos: namespace: 89fc2145-4676-48b8-9edd-29e867879bcb username: nacos password: nacos 现在我们就可以启动这三个服务了，可以在Nacos中看到Seata以及三个服务都正常注册了： 接着我们就可以访问一下服务试试看了： 可以看到效果和上面是一样的，不过现在我们的注册和配置都继承在Nacos中进行了。 我们还可以配置一下事务会话信息的存储方式，默认是file类型，那么就会在运行目录下创建file_store目录，我们可以将其搬到数据库中存储，只需要修改一下配置即可： 将store.session.mode和store.mode的值修改为db 接着我们对数据库信息进行一下配置： 数据库驱动 数据库URL 数据库用户名密码 其他的默认即可： 接着我们需要将对应的数据库进行创建，创建seata数据库，然后直接CV以下语句： -- -------------------------------- The script used when storeMode is 'db' -------------------------------- -- the table to store GlobalSession data CREATE TABLE IF NOT EXISTS `global_table` ( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_status_gmt_modified` (`status` , `gmt_modified`), KEY `idx_transaction_id` (`transaction_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; -- the table to store BranchSession data CREATE TABLE IF NOT EXISTS `branch_table` ( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; -- the table to store lock data CREATE TABLE IF NOT EXISTS `lock_table` ( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(128), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `status` TINYINT NOT NULL DEFAULT '0' COMMENT '0:locked ,1:rollbacking', `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_status` (`status`), KEY `idx_branch_id` (`branch_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; CREATE TABLE IF NOT EXISTS `distributed_lock` ( `lock_key` CHAR(20) NOT NULL, `lock_value` VARCHAR(20) NOT NULL, `expire` BIGINT, primary key (`lock_key`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES ('HandleAllSession', ' ', 0); 完成之后，重启Seata服务端即可： 看到了数据源初始化成功，现在已经在使用数据库进行会话存储了。 如果Seata服务端出现报错，可能是我们自定义事务组的名称太长了： 将globle_table表的字段transaction_server_group长度适当增加一下即可： 到此，关于基于nacos模式下的Seata部署，就完成了。 虽然我们这里实现了分布式事务，但是还是给各位同学提出一个问题（可以把自己所认为的结果打在弹幕上），就我们目前这样的程序设计，在高并发下，真的安全吗？比如同一时间100个同学抢同一个书，但是我们知道同一个书就只有3本，如果这时真的同时来了100个请求要借书，会正常地只借出3本书吗？如果不正常，该如何处理？ window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/SpringCloud（二）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/SpringCloud（二）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/SpringCloud/SpringCloud（三）.html":{"url":"Java/SpringCloud/SpringCloud（三）.html","title":"SpringCloud（三）","keywords":"","body":"微服务应用 前面我们已经完成了SpringCloudAlibaba的学习，我们对一个微服务项目的架构体系已经有了一定的了解，那么本章我们将在应用层面继续探讨微服务。 分布式权限校验 虽然完成前面的部分，我们已经可以自己去编写一个比较中规中矩的微服务项目了，但是还有一个问题我们没有解决，登录问题。假如现在要求用户登录之后，才能进行图书的查询、借阅等操作，那么我们又该如何设计这个系统呢？ 回顾我们之前进行权限校验的原理，服务器是如何判定一个请求是来自哪个用户的呢？ 首先浏览器会向服务端发送请求，访问我们的网站。 服务端收到请求后，会创建一个SESSION ID，并暂时存储在服务端，然后会发送给浏览器作为Cookie保存。 之后浏览器会一直携带此Cookie访问服务器，这样在收到请求后，就能根据携带的Cookie中的SESSION ID判断是哪个用户了。 这样服务端和浏览器之间可以轻松地建立会话了。 但是我们想一下，我们现在采用的是分布式的系统，那么在用户服务进行登录之后，其他服务比如图书服务和借阅服务，它们会知道用户登录了吗？ 实际上我们登录到用户服务之后，Session中的用户数据只会在用户服务的应用中保存，而在其他服务中，并没有对应的信息，但是我们现在希望的是，所有的服务都能够同步这些Session信息，这样我们才能实现在用户服务登录之后其他服务都能知道，那么我们该如何实现Session的同步呢？ 我们可以在每台服务器上都复制一份Session，但是这样显然是很浪费时间的，并且用户验证数据占用的内存会成倍的增加。 将Session移出服务器，用统一存储来存放，比如我们可以直接在Redis或是MySQL中存放用户的Session信息，这样所有的服务器在需要获取Session信息时，统一访问Redis或是MySQL即可，这样就能保证所有服务都可以同步Session了（是不是越来越感觉只要有问题，没有什么是加一个中间件解决不了的） 那么，我们就着重来研究一下，然后实现2号方案，这里我们就使用Redis作为Session统一存储，我们把一开始的压缩包重新解压一次，又来从头开始编写吧。 这里我们就只使用Nacos就行了，和之前一样，我们把Nacos的包导入一下，然后进行一些配置： 现在我们需要为每个服务都添加验证机制，首先导入依赖： org.springframework.session spring-session-data-redis org.springframework.boot spring-boot-starter-data-redis 然后我们依然使用SpringSecurity框架作为权限校验框架： org.springframework.boot spring-boot-starter-security 接着我们在每个服务都编写一下对应的配置文件： spring: session: # 存储类型修改为redis store-type: redis redis: # Redis服务器的信息，该咋写咋写 host: 1.14.121.107 这样，默认情况下，每个服务的接口都会被SpringSecurity所保护，只有登录成功之后，才可以被访问。 我们来打开Nacos看看： 可以看到三个服务都正常注册了，接着我们去访问图书服务： 可以看到，访问失败，直接把我们给重定向到登陆页面了，也就是说必须登陆之后才能访问，同样的方式去访问其他服务，也是一样的效果。 由于现在是统一Session存储，那么我们就可以在任意一个服务登录之后，其他服务都可以正常访问，现在我们在当前页面登录，登录之后可以看到图书服务能够正常访问了： 同时用户服务也能正常访问了： 我们可以查看一下Redis服务器中是不是存储了我们的Session信息： 虽然看起来好像确实没啥问题了，但是借阅服务炸了，我们来看看为什么： 在RestTemplate进行远程调用的时候，由于我们的请求没有携带对应SESSION的Cookie，所以导致验证失败，访问不成功，返回401，所以虽然这种方案看起来比较合理，但是在我们的实际使用中，还是存在一些不便的。 OAuth 2.0 实现单点登录 注意：第一次接触可能会比较难，不太好理解，需要多实践和观察。 前面我们虽然使用了统一存储来解决Session共享问题，但是我们发现就算实现了Session共享，依然存在一些问题，由于我们每个服务都有自己的验证模块，实际上整个系统是存在冗余功能的、同时还有我们上面出现的问题，那么能否实现只在一个服务进行登录，就可以访问其他的服务呢？ 实际上之前的登录模式称为多点登录，而我们希望的是实现单点登陆，因此，我们得找一个更好的解决方案。 这里我们首先需要了解一种全新的登录方式：OAuth 2.0，我们经常看到一些网站支持第三方登录，比如淘宝、咸鱼我们就可以使用支付宝进行登录，腾讯游戏可以用QQ或是微信登陆，以及微信小程序都可以直接使用微信进行登录。我们知道它们并不是属于同一个系统，比如淘宝和咸鱼都不属于支付宝这个应用，但是由于需要获取支付宝的用户信息，这时我们就需要使用 OAuth2.0 来实现第三方授权，基于第三方应用访问用户信息的权限（本质上就是给别人调用自己服务接口的权限），那么它是如何实现的呢？ 四种授权模式 我们还是从理论开始讲解，OAuth 2.0一共有四种授权模式： 客户端模式（Client Credentials） 这是最简单的一种模式，我们可以直接向验证服务器请求一个Token（这里可能有些小伙伴对Token的概念不是很熟悉，Token相当于是一个令牌，我们需要在验证服务器（User Account And Authentication）服务拿到令牌之后，才能去访问资源，比如用户信息、借阅信息等，这样资源服务器才能知道我们是谁以及是否成功登录了） 当然，这里的前端页面只是一个例子，它还可以是其他任何类型的客户端，比如App、小程序甚至是第三方应用的服务。 虽然这种模式比较简便，但是已经失去了用户验证的意义，压根就不是给用户校验准备的，而是更适用于服务内部调用的场景。 密码模式（Resource Owner Password Credentials） 密码模式相比客户端模式，就多了用户名和密码的信息，用户需要提供对应账号的用户名和密码，才能获取到Token。 虽然这样看起来比较合理，但是会直接将账号和密码泄露给客户端，需要后台完全信任客户端不会拿账号密码去干其他坏事，所以这也不是我们常见的。 隐式授权模式（Implicit Grant） 首先用户访问页面时，会重定向到认证服务器，接着认证服务器给用户一个认证页面，等待用户授权，用户填写信息完成授权后，认证服务器返回Token。 它适用于没有服务端的第三方应用页面，并且相比前面一种形式，验证都是在验证服务器进行的，敏感信息不会轻易泄露，但是Token依然存在泄露的风险。 授权码模式（Authrization Code） 这种模式是最安全的一种模式，也是推荐使用的一种，比如我们手机上的很多App都是使用的这种模式。 相比隐式授权模式，它并不会直接返回Token，而是返回授权码，真正的Token是通过应用服务器访问验证服务器获得的。在一开始的时候，应用服务器（客户端通过访问自己的应用服务器来进而访问其他服务）和验证服务器之间会共享一个secret，这个东西没有其他人知道，而验证服务器在用户验证完成之后，会返回一个授权码，应用服务器最后将授权码和secret一起交给验证服务器进行验证，并且Token也是在服务端之间传递，不会直接给到客户端。 这样就算有人中途窃取了授权码，也毫无意义，因为，Token的获取必须同时携带授权码和secret，但是secret第三方是无法得知的，并且Token不会直接丢给客户端，大大减少了泄露的风险。 但是乍一看，OAuth 2.0不应该是那种第三方应用为了请求我们的服务而使用的吗，而我们这里需要的只是实现同一个应用内部服务之间的认证，其实我也可以利用 OAuth2.0 来实现单点登录，只是少了资源服务器这一角色，客户端就是我们的整个系统，接下来就让我们来实现一下。 搭建验证服务器 第一步就是最重要的，我们需要搭建一个验证服务器，它是我们进行权限校验的核心，验证服务器有很多的第三方实现也有Spring官方提供的实现，这里我们使用Spring官方提供的验证服务器。 这里我们将最开始保存好的项目解压，就重新创建一个新的项目，首先我们在父项目中添加最新的SpringCloud依赖： org.springframework.cloud spring-cloud-dependencies 2021.0.1 pom import 接着创建一个新的模块auth-service，添加依赖： org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-security org.springframework.cloud spring-cloud-starter-oauth2 2.2.5.RELEASE 接着我们修改一下配置文件： server: port: 8500 servlet: #为了防止一会在服务之间跳转导致Cookie打架（因为所有服务地址都是localhost，都会存JSESSIONID） #这里修改一下context-path，这样保存的Cookie会使用指定的路径，就不会和其他服务打架了 #但是注意之后的请求都得在最前面加上这个路径 context-path: /sso 接着我们需要编写一下配置类，这里需要两个配置类，一个是OAuth2的配置类，还有一个是SpringSecurity的配置类： @Configuration public class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .anyRequest().authenticated() // .and() .formLogin().permitAll(); //使用表单登录 } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { BCryptPasswordEncoder encoder = new BCryptPasswordEncoder(); auth .inMemoryAuthentication() //直接创建一个用户，懒得搞数据库了 .passwordEncoder(encoder) .withUser(\"test\").password(encoder.encode(\"123456\")).roles(\"USER\"); } @Bean //这里需要将AuthenticationManager注册为Bean，在OAuth配置中使用 @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } } @EnableAuthorizationServer //开启验证服务器 @Configuration public class OAuth2Configuration extends AuthorizationServerConfigurerAdapter { @Resource private AuthenticationManager manager; private final BCryptPasswordEncoder encoder = new BCryptPasswordEncoder(); /** * 这个方法是对客户端进行配置，一个验证服务器可以预设很多个客户端， * 之后这些指定的客户端就可以按照下面指定的方式进行验证 * @param clients 客户端配置工具 */ @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() //这里我们直接硬编码创建，当然也可以像Security那样自定义或是使用JDBC从数据库读取 .withClient(\"web\") //客户端名称，随便起就行 .secret(encoder.encode(\"654321\")) //只与客户端分享的secret，随便写，但是注意要加密 .autoApprove(false) //自动审批，这里关闭，要的就是一会体验那种感觉 .scopes(\"book\", \"user\", \"borrow\") //授权范围，这里我们使用全部all .authorizedGrantTypes(\"client_credentials\", \"password\", \"implicit\", \"authorization_code\", \"refresh_token\"); //授权模式，一共支持5种，除了之前我们介绍的四种之外，还有一个刷新Token的模式 //这里我们直接把五种都写上，方便一会实验，当然各位也可以单独只写一种一个一个进行测试 //现在我们指定的客户端就支持这五种类型的授权方式了 } @Override public void configure(AuthorizationServerSecurityConfigurer security) { security .passwordEncoder(encoder) //编码器设定为BCryptPasswordEncoder .allowFormAuthenticationForClients() //允许客户端使用表单验证，一会我们POST请求中会携带表单信息 .checkTokenAccess(\"permitAll()\"); //允许所有的Token查询请求 } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) { endpoints .authenticationManager(manager); //由于SpringSecurity新版本的一些底层改动，这里需要配置一下authenticationManager，才能正常使用password模式 } } 接着我们就可以启动服务器了： 然后我们使用Postman进行接口测试，首先我们从最简单的客户端模式进行测试，客户端模式只需要提供id和secret即可直接拿到Token，注意需要再添加一个grant_type来表明我们的授权方式，默认请求路径为http://localhost:8500/sso/oauth/token： 发起请求后，可以看到我们得到了Token，它是以JSON格式给到我们的： 我们还可以访问 http://localhost:8500/sso/oauth/check_token 来验证我们的Token是否有效： 可以看到active为true，表示我们刚刚申请到的Token是有效的。 接着我们来测试一下第二种password模式，我们还需要提供具体的用户名和密码，授权模式定义为password即可： 接着我们需要在请求头中添加Basic验证信息，这里我们直接填写id和secret即可： 可以看到在请求头中自动生成了Basic验证相关内容： 响应成功，得到Token信息，并且这里还多出了一个refresh_token，这是用于刷新Token的，我们之后会进行讲解。 查询Token信息之后还可以看到登录的具体用户以及角色权限等。 接着我们来看隐式授权模式，这种模式我们需要在验证服务器上进行登录操作，而不是直接请求Token，验证登录请求地址：http://localhost:8500/sso/oauth/authorize?client_id=web&response_type=token 注意response_type一定要是token类型，这样才会直接返回Token，浏览器发起请求后，可以看到熟悉而又陌生的界面，没错，实际上这里就是使用我们之前讲解的SpringSecurity进行登陆，当然也可以配置一下记住我之类的功能，这里就不演示了： 但是登录之后我们发现出现了一个错误： 这是因为登录成功之后，验证服务器需要将结果给回客户端，所以需要提供客户端的回调地址，这样浏览器就会被重定向到指定的回调地址并且请求中会携带Token信息，这里我们随便配置一个回调地址： @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() .withClient(\"web\") .secret(encoder.encode(\"654321\")) .autoApprove(false) .scopes(\"book\", \"user\", \"borrow\") .redirectUris(\"http://localhost:8201/login\") //可以写多个，当有多个时需要在验证请求中指定使用哪个地址进行回调 .authorizedGrantTypes(\"client_credentials\", \"password\", \"implicit\", \"authorization_code\", \"refresh_token\"); } 接着重启验证服务器，再次访问： 可以看到这里会让我们选择哪些范围进行授权，就像我们在微信小程序中登陆一样，会让我们授予用户信息权限、支付权限、信用查询权限等，我们可以自由决定要不要给客户端授予访问这些资源的权限，这里我们全部选择授予： 授予之后，可以看到浏览器被重定向到我们刚刚指定的回调地址中，并且携带了Token信息，现在我们来校验一下看看： 可以看到，Token也是有效的。 最后我们来看看第四种最安全的授权码模式，这种模式其实流程和上面是一样的，但是请求的是code类型：http://localhost:8500/sso/oauth/authorize?client_id=web&response_type=code 可以看到访问之后，依然会进入到回调地址，但是这时给的就是授权码了，而不是直接给Token，那么这个Token该怎么获取呢？ 按照我们之前讲解的原理，我们需要携带授权码和secret一起请求，才能拿到Token，正常情况下是由回调的服务器进行处理，这里我们就在Postman中进行，我们复制刚刚得到的授权码，接口依然是localhost:8500/sso/oauth/token： 可以看到结果也是正常返回了Token信息： 这样我们四种最基本的Token请求方式就实现了。 最后还有一个是刷新令牌使用的，当我们的Token过期时，我们就可以使用这个refresh_token来申请一个新的Token： 但是执行之后我们发现会直接出现一个内部错误： 查看日志发现，这里还需要我们单独配置一个UserDetailsService，我们直接把Security中的实例注册为Bean： @Bean @Override public UserDetailsService userDetailsServiceBean() throws Exception { return super.userDetailsServiceBean(); } 然后在Endpoint中设置： @Resource UserDetailsService service; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) { endpoints .userDetailsService(service) .authenticationManager(manager); } 最后再次尝试刷新Token： OK，成功刷新Token，返回了一个新的。 基于@EnableOAuth2Sso实现 前面我们将验证服务器已经搭建完成了，现在我们就来实现一下单点登陆吧，SpringCloud为我们提供了客户端的直接实现，我们只需要添加一个注解和少量配置即可将我们的服务作为一个单点登陆应用，使用的是第四种授权码模式。 一句话来说就是，这种模式只是将验证方式由原本的默认登录形式改变为了统一在授权服务器登陆的形式。 首先还是依赖： org.springframework.boot spring-boot-starter-security org.springframework.cloud spring-cloud-starter-oauth2 2.2.5.RELEASE 我们只需要直接在启动类上添加即可： @EnableOAuth2Sso @SpringBootApplication public class BookApplication { public static void main(String[] args) { SpringApplication.run(BookApplication.class, args); } } 我们不需要进行额外的配置类，因为这个注解已经帮我们做了： @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @EnableOAuth2Client @EnableConfigurationProperties({OAuth2SsoProperties.class}) @Import({OAuth2SsoDefaultConfiguration.class, OAuth2SsoCustomConfiguration.class, ResourceServerTokenServicesConfiguration.class}) public @interface EnableOAuth2Sso { } 可以看到它直接注册了OAuth2SsoDefaultConfiguration，而这个类就是帮助我们对Security进行配置的： @Configuration @Conditional({NeedsWebSecurityCondition.class}) public class OAuth2SsoDefaultConfiguration extends WebSecurityConfigurerAdapter { //直接继承的WebSecurityConfigurerAdapter，帮我们把验证设置都写好了 private final ApplicationContext applicationContext; public OAuth2SsoDefaultConfiguration(ApplicationContext applicationContext) { this.applicationContext = applicationContext; } 接着我们需要在配置文件中配置我们的验证服务器相关信息： security: oauth2: client: #不多说了 client-id: web client-secret: 654321 #Token获取地址 access-token-uri: http://localhost:8500/sso/oauth/token #验证页面地址 user-authorization-uri: http://localhost:8500/sso/oauth/authorize resource: #Token信息获取和校验地址 token-info-uri: http://localhost:8500/sso/oauth/check_token 现在我们就开启图书服务，调用图书接口： 可以看到在发现没有登录验证时，会直接跳转到授权页面，进行授权登录，之后才可以继续访问图书服务： 那么用户信息呢？是否也一并保存过来了？我们这里直接获取一下SpringSecurity的Context查看用户信息，获取方式跟我们之前的视频中讲解的是一样的： @RequestMapping(\"/book/{bid}\") Book findBookById(@PathVariable(\"bid\") int bid){ //通过SecurityContextHolder将用户信息取出 SecurityContext context = SecurityContextHolder.getContext(); System.out.println(context.getAuthentication()); return service.getBookById(bid); } 再次访问图书管理接口，可以看到： 这里使用的不是之前的UsernamePasswordAuthenticationToken也不是RememberMeAuthenticationToken，而是新的OAuth2Authentication，它保存了验证服务器的一些信息，以及经过我们之前的登陆流程之后，验证服务器发放给客户端的Token信息，并通过Token信息在验证服务器进行验证获取用户信息，最后保存到Session中，表示用户已验证，所以本质上还是要依赖浏览器存Cookie的。 接下来我们将所有的服务都使用这种方式进行验证，别忘了把重定向地址给所有服务都加上： @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() .withClient(\"web\") .secret(encoder.encode(\"654321\")) .autoApprove(true) //这里把自动审批开了，就不用再去手动选同意了 .scopes(\"book\", \"user\", \"borrow\") .redirectUris(\"http://localhost:8101/login\", \"http://localhost:8201/login\", \"http://localhost:8301/login\") .authorizedGrantTypes(\"client_credentials\", \"password\", \"implicit\", \"authorization_code\", \"refresh_token\"); } 这样我们就可以实现只在验证服务器登陆，如果登陆过其他的服务都可以访问了。 但是我们发现一个问题，就是由于SESSION不同步，每次切换不同的服务进行访问都会重新导验证服务器去验证一次： 这里有两个方案： 像之前一样做SESSION统一存储 设置context-path路径，每个服务单独设置，就不会打架了 但是这样依然没法解决服务间调用的问题，所以仅仅依靠单点登陆的模式不太行。 基于@EnableResourceServer实现 前面我们讲解了将我们的服务作为单点登陆应用直接实现单点登陆，那么现在我们如果是以第三方应用进行访问呢？这时我们就需要将我们的服务作为资源服务了，作为资源服务就不会再提供验证的过程，而是直接要求请求时携带Token，而验证过程我们这里就继续用Postman来完成，这才是我们常见的模式。 一句话来说，跟上面相比，我们只需要携带Token就能访问这些资源服务器了，客户端被独立了出来，用于携带Token去访问这些服务。 我们也只需要添加一个注解和少量配置即可： @EnableResourceServer @SpringBootApplication public class BookApplication { public static void main(String[] args) { SpringApplication.run(BookApplication.class, args); } } 配置中只需要： security: oauth2: client: #基操 client-id: web client-secret: 654321 resource: #因为资源服务器得验证你的Token是否有访问此资源的权限以及用户信息，所以只需要一个验证地址 token-info-uri: http://localhost:8500/sso/oauth/check_token 配置完成后，我们启动服务器，直接访问会发现： 这是由于我们的请求头中没有携带Token信息，现在有两种方式可以访问此资源： 在URL后面添加access_token请求参数，值为Token值 在请求头中添加Authorization，值为Bearer +Token值 我们先来试试看最简的一种： 另一种我们需要使用Postman来完成： 添加验证信息后，会帮助我们转换成请求头信息： 这样我们就将资源服务器搭建完成了。 我们接着来看如何对资源服务器进行深度自定义，我们可以为其编写一个配置类，比如我们现在希望用户授权了某个Scope才可以访问此服务： @Configuration public class ResourceConfiguration extends ResourceServerConfigurerAdapter { //继承此类进行高度自定义 @Override public void configure(HttpSecurity http) throws Exception { //这里也有HttpSecurity对象，方便我们配置SpringSecurity http .authorizeRequests() .anyRequest().access(\"#oauth2.hasScope('lbwnb')\"); //添加自定义规则 //Token必须要有我们自定义scope授权才可以访问此资源 } } 可以看到当没有对应的scope授权时，那么会直接返回insufficient_scope错误： 不知道各位是否有发现，实际上资源服务器完全没有必要将Security的信息保存在Session中了，因为现在只需要将Token告诉资源服务器，那么资源服务器就可以联系验证服务器，得到用户信息，就不需要使用之前的Session存储机制了，所以你会发现HttpSession中没有SPRING_SECURITY_CONTEXT，现在Security信息都是通过连接资源服务器获取。 接着我们将所有的服务都 但是还有一个问题没有解决，我们在使用RestTemplate进行服务间的远程调用时，会得到以下错误： 实际上这是因为在服务调用时没有携带Token信息，我们得想个办法把用户传来的Token信息在进行远程调用时也携带上，因此，我们可以直接使用OAuth2RestTemplate，它会在请求其他服务时携带当前请求的Token信息。它继承自RestTemplate，这里我们直接定义一个Bean： @Configuration public class WebConfiguration { @Resource OAuth2ClientContext context; @Bean public OAuth2RestTemplate restTemplate(){ return new OAuth2RestTemplate(new ClientCredentialsResourceDetails(), context); } } 接着我们直接替换掉之前的RestTemplate即可： @Service public class BorrowServiceImpl implements BorrowService { @Resource BorrowMapper mapper; @Resource OAuth2RestTemplate template; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List borrow = mapper.getBorrowsByUid(uid); User user = template.getForObject(\"http://localhost:8101/user/\"+uid, User.class); //获取每一本书的详细信息 List bookList = borrow .stream() .map(b -> template.getForObject(\"http://localhost:8201/book/\"+b.getBid(), Book.class)) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 可以看到服务成功调用了： 现在我们来将Nacos加入，并通过Feign实现远程调用。 依赖还是贴一下，不然找不到： com.alibaba.cloud spring-cloud-alibaba-dependencies 2021.0.1.0 pom import com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery org.springframework.cloud spring-cloud-starter-loadbalancer 所有服务都已经注册成功了： 接着我们配置一下借阅服务的负载均衡： @Configuration public class WebConfiguration { @Resource OAuth2ClientContext context; @LoadBalanced //和RestTemplate一样直接添加注解就行了 @Bean public OAuth2RestTemplate restTemplate(){ return new OAuth2RestTemplate(new ClientCredentialsResourceDetails(), context); } } 现在我们来把它替换为Feign，老样子，两个客户端： @FeignClient(\"user-service\") public interface UserClient { @RequestMapping(\"/user/{uid}\") User getUserById(@PathVariable(\"uid\") int uid); } @FeignClient(\"book-service\") public interface BookClient { @RequestMapping(\"/book/{bid}\") Book getBookById(@PathVariable(\"bid\") int bid); } 但是配置完成之后，又出现刚刚的问题了，OpenFeign也没有携带Token进行访问： 那么怎么配置Feign携带Token访问呢？遇到这种问题直接去官方查：https://docs.spring.io/spring-cloud-openfeign/docs/current/reference/html/#oauth2-support，非常简单，两个配置就搞定： feign: oauth2: #开启Oauth支持，这样就会在请求头中携带Token了 enabled: true #同时开启负载均衡支持 load-balanced: true 重启服务器，可以看到结果OK了： 这样我们就成功将之前的三个服务作为资源服务器了，注意和我们上面的作为客户端是不同的，将服务直接作为客户端相当于只需要验证通过即可，并且还是要保存Session信息，相当于只是将登录流程换到统一的验证服务器上进行罢了。而将其作为资源服务器，那么就需要另外找客户端（可以是浏览器、小程序、App、第三方服务等）来访问，并且也是需要先进行验证然后再通过携带Token进行访问，这种模式是我们比较常见的模式。 使用jwt存储Token 官网：https://jwt.io JSON Web Token令牌（JWT）是一个开放标准（RFC 7519），它定义了一种紧凑和自成一体的方式，用于在各方之间作为JSON对象安全地传输信息。这些信息可以被验证和信任，因为它是数字签名的。JWT可以使用密钥（使用HMAC算法）或使用RSA或ECDSA进行公钥/私钥对进行签名。 实际上，我们之前都是携带Token向资源服务器发起请求后，资源服务器由于不知道我们Token的用户信息，所以需要向验证服务器询问此Token的认证信息，这样才能得到Token代表的用户信息，但是各位是否考虑过，如果每次用户请求都去查询用户信息，那么在大量请求下，验证服务器的压力可能会非常的大。而使用JWT之后，Token中会直接保存用户信息，这样资源服务器就不再需要询问验证服务器，自行就可以完成解析，我们的目标是不联系验证服务器就能直接完成验证。 JWT令牌的格式如下： 一个JWT令牌由3部分组成：标头(Header)、有效载荷(Payload)和签名(Signature)。在传输的时候，会将JWT的3部分分别进行Base64编码后用.进行连接形成最终需要传输的字符串。 标头：包含一些元数据信息，比如JWT签名所使用的加密算法，还有类型，这里统一都是JWT。 有效载荷：包括用户名称、令牌发布时间、过期时间、JWT ID等，当然我们也可以自定义添加字段，我们的用户信息一般都在这里存放。 签名：首先需要指定一个密钥，该密钥仅仅保存在服务器中，保证不能让其他用户知道。然后使用Header中指定的算法对Header和Payload进行base64加密之后的结果通过密钥计算哈希值，然后就得出一个签名哈希。这个会用于之后验证内容是否被篡改。 这里还是补充一下一些概念，因为很多东西都是我们之前没有接触过的： Base64：就是包括小写字母a-z、大写字母A-Z、数字0-9、符号\"+\"、\"/\"一共64个字符的字符集（末尾还有1个或多个=用来凑够字节数），任何的符号都可以转换成这个字符集中的字符，这个转换过程就叫做Base64编码，编码之后会生成只包含上述64个字符的字符串。相反，如果需要原本的内容，我们也可以进行Base64解码，回到原有的样子。 public void test(){ String str = \"你们可能不知道只用20万赢到578万是什么概念\"; //Base64不只是可以对字符串进行编码，任何byte[]数据都可以，编码结果可以是byte[]，也可以是字符串 String encodeStr = Base64.getEncoder().encodeToString(str.getBytes()); System.out.println(\"Base64编码后的字符串：\"+encodeStr); System.out.println(\"解码后的字符串：\"+new String(Base64.getDecoder().decode(encodeStr))); } 注意Base64不是加密算法，只是一种信息的编码方式而已。 加密算法：加密算法分为对称加密和非对称加密，其中对称加密（Symmetric Cryptography）比较好理解，就像一把锁配了两把钥匙一样，这两把钥匙你和别人都有一把，然后你们直接传递数据，都会把数据用锁给锁上，就算传递的途中有人把数据窃取了，也没办法解密，因为钥匙只有你和对方有，没有钥匙无法进行解密，但是这样有个问题，既然解密的关键在于钥匙本身，那么如果有人不仅窃取了数据，而且对方那边的治安也不好，于是顺手就偷走了钥匙，那你们之间发的数据不就凉凉了吗。 因此，非对称加密（Asymmetric Cryptography）算法出现了，它并不是直接生成一把钥匙，而是生成一个公钥和一个私钥，私钥只能由你保管，而公钥交给对方或是你要发送的任何人都行，现在你需要把数据传给对方，那么就需要使用私钥进行加密，但是，这个数据只能使用对应的公钥进行解密，相反，如果对方需要给你发送数据，那么就需要用公钥进行加密，而数据只能使用私钥进行解密，这样的话就算对方的公钥被窃取，那么别人发给你的数据也没办法解密出来，因为需要私钥才能解密，而只有你才有私钥。 因此，非对称加密的安全性会更高一些，包括HTTPS的隐私信息正是使用非对称加密来保障传输数据的安全（当然HTTPS并不是单纯地使用非对称加密完成的，感兴趣的可以去了解一下） 对称加密和非对称加密都有很多的算法，比如对称加密，就有：DES、IDEA、RC2，非对称加密有：RSA、DAS、ECC 不可逆加密算法：常见的不可逆加密算法有MD5, HMAC, SHA-1, SHA-224, SHA-256, SHA-384, 和SHA-512, 其中SHA-224、SHA-256、SHA-384，和SHA-512我们可以统称为SHA2加密算法，SHA加密算法的安全性要比MD5更高，而SHA2加密算法比SHA1的要高，其中SHA后面的数字表示的是加密后的字符串长度，SHA1默认会产生一个160位的信息摘要。经过不可逆加密算法得到的加密结果，是无法解密回去的，也就是说加密出来是什么就是什么了。本质上，其就是一种哈希函数，用于对一段信息产生摘要，以防止被篡改。 实际上这种算法就常常被用作信息摘要计算，同样的数据通过同样的算法计算得到的结果肯定也一样，而如果数据被修改，那么计算的结果肯定就不一样了。 这里我们就可以利用jwt，将我们的Token采用新的方式进行存储： 这里我们使用最简单的一种方式，对称密钥，我们需要对验证服务器进行一些修改： @Bean public JwtAccessTokenConverter tokenConverter(){ //Token转换器，将其转换为JWT JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey(\"lbwnb\"); //这个是对称密钥，一会资源服务器那边也要指定为这个 return converter; } @Bean public TokenStore tokenStore(JwtAccessTokenConverter converter){ //Token存储方式现在改为JWT存储 return new JwtTokenStore(converter); //传入刚刚定义好的转换器 } @Resource TokenStore store; @Resource JwtAccessTokenConverter converter; private AuthorizationServerTokenServices serverTokenServices(){ //这里对AuthorizationServerTokenServices进行一下配置 DefaultTokenServices services = new DefaultTokenServices(); services.setSupportRefreshToken(true); //允许Token刷新 services.setTokenStore(store); //添加刚刚的TokenStore services.setTokenEnhancer(converter); //添加Token增强，其实就是JwtAccessTokenConverter，增强是添加一些自定义的数据到JWT中 return services; } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) { endpoints .tokenServices(serverTokenServices()) //设定为刚刚配置好的AuthorizationServerTokenServices .userDetailsService(service) .authenticationManager(manager); } 然后我们就可以重启验证服务器了： 可以看到成功获取了AccessToken，但是这里的格式跟我们之前的格式就大不相同了，因为现在它是JWT令牌，我们可以对其进行一下Base64解码： 可以看到所有的验证信息包含在内，现在我们对资源服务器进行配置： security: oauth2: resource: jwt: key-value: lbwnb #注意这里要跟验证服务器的密钥一致，这样算出来的签名才会一致 然后启动资源服务器，请求一下接口试试看： 请求成功，得到数据： 注意如果Token有误，那么会得到： Redis与分布式 在SpringBoot阶段，我们学习了Redis，它是一个基于内存的高性能数据库，我们当时已经学习了包括基本操作、常用数据类型、持久化、事务和锁机制以及使用Java与Redis进行交互等，利用它的高性能，我们还使用它来做Mybatis的二级缓存、以及Token的持久化存储。而这一部分，我们将继续深入，探讨Redis在分布式开发场景下的应用。 主从复制 在分布式场景下，我们可以考虑让Redis实现主从模式： 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(Master)，后者称为从节点(Slave)，数据的复制是单向的，只能由主节点到从节点。Master以写为主，Slave 以读为主。 这样的好处肯定是显而易见的： 实现了读写分离，提高了性能。 在写少读多的场景下，我们甚至可以安排很多个从节点，这样就能够大幅度的分担压力，并且就算挂掉一个，其他的也能使用。 那么我们现在就来尝试实现一下，这里我们还是在Windows下进行测试，打开Redis文件夹，我们要开启两个Redis服务器，修改配置文件redis.windows.conf： # Accept connections on the specified port, default is 6379 (IANA #815344). # If port 0 is specified Redis will not listen on a TCP socket. port 6001 一个服务器的端口设定为6001，复制一份，另一个的端口为6002，接着我们指定配置文件进行启动，打开cmd： 现在我们的两个服务器就启动成功了，接着我们可以使用命令查看当前服务器的主从状态，我们打开客户端： 输入info replication命令来查看当前的主从状态，可以看到默认的角色为：master，也就是说所有的服务器在启动之后都是主节点的状态。那么现在我们希望让6002作为从节点，通过一个命令即可： 可以看到，在输入replicaof 127.0.0.1 6001命令后，就会将6001服务器作为主节点，而当前节点作为6001的从节点，并且角色也会变成：slave，接着我们来看看6001的情况： 可以看到从节点信息中已经出现了6002服务器，也就是说现在我们的6001和6002就形成了主从关系（还包含一个偏移量，这个偏移量反应的是从节点的同步情况） 主服务器和从服务器都会维护一个复制偏移量，主服务器每次向从服务器中传递 N 个字节的时候，会将自己的复制偏移量加上 N。从服务器中收到主服务器的 N 个字节的数据，就会将自己额复制偏移量加上 N，通过主从服务器的偏移量对比可以很清楚的知道主从服务器的数据是否处于一致，如果不一致就需要进行增量同步了。 那么我们现在可以来测试一下，在主节点新增数据，看看是否会同步到从节点： 可以看到，我们在6001服务器插入的a，可以在从节点6002读取到，那么，从节点新增的数据在主节点能得到吗？我们来测试一下： 可以看到，从节点压根就没办法进行数据插入，节点的模式为只读模式。那么如果我们现在不想让6002作为6001的从节点了呢？ 可以看到，通过输入replicaof no one，即可变回Master角色。接着我们再来启动一台6003服务器，流程是一样的： 可以看到，在连接之后，也会直接同步主节点的数据，因此无论是已经处于从节点状态还是刚刚启动完成的服务器，都会从主节点同步数据，实际上整个同步流程为： 从节点执行replicaof ip port命令后，从节点会保存主节点相关的地址信息。 从节点通过每秒运行的定时任务发现配置了新的主节点后，会尝试与该节点建立网络连接，专门用于接收主节点发送的复制命令。 连接成功后，第一次会将主节点的数据进行全量复制，之后采用增量复制，持续将新来的写命令同步给从节点。 当我们的主节点关闭后，从节点依然可以读取数据： 但是从节点会疯狂报错： 当然每次都去敲个命令配置主从太麻烦了，我们可以直接在配置文件中配置，添加这样行即可： replicaof 127.0.0.1 6001 这里我们给6002和6003服务器都配置一下，现在我们重启三个服务器。 当然，除了作为Master节点的从节点外，我们还可以将其作为从节点的从节点，比如现在我们让6003作为6002的从节点： 也就是说，现在差不多是这样的的一个情况： 采用这种方式，优点肯定是显而易见的，但是缺点也很明显，整个传播链路一旦中途出现问题，那么就会导致后面的从节点无法及时同步。 哨兵模式 前面我们讲解了Redis实现主从复制的一些基本操作，那么我们接着来看哨兵模式。 经过之前的学习，我们发现，实际上最关键的还是主节点，因为一旦主节点出现问题，那么整个主从系统将无法写入，因此，我们得想一个办法，处理一下主节点故障的情况。实际上我们可以参考之前的服务治理模式，比如Nacos和Eureka，所有的服务都会被实时监控，那么只要出现问题，肯定是可以及时发现的，并且能够采取响应的补救措施，这就是我们即将介绍的哨兵： 注意这里的哨兵不是我们之前学习SpringCloud Alibaba的那个，是专用于Redis的。哨兵会对所有的节点进行监控，如果发现主节点出现问题，那么会立即让从节点进行投票，选举一个新的主节点出来，这样就不会由于主节点的故障导致整个系统不可写（注意要实现这样的功能最小的系统必须是一主一从，再小的话就没有意义了） 那么怎么启动一个哨兵呢？我们只需要稍微修改一下配置文件即可，这里直接删除全部内容，添加： sentinel monitor lbwnb 127.0.0.1 6001 1 其中第一个和第二个是固定，第三个是为监控对象名称，随意，后面就是主节点的相关信息，包括IP地址和端口，最后一个1我们暂时先不说，然后我们使用此配置文件启动服务器，可以看到启动后： 可以看到以哨兵模式启动后，会自动监控主节点，然后还会显示那些节点是作为从节点存在的。 现在我们直接把主节点关闭，看看会发生什么事情： 可以看到从节点还是正常的在报错，一开始的时候不会直接重新进行选举而是继续尝试重连（因为有可能只是网络小卡一下，没必要这么敏感），但是我们发现，经过一段时间之后，依然无法连接，哨兵输出了以下内容： 可以看到哨兵发现主节点已经有一段时间不可用了，那么就会开始进行重新选举，6003节点被选为了新的主节点，并且之前的主节点6001变成了新的主节点的从节点： 当我们再次启动6001时，会发现，它自动变成了6003的从节点，并且会将数据同步过来： 那么，这个选举规则是怎样的呢？是在所有的从节点中随机选取还是遵循某种规则呢？ 首先会根据优先级进行选择，可以在配置文件中进行配置，添加replica-priority配置项（默认是100），越小表示优先级越高。 如果优先级一样，那就选择偏移量最大的 要是还选不出来，那就选择runid（启动时随机生成的）最小的。 要是哨兵也挂了咋办？没事，咱们可以多安排几个哨兵，只需要把哨兵的配置复制一下，然后修改端口，这样就可以同时启动多个哨兵了，我们启动3个哨兵（一主二从三哨兵），这里我们吧最后一个值改为2： sentinel monitor lbwnb 192.168.0.8 6001 2 这个值实际上代表的是当有几个哨兵认为主节点挂掉时，就判断主节点真的挂掉了 现在我们把6001节点挂掉，看看这三个哨兵会怎么样： 可以看到都显示将master切换为6002节点了。 那么，在哨兵重新选举新的主节点之后，我们Java中的Redis的客户端怎么感知到呢？我们来看看，首先还是导入依赖： redis.clients jedis 4.2.1 public class Main { public static void main(String[] args) { //这里我们直接使用JedisSentinelPool来获取Master节点 //需要把三个哨兵的地址都填入 try (JedisSentinelPool pool = new JedisSentinelPool(\"lbwnb\", new HashSet<>(Arrays.asList(\"192.168.0.8:26741\", \"192.168.0.8:26740\", \"192.168.0.8:26739\")))) { Jedis jedis = pool.getResource(); //直接询问并得到Jedis对象，这就是连接的Master节点 jedis.set(\"test\", \"114514\"); //直接写入即可，实际上就是向Master节点写入 Jedis jedis2 = pool.getResource(); //再次获取 System.out.println(jedis2.get(\"test\")); //读取操作 } catch (Exception e) { e.printStackTrace(); } } } 这样，Jedis对象就可以通过哨兵来获取，当Master节点更新后，也能得到最新的。 集群搭建 如果我们服务器的内存不够用了，但是现在我们的Redis又需要继续存储内容，那么这个时候就可以利用集群来实现扩容。 因为单机的内存容量最大就那么多，已经没办法再继续扩展了，但是现在又需要存储更多的内容，这时我们就可以让N台机器上的Redis来分别存储各个部分的数据（每个Redis可以存储1/N的数据量），这样就实现了容量的横向扩展。同时每台Redis还可以配一个从节点，这样就可以更好地保证数据的安全性。 那么问题来，现在用户来了一个写入的请求，数据该写到哪个节点上呢？我们来研究一下集群的机制： 首先，一个Redis集群包含16384个插槽，集群中的每个Redis 实例负责维护一部分插槽以及插槽所映射的键值数据，那么这个插槽是什么意思呢？ 实际上，插槽就是键的Hash计算后的一个结果，注意这里出现了计算机网络中的CRC循环冗余校验，这里采用CRC16，能得到16个bit位的数据，也就是说算出来之后结果是0-65535之间，再进行取模，得到最终结果： Redis key的路由计算公式：slot = CRC16（key） % 16384 结果的值是多少，就应该存放到对应维护的Redis下，比如Redis节点1负责0-25565的插槽，而这时客户端插入了一个新的数据a=10，a在Hash计算后结果为666，那么a就应该存放到1号Redis节点中。简而言之，本质上就是通过哈希算法将插入的数据分摊到各个节点的，所以说哈希算法真的是处处都有用啊。 那么现在我们就来搭建一个简单的Redis集群，这里创建6个配置，注意开启集群模式： # Normal Redis instances can't be part of a Redis Cluster; only nodes that are # started as cluster nodes can. In order to start a Redis instance as a # cluster node enable the cluster support uncommenting the following: # cluster-enabled yes 接着记得把所有的持久化文件全部删除，所有的节点内容必须是空的。 然后输入redis-cli.exe --cluster create --cluster-replicas 1 127.0.0.1:6001 127.0.0.1:6002 127.0.0.1:6003 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003，这里的--cluster-replicas 1指的是每个节点配一个从节点： 输入之后，会为你展示客户端默认分配的方案，并且会询问你当前的方案是否合理。可以看到6001/6002/6003都被选为主节点，其他的为从节点，我们直接输入yes即可： 最后分配成功，可以看到插槽的分配情况： 现在我们随便连接一个节点，尝试插入一个值： 在插入时，出现了一个错误，实际上这就是因为a计算出来的哈希值（插槽），不归当前节点管，我们得去管这个插槽的节点执行，通过上面的分配情况，我们可以得到15495属于节点6003管理： 在6003节点插入成功，当然我们也可以使用集群方式连接，这样我们无论在哪个节点都可以插入，只需要添加-c表示以集群模式访问： 可以看到，在6001节点成功对a的值进行了更新，只不过还是被重定向到了6003节点进行插入。 我们可以输入cluster nodes命令来查看当前所有节点的信息： 那么现在如果我们让某一个主节点挂掉会怎么样？现在我们把6001挂掉： 可以看到原本的6001从节点7001，晋升为了新的主节点，而之前的6001已经挂了，现在我们将6001重启试试看： 可以看到6001变成了7001的从节点，那么要是6001和7001都挂了呢？ 这时我们尝试插入新的数据： 可以看到，当存在节点不可用时，会无法插入新的数据，现在我们将6001和7001恢复： 可以看到恢复之后又可以继续正常使用了。 最后我们来看一下如何使用Java连接到集群模式下的Redis，我们需要用到JedisCluster对象： public class Main { public static void main(String[] args) { //和客户端一样，随便连一个就行，也可以多写几个，构造方法有很多种可以选择 try(JedisCluster cluster = new JedisCluster(new HostAndPort(\"192.168.0.8\", 6003))){ System.out.println(\"集群实例数量：\"+cluster.getClusterNodes().size()); cluster.set(\"a\", \"yyds\"); System.out.println(cluster.get(\"a\")); } } } 操作基本和Jedis对象一样，这里就不多做赘述了。 分布式锁 在我们的传统单体应用中，经常会用到锁机制，目的是为了防止多线程竞争导致的并发问题，但是现在我们在分布式环境下，又该如何实现锁机制呢？可能一条链路上有很多的应用，它们都是独立运行的，这时我们就可以借助Redis来实现分布式锁。 还记得我们上一章最后提出的问题吗？ @Override public boolean doBorrow(int uid, int bid) { //1. 判断图书和用户是否都支持借阅，如果此时来了10个线程，都进来了，那么都能够判断为可以借阅 if(bookClient.bookRemain(bid) 实际上在高并发下，我们看似正常的借阅流程，会出现问题，比如现在同时来了10个同学要借同一本书，但是现在只有3本，而我们的判断规则是，首先看书够不够，如果此时这10个请求都已经走到这里，并且都判定为可以进行借阅，那么问题就出现了，接下来这10个请求都开始进行借阅操作，导致库存直接爆表，形成超借问题（在电商系统中也存在同样的超卖问题） 因此，为了解决这种问题，我们就可以利用分布式锁来实现。那么Redis如何去实现分布式锁呢？ 在Redis存在这样一个命令： setnx key value 这个命令看起来和set命令差不多，但是它有一个机制，就是只有当指定的key不存在的时候，才能进行插入，实际上就是set if not exists的缩写。 可以看到，当客户端1设定a之后，客户端2使用setnx会直接失败。 当客户端1将a删除之后，客户端2就可以使用setnx成功插入了。 利用这种特性，我们就可以在不同的服务中实现分布式锁，那么问题来了，要是某个服务加了锁但是卡顿了呢，或是直接崩溃了，那这把锁岂不是永远无法释放了？因此我们还可以考虑加个过期时间： set a 666 EX 5 NX 这里使用set命令，最后加一个NX表示是使用setnx的模式，和上面是一样的，但是可以通过EX设定过期时间，这里设置为5秒，也就是说如果5秒还没释放，那么就自动删除。 当然，添加了过期时间，带了的好处是显而易见的，但是同时也带来了很多的麻烦，我们来设想一下这种情况： 因此，单纯只是添加过期时间，会出现这种把别人加的锁谁卸了的情况，要解决这种问题也很简单，我们现在的目标就是保证任务只能删除自己加的锁，如果是别人加的锁是没有资格删的，所以我们可以吧a的值指定为我们任务专属的值，比如可以使用UUID之类的，如果在主动删除锁的时候发现值不是我们当前任务指定的，那么说明可能是因为超时，其他任务已经加锁了。 如果你在学习本篇之前完成了JUC并发编程篇的学习，那么一定会有一个疑惑，如果在超时之前那一刹那进入到释放锁的阶段，获取到值肯定还是自己，但是在即将执行删除之前，由于超时机制导致被删除并且其他任务也加锁了，那么这时再进行删除，仍然会导致删除其他任务加的锁。 实际上本质还是因为锁的超时时间不太好衡量，如果超时时间能够设定地比较恰当，那么就可以避免这种问题了。 要解决这个问题，我们可以借助一下Redisson框架，它是Redis官方推荐的Java版的Redis客户端。它提供的功能非常多，也非常强大，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期，它为我们提供了很多种分布式锁的实现，使用起来也类似我们在JUC中学习的锁，这里我们尝试使用一下它的分布式锁功能。 org.redisson redisson 3.17.0 io.netty netty-all 4.1.75.Final 首先我们来看看不加锁的情况下： public static void main(String[] args) { for (int i = 0; i { try(Jedis jedis = new Jedis(\"192.168.0.10\", 6379)){ for (int j = 0; j 这里没有直接用incr而是我们自己进行计算，方便模拟，可以看到运行结束之后a的值并不是我们想要的： 现在我们来给它加一把锁，注意这个锁是基于Redis的，不仅仅只可以用于当前应用，是能够垮系统的： public static void main(String[] args) { Config config = new Config(); config.useSingleServer().setAddress(\"redis://192.168.0.10:6379\"); //配置连接的Redis服务器，也可以指定集群 RedissonClient client = Redisson.create(config); //创建RedissonClient客户端 for (int i = 0; i { try(Jedis jedis = new Jedis(\"192.168.0.10\", 6379)){ RLock lock = client.getLock(\"testLock\"); //指定锁的名称，拿到锁对象 for (int j = 0; j 可以看到结果没有问题： 注意，如果用于存放锁的Redis服务器挂了，那么肯定是会出问题的，这个时候我们就可以使用RedLock，它的思路是，在多个Redis服务器上保存锁，只需要超过半数的Redis服务器获取到锁，那么就真的获取到锁了，这样就算挂掉一部分节点，也能保证正常运行，这里就不做演示了。 MySQL与分布式 前面我讲解了Redis在分布式场景的下的相关应用，接着我们来看看MySQL数据库在分布式场景下的应用。 主从复制 当我们使用MySQL的时候，也可以采取主从复制的策略，它的实现思路基本和Redis相似，也是采用增量复制的方式，MySQL会在运行的过程中，会记录二进制日志，所有的DML和DDL操作都会被记录进日志中，主库只需要将记录的操作复制给从库，让从库也运行一次，那么就可以实现主从复制。但是注意它不会在一开始进行全量复制，所以最好再开始主从之前将数据库的内容保持一致。 和之前一样，一旦我们实现了主从复制，那么就算主库出现故障，从库也能正常提供服务，并且还可以实现读写分离等操作。这里我们就使用两台主机来搭建一主一从的环境，首先确保两台服务器都安装了MySQL数据库并且都已经正常运行了： 接着我们需要创建对应的账号，一会方便从库进行访问的用户： CREATE USER test identified with mysql_native_password by '123456'; 接着我们开启一下外网访问： sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 修改配置文件： # If MySQL is running as a replication slave, this should be # changed. Ref https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_tmpdir # tmpdir = /tmp # # Instead of skip-networking the default is now to listen only on # localhost which is more compatible and is not less secure. # bind-address = 127.0.0.1 这里注释掉就行 现在我们重启一下MySQL服务： sudo systemctl restart mysql.service 现在我们首先来配置主库，主库只需要为我们刚刚创建好的用户分配一个主从复制的权限即可： grant replication slave on *.* to test; FLUSH PRIVILEGES; 然后我们可以输入命令来查看主库的相关情况： 这样主库就搭建完成了，接着我们需要将从库进行配置，首先是配置文件： # The following can be used as easy to replay backup logs or for replication. # note: if you are setting up a replication slave, see README.Debian about # other settings you may need to change. # 这里需要将server-id配置为其他的值（默认是1）所有Mysql主从实例的id必须唯一，不能打架，不然一会开启会失败 server-id = 2 进入数据库，输入： change replication source to SOURCE_HOST='192.168.0.8',SOURCE_USER='test',SOURCE_PASSWORD='123456',SOURCE_LOG_FILE='binlog.000004',SOURCE_LOG_POS=591; 注意后面的logfile和pos就是我们上面从主库中显示的信息。 执行完成后，显示OK表示没有问题，接着输入： start replica; 现在我们的从机就正式启动了，现在我们输入： show replica status\\G; 来查看当前从机状态，可以看到： 最关键的是下面的Replica_IO_Running和Replica_SQL_Running必须同时为Yes才可以，实际上从库会创建两个线程，一个线程负责与主库进行通信，获取二进制日志，暂时存放到一个中间表（Relay_Log）中，而另一个线程则是将中间表保存的二进制日志的信息进行执行，然后插入到从库中。 最后配置完成，我们来看看在主库进行操作会不会同步到从库： 可以看到在主库中创建的数据库，被同步到从库中了，我们再来试试看创建表和插入数据： use yyds; create table test ( `id` int primary key, `name` varchar(255) NULL, `passwd` varchar(255) NULL ); 现在我们随便插入一点数据： 这样，我们的MySQL主从就搭建完成了，那么如果主机此时挂了会怎么样？ 可以看到IO线程是处于重连状态，会等待主库重新恢复运行。 分库分表 在大型的互联网系统中，可能单台MySQL的存储容量无法满足业务的需求，这时候就需要进行扩容了。 和之前的问题一样，单台主机的硬件资源是存在瓶颈的，不可能无限制地纵向扩展，这时我们就得通过多台实例来进行容量的横向扩容，我们可以将数据分散存储，让多台主机共同来保存数据。 那么问题来了，怎么个分散法？ 垂直拆分：我们的表和数据库都可以进行垂直拆分，所谓垂直拆分，就是将数据库中所有的表，按照业务功能拆分到各个数据库中（是不是感觉跟前面两章的学习的架构对应起来了）而对于一张表，也可以通过外键之类的机制，将其拆分为多个表。 水平拆分：水平拆分针对的不是表，而是数据，我们可以让很多个具有相同表的数据库存放一部分数据，相当于是将数据分散存储在各个节点上。 那么要实现这样的拆分操作，我们自行去编写代码工作量肯定是比较大的，因此目前实际上已经有一些解决方案了，比如我们可以使用MyCat（也是一个数据库中间件，相当于挂了一层代理，再通过MyCat进行分库分表操作数据库，只需要连接就能使用，类似的还有ShardingSphere-Proxy）或是Sharding JDBC（应用程序中直接对SQL语句进行分析，然后转换成分库分表操作，需要我们自己编写一些逻辑代码），这里我们就讲解一下Sharding JDBC。 Sharding JDBC 官方文档（中文）：https://shardingsphere.apache.org/document/5.1.0/cn/overview/#shardingsphere-jdbc 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务，它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。 适用于任何基于 JDBC 的 ORM 框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template 或直接使用 JDBC； 支持任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, HikariCP 等； 支持任意实现 JDBC 规范的数据库，目前支持 MySQL，PostgreSQL，Oracle，SQLServer 以及任何可使用 JDBC 访问的数据库。 这里我们主要演示一下水平分表方式，我们直接创建一个新的SpringBoot项目即可，依赖如下： org.apache.shardingsphere shardingsphere-jdbc-core-spring-boot-starter 5.1.0 org.mybatis.spring.boot mybatis-spring-boot-starter 2.2.2 org.projectlombok lombok true org.springframework.boot spring-boot-starter-test test 数据库我们这里直接用上节课的即可，因为只需要两个表结构一样的数据库即可，正好上节课进行了同步，所以我们直接把从库变回正常状态就可以了： stop replica; 接着我们把两个表的root用户密码改一下，一会用这个用户连接数据库： update user set authentication_string='' where user='root'; update user set host = '%' where user = 'root'; alter user root identified with mysql_native_password by '123456'; FLUSH PRIVILEGES; 接着我们来看，如果直接尝试开启服务器，那肯定是开不了的，因为我们要配置数据源： 那么数据源该怎么配置呢？现在我们是一个分库分表的状态，需要配置两个数据源： spring: shardingsphere: datasource: # 有几个数据就配几个，这里是名称，按照下面的格式，名称+数字的形式 names: db0,db1 # 为每个数据源单独进行配置 db0: # 数据源实现类，这里使用默认的HikariDataSource type: com.zaxxer.hikari.HikariDataSource # 数据库驱动 driver-class-name: com.mysql.cj.jdbc.Driver # 不用我多说了吧 jdbc-url: jdbc:mysql://192.168.0.8:3306/yyds username: root password: 123456 db1: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://192.168.0.13:3306/yyds username: root password: 123456 如果启动没有问题，那么就是配置成功了： 接着我们需要对项目进行一些编写，添加我们的用户实体类和Mapper： @Data @AllArgsConstructor public class User { int id; String name; String passwd; } @Mapper public interface UserMapper { @Select(\"select * from test where id = #{id}\") User getUserById(int id); @Insert(\"insert into test(id, name, passwd) values(#{id}, #{name}, #{passwd})\") int addUser(User user); } 实际上这些操作都是常规操作，在编写代码时关注点依然放在业务本身上，现在我们就来编写配置文件，我们需要告诉ShardingJDBC要如何进行分片，首先明确：现在是两个数据库都有test表存放用户数据，我们目标是将用户信息分别存放到这两个数据库的表中。 不废话了，直接上配置： spring: shardingsphere: rules: sharding: tables: #这里填写表名称，程序中对这张表的所有操作，都会采用下面的路由方案 #比如我们上面Mybatis就是对test表进行操作，所以会走下面的路由方案 test: #这里填写实际的路由节点，比如现在我们要分两个库，那么就可以把两个库都写上，以及对应的表 #也可以使用表达式，比如下面的可以简写为 db$->{0..1}.test actual-data-nodes: db0.test,db1.test #这里是分库策略配置 database-strategy: #这里选择标准策略，也可以配置复杂策略，基于多个键进行分片 standard: #参与分片运算的字段，下面的算法会根据这里提供的字段进行运算 sharding-column: id #这里填写我们下面自定义的算法名称 sharding-algorithm-name: my-alg sharding-algorithms: #自定义一个新的算法，名称随意 my-alg: #算法类型，官方内置了很多种，这里演示最简单的一种 type: MOD props: sharding-count: 2 props: #开启日志，一会方便我们观察 sql-show: true 其中，分片算法有很多内置的，可以在这里查询：https://shardingsphere.apache.org/document/5.1.0/cn/user-manual/shardingsphere-jdbc/builtin-algorithm/sharding/，这里我们使用的是MOD，也就是取模分片算法，它会根据主键的值进行取模运算，比如我们这里填写的是2，那么就表示对主键进行模2运算，根据数据源的名称，比如db0就是取模后为0，db1就是取模后为1（官方文档描述的并不是很清楚），也就是说，最终实现的效果就是单数放在`db1`，双数放在`db0`，当然它还支持一些其他的算法，这里就不多介绍了。 那么现在我们编写一个测试用例来看看，是否能够按照我们上面的规则进行路由： @SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { for (int i = 0; i 现在我们可以开始运行了： 测试通过，我们来看看数据库里面是不是按照我们的规则进行数据插入的： 可以看到这两张表，都成功按照我们指定的路由规则进行插入了，我们来看看详细的路由情况，通过控制台输出的SQL就可以看到： 可以看到所有的SQL语句都有一个Logic SQL（这个就是我们在Mybatis里面写的，是什么就是什么）紧接着下面就是Actual SQL，也就是说每个逻辑SQL最终会根据我们的策略转换为实际SQL，比如第一条数据，它的id是0，那么实际转换出来的SQL会在db0这个数据源进行插入。 这样我们就很轻松地实现了分库策略。 分库完成之后，接着我们来看分表，比如现在我们的数据库中有test_0和test_1两张表，表结构一样，但是我们也是希望能够根据id取模运算的结果分别放到这两个不同的表中，实现思路其实是差不多的，这里首先需要介绍一下两种表概念： 逻辑表：相同结构的水平拆分数据库（表）的逻辑名称，是 SQL 中表的逻辑标识。 例：订单数据根据主键尾数拆分为 10 张表，分别是 t_order_0 到 t_order_9，他们的逻辑表名为 t_order 真实表：在水平拆分的数据库中真实存在的物理表。 即上个示例中的 t_order_0 到 t_order_9 现在我们就以一号数据库为例，那么我们在里面创建上面提到的两张表，之前的那个test表删不删都可以，就当做不存在就行了： create table test_0 ( `id` int primary key, `name` varchar(255) NULL, `passwd` varchar(255) NULL ); create table test_1 ( `id` int primary key, `name` varchar(255) NULL, `passwd` varchar(255) NULL ); 接着我们不要去修改任何的业务代码，Mybatis里面写的是什么依然保持原样，即使我们的表名已经变了，我们需要做的是通过路由来修改原有的SQL，配置如下： spring: shardingsphere: rules: sharding: tables: test: actual-data-nodes: db0.test_$->{0..1} #现在我们来配置一下分表策略，注意这里是table-strategy上面是database-strategy table-strategy: #基本都跟之前是一样的 standard: sharding-column: id sharding-algorithm-name: my-alg sharding-algorithms: my-alg: #这里我们演示一下INLINE方式，我们可以自行编写表达式来决定 type: INLINE props: #比如我们还是希望进行模2计算得到数据该去的表 #只需要给一个最终的表名称就行了test_，后面的数字是表达式取模算出的 #实际上这样写和MOD模式一模一样 algorithm-expression: test_$->{id % 2} #没错，查询也会根据分片策略来进行，但是如果我们使用的是范围查询，那么依然会进行全量查询 #这个我们后面紧接着会讲，这里先写上吧 allow-range-query-with-inline-sharding: false 现在我们来测试一下，看看会不会按照我们的策略进行分表插入： 可以看到，根据我们的算法，原本的逻辑表被修改为了最终进行分表计算后的结果，我们来查看一下数据库： 插入我们了解完毕了，我们来看看查询呢： @SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { System.out.println(mapper.getUserById(0)); System.out.println(mapper.getUserById(1)); } } 可以看到，根据我们配置的策略，查询也会自动选择对应的表进行，是不是感觉有内味了。 那么如果是范围查询呢？ @Select(\"select * from test where id between #{start} and #{end}\") List getUsersByIdRange(int start, int end); @SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { System.out.println(mapper.getUsersByIdRange(3, 5)); } } 我们来看看执行结果会怎么样： 可以看到INLINE算法默认是不支持进行全量查询的，我们得将上面的配置项改成true： allow-range-query-with-inline-sharding: true 再次进行测试： 可以看到，最终出来的SQL语句是直接对两个表都进行查询，然后求出一个并集出来作为最后的结果。 当然除了分片之外，还有广播表和绑定表机制，用于多种业务场景下，这里就不多做介绍了，详细请查阅官方文档。 分布式序列算法 前面我们讲解了如何进行分库分表，接着我们来看看分布式序列算法。 在复杂分布式系统中，特别是微服构架中，往往需要对大量的数据和消息进行唯一标识。随着系统的复杂，数据的增多，分库分表成为了常见的方案，对数据分库分表后需要有一个唯一ID来标识一条数据或消息（如订单号、交易流水、事件编号等），此时一个能够生成全局唯一ID的系统是非常必要的。 比如我们之前创建过学生信息表、图书借阅表、图书管理表，所有的信息都会有一个ID作为主键，并且这个ID有以下要求： 为了区别于其他的数据，这个ID必须是全局唯一的。 主键应该尽可能的保持有序，这样会大大提升索引的查询效率。 那么我们在分布式系统下，如何保证ID的生成满足上面的需求呢？ 使用UUID：UUID是由一组32位数的16进制数字随机构成的，我们可以直接使用JDK为我们提供的UUID类来创建： public static void main(String[] args) { String uuid = UUID.randomUUID().toString(); System.out.println(uuid); } 结果为73d5219b-dc0f-4282-ac6e-8df17bcd5860，生成速度非常快，可以看到确实是能够保证唯一性，因为每次都不一样，而且这么长一串那重复的概率真的是小的可怜。 但是它并不满足我们上面的第二个要求，也就是说我们需要尽可能的保证有序，而这里我们得到的都是一些无序的ID。 雪花算法（Snowflake）： 我们来看雪花算法，它会生成一个一个64bit大小的整型的ID，int肯定是装不下了。 可以看到它主要是三个部分组成，时间+工作机器ID+序列号，时间以毫秒为单位，41个bit位能表示约70年的时间，时间纪元从2016年11月1日零点开始，可以使用到2086年，工作机器ID其实就是节点ID，每个节点的ID都不相同，那么就可以区分出来，10个bit位可以表示最多1024个节点，最后12位就是每个节点下的序列号，因此每台机器每毫秒就可以有4096个系列号。 这样，它就兼具了上面所说的唯一性和有序性了，但是依然是有缺点的，第一个是时间问题，如果机器时间出现倒退，那么就会导致生成重复的ID，并且节点容量只有1024个，如果是超大规模集群，也是存在隐患的。 ShardingJDBC支持以上两种算法为我们自动生成ID，文档：https://shardingsphere.apache.org/document/5.1.0/cn/user-manual/shardingsphere-jdbc/builtin-algorithm/keygen/ 这里，我们就是要ShardingJDBC来让我们的主键ID以雪花算法进行生成，首先是配置数据库，因为我们默认的id是int类型，装不下64位的，改一下： ALTER TABLE `yyds`.`test` MODIFY COLUMN `id` bigint NOT NULL FIRST; 接着我们需要修改一下Mybatis的插入语句，因为现在id是由ShardingJDBC自动生成，我们就不需要自己加了： @Insert(\"insert into test(name, passwd) values(#{name}, #{passwd})\") int addUser(User user); 接着我们在配置文件中将我们的算法写上： spring: shardingsphere: datasource: sharding: tables: test: actual-data-nodes: db0.test,db1.test #这里还是使用分库策略 database-strategy: standard: sharding-column: id sharding-algorithm-name: my-alg #这里使用自定义的主键生成策略 key-generate-strategy: column: id key-generator-name: my-gen key-generators: #这里写我们自定义的主键生成算法 my-gen: #使用雪花算法 type: SNOWFLAKE props: #工作机器ID，保证唯一就行 worker-id: 666 sharding-algorithms: my-alg: type: MOD props: sharding-count: 2 接着我们来编写一下测试用例： @SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { for (int i = 0; i 可以看到日志： 在插入的时候，将我们的SQL语句自行添加了一个id字段，并且使用的是雪花算法生成的值，并且也是根据我们的分库策略在进行插入操作。 读写分离 最后我们来看看读写分离，我们之前实现了MySQL的主从，那么我们就可以将主库作为读，从库作为写： 这里我们还是将数据库变回主从状态，直接删除当前的表，我们重新来过： drop table test; 我们需要将从库开启只读模式，在MySQL配置中进行修改： read-only = 1 这样从库就只能读数据了（但是root账号还是可以写数据），接着我们重启服务器： sudo systemctl restart mysql.service 然后进入主库，看看状态： 现在我们配置一下从库： change replication source to SOURCE_HOST='192.168.0.13',SOURCE_USER='test',SOURCE_PASSWORD='123456',SOURCE_LOG_FILE='binlog.000007',SOURCE_LOG_POS=19845; start replica; 现在我们在主库创建表： create table test ( `id` bigint primary key, `name` varchar(255) NULL, `passwd` varchar(255) NULL ); 然后我们就可以配置ShardingJDBC了，打开配置文件： spring: shardingsphere: rules: #配置读写分离 readwrite-splitting: data-sources: #名称随便写 user-db: #使用静态类型，动态Dynamic类型可以自动发现auto-aware-data-source-name，这里不演示 type: Static props: #配置写库（只能一个） write-data-source-name: db0 #配置从库（多个，逗号隔开） read-data-source-names: db1 #负载均衡策略，可以自定义 load-balancer-name: my-load load-balancers: #自定义的负载均衡策略 my-load: type: ROUND_ROBIN 注意把之前改的用户实体类和Mapper改回去，这里我们就不用自动生成ID的了。所有的负载均衡算法地址：https://shardingsphere.apache.org/document/5.1.0/cn/user-manual/shardingsphere-jdbc/builtin-algorithm/load-balance/ 现在我们就来测试一下吧： @SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { mapper.addUser(new User(10, \"aaa\", \"bbb\")); System.out.println(mapper.getUserById(10)); } } 运行看看SQL日志： 可以看到，当我们执行插入操作时，会直接向db0进行操作，而读取操作是会根据我们的配置，选择db1进行操作。 至此，微服务应用章节到此结束。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/SpringCloud（三）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/SpringCloud（三）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/SpringCloud/SpringCloud（四）.html":{"url":"Java/SpringCloud/SpringCloud（四）.html","title":"SpringCloud（四）","keywords":"","body":" 消息队列 经过前面的学习，我们已经了解了我们之前的技术在分布式环境下的应用，接着我们来看最后一章的内容。 那么，什么是消息队列呢？ 我们之前如果需要进行远程调用，那么一般可以通过发送HTTP请求来完成，而现在，我们可以使用第二种方式，就是消息队列，它能够将发送方发送的信息放入队列中，当新的消息入队时，会通知接收方进行处理，一般消息发送方称为生产者，接收方称为消费者。 这样我们所有的请求，都可以直接丢到消息队列中，再由消费者取出，不再是直接连接消费者的形式了，而是加了一个中间商，这也是一种很好的解耦方案，并且在高并发的情况下，由于消费者能力有限，消息队列也能起到一个削峰填谷的作用，堆积一部分的请求，再由消费者来慢慢处理，而不会像直接调用那样请求蜂拥而至。 那么，消息队列具体实现有哪些呢： RabbitMQ - 性能很强，吞吐量很高，支持多种协议，集群化，消息的可靠执行特性等优势，很适合企业的开发。 Kafka - 提供了超高的吞吐量，ms级别的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。 RocketMQ - 阿里巴巴推出的消息队列，经历过双十一的考验，单机吞吐量高，消息的高可靠性，扩展性强，支持事务等，但是功能不够完整，语言支持性较差。 我们这里，主要讲解的是RabbitMQ消息队列。 RabbitMQ 消息队列 官方网站：https://www.rabbitmq.com RabbitMQ拥有数万计的用户，是最受欢迎的开源消息队列之一，从T-Mobile到Runtastic，RabbitMQ在全球范围内用于小型初创企业和大型企业。 RabbitMQ轻量级，易于在本地和云端部署，它支持多种消息协议。RabbitMQ可以部署在分布式和联合配置中，以满足大规模、高可用性要求。 RabbitMQ在许多操作系统和云环境中运行，并为大多数流行语言提供了广泛的开发者工具。 我们首先还是来看看如何进行安装。 安装消息队列 下载地址：https://www.rabbitmq.com/download.html 由于除了消息队列本身之外还需要Erlang环境（RabbitMQ就是这个语言开发的）所以我们就在我们的Ubuntu服务器上进行安装。 首先是Erlang，比较大，1GB左右： sudo apt install erlang 接着安装RabbitMQ： sudo apt install rabbitmq-server 安装完成后，可以输入： sudo rabbitmqctl status 来查看当前的RabbitMQ运行状态，包括运行环境、内存占用、日志文件等信息： Runtime OS PID: 13718 OS: Linux Uptime (seconds): 65 Is under maintenance?: false RabbitMQ version: 3.8.9 Node name: rabbit@ubuntu-server-2 Erlang configuration: Erlang/OTP 23 [erts-11.1.8] [source] [64-bit] [smp:2:2] [ds:2:2:10] [async-threads:64] Erlang processes: 280 used, 1048576 limit Scheduler run queue: 1 Cluster heartbeat timeout (net_ticktime): 60 这样我们的RabbitMQ服务器就安装完成了，要省事还得是Ubuntu啊。 可以看到默认有两个端口名被使用： Listeners Interface: [::], port: 25672, protocol: clustering, purpose: inter-node and CLI tool communication Interface: [::], port: 5672, protocol: amqp, purpose: AMQP 0-9-1 and AMQP 1.0 我们一会主要使用的就是amqp协议的那个端口5672来进行连接，25672是集群化端口，之后我们也会用到。 接着我们还可以将RabbitMQ的管理面板开启，这样话就可以在浏览器上进行实时访问和监控了： sudo rabbitmq-plugins enable rabbitmq_management 再次查看状态，可以看到多了一个管理面板，使用的是HTTP协议： Listeners Interface: [::], port: 25672, protocol: clustering, purpose: inter-node and CLI tool communication Interface: [::], port: 5672, protocol: amqp, purpose: AMQP 0-9-1 and AMQP 1.0 Interface: [::], port: 15672, protocol: http, purpose: HTTP API 我们打开浏览器直接访问一下： 可以看到需要我们进行登录才可以进入，我们这里还需要创建一个用户才可以，这里就都用admin： sudo rabbitmqctl add_user 用户名 密码 将管理员权限给予我们刚刚创建好的用户： sudo rabbitmqctl set_user_tags admin administrator 创建完成之后，我们登录一下页面： 进入了之后会显示当前的消息队列情况，包括版本号、Erlang版本等，这里需要介绍一下RabbitMQ的设计架构，这样我们就知道各个模块管理的是什么内容了： 生产者（Publisher）和消费者（Consumer）：不用多说了吧。 Channel：我们的客户端连接都会使用一个Channel，再通过Channel去访问到RabbitMQ服务器，注意通信协议不是http，而是amqp协议。 Exchange：类似于交换机一样的存在，会根据我们的请求，转发给相应的消息队列，每个队列都可以绑定到Exchange上，这样Exchange就可以将数据转发给队列了，可以存在很多个，不同的Exchange类型可以用于实现不同消息的模式。 Queue：消息队列本体，生产者所有的消息都存放在消息队列中，等待消费者取出。 Virtual Host：有点类似于环境隔离，不同环境都可以单独配置一个Virtual Host，每个Virtual Host可以包含很多个Exchange和Queue，每个Virtual Host相互之间不影响。 使用消息队列 我们就从最简的的模型开始讲起： （一个生产者 -> 消息队列 -> 一个消费者） 生产者只需要将数据丢进消息队列，而消费者只需要将数据从消息队列中取出，这样就实现了生产者和消费者的消息交互。我们现在来演示一下，首先进入到我们的管理页面，这里我们创建一个新的实验环境，只需要新建一个Virtual Host即可： 添加新的虚拟主机之后，我们可以看到，当前admin用户的主机访问权限中新增了我们刚刚添加的环境： 现在我们来看看交换机： 交换机列表中自动为我们新增了刚刚创建好的虚拟主机相关的预设交换机，一共7个，这里我们首先介绍一下前面两个direct类型的交换机，一个是（AMQP default）还有一个是amq.direct，它们都是直连模式的交换机，我们来看看第一个： 第一个交换机是所有虚拟主机都会自带的一个默认交换机，并且此交换机不可删除，此交换机默认绑定到所有的消息队列，如果是通过默认交换机发送消息，那么会根据消息的routingKey（之后我们发消息都会指定）决定发送给哪个同名的消息队列，同时也不能显示地将消息队列绑定或解绑到此交换机。 我们可以看到，详细信息中，当前交换机特性是持久化的，也就是说就算机器重启，那么此交换机也会保留，如果不是持久化，那么一旦重启就会消失。实际上我们在列表中看到D的字样，就表示此交换机是持久化的，包含一会我们要讲解的消息队列列表也是这样，所有自动生成的交换机都是持久化的。 我们接着来看第二个交换机，这个交换机是一个普通的直连交换机： 这个交换机和我们刚刚介绍的默认交换机类型一致，并且也是持久化的，但是我们可以看到它是具有绑定关系的，如果没有指定的消息队列绑定到此交换机上，那么这个交换机无法正常将信息存放到指定的消息队列中，也是根据routingKey寻找消息队列（但是可以自定义） 我们可以在下面直接操作，让某个队列绑定，这里我们先不进行操作。 介绍完了两个最基本的交换机之后（其他类型的交换机我们会在后面进行介绍），我们接着来看消息队列： 可以看到消息队列列表中没有任何的消息队列，我们可以来尝试添加一个新的消息队列： 第一行，我们选择我们刚刚创建好的虚拟主机，在这个虚拟主机下创建此消息队列，接着我们将其类型定义为Classic类型，也就是经典类型（其他类型我们会在后面逐步介绍）名称随便起一个，然后持久化我们选择Transient暂时的（当然也可以持久化，看你自己）自动删除我们选择No（需要至少有一个消费者连接到这个队列，之后，一旦所有与这个队列连接的消费者都断开时，就会自动删除此队列）最下面的参数我们暂时不进行任何设置（之后会用到） 现在，我们就创建好了一个经典的消息队列： 点击此队列的名称，我们可以查看详细信息： 详细相信中包括队列的当前负载状态、属性、消息队列占用的内存，消息数量等，一会我们发送消息时可以进一步进行观察。 现在我们需要将此消息队列绑定到上面的第二个直连交换机，这样我们就可以通过此交换机向此消息队列发送消息了： 这里填写之前第二个交换机的名称还有我们自定义的routingKey（最好还是和消息队列名称一致，这里是为了一会演示两个交换机区别用）我们直接点击绑定即可： 绑定之后我们可以看到当前队列已经绑定对应的交换机了，现在我们可以前往交换机对此消息队列发送一个消息： 回到交换机之后，可以卡到这边也是同步了当前的绑定信息，在下方，我们直接向此消息队列发送信息： 点击发送之后，我们回到刚刚的交换机详细页面，可以看到已经有一条新的消息在队列中了： 我们可以直接在消息队列这边获取消息队列中的消息，找到下方的Get message选项： 可以看到有三个选择，首先第一个Ack Mode，这个是应答模式选择，一共有4个选项： Nack message requeue true：拒绝消息，也就是说不会将消息从消息队列取出，并且重新排队，一次可以拒绝多个消息。 Ack message requeue false：确认应答，确认后消息会从消息队列中移除，一次可以确认多个消息。 Reject message requeue true/false：也是拒绝此消息，但是可以指定是否重新排队。 这里我们使用默认的就可以了，这样只会查看消息是啥，但是不会取出，消息依然存在于消息队列中，第二个参数是编码格式，使用默认的就可以了，最后就是要生效的操作数量，选择1就行： 可以看到我们刚刚的消息已经成功读取到。 现在我们再去第一个默认交换机中尝试发送消息试试看： 如果我们使用之前自定义的routingKey，会显示没有路由，这是因为默认的交换机只会找对应名称的消息队列，我们现在向yyds发送一下试试看： 可以看到消息成功发布了，我们来接收一下看看： 可以看到成功发送到此消息队列中了。 当然除了在交换机发送消息给消息队列之外，我们也可以直接在消息队列这里发： 效果是一样的，注意这里我们可以选择是否将消息持久化，如果是持久化消息，那么就算服务器重启，此消息也会保存在消息队列中。 最后如果我们不需要再使用此消息队列了，我们可以手动对其进行删除或是清空： 点击Delete Queue删除我们刚刚创建好的yyds队列，到这里，我们对应消息队列的一些简单使用，就讲解完毕了。 使用Java操作消息队列 现在我们来看看如何通过Java连接到RabbitMQ服务器并使用消息队列进行消息发送（这里一起讲解，包括Java基础版本和SpringBoot版本），首先我们使用最基本的Java客户端连接方式： com.rabbitmq amqp-client 5.14.2 依赖导入之后，我们来实现一下生产者和消费者，首先是生产者，生产者负责将信息发送到消息队列： public static void main(String[] args) { //使用ConnectionFactory来创建连接 ConnectionFactory factory = new ConnectionFactory(); //设定连接信息，基操 factory.setHost(\"192.168.0.12\"); factory.setPort(5672); //注意这里写5672，是amqp协议端口 factory.setUsername(\"admin\"); factory.setPassword(\"admin\"); factory.setVirtualHost(\"/test\"); //创建连接 try(Connection connection = factory.newConnection()){ }catch (Exception e){ e.printStackTrace(); } } 这里我们可以直接在程序中定义并创建消息队列（实际上是和我们在管理页面创建一样的效果）客户端需要通过连接创建一个新的通道（Channel），同一个连接下可以有很多个通道，这样就不用创建很多个连接也能支持分开发送了。 try(Connection connection = factory.newConnection(); Channel channel = connection.createChannel()){ //通过Connection创建新的Channel //声明队列，如果此队列不存在，会自动创建 channel.queueDeclare(\"yyds\", false, false, false, null); //将队列绑定到交换机 channel.queueBind(\"yyds\", \"amq.direct\", \"my-yyds\"); //发布新的消息，注意消息需要转换为byte[] channel.basicPublish(\"amq.direct\", \"my-yyds\", null, \"Hello World!\".getBytes()); }catch (Exception e){ e.printStackTrace(); } 其中queueDeclare方法的参数如下： queue：队列的名称（默认创建后routingKey和队列名称一致） durable：是否持久化。 exclusive：是否排他，如果一个队列被声明为排他队列，该队列仅对首次声明它的连接可见，并在连接断开时自动删除。排他队列是基于Connection可见，同一个Connection的不同Channel是可以同时访问同一个连接创建的排他队列，并且，如果一个Connection已经声明了一个排他队列，其他的Connection是不允许建立同名的排他队列的，即使该队列是持久化的，一旦Connection关闭或者客户端退出，该排他队列都会自动被删除。 autoDelete：是否自动删除。 arguments：设置队列的其他一些参数，这里我们暂时不需要什么其他参数。 其中queueBind方法参数如下： queue：需要绑定的队列名称。 exchange：需要绑定的交换机名称。 routingKey：不用多说了吧。 其中basicPublish方法的参数如下： exchange: 对应的Exchange名称，我们这里就使用第二个直连交换机。 routingKey：这里我们填写绑定时指定的routingKey，其实和之前在管理页面操作一样。 props：其他的配置。 body：消息本体。 执行完成后，可以在管理页面中看到我们刚刚创建好的消息队列了： 并且此消息队列已经成功与amq.direct交换机进行绑定： 那么现在我们的消息队列中已经存在数据了，怎么将其读取出来呢？我们来看看如何创建一个消费者： public static void main(String[] args) throws IOException, TimeoutException { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"10.37.129.4\"); factory.setPort(5672); factory.setUsername(\"admin\"); factory.setPassword(\"admin\"); factory.setVirtualHost(\"/test\"); //这里不使用try-with-resource，因为消费者是一直等待新的消息到来，然后按照 //我们设定的逻辑进行处理，所以这里不能在定义完成之后就关闭连接 Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //创建一个基本的消费者 channel.basicConsume(\"yyds\", false, (s, delivery) -> { System.out.println(new String(delivery.getBody())); //basicAck是确认应答，第一个参数是当前的消息标签，后面的参数是 //是否批量处理消息队列中所有的消息，如果为false表示只处理当前消息 channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); //basicNack是拒绝应答，最后一个参数表示是否将当前消息放回队列，如果 //为false，那么消息就会被丢弃 //channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, false); //跟上面一样，最后一个参数为false，只不过这里省了 //channel.basicReject(delivery.getEnvelope().getDeliveryTag(), false); }, s -> {}); } 其中basicConsume方法参数如下： queue - 消息队列名称，直接指定。 autoAck - 自动应答，消费者从消息队列取出数据后，需要跟服务器进行确认应答，当服务器收到确认后，会自动将消息删除，如果开启自动应答，那么消息发出后会直接删除。 deliver - 消息接收后的函数回调，我们可以在回调中对消息进行处理，处理完成后，需要给服务器确认应答。 cancel - 当消费者取消订阅时进行的函数回调，这里暂时用不到。 现在我们启动一下消费者，可以看到立即读取到我们刚刚插入到队列中的数据： 我们现在继续在消息队列中插入新的数据，这里直接在网页上进行操作就行了，同样的我们也可以在消费者端接受并进行处理。 现在我们把刚刚创建好的消息队列删除。 官方文档：https://docs.spring.io/spring-amqp/docs/current/reference/html/ 前面我们已经完成了RabbitMQ的安装和简单使用，并且通过Java连接到服务器。现在我们来尝试在SpringBoot中整合消息队列客户端，首先是依赖： org.springframework.boot spring-boot-starter-amqp 接着我们需要配置RabbitMQ的地址等信息： spring: rabbitmq: addresses: 192.168.0.4 username: admin password: admin virtual-host: /test 这样我们就完成了最基本信息配置，现在我们来看一下，如何像之前一样去声明一个消息队列，我们只需要一个配置类就行了： @Configuration public class RabbitConfiguration { @Bean(\"directExchange\") //定义交换机Bean，可以很多个 public Exchange exchange(){ return ExchangeBuilder.directExchange(\"amq.direct\").build(); } @Bean(\"yydsQueue\") //定义消息队列 public Queue queue(){ return QueueBuilder .nonDurable(\"yyds\") //非持久化类型 .build(); } @Bean(\"binding\") public Binding binding(@Qualifier(\"directExchange\") Exchange exchange, @Qualifier(\"yydsQueue\") Queue queue){ //将我们刚刚定义的交换机和队列进行绑定 return BindingBuilder .bind(queue) //绑定队列 .to(exchange) //到交换机 .with(\"my-yyds\") //使用自定义的routingKey .noargs(); } } 接着我们来创建一个生产者，这里我们直接编写在测试用例中： @SpringBootTest class SpringCloudMqApplicationTests { //RabbitTemplate为我们封装了大量的RabbitMQ操作，已经由Starter提供，因此直接注入使用即可 @Resource RabbitTemplate template; @Test void publisher() { //使用convertAndSend方法一步到位，参数基本和之前是一样的 //最后一个消息本体可以是Object类型，真是大大的方便 template.convertAndSend(\"amq.direct\", \"my-yyds\", \"Hello World!\"); } } 现在我们来运行一下这个测试用例： 可以看到后台自动声明了我们刚刚定义好的消息队列和交换机以及对应的绑定关系，并且我们的数据也是成功插入到消息队列中： 现在我们再来看看如何创建一个消费者，因为消费者实际上就是一直等待消息然后进行处理的角色，这里我们只需要创建一个监听器就行了，它会一直等待消息到来然后再进行处理： @Component //注册为Bean public class TestListener { @RabbitListener(queues = \"yyds\") //定义此方法为队列yyds的监听器，一旦监听到新的消息，就会接受并处理 public void test(Message message){ System.out.println(new String(message.getBody())); } } 接着我们启动服务器： 可以看到控制台成功输出了我们之前放入队列的消息，并且管理页面中也显示此消费者已经连接了： 接着我们再通过管理页面添加新的消息看看，也是可以正常进行接受的。 当然，如果我们需要确保消息能够被消费者接受并处理，然后得到消费者的反馈，也是可以的： @Test void publisher() { //会等待消费者消费然后返回响应结果 Object res = template.convertSendAndReceive(\"amq.direct\", \"my-yyds\", \"Hello World!\"); System.out.println(\"收到消费者响应：\"+res); } 消费者这边只需要返回一个对应的结果即可： @RabbitListener(queues = \"yyds\") public String receiver(String data){ System.out.println(\"一号消息队列监听器 \"+data); return \"收到!\"; } 测试没有问题： 那么如果我们需要直接接收一个JSON格式的消息，并且希望直接获取到实体类呢？ @Data public class User { int id; String name; } @Configuration public class RabbitConfiguration { ... @Bean(\"jacksonConverter\") //直接创建一个用于JSON转换的Bean public Jackson2JsonMessageConverter converter(){ return new Jackson2JsonMessageConverter(); } } 接着我们只需要指定转换器就可以了： @Component public class TestListener { //指定messageConverter为我们刚刚创建的Bean名称 @RabbitListener(queues = \"yyds\", messageConverter = \"jacksonConverter\") public void receiver(User user){ //直接接收User类型 System.out.println(user); } } 现在我们直接在管理页面发送： {\"id\":1,\"name\":\"LB\"} 可以看到成功完成了转换，并输出了用户信息： 同样的，我们也可以直接发送User，因为我们刚刚已经配置了Jackson2JsonMessageConverter为Bean，所以直接使用就可以了： @Test void publisher() { template.convertAndSend(\"amq.direct\", \"yyds\", new User()); } 可以看到后台的数据类型为： 这样，我们就通过SpringBoot实现了RabbitMQ的简单使用。 死信队列 消息队列中的数据，如果迟迟没有消费者来处理，那么就会一直占用消息队列的空间。比如我们模拟一下抢车票的场景，用户下单高铁票之后，会进行抢座，然后再进行付款，但是如果用户下单之后并没有及时的付款，这张票不可能一直让这个用户占用着，因为你不买别人还要买呢，所以会在一段时间后超时，让这张票可以继续被其他人购买。 这时，我们就可以使用死信队列，将那些用户超时未付款的或是用户主动取消的订单，进行进一步的处理，以下类型的消息都会被判定为死信： 消息被拒绝(basic.reject / basic.nack)，并且requeue = false 消息TTL过期 队列达到最大长度 那么如何构建这样的一种使用模式呢？实际上本质就是一个死信交换机+绑定的死信队列，当正常队列中的消息被判定为死信时，会被发送到对应的死信交换机，然后再通过交换机发送到死信队列中，死信队列也有对应的消费者去处理消息。 这里我们直接在配置类中创建一个新的死信交换机和死信队列，并进行绑定： @Configuration public class RabbitConfiguration { @Bean(\"directDlExchange\") public Exchange dlExchange(){ //创建一个新的死信交换机 return ExchangeBuilder.directExchange(\"dlx.direct\").build(); } @Bean(\"yydsDlQueue\") //创建一个新的死信队列 public Queue dlQueue(){ return QueueBuilder .nonDurable(\"dl-yyds\") .build(); } @Bean(\"dlBinding\") //死信交换机和死信队列进绑定 public Binding dlBinding(@Qualifier(\"directDlExchange\") Exchange exchange, @Qualifier(\"yydsDlQueue\") Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\"dl-yyds\") .noargs(); } ... @Bean(\"yydsQueue\") public Queue queue(){ return QueueBuilder .nonDurable(\"yyds\") .deadLetterExchange(\"dlx.direct\") //指定死信交换机 .deadLetterRoutingKey(\"dl-yyds\") //指定死信RoutingKey .build(); } ... } 接着我们将监听器修改为死信队列监听： @Component public class TestListener { @RabbitListener(queues = \"dl-yyds\", messageConverter = \"jacksonConverter\") public void receiver(User user){ System.out.println(user); } } 配置完成后，我们来尝试启动一下吧，注意启动之前记得把之前的队列给删了，这里要重新定义。 队列列表中已经出现了我们刚刚定义好的死信队列，并且yyds队列也支持死信队列发送功能了，现在我们尝试向此队列发送一个消息，但是我们将其拒绝： 可以看到拒绝后，如果不让消息重新排队，那么就会变成死信，直接被丢进死信队列中，可以看到在拒绝后： 现在我们来看看第二种情况，RabbitMQ支持将超过一定时间没被消费的消息自动删除，这需要消息队列设定TTL值，如果消息的存活时间超过了Time To Live值，就会被自动删除，自动删除后的消息如果有死信队列，那么就会进入到死信队列中。 现在我们将yyds消息队列设定TTL值（毫秒为单位）： @Bean(\"yydsQueue\") public Queue queue(){ return QueueBuilder .nonDurable(\"yyds\") .deadLetterExchange(\"dlx.direct\") .deadLetterRoutingKey(\"dl-yyds\") .ttl(5000) //如果5秒没处理，就自动删除 .build(); } 现在我们重启测试一下，注意修改了之后记得删除之前的yyds队列： 可以看到现在yyds队列已经具有TTL特性了，我们现在来插入一个新的消息： 可以看到消息5秒钟之后就不见了，而是被丢进了死信队列中。 最后我们来看一下当消息队列长度达到最大的情况，现在我们将消息队列的长度进行限制： @Bean(\"yydsQueue\") public Queue queue(){ return QueueBuilder .nonDurable(\"yyds\") .deadLetterExchange(\"dlx.direct\") .deadLetterRoutingKey(\"dl-yyds\") .maxLength(3) //将最大长度设定为3 .build(); } 现在我们重启一下，然后尝试连续插入4个消息： 可以看到yyds消息队列新增了Limit特性，也就是限定长度： @Test void publisher() { for (int i = 0; i 可以看到因为长度限制为3，所以有一个消息直接被丢进了死信队列中，为了能够更直观地观察消息队列的机制，我们为User类新增一个时间字段： @Data public class User { int id; String name; String date = new Date().toString(); } 接着每隔一秒钟插入一个： @Test void publisher() throws InterruptedException { for (int i = 0; i 再次进行上述实验，可以发现如果到达队列长度限制，那么每次插入都会把位于队首的消息丢进死信队列，来腾出空间给新来的消息。 工作队列模式 注意：XX模式只是一种设计思路，并不是指的具体的某种实现，可以理解为实现XX模式需要怎么去写。 前面我们了解了最简的一个消费者一个生产者的模式，接着我们来了解一下一个生产者多个消费者的情况： 实际上这种模式就非常适合多个工人等待新的任务到来的场景，我们的任务有很多个，一个一个丢进消息队列，而此时工人有很多个，那么我们就可以将这些任务分配个各个工人，让他们各自负责一些任务，并且做的快的工人还可以做完成一些（能者多劳）。 非常简单，我们只需要创建两个监听器即可： @Component public class TestListener { @RabbitListener(queues = \"yyds\") public void receiver(String data){ //这里直接接收String类型的数据 System.out.println(\"一号消息队列监听器 \"+data); } @RabbitListener(queues = \"yyds\") public void receiver2(String data){ System.out.println(\"二号消息队列监听器 \"+data); } } 可以看到我们发送消息时，会自动进行轮询分发： 那么如果我们一开始就在消息队列中放入一部分消息在开启消费者呢？ 可以看到，如果是一开始就存在消息，会被一个消费者一次性全部消耗，这是因为我们没有对消费者的Prefetch count（预获取数量，一次性获取消息的最大数量）进行限制，也就是说我们现在希望的是消费者一次只能拿一个消息，而不是将所有的消息全部都获取。 因此我们需要对这个数量进行一些配置，这里我们需要在配置类中定义一个自定义的ListenerContainerFactory，可以在这里设定消费者Channel的PrefetchCount的大小： @Resource private CachingConnectionFactory connectionFactory; @Bean(name = \"listenerContainer\") public SimpleRabbitListenerContainerFactory listenerContainer(){ SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setPrefetchCount(1); //将PrefetchCount设定为1表示一次只能取一个 return factory; } 接着我们在监听器这边指定即可： @Component public class TestListener { @RabbitListener(queues = \"yyds\", containerFactory = \"listenerContainer\") public void receiver(String data){ System.out.println(\"一号消息队列监听器 \"+data); } @RabbitListener(queues = \"yyds\", containerFactory = \"listenerContainer\") public void receiver2(String data){ System.out.println(\"二号消息队列监听器 \"+data); } } 现在我们再次启动服务器，可以看到PrefetchCount被限定为1了： 再次重复上述的实现，可以看到消息不会被一号消费者给全部抢走了： 当然除了去定义两个相同的监听器之外，我们也可以直接在注解中定义，比如我们现在需要10个同样的消费者： @Component public class TestListener { @RabbitListener(queues = \"yyds\", containerFactory = \"listenerContainer\", concurrency = \"10\") public void receiver(String data){ System.out.println(\"一号消息队列监听器 \"+data); } } 可以看到在管理页面中出现了10个消费者： 至此，有关工作队列模式就讲到这里。 发布订阅模式 前面我们已经了解了RabbitMQ客户端的一些基本操作，包括普通的消息模式，接着我们来了解一下其他的模式，首先是发布订阅模式，它支持多种方式： 比如我们在阿里云买了云服务器，但是最近快到期了，那么就会给你的手机、邮箱发送消息，告诉你需要去续费了，但是手机短信和邮件发送并不一定是同一个业务提供的，但是现在我们又希望能够都去执行，所以就可以用到发布订阅模式，简而言之就是，发布一次，消费多个。 实现这种模式其实也非常简单，但是如果使用我们之前的直连交换机，肯定是不行的，我们这里需要用到另一种类型的交换机，叫做fanout（扇出）类型，这时一种广播类型，消息会被广播到所有与此交换机绑定的消息队列中。 这里我们使用默认的交换机： 这个交换机是一个fanout类型的交换机，我们就是要它就行了： @Configuration public class RabbitConfiguration { @Bean(\"fanoutExchange\") public Exchange exchange(){ //注意这里是fanoutExchange return ExchangeBuilder.fanoutExchange(\"amq.fanout\").build(); } @Bean(\"yydsQueue1\") public Queue queue(){ return QueueBuilder.nonDurable(\"yyds1\").build(); } @Bean(\"binding\") public Binding binding(@Qualifier(\"fanoutExchange\") Exchange exchange, @Qualifier(\"yydsQueue1\") Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\"yyds1\") .noargs(); } @Bean(\"yydsQueue2\") public Queue queue2(){ return QueueBuilder.nonDurable(\"yyds2\").build(); } @Bean(\"binding2\") public Binding binding2(@Qualifier(\"fanoutExchange\") Exchange exchange, @Qualifier(\"yydsQueue2\") Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\"yyds2\") .noargs(); } } 这里我们将两个队列都绑定到此交换机上，我们先启动看看效果： 绑定没有什么问题，接着我们搞两个监听器，监听一下这两个队列： @Component public class TestListener { @RabbitListener(queues = \"yyds1\") public void receiver(String data){ System.out.println(\"一号消息队列监听器 \"+data); } @RabbitListener(queues = \"yyds2\") public void receiver2(String data){ System.out.println(\"二号消息队列监听器 \"+data); } } 现在我们通过交换机发送消息，看看是不是两个监听器都会接收到消息： 可以看到确实是两个消息队列都能够接受到此消息： 这样我们就实现了发布订阅模式。 路由模式 路由模式实际上我们一开始就已经实现了，我们可以在绑定时指定想要的routingKey只有生产者发送时指定了对应的routingKey才能到达对应的队列。 当然除了我们之前的一次绑定之外，同一个消息队列可以多次绑定到交换机，并且使用不同的routingKey，这样只要满足其中一个都可以被发送到此消息队列中： @Configuration public class RabbitConfiguration { @Bean(\"directExchange\") public Exchange exchange(){ return ExchangeBuilder.directExchange(\"amq.direct\").build(); } @Bean(\"yydsQueue\") public Queue queue(){ return QueueBuilder.nonDurable(\"yyds\").build(); } @Bean(\"binding\") //使用yyds1绑定 public Binding binding(@Qualifier(\"directExchange\") Exchange exchange, @Qualifier(\"yydsQueue\") Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\"yyds1\") .noargs(); } @Bean(\"binding2\") //使用yyds2绑定 public Binding binding2(@Qualifier(\"directExchange\") Exchange exchange, @Qualifier(\"yydsQueue\") Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\"yyds2\") .noargs(); } } 启动后我们可以看到管理面板中出现了两个绑定关系： 这里可以测试一下，随便使用哪个routingKey都可以。 主题模式 实际上这种模式就是一种模糊匹配的模式，我们可以将routingKey以模糊匹配的方式去进行转发。 我们可以使用*或#来表示： * - 表示任意的一个单词 # - 表示0个或多个单词 这里我们来测试一下： @Configuration public class RabbitConfiguration { @Bean(\"topicExchange\") //这里使用预置的Topic类型交换机 public Exchange exchange(){ return ExchangeBuilder.topicExchange(\"amq.topic\").build(); } @Bean(\"yydsQueue\") public Queue queue(){ return QueueBuilder.nonDurable(\"yyds\").build(); } @Bean(\"binding\") public Binding binding2(@Qualifier(\"topicExchange\") Exchange exchange, @Qualifier(\"yydsQueue\") Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\"*.test.*\") .noargs(); } } 启动项目，可以看到只要是满足通配符条件的都可以成功转发到对应的消息队列： 接着我们可以再试试看#通配符。 除了我们这里使用的默认主题交换机之外，还有一个叫做amq.rabbitmq.trace的交换机： 可以看到它也是topic类型的，那么这个交换机是做什么的呢？实际上这是用于帮助我们记录和追踪生产者和消费者使用消息队列的交换机，它是一个内部的交换机，那么如果使用呢？首先创建一个消息队列用于接收记录： 接着我们需要在控制台将虚拟主机/test的追踪功能开启： sudo rabbitmqctl trace_on -p /test 开启后，我们将此队列绑定到上面的交换机上： 由于发送到此交换机上的routingKey为routing key为 publish.交换机名称 和 deliver.队列名称，分别对应生产者投递到交换机的消息，和消费者从队列上获取的消息，因此这里使用#通配符进行绑定。 现在我们来测试一下，比如还是往yyds队列发送消息： 可以看到在发送消息，并且消费者已经处理之后，trace队列中新增了两条消息，那么我们来看看都是些什么消息： 通过追踪，我们可以很明确地得知消息发送的交换机、routingKey、用户等信息，包括信息本身，同样的，消费者在取出数据时也有记录： 我们可以明确消费者的地址、端口、具体操作的队列以及取出的消息信息等。 到这里，我们就已经了解了3种类型的交换机。 第四种交换机类型 通过前面的学习，我们已经介绍了三种交换机类型，现在我们来介绍一下第四种交换机类型header，它是根据头部信息来决定的，在我们发送的消息中是可以携带一些头部信息的（类似于HTTP），我们可以根据这些头部信息来决定路由到哪一个消息队列中。 @Configuration public class RabbitConfiguration { @Bean(\"headerExchange\") //注意这里返回的是HeadersExchange public HeadersExchange exchange(){ return ExchangeBuilder .headersExchange(\"amq.headers\") //RabbitMQ为我们预置了两个，这里用第一个就行 .build(); } @Bean(\"yydsQueue\") public Queue queue(){ return QueueBuilder.nonDurable(\"yyds\").build(); } @Bean(\"binding\") public Binding binding2(@Qualifier(\"headerExchange\") HeadersExchange exchange, //这里和上面一样的类型 @Qualifier(\"yydsQueue\") Queue queue){ return BindingBuilder .bind(queue) .to(exchange) //使用HeadersExchange的to方法，可以进行进一步配置 //.whereAny(\"a\", \"b\").exist(); 这个是只要存在任意一个指定的头部Key就行 //.whereAll(\"a\", \"b\").exist(); 这个是必须存在所有指定的的头部Key .where(\"test\").matches(\"hello\"); //比如我们现在需要消息的头部信息中包含test，并且值为hello才能转发给我们的消息队列 //.whereAny(Collections.singletonMap(\"test\", \"hello\")).match(); 传入Map也行，批量指定键值对 } } 现在我们来启动一下试试看： 结果发现，消息可以成功发送到消息队列，这就是使用头部信息进行路由。 这样，我们就介绍完了所有四种类型的交换机。 集群搭建 前面我们对于RabbitMQ的相关内容已经基本讲解完毕了，最后我们来尝试搭建一个集群，让RabbitMQ之间进行数据复制（镜像模式）稍微有点麻烦，跟着视频走吧。 可能会用到的一些命令： sudo rabbitmqctl stop_app sudo rabbitmqctl join_cluster rabbit@ubuntu-server sudo rabbitmqctl start_app 实现复制即可。 SpringCloud 消息组件 前面我们已经学习了如何使用RabbitMQ消息队列，接着我们来简单介绍一下SpringCloud为我们提供的一些消息组件。 SpringCloud Stream 官方文档：https://docs.spring.io/spring-cloud-stream/docs/3.2.2/reference/html/ 前面我们介绍了RabbitMQ，了解了消息队列相关的一些操作，但是可能我们会遇到不同的系统在用不同的消息队列，比如系统A用的Kafka、系统B用的RabbitMQ，但是我们现在又没有学习过Kafka，那么怎么办呢？有没有一种方式像JDBC一样，我们只需要关心SQL和业务本身，而不用关心数据库的具体实现呢？ SpringCloud Stream能够做到，它能够屏蔽底层实现，我们使用统一的消息队列操作方式就能操作多种不同类型的消息队列。 它屏蔽了RabbitMQ底层操作，让我们使用统一的Input和Output形式，以Binder为中间件，这样就算我们切换了不同的消息队列，也无需修改代码，而具体某种消息队列的底层实现是交给Stream在做的。 这里我们创建一个新的项目来测试一下： 依赖如下： org.springframework.cloud spring-cloud-dependencies 2021.0.1 pom import org.springframework.cloud spring-cloud-starter-stream-rabbit org.springframework.boot spring-boot-starter-web 首先我们来编写一下生产者，首先是配置文件： server: port: 8001 spring: cloud: stream: binders: #此处配置要绑定的rabbitmq的服务信息 local-server: #绑定名称，随便起一个就行 type: rabbit #消息组件类型，这里使用的是RabbitMQ，就填写rabbit environment: #服务器相关信息，按照下面的方式填写就行，爆红别管 spring: rabbitmq: host: 192.168.0.6 port: 5672 username: admin password: admin virtual-host: /test bindings: test-out-0: destination: test.exchange 接着我们来编写一个Controller，一会访问一次这个接口，就向消息队列发送一个数据： @RestController public class PublishController { @Resource StreamBridge bridge; //通过bridge来发送消息 @RequestMapping(\"/publish\") public String publish(){ //第一个参数其实就是RabbitMQ的交换机名称（数据会发送给这个交换机，到达哪个消息队列，不由我们决定） //这个交换机的命名稍微有一些规则: //输入: + -in- + //输出: + -out- + //这里我们使用输出的方式，来将数据发送到消息队列，注意这里的名称会和之后的消费者Bean名称进行对应 bridge.send(\"test-out-0\", \"HelloWorld!\"); return \"消息发送成功！\"+new Date(); } } 现在我们来将生产者启动一下，访问一下接口： 可以看到消息成功发送，我们来看看RabbitMQ这边的情况： 新增了一个test-in-0交换机，并且此交换机是topic类型的： 但是目前没有任何队列绑定到此交换机上，因此我们刚刚发送的消息实际上是没有给到任何队列的。 接着我们来编写一下消费者，消费者的编写方式比较特别，只需要定义一个Consumer就可以了，其他配置保持一致： @Component public class ConsumerComponent { @Bean(\"test\") //注意这里需要填写我们前面交换机名称中\"名称\"，这样生产者发送的数据才会正确到达 public Consumer consumer(){ return System.out::println; } } 配置中需要修改一下目标交换机： server: port: 8002 spring: cloud: stream: ... bindings: #因为消费者是输入，默认名称为 方法名-in-index，这里我们将其指定为我们刚刚定义的交换机 test-in-0: destination: test.exchange 接着我们直接启动就可以了，可以看到启动之后，自动为我们创建了一个新的队列： 而这个队列实际上就是我们消费者等待数据到达的队列： 可以看到当前队列直接绑定到了我们刚刚创建的交换机上，并且routingKey是直接写的#，也就是说一会消息会直接过来。 现在我们再来访问一些消息发送接口： 可以看到消费者成功地进行消费了： 这样，我们就通过使用SpringCloud Stream来屏蔽掉底层RabbitMQ来直接进行消息的操作了。 SpringCloud Bus 官方文档：https://cloud.spring.io/spring-cloud-bus/reference/html/ 实际上它就相当于是一个消息总线，可用于向各个服务广播某些状态的更改（比如云端配置更改，可以结合Config组件实现动态更新配置，当然我们前面学习的Nacos其实已经包含这个功能了）或其他管理指令。 这里我们也是简单使用一下吧，Bus需要基于一个具体的消息队列实现，比如RabbitMQ或是Kafka，这里我们依然使用RabbitMQ。 我们将最开始的微服务拆分项目继续使用，比如现在我们希望借阅服务的某个接口调用时，能够给用户服务和图书服务发送一个通知，首先是依赖： org.springframework.cloud spring-cloud-starter-bus-amqp org.springframework.boot spring-boot-starter-actuator 接着我们只需要在配置文件中将RabbitMQ的相关信息配置： spring: rabbitmq: addresses: 192.168.0.6 username: admin password: admin virtual-host: /test management: endpoints: web: exposure: include: \"*\" #暴露端点，一会用于提醒刷新 然后启动我们的三个服务器，可以看到在管理面板中： 新增了springCloudBug这样一个交换机，并且： 自动生成了各自的消息队列，这样就可以监听并接收到消息了。 现在我们访问一个端口： 此端口是用于通知别人进行刷新，可以看到调用之后，消息队列中成功出现了一次消费： 现在我们结合之前使用的Config配置中心，来看看是不是可以做到通知之后所有的配置动态刷新了。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/SpringCloud（四）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/SpringCloud/SpringCloud（四）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/算法/":{"url":"Java/算法/","title":"算法","keywords":"","body":"window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/README.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/README.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/算法/数据结构与算法（一）.html":{"url":"Java/算法/数据结构与算法（一）.html","title":"数据结构与算法（一）","keywords":"","body":" 线性结构篇 注意：开始本篇学习之前，请确保你完成了 C语言程序设计 篇视频教程，否则无法进行学习。 我们本系列课程分为基础知识和算法实战两部分，其中算法实战在LeetCode上进行：https://leetcode.cn/，各位可以提前在平台上注册好相关账号。 学习完数据结构，各位小伙伴可以尝试参加算法相关的学科竞赛，如ICPC-ACM、蓝桥杯等，算法类的比赛含金量相比项目类比赛更高，也更有价值，相应的，算法类竞赛难道会更大一些，尤其是ICPC-ACM大学生程序设计竞赛，一般都是各个高校内顶尖级队伍进行参赛，甚至还有中学队伍（这类学生预定清华、北大），因为算法更加考验个人的思维能力和天赋水平，相比其他计算机基础课程，数据结构和算法是难度最高的，也是各大高校考研的重点内容。 不过虽然很难，并且考验个人天赋，但是大部分人通过努力学习是完全能够掌握基础部分的，在应对80%的题目时，是完全有机会解决的，所以，不要怀疑自己，说不定你就是下一个大佬。 这里也说一下面试推荐书籍，内含多种常用算法以及解题分析，值得一看： 本篇内容虽然继续以C语言为基础进行讲解，但是将不再涉及到C语言的语言层面相关内容，更多的是数据结构和算法的思想，实际上用任意一种语言都可以实现。 什么是数据结构与算法 回顾我们之前的C语言程序设计阶段，我们已经接触过基本数据类型，并且能够使用结构体对数据进行组织，我们可以很轻松地使用一个结构体来存放一个学生的完整数据，在数据结构学习阶段，我们还会进一步地研究。 数据结构 那么，我们来看看，什么是数据结构呢？ 数据结构(data structure)是带有结构特性的数据元素的集合，它研究的是数据的逻辑结构和数据的物理结构以及它们之间的相互关系。 比如现在我们需要保存100个学生的数据，那么你首先想到的肯定是使用数组吧！没错，没有什么比数组更适合存放这100个学生的数据了，但是如果我们现在有了新的需求呢？我们不仅仅是存放这些数据，我们还希望能够将这些数据按顺序存放，支持在某个位置插入一条数据、删除一条数据、修改一条数据等，这时候，数组就显得有些乏力了。 我们需要一种更好的数据表示和组织方式，才能做到类似于增删改查这样的操作，而完成这些操作所用到的方法，我们称其为“算法”，所以数据结构和算法，一般是放在一起进行讲解的。 算法 比如现在我们希望你求出1-100所有数字的和，请通过程序来实现： int main() { int sum = 0; for (int i = 1; i 我们很容易就能编写出这样的程序，实际上只需要一个for循环就能搞定了，而这就是我们设计的算法。 在之前的C语言程序设计阶段，我们其实已经学习了许多算法，包括排序算法、动态规划等。 当然，解决问题的算法并不是只有一种，实际上我们上面的方式并不是最优的算法，如果想要求得某一段整数的和，其实使用高斯求和公式能够瞬间得到结果： $$ \\sum=\\frac{(首项+末项)\\times项数}{2} $$ 所以，我们完全没必要循环那么多次进行累加计算，而是直接使用数学公式： int main() { printf(\"%d\", (1 + 100) * 100 / 2); } 所以，算法的尽头还得是数学啊。 可见，不同的算法，执行的效率也是有很大差别的，这里我们就要提到算法的复杂度了。衡量一个算法的复杂程度需要用到以下两个指标： 时间复杂度T(n)：算法程序在执行时消耗的时间长度，一般与输入数据的规模n有关。 空间复杂度S(n)：算法程序在执行时占用的存储单元长度，同样与数据的输入规模n有关，大部分情况下，我们都是采取空间换时间的算法。 比如我们上面的两种算法，第一种需要执行n次循环，每轮循环进行一次累加操作，而第二种只需要进行一次计算即可。实际中我们计算时间复杂度时，其实并不一定要计算精确的执行次数，而只需要大概执行次数，那么这里我们使用O渐进表示法。 大O符号（Big O notation）：是用于描述函数渐进行为的数学符号。 而这里的循环次数，实际上就是我们需要知道的大致执行次数，所以第一种算法的时间复杂度为：O(n)，其中n就是项数，因为它需要执行n次计算才能得到最后的结果。而第二种算法的时间复杂度为：O(1)，因为它只需要执行一次计算（更准确的说它的执行次数是一个常数，跟项数n毫无关系），显然，当n变得非常大时，第二种方法的计算速度远超第一种。 再比如我们之前使用的冒泡排序算法，需要进行两轮循环，而循环的次数在经过优化之后为(n - 1)(n - 1)/2，得到的结果中包含了一个n的平方，此时这种算法的时间复杂度就来到O(n^2)了。 在不同的空间复杂度下，可能n小的时候还没什么感觉，但是当n变得非常大时，差距就不是一点半点了，我们来看看常用函数的增长曲线： 所以我们在设计算法的时候，一定要考虑到时间和空间复杂度的问题，这里列出常用函数的增长表： 函数 类型 解释 $\\Omicron(1)$ 常数阶 如果算法能够优化到这个程度，那么基本上算是最快的算法了。 $\\Omicron(\\log_{2}n)$ 对数阶 仅次于常数阶的速度，我们后面会介绍的二分搜索算法，就能够到达这个级别。 $\\Omicron(n)$ 线性阶 我们后面介绍的线性表插入、删除数据，包括动态规划类算法能够达到线性阶。 $\\Omicron(n\\log_{2}n)$ 线性对数阶 相当于在对数阶算法外层套了一层线性阶循环。 $\\Omicron(n^2)$ 平方阶 我们前面学习的冒泡排序，需要进行两重循环，实际上就是平方阶。 $\\Omicron(n^3)$ 立方阶 从立方阶开始，时间复杂度就开始变得有点大了。 $\\Omicron(2^n)$ 指数阶 我们前面介绍的斐波那契数列递归算法，就是一个指数阶的算法，因为它包含大量的重复计算。 $\\Omicron(n!)$ 阶乘 这个增长速度比指数阶还恐怖，但是一般很少有算法能达到这个等级。 我们在编写算法时，一定要注意算法的时间复杂度，当时间复杂度太大时，可能计算机就很难在短时间内计算出结果了。 案例：二分搜索算法 现在有一个从小到大排序的数组，给你一个目标值target，现在请你找到这个值在数组中的对应下标，如果没有，请返回-1： int search(int* nums, int numsSize, int target){ //请实现查找算法 } int main() { int arr[] = {1, 3, 4, 6, 7,8, 10, 11, 13, 15}, target = 3; printf(\"%d\", search(arr, 10, target)); } 此时，最简单的方法就是将数组中的元素一个一个进行遍历，总有一个是，如果遍历完后一个都没有，那么就结束： int search(int* nums, int numsSize, int target){ for (int i = 0; i 虽然这样的算法简单粗暴，但是并不是最好的，我们需要遍历n次才能得到结果，时间复杂度为$\\Omicron(n)$，我们可以尝试将其优化到更低的时间复杂度。这里我们利用它有序的特性，实际上当我们查找到大于目标target的数时，就没必要继续寻找了： int search(int* nums, int numsSize, int target){ for (int i = 0; i target) break; } return -1; } 这样循环进行的次数也许就会减小了，但是如果我们要寻找的目标target刚好是最后几个元素呢？这时时间复杂度又来到到了$\\Omicron(n)$，那么有没有更好的办法呢？我们依然可以继续利用数组有序的特性，既然是有序的，那么我们不妨随机在数组中找一个数，如果这个数大于目标，那么就不再考虑右边的部分，如果小于目标，那么就考虑左边的部分，然后继续在另一部分中再次随机找一个数，这样每次都能将范围缩小，直到找到为止（其思想就比较类似于牛顿迭代法，再次强调数学的重要性） 而二分思想就是将一个有序数组不断进行平分，直到找到为止，这样我们每次寻找的范围会不断除以2，所以查找的时间复杂度就降到了$\\Omicron(\\log_{2}n)$，相比一个一个比较，效率就高了不少： 好了，那么现在我们就可以利用这种思想，编写出二分搜索算法了，因为每一轮都在进行同样的搜索操作，只是范围不一样，所以这里直接采用递归分治算法： int binarySearch(int * nums, int target, int left, int right){ //left代表左边界，right代表右边界 if(left > right) return -1; //如果左边大于右边，那么肯定就找完了，所以直接返回 int mid = (left + right) / 2; //这里计算出中间位置 if(nums[mid] == target) return mid; //直接比较，如果相等就返回下标 if(nums[mid] > target) //这里就是大于或小于的情况了，这里mid+1和mid-1很多人不理解，实际上就是在下一次寻找中不算上当前的mid，因为这里已经比较过了，所以说左边就-1，右边就+1 return binarySearch(nums, target, left, mid - 1); //如果大于，那么说明肯定不在右边，直接去左边找 else return binarySearch(nums, target, mid + 1, right); //如果小于，那么说明肯定不在左边，直接去右边找 } int search(int* nums, int numsSize, int target){ return binarySearch(nums, target, 0, numsSize - 1); } 当然也可以使用while循环来实现二分搜索，如果需要验证自己的代码是否有问题，可以直接在力扣上提交代码：https://leetcode.cn/problems/binary-search/ 线性表 那么作为数据结构的开篇，我们就从最简单的线性表开始介绍。 还记得我们开篇提了一个问题吗？ 我们还希望能够将这些数据按顺序存放，支持在某个位置插入一条数据、删除一条数据、修改一条数据等，这时候，数组就显得有些乏力了。 数组无法做到这么高级的功能，那么我们就需要定义一种更加高级的数据结构来做到，我们可以使用线性表（Linear List） 线性表是由同一类型的数据元素构成的有序序列的线性结构。线性表中元素的个数就是线性表的长度，表的起始位置称为表头，表的结束位置称为表尾，当一个线性表中没有元素时，称为空表。 线性表一般需要包含以下功能： 初始化线性表：将一个线性表进行初始化，得到一个全新的线性表。 获取指定位置上的元素：直接获取线性表指定位置i上的元素。 获取元素的位置：获取某个元素在线性表上的位置i。 插入元素：在指定位置i上插入一个元素。 删除元素：删除指定位置i上的一个元素。 获取长度：返回线性表的长度。 也就是说，现在我们需要设计的是一种功能完善的表结构，它不像是数组那么低级，而是真正意义上的表： 简单来说它就是列表，比如我们的菜单，我们在点菜时就需要往菜单列表中添加菜品或是删除菜品，这时列表就很有用了，因为数组长度固定、操作简单，而我们添加菜品、删除菜品这些操作又要求长度动态变化、操作多样。 那么，如此高级的数据结构，我们该如何去实现呢？实现线性表的结构一般有两种，一种是顺序存储实现，还有一种是链式存储实现，我们先来看第一种，也是最简单的的一种。 顺序表 前面我们说到，既然数组无法实现这样的高级表结构，那么我就基于数组，对其进行强化，也就是说，我们存放数据还是使用数组，但是我们可以为其编写一些额外的操作来强化为线性表，像这样底层依然采用顺序存储实现的线性表，我们称为顺序表。 这里我们可以先定义一个新的结构体类型，将一些需要用到的数据保存在一起，这里我们以int类型的线性表为例： typedef int E; //这里我们的元素类型就用int为例吧，先起个别名 struct List { E array[10]; //实现顺序表的底层数组 int capacity; //表示底层数组的容量 }; 为了一会使用方便，我们可以给其起一个别名： typedef struct List * ArrayList; //因为是数组实现，所以就叫ArrayList，这里直接将List的指针起别名 然后我们就可以开始编写第一个初始化操作了： void initList(ArrayList list){ list->capacity = 10; //直接将数组的容量设定为10即可 } 但是我们发现一个问题，这样的话我们的顺序表长度不就是固定为10的了吗？而前面我们线性表要求的是长度是动态增长的，那么这个时候怎么办呢？我们可以直接使用一个指针来指向底层数组的内存区域，当装不下的时候，我们可以创建一个新的更大的内存空间来存放数据，这样就可以实现扩容了，所以我们来修改一下： struct List { E * array; //指向顺序表的底层数组 int capacity; //数组的容量 }; 接着我们修改一下初始化函数： void initList(ArrayList list){ //这里就默认所有的顺序表初始大小都为10吧，随意 list->array = malloc(sizeof(E) * 10); //使用malloc函数申请10个int大小的内存空间，作为底层数组使用 list->capacity = 10; //容量同样设定为10 } 但是还没完，因为我们的表里面，默认情况下是没有任何元素的，我们还需要一个变量来表示当前表中的元素数量： struct List { E * array; //指向顺序表的底层数组 int capacity; //数组的容量 int size; //表中的元素数量 }; typedef struct List * ArrayList; void initList(ArrayList list){ //这里就默认所有的顺序表初始大小都为10吧，随意 list->array = malloc(sizeof(int) * 10); //使用malloc函数申请10个int大小的内存空间，作为底层数组使用 list->capacity = 10; //容量同样设定为10 list->size = 0; //元素数量默认为0 } 还有一种情况我们需要考虑，也就是说如果申请内存空间失败，那么需要返回一个结果告诉调用者： _Bool initList(ArrayList list){ list->array = malloc(sizeof(int) * 10); if(list->array == NULL) return 0; //需要判断如果申请的结果为NULL的话表示内存空间申请失败 list->capacity = 10; list->size = 0; return 1; //正常情况下返回true也就是1 } 这样，一个比较简单的顺序表就定义好，我们可以通过initList函数对其进行初始化： int main() { struct List list; //创建新的结构体变量 if(initList(&list)){ //对其进行初始化，如果失败就直接结束 ... } else{ printf(\"顺序表初始化失败，无法启动程序！\"); } } 接着我们来编写一下插入和删除操作，对新手来说也是比较难以理解的操作： 我们先设计好对应的函数： void insertList(ArrayList list, E element, int index){ //list就是待操作的表，element就是需要插入的元素，index就是插入的位置（注意顺序表的index是按位序计算的，从1开始，一般都是第index个元素） } 我们按照上面的思路来编写一下代码： void insertList(ArrayList list, E element, int index){ for (int i = list->size; i > index - 1; i--) //先使用for循环将待插入位置后续的元素全部丢到后一位 list->array[i] = list->array[i - 1]; list->array[index - 1] = element; //挪完之后，位置就腾出来了，直接设定即可 list->size++; //别忘了插入之后相当于多了一个元素，记得size + 1 } 现在我们可以来测试一下了： void printList(ArrayList list){ //编写一个函数用于打印表当前的数据 for (int i = 0; i size; ++i) //表里面每个元素都拿出来打印一次 printf(\"%d \", list->array[i]); printf(\"\\n\"); } int main() { struct List list; if(initList(&list)){ insertList(&list, 666, 1); //每次插入操作后都打印一下表，看看当前的情况 printList(&list); insertList(&list, 777, 1); printList(&list); insertList(&list, 888, 2); printList(&list); } else{ printf(\"顺序表初始化失败，无法启动程序！\"); } } 运行结果如下： 虽然这样看起来没什么问题了，但是如果我们在非法的位置插入元素会出现问题： insertList(&list, 666, -1); //第一个位置就是0，怎么可能插入到-1这个位置呢，这样肯定是不正确的，所以我们需要进行判断 printList(&list); 我们需要检查一下插入的位置是否合法： 转换成位序，也就是[1, size + 1]这个闭区间，所以我们在一开始的时候进行判断： _Bool insertList(ArrayList list, E element, int index){ if(index list->size + 1) return 0; //如果在非法位置插入，返回0表示插入操作执行失败 for (int i = list->size; i > index - 1; i--) list->array[i] = list->array[i - 1]; list->array[index - 1] = element; list->size++; return 1; //正常情况返回1 } 我们可以再来测试一下： if(insertList(&list, 666, -1)){ printList(&list); } else{ printf(\"插入失败！\"); } 不过我们还是没有考虑到一个情况，那么就是如果我们的表已经装满了，也就是说size已经达到申请的内存空间最大的大小了，那么此时我们就需要考虑进行扩容了，否则就没办法插入新的元素了： _Bool insertList(ArrayList list, E element, int index){ if(index list->size + 1) return 0; if(list->size == list->capacity) { //如果size已经到达最大的容量了，肯定是插不进了，那么此时就需要扩容了 int newCapacity = list->capacity + (list->capacity >> 1); //我们先计算一下新的容量大小，这里我取1.5倍原长度，当然你们也可以想扩多少扩多少 E * newArray = realloc(list->array, sizeof(E) * newCapacity); //这里我们使用新的函数realloc重新申请更大的内存空间 if(newArray == NULL) return 0; //如果申请失败，那么就确实没办法插入了，只能返回0表示插入失败了 list->array = newArray; list->capacity = newCapacity; } for (int i = list->size; i > index - 1; i--) list->array[i] = list->array[i - 1]; list->array[index - 1] = element; list->size++; return 1; } realloc函数可以做到控制动态内存开辟的大小，重新申请的内存空间大小就是我们指定的新的大小，并且原有的数据也会放到新申请的空间中，所以非常方便。当然如果因为内存不足之类的原因导致内存空间申请失败，那么会返回NULL，所以别忘了进行判断。 这样，我们的插入操作就编写完善了，我们可以来测试一下： int main() { struct List list; if(initList(&list)){ for (int i = 0; i 成功得到结果： 这样，我们就完成了顺序表的插入操作，接着我们来编写一下删除操作，其实删除操作也比较类似，也需要对元素进行批量移动，但是我们不需要考虑扩容问题，我们先设计好函数： void deleteList(ArrayList list, int index){ //list就是待操作的表，index是要删除的元素位序 } 按照我们上面插入的思路，我们反过来想一想然后实现删除呢？首先是删除的范围： 换算成位序就是[1, size]这个闭区间内容，所以我们先来限定一下合法范围： _Bool deleteList(ArrayList list, int index){ if(index list->size) return 0; return 1; //正常情况返回1 } 接着就是删除元素之后，我们还需要做什么呢？我们应该将删除的这个元素后面的全部元素前移一位： 我们按照这个思路，来编写一下删除操作： _Bool deleteList(ArrayList list, int index){ if(index list->size) return 0; for (int i = index - 1; i size - 1; ++i) list->array[i] = list->array[i + 1]; //实际上只需要依次把后面的元素覆盖到前一个即可 list->size--; //最后别忘了size - 1 return 1; } 删除相比插入要简单一些，我们来测试一下吧： for (int i = 0; i 成功得到结果： OK，那么插入和删除操作我们就成功完成了，还有一些比较简单的功能，我们这里也来依次实现一下，首先是获取长度： int sizeList(ArrayList list){ return list->size; //直接返回size就完事 } 接着是按位置获取元素和查找指定元素的位置： E * getList(ArrayList list, int index){ if(index list->size) return NULL; //如果超出范围就返回NULL return &list->array[index - 1]; } int findList(ArrayList list, E element){ for (int i = 0; i size; ++i) { //一直遍历，如果找到那就返回位序 if(list->array[i] == element) return i + 1; } return -1; //如果遍历完了都没找到，那么就返回-1 } 这样，我们的线性表就实现完成了，完整代码如下： #include #include typedef int E; struct List { E * array; int capacity; int size; }; typedef struct List * ArrayList; _Bool initList(ArrayList list){ list->array = malloc(sizeof(E) * 10); if(list->array == NULL) return 0; list->capacity = 10; list->size = 0; return 1; } _Bool insertList(ArrayList list, E element, int index){ if(index list->size + 1) return 0; if(list->size == list->capacity) { int newCapacity = list->capacity + (list->capacity >> 1); E * newArray = realloc(list->array, newCapacity * sizeof(E)); if(newArray == NULL) return 0; list->array = newArray; list->capacity = newCapacity; } for (int i = list->size; i > index - 1; --i) list->array[i] = list->array[i - 1]; list->array[index - 1] = element; list->size++; return 1; } _Bool deleteList(ArrayList list, int index){ if(index list->size) return 0; for (int i = index - 1; i size - 1; ++i) list->array[i] = list->array[i + 1]; list->size--; return 1; } int sizeList(ArrayList list){ return list->size; } E * getList(ArrayList list, int index){ if(index list->size) return NULL; return &list->array[index - 1]; } int findList(ArrayList list, E element){ for (int i = 0; i size; ++i) { if(list->array[i] == element) return i + 1; } return -1; } 问题：请问顺序实现的线性表，插入、删除、获取元素操作的时间复杂度为？ 插入：因为要将后续所有元素都向后移动，所以平均时间复杂度为$O(n)$ 删除：同上，因为要将所有元素向前移动，所以平均时间复杂度为$O(n)$ 获取元素：因为可以利用数组特性直接通过下标访问到对应元素，所以时间复杂度为$O(1)$ 顺序表习题： 在一个长度为n的顺序表中，向第i个元素前插入一个新的元素时，需要向后移动多少个元素？ A. n - i B. n - i + 1 C. n - i - 1 D. i 注意这里要求的是向第i个元素前插入（第i个表示的是位序，不是下标，不要搞混了，第1个元素下标就为0），这里我们假设n为3，i为2，那么也就是说要在下标为1的这个位置上插入元素，那么就需要移动后面的2个元素，所以答案是B 顺序表是一种（ ）的存储结构？ A. 随机存取 B. 顺序存取 C. 索引存取 D. 散列存取 首先顺序表底层是基于数组实现的，那么它肯定是支持随机访问的，因为我们可以直接使用下标想访问哪一个就访问哪一个，所以选择A，不要看到名字叫做顺序表就选择顺序存取，因为它并不需要按照顺序来进行存取，链表才是。这里也没有建立索引去访问元素，也更不可能是散列存取了，散列存取我们会在后面的哈希表中进行介绍 链表 前面我们介绍了如何使用数组实现线性表，我们接着来看第二种方式，我们可以使用链表来实现，那么什么是链表呢？ 链表不同于顺序表，顺序表底层采用数组作为存储容器，需要分配一块连续且完整的内存空间进行使用，而链表则不需要，它通过一个指针来连接各个分散的结点，形成了一个链状的结构，每个结点存放一个元素，以及一个指向下一个结点的指针，通过这样一个一个相连，最后形成了链表。它不需要申请连续的空间，只需要按照顺序连接即可，虽然物理上可能不相邻，但是在逻辑上依然是每个元素相邻存放的，这样的结构叫做链表（单链表）。 链表分为带头结点的链表和不带头结点的链表，戴头结点的链表就是会有一个头结点指向后续的整个链表，但是头结点不存放数据： 而不带头结点的链表就像上面那样，第一个节点就是存放数据的结点，一般设计链表都会采用带头结点的结构，因为操作更加方便。 那么我们就来尝试编写一个带头结点的链表： typedef int E; //这个还是老样子 struct ListNode { E element; //保存当前元素 struct ListNode * next; //指向下一个结点的指针 }; typedef struct Node * Node; //这里我们直接为结点指针起别名，可以直接作为表实现 同样的，我们先将初始化函数写好： void initList(Node head){ head->next = NULL; //头结点默认下一个为NULL } int main() { struct ListNode head; //这里创建一个新的头结点，头结点不存放任何元素，只做连接，连接整个链表 initList(&head); //先进行初始化 } 接着我们来设计一下链表的插入和删除，我们前面实现了顺序表的插入，那么链表的插入该怎么做呢？ 我们可以先修改新插入的结点的后继结点（也就是下一个结点）指向，指向原本在这个位置的结点： 接着我们可以将前驱结点（也就是上一个结点）的后继结点指向修改为我们新插入的结点： 这样，我们就成功插入了一个新的结点，现在新插入的结点到达了原本的第二个位置上： 按照这个思路，我们来实现一下，首先设计一下函数： void insertList(Node head, E element, int index){ //head是头结点，element为待插入元素，index是待插入下标 } 接着我们需要先找到待插入位置的前驱结点： _Bool insertList(Node head, E element, int index){ if(index next; //正常情况下继续向后找 if(head == NULL) return 0; //如果在寻找的过程中发型已经没有后续结点了，那么说明index超出可插入的范围了，也是非法的，直接润 } return 1; } 在循环操作完成后，如果没问题那么会找到对应插入位置的前驱结点，我们只需要按照上面分析的操作来编写代码即可： _Bool insertList(Node head, E element, int index){ if(index next; if(head == NULL) return 0; } Node node = malloc(sizeof (struct ListNode)); if(node == NULL) return 0; //创建一个新的结点，如果内存空间申请失败返回0 node->element = element; //将元素保存到新创建的结点中 node->next = head->next; //先让新插入的节点指向原本位置上的这个结点 head->next = node; //接着将前驱结点指向新的这个结点 return 1; } 这样，我们就编写好了链表的插入操作了，我们可以来测试一下： void printList(Node head){ while (head->next) { head = head->next; printf(\"%d \", head->element); //因为头结点不存放数据，所以从第二个开始打印 } } int main() { struct ListNode head; initList(&head); for (int i = 0; i 成功得到结果： 那么链表的插入我们研究完了，接着就是结点的删除了，那么我们如何实现删除操作呢？实际上也会更简单一些，我们可以直接将待删除节点的前驱结点指向修改为待删除节点的下一个： 这样，在逻辑上来说，待删除结点其实已经不在链表中了，所以我们只需要释放掉待删除结点占用的内存空间就行了： 那么我们就按照这个思路来编写一下程序，首先还是设计函数： void deleteList(Node head, int index){ //head就是头结点，index依然是待删除的结点位序 } 首先我们还是需要找到待删除结点的前驱结点： _Bool deleteList(Node head, int index){ if(index next; if(head == NULL) return 0; } if(head->next == NULL) return 0; //注意删除的范围，如果前驱结点的下一个已经是NULL了，那么也说明超过了范围 return 1; } 最后就是按照我们上面说的删除结点了： _Bool deleteList(Node head, int index){ if(index next; if(head == NULL) return 0; } if(head->next == NULL) return 0; Node tmp = head->next; //先拿到待删除结点 head->next = head->next->next; //直接让前驱结点指向下一个的下一个结点 free(tmp); //最后使用free函数释放掉待删除结点的内存 return 1; } 这样，我们就成功完成了链表的删除操作： int main() { struct ListNode head; initList(&head); for (int i = 0; i 最后得到结果也是正确的： 接着就是链表的一些其他操作了，这里我们也来实现一下，首先是获取对应位置上的元素： E * getList(Node head, int index){ if(index next; //因为不算头结点，所以使用do-while语句 if(head == NULL) return NULL; //如果已经超出长度那肯定也不行 } while (--index); //到达index就结束 return &head->element; } 接着是查找对应元素的位置： int findList(Node head, E element){ head = head->next; //先走到第一个结点 int i = 1; //计数器 while (head) { if(head->element == element) return i; //如果找到，那么就返回i head = head->next; //没找到就继续向后看 i++; //i记住要自增 } return -1; //都已经走到链表尾部了，那么就确实没找到了，返回-1 } 接着是求链表的长度，这个太简单了： int sizeList(Node head){ int i = 0; //从0开始 while (head->next) { //如果下一个为NULL那就停止 head = head->next; i++; //每向后找一个就+1 } return i; } 这样，我们的链表就编写完成了，整个代码如下： #include #include typedef int E; struct ListNode { E element; struct ListNode * next; }; typedef struct ListNode * Node; void initList(Node node){ node->next = NULL; } _Bool insertList(Node head, E element, int index){ if(index next; if(head == NULL) return 0; } Node node = malloc(sizeof(struct ListNode)); if(node == NULL) return 0; node->element = element; node->next = head->next; head->next = node; return 1; } _Bool deleteList(Node head, int index){ if(index next; if(head == NULL) return 0; } if(head->next == NULL) return 0; Node tmp = head->next; head->next = head->next->next; free(tmp); return 1; } E * getList(Node head, int index){ if(index next; if(head == NULL) return 0; } while (--index); return &head->element; } int findList(Node head, E element){ head = head->next; int i = 1; while (head) { if(head->element == element) return i; head = head->next; i++; } return -1; } int sizeList(Node head){ int i = -1; while (head) { head = head->next; i++; } return i; } 问题：请问链式实现的线性表，插入、删除、获取元素操作的时间复杂度为？ 插入：因为要寻找对应位置的前驱结点，所以平均时间复杂度为$O(n)$，但是不需要做任何的移动操作，效率肯定是比顺序表要高的。 删除：同上，所以平均时间复杂度为$O(n)$ 获取元素：由于必须要挨个向后寻找，才能找到对应的结点，所以时间复杂度为$O(n)$，不支持随机访问，只能顺序访问，比顺序表慢。 问题：什么情况下使用顺序表，什么情况下使用链表呢？ 通过分析顺序表和链表的特性我们不难发现，链表在随机访问元素时，需要通过遍历来完成，而顺序表则利用数组的特性直接访问得到，所以，当我们读取数据多于插入或是删除数据的情况下时，使用顺序表会更好。 而顺序表在插入元素时就显得有些鸡肋了，因为需要移动后续元素，整个移动操作会浪费时间，而链表则不需要，只需要修改结点 指向即可完成插入，所以在频繁出现插入或删除的情况下，使用链表会更好。 链表练习题： 在一个长度为n (n>1)的单链表上，设有头和尾两个指针，执行（ ）操作与链表的长度有关？ A．删除单链表中的第一个元素 B．删除单链表中的最后一个元素 C．在单链表第一个元素前插入一个新元素 D．在单链表最后一个元素后插入一个新元素 注意题干，现在有指向链表头尾的两个指针，那么A、C肯定是可以直接通过头结点找到的，无论链表长度如何都不影响，D也可以直接通过尾指针进行拼接，只有B需要尾指针的前驱结点，此时只能从头开始遍历得到，所以选择B 在一个单链表HL中（HL为头结点指针），若要向表头插入一个由指针p指向的结点，则执行？ A． HL＝p; p->next＝HL; B． p->next＝HL; HL＝p; C． p->next＝HL; p＝HL; D． p->next＝HL->next; HL->next＝p; 既然要在表头插入一个数据，也就是说要在第一个位置插入，那么根据我们之前讲解的链表的插入，只需要将头结点指向新的结点，再让新的结点指向原本的第一个结点即可，所以选择D 链表不具备的特点是？ A．可随机访问任一结点 B．插入删除不需要移动元素 C．不必事先估计存储空间 D．所需空间与其长度成正比 我们前面说了，链表由于是链式存储结构，无法直接访问到对应下标的元素，所以我们只能通过遍历去找到对应位置的元素，故选择A 双向链表和循环链表 前面我们介绍了单链表，通过这样的链式存储，我们不用再像顺序表那样一次性申请一段连续的空间，而是只需要单独为结点申请内存空间，同时在插入和删除的速度上也比顺序表轻松。不过有一个问题就是，如果我们想要操作某一个结点，比如删除或是插入，那么由于单链表的性质，我们只能先去找到它的前驱结点，才能进行。 为了解决这种查找前驱结点非常麻烦的问题，我们可以让结点不仅保存指向后续结点的指针，同时也保存指向前驱结点的指针： 这样我们无论在哪个结点，都能够快速找到对应的前驱结点，就很方便了，这样的链表我们成为双向链表（双链表） 这里我们也来尝试实现一下，首先定义好结构体： typedef int E; struct ListNode { E element; //保存当前元素 struct ListNode * next; //指向下一个结点的指针 struct ListNode * prev; //指向上一个结点的指针 }; typedef struct ListNode * Node; 接着是初始化方法，在初始化时需要将前驱和后继都设置为NULL： void initNode(Node node){ node->next = node->prev = NULL; } int main() { struct ListNode head; initNode(&head); } 接着是双向链表的插入操作，这就比单链表要麻烦一些了，我们先来分析一下： 首先我们需要考虑后继结点，当新的结点插入之后，新的结点的后继结点就是原本在此位置上的结点，所以我们可以先将待插入结点的后继指针指向此位置上的结点： 由于是双向链表，所以我们需要将原本在此位置上的结点的前驱指针指向新的结点： 接着我们来处理一下前驱结点，首先将前驱结点的后继指针修改为新的结点： 最后我们将新的结点的前驱指针指向前驱结点即可： 这样，我们就完成了双向链表中结点的插入操作，按照这个思路，我们来设计一下函数吧： _Bool insertList(Node head, E element, int index){ if(index next; if(head == NULL) return 0; } Node node = malloc(sizeof (struct ListNode)); //创建新的结点 if(node == NULL) return 0; node->element = element; if(head->next) { //首先处理后继结点，现在有两种情况，一种是后继结点不存在的情况，还有一种是后继结点存在的情况 head->next->prev = node; //如果存在则修改对应的两个指针 node->next = head->next; } else { node->next = NULL; //不存在直接将新结点的后继指针置为NULL } head->next = node; //接着是前驱结点，直接操作就行 node->prev = head; return 1; } 这样，我们就编写好了双向链表的插入操作，来测试一下吧： int main() { struct ListNode head; initNode(&head); for (int i = 0; i next; printf(\"%d -> \", node->element); } while (node->next != NULL); printf(\"\\n\"); //再来反向遍历一次 do { printf(\"%d -> \", node->element); node = node->prev; } while (node->prev != NULL); } 可以看到结果没有问题： 无论是正向遍历还是反向遍历，都可以正常完成，相比单链表的灵活度肯定是更大的，我们接着来看删除操作，其实删除操作也是差不多的方式： 我们只需将前驱结点和后继结点的指向修改即可： 接着直接删除对应的结点即可： 现在我们就来编码吧： _Bool deleteList(Node head, int index){ if(index next; if(head == NULL) return 0; } if(head->next == NULL) return 0; Node tmp = head->next; //先拿到待删除结点 if(head->next->next) { //这里有两种情况待删除结点存在后继结点或是不存在 head->next->next->prev = head; head->next = head->next->next; //按照上面分析的来 }else{ head->next = NULL; //相当于删的是最后一个结点，所以直接后继为NULL就完事 } free(tmp); //最后释放已删除结点的内存 return 1; } 这样，我们就实现了双向链表的插入和删除操作，其他操作这里就不演示了。 接着我们再来简单认识一下另一种类型的链表，循环链表，这种链表实际上和前面我们讲的链表是一样的，但是它的最后一个结点，是与头结点相连的，双向链表和单向链表都可以做成这样的环形结构，我们这里以单链表为例： 这种类型的链表实际上与普通链表的唯一区别就在于最后是否连接到头结点，因此循环链表支持从任意一个结点出发都可以到达任何的结点，而普通的链表则只能从头结点出发才能到达任意结点，同样也是为了更灵活而设计的。 链表练习题： 与单链表相比，双链表的优点之一是？ A．插入、删除操作更简单 B．可以进行随机访问 C．可以省略表头指针或表尾指针 D．顺序访问相邻结点更灵活 首先插入删除操作并没有更简单，反而更复杂了，随机访问肯定也是不行的，省略表头表尾指针实际上单链表也可以，所以直接冲D就完事了 非空的循环单链表head的尾结点（由p所指向）满足？ A．p->next == NULL B．p == NULL C．p->next ==head D．p == head 前面我们说了，循环链表实际上唯一区别就是尾部的下一个结点会指向头部，所以这里选择C 若某表最常用的操作是在最后一个结点之后插入一个结点或删除最后一个结点，则采用什么存储方式最节省运算时间？ A．单链表 B．给出表头指针的单循环链表 C．双链表 D．带头结点的双循环链表 题干说明了常用的是在尾结点插入或删除尾结点，那么此时不仅需要快速找到最后一个结点，也需要快速找到最后一个结点的前驱结点，所以肯定是使用双向链表，为了快速找到尾结点，使用循环双向链表从头结点直接向前就能找到，所以选择D 如果对线性表的操作只有两种，即删除第一个元素，在最后一个元素的后面插入新元素，则最好使用？ A．只有表头指针没有表尾指针的循环单链表 B．只有表尾指针没有表头指针的循环单链表 C．非循环双链表 D．循环双链表 首先这里需要操作两个内容，一个是删除第一个元素，另一个是在最后插入新元素，所以A的话只有表头指针虽然循环但是还是得往后遍历才行，而B正好符合，因为循环链表的尾指针可以快速到达头结点，C不可能，D的话，循环双链表也可以，但是没有单链表节省空间，故B是最优解 特殊线性表 前面我们讲解的基础的线性表，通过使用线性表，我们就可以很方便地对数据进行管理了。这一部分，我们将继续认识一些特殊的线性表，它有着特别的规则，在特定场景有着很大的作用，也是考察的重点。 栈 栈（也叫堆栈，Stack）是一种特殊的线性表，它只能在在表尾进行插入和删除操作，就像下面这样： 也就是说，我们只能在一端进行插入和删除，当我们依次插入1、2、3、4这四个元素后，连续进行四次删除操作，删除的顺序刚好相反：4、3、2、1，我们一般将其竖着看： 底部称为栈底，顶部称为栈顶，所有的操作只能在栈顶进行，也就是说，被压在下方的元素，只能等待其上方的元素出栈之后才能取出，就像我们往箱子里里面放的书一样，因为只有一个口取出里面的物品，所以被压在下面的书只能等上面的书被拿出来之后才能取出，这就是栈的思想，它是一种先进后出的数据结构（FILO，First In, Last Out） 实现栈也是非常简单的，可以基于我们前面的顺序表或是链表，这里我们先使用顺序表来实现一下，这里我们需要实现两个新的操作： pop：出栈操作，从栈顶取出一个元素。 push：入栈操作，向栈中压入一个新的元素。 首先还是按照我们的顺序表进行编写： typedef int E; struct Stack { E * array; int capacity; int top; //这里使用top来表示当前的栈顶位置，存的是栈顶元素的下标 }; typedef struct Stack * ArrayStack; //起个别名 接着我们需要编写一个初始化方法： _Bool initStack(ArrayStack stack){ stack->array = malloc(sizeof(E) * 10); if(stack->array == NULL) return 0; stack->capacity = 10; //容量还是10 stack->top = -1; //由于栈内没有元素，那么栈顶默认就为-1 return 1; } int main(){ struct Stack stack; initStack(&stack); } 接着就是栈的两个操作了，一个是入栈操作，一个是出栈操作： _Bool pushStack(ArrayStack stack, E element){ //入栈操作只需要给元素就可以，不需要index，因为只能从尾部入栈 } 由于入栈只能在尾部插入，所以就很好写了： _Bool pushStack(ArrayStack stack, E element){ stack->array[stack->top + 1] = element; //直接设定栈顶元素 stack->top++; //栈顶top变量记得自增 return 1; } 我们来测试一下吧： void printStack(ArrayStack stack){ printf(\"| \"); for (int i = 0; i top + 1; ++i) { printf(\"%d, \", stack->array[i]); } printf(\"\\n\"); } int main(){ struct Stack stack; initStack(&stack); for (int i = 0; i 测试结果也是正确的： 可以看到，从栈底到栈顶一次是0、100、200，不过我们现在的push操作还不够完美，因为栈有可能塞满，所以要进行扩容处理： _Bool pushStack(ArrayStack stack, E element){ if(stack->top + 1 == stack->capacity) { //栈顶+1如果等于容量的话，那么说明已经塞满了 int newCapacity = stack->capacity + (stack->capacity >> 1); //大体操作和顺序表一致 E * newArray = realloc(stack->array, newCapacity * sizeof(E)); if(newArray == NULL) return 0; stack->array = newArray; stack->capacity = newCapacity; } stack->array[stack->top + 1] = element; stack->top++; return 1; } 这样我们的入栈操作就编写完成了，接着是出栈操作，出栈操作我们只需要将栈顶元素取出即可： _Bool isEmpty(ArrayStack stack){ //在出栈之前，我们还需要使用isEmpty判断一下栈是否为空，空栈元素都没有出个毛 return stack->top == -1; } E popStack(ArrayStack stack){ return stack->array[stack->top--]; //直接返回栈顶元素，注意多加一个自减操作 } 我们来测试一下吧： int main(){ struct Stack stack; initStack(&stack); for (int i = 0; i 可以看到，出栈顺序和入栈顺序是完全相反的： 当然使用数组实现栈除了这种可以自己扩容的之外，也有固定大小的栈，当栈已满时，就无法再进行入栈操作了。 不过有些时候，栈的利用率可能会很低，这个时候我们可以将一个固定长度的数组共享给两个栈来使用： 数组的两头分别作为两个栈的栈底，当两个栈的栈顶指针相遇时（栈顶指针下标之差绝对值为1时），表示栈已满。通过这种方式，我们就可以将数组占用的空间更充分地使用，这样的栈我们称为共享栈。 前面我们演示了使用顺序表实现栈，我们接着来看如何使用链表来实现栈，实际上使用链表会更加的方便，我们可以直接将头结点指向栈顶结点，而栈顶结点连接后续的栈内结点： 当有新的元素入栈，只需要在链表头部插入新的结点即可，我们来尝试编写一下： typedef int E; struct ListNode { E element; struct ListNode * next; }; typedef struct ListNode * Node; void initStack(Node head){ head->next = NULL; } int main(){ struct ListNode head; initStack(&head); } 接着我们来编写一下入栈操作： 代码如下： _Bool pushStack(Node head, E element){ Node node = malloc(sizeof(struct ListNode)); //创建新的结点 if(node == NULL) return 0; //失败就返回0 node->next = head->next; //将当前结点的下一个设定为头结点的下一个 node->element = element; //设置元素 head->next = node; //将头结点的下一个设定为当前结点 return 1; } 我们来编写一个测试： void printStack(Node head){ printf(\"| \"); head = head->next; while (head){ printf(\"%d \", head->element); head = head->next; } printf(\"\\n\"); } int main(){ struct ListNode head; initStack(&head); for (int i = 0; i 可以看到结果没有问题： 其实出栈也是同理，所以我们只需要将第一个元素移除即可： _Bool isEmpty(Node head){ return head->next == NULL; //判断栈是否为空只需要看头结点下一个是否为NULL即可 } E popStack(Node head){ Node top = head->next; head->next = head->next->next; E e = top->element; free(top); //别忘了释放结点的内存 return e; //返回出栈元素 } 这里我们来测试一下： int main(){ struct ListNode head; initStack(&head); for (int i = 0; i 实际上无论使用链表还是顺序表，都可以很轻松地实现栈，因为栈的插入和删除操作很特殊。 栈练习题： 若进栈序列为1，2，3，4，则不可能得到的出栈序列是？ A. 3，2，1，4 B. 3，2，4，1 C. 4，2，3，1 D. 2，3，4，1 注意进栈并不一定会一次性全部进栈，可能会出现边进边出的情况，所以出栈的顺序可能有很多种情况，首先来看A，第一个出栈的是3，那么按照顺序，说明前面一定入栈了2、1，在出栈时4还没有入栈，然后是2、1最后是4，没有问题。接着是B，跟前面的A一样，不过这次是先出站3、2，而1留在栈中，接着4入栈，然后再让4、1出栈，也是正确的。然后是C，首先是4出栈，那么说明前三个一定都入栈了，而此时却紧接着的一定是3，而这里是2，错误。所以选择C 假设有5个整数以1、2、3、4、5的顺序被压入堆栈，且出栈顺序为3、5、4、2、1，那么栈大小至少为？ A.2 B.3 C.4 D.5 首先我们分析一下，第一个出栈的元素为3，那么也就是说前面的1、2都在栈内，所以大小至少为3，然后是5，那么说明此时栈内为1、2、4，算是出栈的5，那么至少需要的大小就是4了，所以选择C 队列 前面我们学习了栈，栈中元素只能栈顶出入，它是一种特殊的线性表，同样的，队列（Queue）也是一种特殊的线性表。 就像我们在超市、食堂需要排队一样，我们总是排成一列，先到的人就排在前面，后来的人就排在后面，越前面的人越先完成任务，这就是队列，队列有队头和队尾： 秉承先来后到的原则，队列中的元素只能从队尾进入，只能从队首出去，也就是说，入队顺序为1、2、3、4，那么出队顺序也一定是1、2、3、4，所以队列是一种先进先出（FIFO，First In, First Out）的数据结构。 想要实现队列也是很简单的，也可以通过两种线性表来实现，我们先来看看使用顺序表如何实现队列，假设一开始的时候队列中有0个元素，队首和队尾一般都初始都是-1这个位置： 此时有新的元素入队了，队尾向后移动一格（+1），然后在所指向位置插入新的元素： 之后都是同样的方式进行插入，队尾会一直向后移动： 现在我们想要执行出队操作了，那么需要将队首向后移动一格，然后删除队首指向的元素： 看起来设计的还挺不错的，不过这样有一个问题，这个队列是一次性的，如果队列经过反复出队入队操作，那么最后指针会直接指向数组的最后，如果我们延长数组的话，也不是一个办法，不可能无限制的延伸下去吧？所以一般我们采用循环队列的形式，来实现重复使用一个数组（不过就没办法扩容了，大小是固定的） 我们可以在移动队首队尾指针时，考虑循环的问题，也就是说如果到达了数组尽头，那么就直接从数组的前面重新开始计算，这样就相当于逻辑上都循环了，队首和队尾指针在一开始的时候都指向同一个位置，每入队一个新的元素，依然是先让队尾后移一位，在所指向位置插入元素，出队同理。 不过这样还是有问题，既然是循环的，那么怎么判断队列是否已满呢？ 由于队首指针和队尾指针重合时表示队列为空，所以我们只能舍弃一个存储单元，当队尾距离队首一个单元的时候，表示队列已满。 好了，现在理论讲解完毕，我们可以开始编写代码了： typedef int E; struct Queue { E * array; int capacity; //数组容量 int rear, front; //队尾、队首指针 }; typedef struct Queue * ArrayQueue; 接着我们来对其进行初始化： _Bool initQueue(ArrayQueue queue){ queue->array = malloc(sizeof(E) * 10); if(queue->array == NULL) return 0; queue->capacity = 10; queue->front = queue->rear = 0; //默认情况下队首和队尾都指向0的位置 return 1; } int main(){ struct Queue queue; initQueue(&queue); } 接着我们来编写一下入队操作： _Bool offerQueue(ArrayQueue queue, E element){ if((queue->rear + 1) % queue->capacity == queue->front) //先判断队列是否已满，如果队尾下一个就是队首，那么说明已满 return 0; queue->rear = (queue->rear + 1) % queue->capacity; //队尾先向前移动一位，注意取余计算才能实现循环 queue->array[queue->rear] = element; //在新的位置插入元素 return 1; } 我们来测试一下： void printQueue(ArrayQueue queue){ printf(\"front; //遍历队列需要从队首开始 do { i = (i + 1) % queue->capacity; //先向后循环移动 printf(\"%d \", queue->array[i]); //然后打印当前位置上的元素 } while (i != queue->rear); //当到达队尾时，结束 printf(\" 最后结果如下： 我们接着来看出队操作： _Bool isEmpty(ArrayQueue queue){ //在出队之前需要先看看容量是否足够 return queue->rear == queue->front; } E pollQueue(ArrayQueue queue){ queue->front = (queue->front + 1) % queue->capacity; //先将队首指针后移 return queue->array[queue->front]; //出队，完事 } 我们来测试一下吧： int main(){ struct Queue queue; initQueue(&queue); for (int i = 0; i 我们来看看结果： 可以看到，队列是先进先出的，我们是以什么顺序放入队列中，那么出来的就是是什么顺序。 同样的，队列也可以使用链表来实现，并且使用链表的话就不需要关心容量之类的问题了，会更加灵活一些： 注意我们需要同时保存队首和队尾两个指针，因为是单链表，所以队首需要存放指向头结点的指针，因为需要的是前驱结点，而队尾则直接是指向尾结点的指针即可，后面只需要直接在后面拼接就行。 当有新的元素入队时，只需要拼在队尾就行了，同时队尾指针也要后移一位： 出队时，只需要移除队首指向的下一个元素即可： 那么我们就按照这个思路，来编写一下代码吧： typedef int E; struct LNode { E element; struct LNode * next; }; typedef struct LNode * Node; struct Queue{ Node front, rear; }; typedef struct Queue * LinkedQueue; //因为要存储首位两个指针，所以这里封装一个新的结构体吧 接着是初始化，初始化的时候，需要把头结点先创建出来： _Bool initQueue(LinkedQueue queue){ Node node = malloc(sizeof(struct LNode)); if(node == NULL) return 0; node->next = NULL; queue->front = queue->rear = node; //一开始两个指针都是指向头结点的，表示队列为空 return 1; } int main(){ struct Queue queue; initQueue(&queue); } 首先是入队操作，入队其实直接在后面插入新的结点就行了： _Bool offerQueue(LinkedQueue queue, E element){ Node node = malloc(sizeof(struct LNode)); if(node == NULL) return 0; node->next = NULL; node->element = element; queue->rear->next = node; //先让尾结点的下一个指向新的结点 queue->rear = node; //然后让队尾指针指向新的尾结点 return 1; } 我们来测试一下看看： void printQueue(LinkedQueue queue){ printf(\"front->next; while (1) { //注意不能直接判空，因为前面我们没考虑，也就没将新结点next设定为NULL printf(\"%d \", node->element); if(node == queue->rear) break; //当已经打印最后一个元素后，再结束 else node = node->next; } printf(\" 测试结果如下： 接着是出队操作，出队操作要相对麻烦一点： E pollQueue(LinkedQueue queue){ E e = queue->front->next->element; Node node = queue->front->next; queue->front->next = queue->front->next->next; //直接让头结点指向下下个结点 if(queue->rear == node) queue->rear = queue->front; //如果队尾就是待出队的结点，那么队尾回到队首位置上 free(node); //释放内存 return e; } 这样，我们就编写好了： int main(){ struct Queue queue; initQueue(&queue); for (int i = 0; i 测试结果如下： 效果和前面的数组实现是一样的，只不过使用链表会更加灵活一些。 队列练习题： 使用链表方式存储的队列，在进行出队操作时需要？ A. 仅修改头结点指向 B. 仅修改尾指针 C. 头结点指向、尾指针都要修改 D. 头结点指向、尾指针可能都要修改 首先出队肯定是要动头结点指向的，但是不一定需要动尾指针，因为只有当尾指针指向的是待出队的元素时才需要，因为执行后队列就为空了，所以需要将队尾指针移回头结点处，选择D 引起循环队列队头位置发生变化的操作是？ A. 出队 B. 入队 C. 获取队头元素 D. 获取队尾元素 这个题还是很简单的，因为只有出队操作才会使得队头位置后移，所以选择A 算法实战 欢迎来到线性结构篇算法实战，这一部分我们将从算法相关题目上下手，解决实际问题，其中链表作为重点考察项目。 （简单）删除链表中重复元素 本题来自LeetCode：83. 删除排序链表中的重复元素 给定一个已排序的链表的头 head（注意是无头结点的链表，上来第一个结点就是存放第一个元素） ， 删除所有重复的元素，使每个元素只出现一次 。返回已排序的链表 。 示例 1： 输入：head = [1,1,2] 输出：[1,2] 示例 2： 输入：head = [1,1,2,3,3] 输出：[1,2,3] 这道题实际上比较简单，只是考察各位小伙伴对于链表数据结构的掌握程度，我们只需要牢牢记住如何对链表中的元素进行删除操作就能轻松解决这道题了。 struct ListNode* deleteDuplicates(struct ListNode* head){ if(head == NULL) return head; //首先如果进来的就是NULL，那就不用再浪费时间了 struct ListNode * node = head; //这里用一个指针来表示当前所指向的结点 while (node->next != NULL) { //如果结点的下一个为空，就没必要再判断了，否则不断进行判断 if(node->next->val == node->val) { //如果下一个节点跟当前节点值一样，那么删除下一个节点 node->next = node->next->next; } else { node = node->next; //否则继续从下一个节点开始向后判断 } } return head; //最后原样返回头结点 } （简单）反转链表 本题来自LeetCode：206. 反转链表 给你单链表的头节点 head ，请你反转链表，并返回反转后的链表。 示例 1： 输入：head = [1,2,3,4,5] 输出：[5,4,3,2,1] 示例 2： 输入：head = [1,2] 输出：[2,1] 这道题依然是考察各位小伙伴对于链表相关操作的掌握程度，我们如何才能将一个链表的顺序进行反转，关键就在于如何修改每个节点的指针指向。 struct ListNode* reverseList(struct ListNode* head){ struct ListNode * newHead = NULL, * tmp; //创建一个指针存放新的头结点（注意默认要为NULL），和一个中间暂存指针 while (head != NULL) { //这里利用head不断向后遍历，来依次修改每个结点的指向 tmp = head; //先暂存当前结点 head = head->next; //head可以先后移了 tmp->next = newHead; //将暂存节点的下一个节点，指向前一个结点 newHead = tmp; //最后新的头结点就是tmp所指向结点，这样循环操作直到结束 } return newHead; //最后返回新的结点即可 } （中等）旋转链表 本题来自LeetCode：61. 旋转链表 给你一个链表的头节点 head ，旋转链表，将链表每个节点向右移动 k 个位置。 示例 1： 输入：head = [1,2,3,4,5], k = 2 输出：[4,5,1,2,3] 示例 2： 输入：head = [0,1,2], k = 4 输出：[2,0,1] 这道题需要我们进行一些思考了，首先我们要知道，在经过旋转之后最终的头结点是哪一个，在知道后，这道题就很简单了，我们只需要断掉对应头结点的指针即可，最后返回头结点，就是旋转之后的链表了。 struct ListNode* rotateRight(struct ListNode* head, int k){ if(head == NULL || k == 0) return head; //如果给进来的链表是空的，或者说k为0，那么就没必要再继续了 struct ListNode * node = head; int len = 1; while (node->next) { //先来算一波链表的长度 node = node->next; len++; } if(k == len) return head; //如果len和k长度一样，那也没必要继续了 node->next = head; //将链表连起来变成循环的，一会再切割 int index = len - k % len; //计算头结点最终位置 node = head; while (--index) node = node->next; head = node->next; //找到新的头结点 node->next = NULL; //切断尾部与头部 return head; //返回新的头结点 } （简单）有效的括号 本题来自LeetCode：20. 有效的括号 给定一个只包括 '('，')'，'{'，'}'，'['，']' 的字符串 s ，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 示例 1： 输入：s = \"()\" 输出：true 示例 2： 输入：s = \"()[]{}\" 输出：true 示例 3： 输入：s = \"(]\" 输出：false 示例 4： 输入：s = \"([)]\" 输出：false 示例 5： 输入：s = \"{[]}\" 输出：true 题干很明确，就是需要我们去对这些括号完成匹配，如果给定字符串中的括号无法完成一一匹配的话，那么就表示匹配失败。实际上这种问题我们就可以利用前面学习的栈这种数据结构来解决，我们可以将所有括号的左半部分放入栈中，当遇到右半部分时，进行匹配，如果匹配失败，那么就失败，如果匹配成功，那么就消耗一个左半部分，直到括号消耗完毕。 #include #include #include typedef char E; struct LNode { E element; struct LNode * next; }; typedef struct LNode * Node; void initStack(Node head){ head->next = NULL; } _Bool pushStack(Node head, E element){ Node node = malloc(sizeof(struct LNode)); if(node == NULL) return 0; node->next = head->next; node->element = element; head->next = node; return 1; } _Bool isEmpty(Node head){ return head->next == NULL; } E popStack(Node head){ Node top = head->next; head->next = head->next->next; E e = top->element; free(top); return e; } bool isValid(char * s){ unsigned long len = strlen(s); if(len % 2 == 1) return false; //如果长度不是偶数，那么一定不能成功匹配 struct LNode head; initStack(&head); for (int i = 0; i 一般遇到括号匹配问题、算式计算问题，都可以使用栈这种数据结构来轻松解决。当然使用C语言太过原始，像Java、C++这些语言一般系统库都会直接提供栈的实现类，所以我们在打比赛时，可以尽量选择这些方便的语言，能节省不少时间。 （简单）第 k 个缺失的正整数 本题来自LeetCode：1539. 第 k 个缺失的正整数 给你一个 严格升序排列 的正整数数组 arr 和一个整数 k 。 请你找到这个数组里第 k 个缺失的正整数。 示例 1： 输入：arr = [2,3,4,7,11], k = 5 输出：9 解释：缺失的正整数包括 [1,5,6,8,9,10,12,13,...] 。第 5 个缺失的正整数为 9 。 示例 2： 输入：arr = [1,2,3,4], k = 2 输出：6 解释：缺失的正整数包括 [5,6,7,...] 。第 2 个缺失的正整数为 6 。 实际上这种问题，我们第一个能够想到的就是直接通过遍历挨个寻找，从头开始一个一个找，总能找到第K个吧？我们可以很轻松地得到如下的代码： int findKthPositive(int* arr, int arrSize, int k){ int j = 1, i = 0; //直接从第一个元素开始挨个找 while (i 不过这样的效率并不高，如果这个数组特别长的话，那么我们总不可能还是挨个看吧？这样的遍历查找算法的时间复杂度为$O(n)$，那么有没有更好的算法能够解决这种问题呢？ 既然这个数组是有序的，那么我们不妨直接采用二分搜索的思想，通过使用二分搜索，我们就可以更快速地找到对应的位置，但是有一个问题，我们怎么知道二分搜索找到的数，是不是第N个数呢？实际上也很简单，通过规律我们不难发现，如果某个位置上的数不匹配，那么被跳过的数k一定满足： $$ k = arr[i] - i - 1 $$ 所以，我们只需要找到一个大于等于k的位置即可，并且要尽可能的接近，在找到之后，再根据公式去寻找即可： int findKthPositive(int *arr, int arrSize, int k) { if (arr[0] > k) return k; int l = 0, r = arrSize; while (l = k) { r = mid; } else { l = mid + 1; } } return k - (arr[l - 1] - (l - 1) - 1) + arr[l - 1]; } window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（一）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（一）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/算法/数据结构与算法（二）.html":{"url":"Java/算法/数据结构与算法（二）.html","title":"数据结构与算法（二）","keywords":"","body":" 树形结构篇 前面我们学习了线性相关的数据结构，了解了顺序表和链表两种类型，我们接着来看树形结构。这一章会更加考验各位小伙伴的数学功底以及逻辑思维，难度会更大一些。 树与森林 树是一种全新的数据结构，它就像一棵树的树枝一样，不断延伸。 树结构介绍 一棵树就像下面这样连接： 可以看到，现在一个结点下面可能会连接多个节点，并不断延伸，就像树枝一样，每个结点都有可能是一个分支点，延伸出多个分支，从位于最上方的结点开始不断向下，而这种数据结构，我们就称为树（Tree）注意分支只能向后单独延伸，之后就分道扬镳了，不能与其他分支上的结点相交！ 我们一般称位于最上方的结点为树的根结点（Root）因为整棵树正是从这里开始延伸出去的。 每个结点连接的子结点数目（分支的数目），我们称为结点的度（Degree），而各个结点度的最大值称为树的度。 每个结点延伸下去的下一个结点都可以称为一棵子树（SubTree）比如结点B及其之后延伸的所有分支合在一起，就是一棵A的子树。 每个结点的层次（Level）按照从上往下的顺序，树的根结点为1，每向下一层+1，比如G的层次就是3，整棵树中所有结点的最大层次，就是这颗树的深度（Depth），比如上面这棵树的深度为4，因为最大层次就是4。 由于整棵树错综复杂，所以说我们需要先规定一下结点之间的称呼，就像族谱那样： 与当前结点直接向下相连的结点，我们称为子结点（Child），比如B、C、D结点，都是A的子结点，就像族谱中的父子关系一样，下一代一定是子女，相反的，那么A就是B、C、D的父结点（Parent），也可以叫双亲结点。 如果某个节点没有任何的子结点（结点度为0时）那么我们称这个结点为叶子结点（因为已经到头了，后面没有分支了，这时就该树枝上长叶子了那样）比如K、L、F、G、M、I、J结点，都是叶子结点。 如果两个结点的父结点是同一个，那么称这两个节点为兄弟结点（Sibling）比如B和C就是兄弟结点，因为都是A的孩子。 从根结点开始一直到某个结点的整条路径的所有结点，都是这个结点的祖先结点（Ancestor）比如L的祖先结点就是A、B、E 那么在了解了树的相关称呼之后，相信各位就应该对树有了一定的了解，虽然概念比较多，但是还请各位一定记住，不然后面就容易听懵。 森林 森林其实很好理解，一片森林肯定是是由很多棵树构成的，比如下面的三棵树： 它们共同组成了一片森林，因此，m（m≥0）棵树的集合我们称为森林（Forest） 二叉树 前面我们给大家介绍了树的概念，而我们本章需要着重讨论的是二叉树（Binary Tree）它是一种特殊的树，它的度最大只能为2，所以我们称其为二叉树，一棵二叉树大概长这样： 并且二叉树任何结点的子树是有左右之分的，不能颠倒顺序，比如A结点左边的子树，称为左子树，右边的子树称为右子树。 二叉树有5种基本形态，分别是： 当然，对于某些二叉树我们有特别的称呼，比如，在一棵二叉树中，所有分支结点都存在左子树和右子树，且叶子结点都在同一层： 这样的二叉树我们称为满二叉树，可以看到整棵树都是很饱满的，没有出现任何度为1的结点，当然，还有一种特殊情况： 可以看到只有最后一层有空缺，并且所有的叶子结点是按照从左往右的顺序排列的，这样的二叉树我们一般称其为完全二叉树，所以，一棵满二叉树，一定是一棵完全二叉树。 树和森林的转换 二叉树和树、森林之间是可以相互转换的。 我们可以使用下面的规律将一棵普通的树转换为一棵二叉树： 最左边孩子结点 -> 左子树结点（左孩子） 兄弟结点 -> 右子树结点（右孩子） 我们以下面的这棵树为例： 我们优先从左边开始看，B、F、G都是A的子结点，根据上面的规律，我们将B作为左子树： 接着继续从左往右看，由于F是B的兄弟结点，那么根据规律，F作为B的右子树： 接着是G，G是F的兄弟结点，那么G继续作为F的右子树： 我们接着来看第三排，依然是从左往右，C是B的子节点，所以C作为B的左子树： 接着，D是C的兄弟节点，那么D就作为C的右子树了： 此时还有一个H结点，它是G的子结点，所以直接作为G的左子树： 现在只剩下最后一排了，E是D的子结点，K是H的子结点，所以最后就像这样了： 按照规律，我们就将一棵树转换为了二叉树。当然还有一种更简单的方法，我们可以直接将所有的兄弟结点连起来（橙色横线）： 接着擦掉所有结点除了最左边结点以外的连线： 所有的黑色连线偏向左边，橙色连线偏向右边： 效果是一样的，这两种方式都可以，你觉得哪一种简单就使用哪一种就行了。我们会发现，无论一棵树长成啥样，转换为二叉树后，根节点一定没有右子树。 思考：那二叉树咋变回普通的树呢？实际上我们只需要反推回去就行了。 那么森林呢，森林如何转换为一棵二叉树呢？其实很简单： 首先我们还是按照二叉树转换为树的规则，将森林中所有树转换为二叉树，接着我们只需要依次连接即可： 注意连接每一棵树的时候，一律从根结点的右边开始，不断向右连接。 我们发现，相比树转换为二叉树，森林转换为二叉树之后，根节点就存在右子树了，右子树连接的都是森林中其他的树。 思考：现在有一棵二叉树，我们想要转回去，我们怎么知道到底是将其转换为森林还是转换为树呢？ 二叉树的性质 由于二叉树结构特殊，我们可以总结出以下的五个性质： 性质一：对于一棵二叉树，第i层的最大结点数量为 $2^{i-1}$ 个，比如二叉树的第一层只有一个根结点，也就是 $2^0 = 1$ ，而二叉树的第三层可以有 $2^2 = 4$ 个结点。 性质二：对于一棵深度为k的二叉树，可以具有的最大结点数量为： $$ n = 2^0 + 2^1 + 2^2 + ... + 2^{k-1} $$ 我们发现，实际上每一层的结点数量，组成了一个等比数列，公比q为2，结合等比数列求和公式，我们可以将其简化为： $$ S_n = \\frac {a_1 \\times (1 - q^n)} {1 - q} = \\frac {1 \\times (1 - 2^k)} {1 - 2} = - (1 - 2^k) = 2^k - 1 $$ 所以一棵深度为k的二叉树最大结点数量为 $n = 2^k - 1$，顺便得出，结点的边数为 $E = n - 1$。 性质三：假设一棵二叉树中度为0、1、2的结点数量分别为$n_0$、$n_1$、$n_2$，由于一棵二叉树中只有这三种类型的结点，那么可以直接得到结点总数： $$ n = n_0 + n_1 + n_2 $$ 我们不妨换一个思路，我们从二叉树的边数上考虑，因为每个结点有且仅有一条边与其父结点相连，那么边数之和就可以表示为： $$ E = n_1 + 2n_2 $$ 度为1的结点有一条边，度为2的结点有两条边，度为0的结点没有，加在一起就是整棵二叉树的边数之和，结合我们在性质二中推导的结果，可以得到另一种计算结点总数的方式： $$ E = n - 1 = n_1 + 2n_2 $$ $$ n = n_1 + 2n_2 + 1 $$ 再结合我们第一个公式： $$ n = n_0 + n_1 + n_2 = n_1 + 2n_2 + 1 $$ 综上，对于任何一棵二叉树，如果其叶子结点个数为 $n_0$ ，度为2的结点个数为 $n_2$ ，那么两者满足以下公式： $$ n_0 = n_2 + 1 $$ （性质三的推导过程比较复杂，如果觉得麻烦推荐直接记忆） 性质四：完全二叉树除了最后一层有空缺外，其他层数都是饱满的，假设这棵二叉树为满二叉树，那么根据我们前面得到的性质，假设层数为k，那么结点数量为：$n = 2^k - 1$ ，根据完全二叉树的性质，最后一层可以满可以不满，那么一棵完全二叉树结点数n满足： $$ 2^{k-1} - 1 n肯定是一个整数，那么可以写为： $$ 2^{k - 1} n个结点的完全二叉树深度为 $k = \\lfloor log_2n \\rfloor + 1$ 。 （性质四的推导过程比较复杂，如果觉得麻烦推荐直接记忆） 性质五：一颗有n个结点的完全二叉树，由性质四得到深度为 $k = \\lfloor log_2n \\rfloor + 1$ 现在对于任意一个结点i，结点的顺序为从上往下，从左往右： 对于一个拥有左右孩子的结点来说，其左孩子为2i，右孩子为2i + 1。 如果i = 1，那么此结点为二叉树的根结点，如果i > 1，那么其父结点就是 $\\lfloor i/2 \\rfloor$，比如第3个结点的父结点为第1个节点，也就是根结点。 如果2i > n，则结点i没有左孩子，比如下面图中的二叉树，n为5，假设此时i = 3，那么2i = 6 > n = 5 说明第三个结点没有左子树。 如果2i + 1 > n，则结点i没有右孩子。 以上五条二叉树的性质一般是笔试重点内容，还请务必牢记，如果觉得推导过程比较麻烦，推荐直接记忆结论。 二叉树练习题： 由三个结点可以构造出多少种不同的二叉树？ 这个问题我们可以直接手画得到结果，一共是五种，当然，如果要求N个结点的话，可以利用动态规划求解，如果这道题是求N个结点可以构造多少二叉树，我们可以分析一下： 假设现在只有一个结点或者没有结点，那么只有一种，$h(0) = h(1) = 1$ 假设现在有两个结点，那么其中一个拿来做根结点，剩下这一个可以左边可以右边，要么左边零个结点右边一个结点，要么左边一个结点右边零个结点，所以说 $h(2) = h(1) × h(0) + h(0) × h(1) = 2$ 假设现在有三个结点，那么依然是其中一个拿来做根节点，剩下的两个结点情况就多了，要么两个都在左边，两个都在右边，或者一边一个，所以说 $h(3) = h(2) × h(0) + h(1) × h(1) + h(0) × h(2)$ 我们发现，它是非常有规律的，N每+1，项数多一项，所以我们只需要按照规律把所有情况的结果相加就行了，我们按照上面推导的结果，编写代码： int main(){ int size; scanf(\"%d\", &size); //读取需要求的N int dp[size + 1]; dp[0] = dp[1] = 1; //没有结点或是只有一个结点直接得到1 for (int i = 2; i 成功得到结果，当然，实际上我们根据这个规律，还可以将其进一步简化，求出的结果序列为：1, 1, 2, 5, 14, 42, 132...，这种类型的数列我们称为卡特兰数，以中国蒙古族数学家明安图 (1692-1763)和比利时的数学家欧仁·查理·卡塔兰 (1814–1894)的名字来命名，它的通项公式为： $$ Cn = \\frac {1} {n + 1}C^n{2n} = \\frac {1} {n + 1} \\times \\frac {(2n)!} {n!\\times(2n - n)!} = \\frac {(2n)!} {n!\\times (n + 1)!} $$ 所以说不需要动态规划了，直接一个算式解决问题： int factorial(int n){ int res = 1; for (int i = 2; i 只不过这里用的是int，运算过程中如果数字太大的话就没办法了 一棵完全二叉树有1001个结点，其中叶子结点的个数为？ 既然是完全二叉树，那么最下面这一排肯定是按顺序排的，并且上面各层应该是排满了的，那么我们先求出层数，根据性质四： $$ k = \\lfloor log_2n \\rfloor + 1 = 9 + 1 = 10 $$ 所以此二叉树的层数为10，也就是说上面9层都是满满当当的，最后一层不满，那么根据性质二，我们求出前9层的结点数： $$ n = 2^k - 1 = 511 $$ 那么剩下的结点就都是第十层的了，得到第十层所有叶子结点数量 $ = 1001 - 511 = 490$，因为第十层并不满，剩下的叶子第九层也有，所以最后我们还需要求出第九层的叶子结点数量，先计算第九层的所有结点数量： $$ n = 2^{i - 1}=256 $$ 接着我们需要去掉那些第九层度为一和度为二的结点，其实只需要让第十层都叶子结点除以2就行了： $$ n = (490 + 1) / 2 = 245 $$ 注意在除的时候+1，因为有可能会出现一个度为1的结点，此时也需要剔除，所以说+1变成偶数这样才可以正确得到结果。最后剔除这些结点，得到最终结果： $$ n_0 = 256 - 245 + 490 = 501 $$ 所以这道题的答案为501。 深度为h的满m叉树的第k层有多少个结点？ 这道题只是看着复杂，但是实际上我们把之前推导都公式带进来就行了。但是注意，难点在于，这道题给的是满m叉树，而不是满二叉树，满二叉树根据性质一我们已经知道： $$ n = 2^{i-1} $$ 那m叉树呢？实际上也是同理的，我们以三叉树为例，每向下一层，就划分三个孩子结点出来： 每一层的最大结点数依次为：1、3、9、27.... 我们发现，实际上每一层的最大结点数，正好是3的次方，所以说无论多少叉树，实际上变化的就是底数而已，所以说深度为h（h在这里没卵用，障眼法罢了）的满m叉树第k层的结点数： $$ n = m^{k-1} $$ 一棵有1025个结点的二叉树的层数k的取值范围是？ 这个问题比较简单，层数的最小值实际上就是为完全二叉树的情况，层数的最大值实际上就是连成一根线的情况，结点数就是层数，所以说根据性质四得到最小深度为11，最大深度就直接1025了，k的范围是11 - 1025 将一棵树转换为二叉树时，根节点的右边连接的是？ 根据我们前面总结得到的性质，树转换为二叉树之后，根节点一定没有右子树，所以为空 二叉树的构建 前面我们介绍了二叉树的几个重要性质，那么现在我们就来尝试在程序中表示和使用一棵二叉树。 二叉树的存储形式也可以使用我们前面的两种方式，一种是使用数组进行存放，还有一种就是使用链式结构，只不过之前链式结构需要强化一下才可以表示为二叉树。 首先我们来看数组形式的表示方式，利用前面所推导的性质五，我们可以按照以下顺序进行存放： 这颗二叉树的顺序存储： 从左往右，编号i从1开始，比如现在我们需要获取A的右孩子，那么就需要根据性质五进行计算，因为右孩子为2i + 1，所以A的右边孩子的编号就是3，也就是结点C。 这种表示形式使用起来并不方便，而且存在大量的计算，所以说我们只做了解即可，我们的重点是下面的链式存储方式。 我们在前面使用链表的时候，每个结点不仅存放对应的数据，而且会存放一个指向下一个结点的指针： 而二叉树也可以使用这样的链式存储形式，只不过现在一个结点需要存放一个指向左子树的指针和一个指向右子树的指针了： 通过这种方式，我们就可以通过连接不同的结点形成一颗二叉树了，这样也更便于我们去理解它，我们首先定义一个结构体： typedef char E; struct TreeNode { E element; //存放元素 struct TreeNode * left; //指向左子树的指针 struct TreeNode * right; //指向右子树的指针 }; typedef struct TreeNode * Node; 比如我们现在想要构建一颗像这样的二叉树： 首先我们需要创建好这几个结点： int main(){ Node a = malloc(sizeof(struct TreeNode)); //依次创建好这五个结点 Node b = malloc(sizeof(struct TreeNode)); Node c = malloc(sizeof(struct TreeNode)); Node d = malloc(sizeof(struct TreeNode)); Node e = malloc(sizeof(struct TreeNode)); a->element = 'A'; b->element = 'B'; c->element = 'C'; d->element = 'D'; e->element = 'E'; } 接着我们从最上面开始，挨着进行连接，首先是A这个结点： int main(){ ... a->left = b; //A的左孩子是B a->right = c; //A的右孩子是C } 然后是B这个结点： int main(){ ... b->left = d; //B的左孩子是D b->right = e; //B的右孩子是E //别忘了把其他的结点改为NULL ... } 这样的话，我们就成功构建好了这棵二叉树： int main(){ ... printf(\"%c\", a->left->left->element); //比如现在我想要获取A左孩子的左孩子，那么就可以直接left二连 } 断点调试也可以看的很清楚： 二叉树的遍历 前面我们通过使用链式结构，成功构建出了一棵二叉树，接着我们来看看如何遍历一棵二叉树，也就是说我们想要访问二叉树的每一个结点，由于树形结构特殊，遍历顺序并不唯一，所以一共有四种访问方式：前序遍历、中序遍历、后序遍历、层序遍历。不同的访问方式输出都结点顺序也不同。 首先我们来看最简单的前序遍历： 前序遍历是一种勇往直前的态度，走到哪就遍历到那里，先走左边再走右边，比如上面的这个图，首先会从根节点开始： 从A开始，先左后右，那么下一个就是B，然后继续走左边，是D，现在ABD走完之后，B的左边结束了，那么就要开始B的右边了，所以下一个是E，E结束之后，现在A的左子树已经全部遍历完成了，然后就是右边，接着就是C，C没有左子树了，那么只能走右边了，最后输出F，所以上面这个二叉树的前序遍历结果为：ABDECF 打印根节点 前序遍历左子树 前序遍历右子树 我们不难发现规律，整棵二叉树（包括子树）的根节点一定是出现在最前面的，比如A在最前面，A的左子树根结点B也是在最前面的。 接着我们来通过代码实现一下，首先先把咱们这棵二叉树组装好： int main(){ Node a = malloc(sizeof(struct TreeNode)); Node b = malloc(sizeof(struct TreeNode)); Node c = malloc(sizeof(struct TreeNode)); Node d = malloc(sizeof(struct TreeNode)); Node e = malloc(sizeof(struct TreeNode)); Node f = malloc(sizeof(struct TreeNode)); a->element = 'A'; b->element = 'B'; c->element = 'C'; d->element = 'D'; e->element = 'E'; f->element = 'F'; a->left = b; a->right = c; b->left = d; b->right = e; c->right = f; c->left = NULL; d->left = e->right = NULL; e->left = e->right = NULL; f->left = f->right = NULL; } 组装好之后，我们来实现一下前序遍历的函数： void preOrder(Node root){ //传入的是二叉树的根结点 } 那么现在我们拿到根结点之后该怎么去写呢？既然是走到哪里打印到哪里，那么我们就先打印一下当前结点的值： void preOrder(Node root){ printf(\"%c\", root->element); //不多bb先打印再说 } 打印完成之后，我们就按照先左后右的规则往后遍历下一个结点，这里我们就直接使用递归来完成： void preOrder(Node root){ printf(\"%c\", root->element); preOrder(root->left); //将左孩子结点递归交给下一级 preOrder(root->right); //等上面的一系列向左递归结束后，再以同样的方式去到右边 } 不过还没，我们的递归肯定是需要一个终止条件的，不可能无限地进行下去，如果已经走到底了，那么就不能再往下走了，所以： void preOrder(Node root){ if(root == NULL) return; //如果走到NULL了，那就表示已经到头了，直接返回 printf(\"%c\", root->element); preOrder(root->left); preOrder(root->right); } 最后我们来测试一下吧： int main(){ ... preOrder(a); } 可以看到结果为： 这样我们就通过一个简单的递归操作完成了对一棵二叉树的前序遍历，如果不太好理解，建议结合调试进行观察。 当然也有非递归的写法，我们使用循环，但是就比较麻烦了，我们需要使用栈来帮助我们完成（实际上递归写法本质上也是在利用栈），我们依然是从第一个结点开始，先走左边，每向下走一步，先输出节点的值，然后将对应的结点丢到栈中，当走到尽头时，表示左子树已经遍历完成，接着就是从栈中依次取出栈顶节点，如果栈顶结点有右子树，那么再按照同样的方式遍历其右子树，重复执行上述操作，直到栈清空为止。 一路向左，不断入栈，直到尽头 到达尽头后，出栈，看看有没有右子树，如果没有就继续出栈，直到遇到有右子树的为止 拿到右子树后，从右子树开始，重复上述步骤，直到栈清空 比如我们还是以上面的这棵树为例： 首先我们依然从根结点A出发，不断遍历左子树，沿途打印结果并将节点丢进栈中： 当遍历到D结点时，没有左子树了，此时将栈顶结点D出栈，发现没有右节点，继续出栈，得到B结点，接着得到当前结点的右孩子E结点，然后重复上述步骤： 接着发现E也没有左子树了，同样的，又开始出栈，此时E没有右子树，接着看A，A有右子树，所以继续从C开始，重复上述步骤： 由于C之后没有左子树，那么就出栈获取右子树，此时得到结点F，继续重复上述步骤： 最后F出栈，没有右子树了，栈空，结束。 按照这个思路，我们来编写一下程序吧： typedef char E; struct TreeNode { E element; struct TreeNode * left; struct TreeNode * right; }; typedef struct TreeNode * Node; //------------- 栈 ------------------- typedef Node T; //这里栈内元素类型定义为上面的Node，也就是二叉树结点指针 struct StackNode { T element; struct StackNode * next; }; typedef struct StackNode * SNode; //这里就命名为SNode，不然跟上面冲突了就不好了 void initStack(SNode head){ head->next = NULL; } _Bool pushStack(SNode head, T element){ SNode node = malloc(sizeof(struct StackNode)); if(node == NULL) return 0; node->next = head->next; node->element = element; head->next = node; return 1; } _Bool isEmpty(SNode head){ return head->next == NULL; } T popStack(SNode head){ SNode top = head->next; head->next = head->next->next; T e = top->element; free(top); return e; } //------------------------------------- void preOrder(Node root){ struct StackNode stack; //栈先搞出来 initStack(&stack); while (root || !isEmpty(&stack)){ //两个条件，只有当栈空并且节点为NULL时才终止循环 while (root) { //按照我们的思路，先不断遍历左子树，直到没有为止 pushStack(&stack, root); //途中每经过一个结点，就将结点丢进栈中 printf(\"%c\", root->element); //然后打印当前结点元素值 root = root->left; //继续遍历下一个左孩子结点 } root = popStack(&stack); //经过前面的循环，明确左子树全部走完了，接着就是右子树了 root = root->right; //得到右孩子，如果有右孩子，下一轮会重复上面的步骤；如果没有右孩子那么这里的root就被赋值为NULL了，下一轮开始会直接跳过上面的while，继续出栈下一个结点再找右子树 } } 这样，我们就通过非递归的方式实现了前序遍历，可以看到代码是相当复杂的，也不推荐这样编写。 那么前序遍历我们了解完了，接着就是中序遍历了，中序遍历在顺序上与前序遍历不同，前序遍历是走到哪就打印到哪，而中序遍历需要先完成整个左子树的遍历后再打印，然后再遍历其右子树。 我们还是以上面的二叉树为例： 首先需要先不断遍历左子树，走到最底部，但是沿途并不进行打印，而是到底之后，再打印，所以第一个打印的是D，接着由于没有右子树，所以我们回到B，此时再打印B，然后再去看B的右结点E，由于没有左子树和右子树了，所以直接打印E，左边遍历完成，接着回到A，打印A，然后对A的右子树重复上述操作。所以说遍历的基本规则还是一样的，只是打印值的时机发生了改变。 中序遍历左子树 打印结点 中序遍历右子树 所以这棵二叉树的中序遍历结果为：DBEACF，我们可以发现一个规律，就是在某个结点的左子树中所有结点，其中序遍历结果也是按照这样的规律排列的，比如A的左子树中所有结点，中序遍历结果中全部都在A的左边，右子树中所有的结点，全部都在A的右边（这个规律很关键，后面在做一些算法题时会用到） 那么怎么才能将打印调整到左子树全部遍历结束之后呢？其实很简单： void inOrder(Node root){ if(root == NULL) return; inOrder(root->left); //先完成全部左子树的遍历 printf(\"%c\", root->element); //等待左子树遍历完成之后再打印 inOrder(root->right); //然后就是对右子树进行遍历 } 我们只需要将打印放到左子树遍历之后即可，这样打印出来的结果就是中序遍历的结果了： 同样的，如果采用的是非递归，那么我也只需要稍微改动一个地方即可： ... void inOrder(Node root){ struct StackNode stack; initStack(&stack); while (root || !isEmpty(&stack)){ //其他都不变 while (root) { pushStack(&stack, root); root = root->left; } root = popStack(&stack); printf(\"%c\", root->element); //只需要将打印时机延后到左子树遍历完成 root = root->right; } } 这样，我们就实现了二叉树的中序遍历，实际上还是很好理解的。 接着我们来看一下后序遍历，后序遍历继续将打印的时机延后，需要等待左右子树全部遍历完成，才会去进行打印。 首先还是一路向左，到达结点D，此时结点D没有左子树了，接着看结点D还有没有右子树，发现也没有，左右子树全部遍历完成，那么此时再打印D，同样的，D完事之后就回到B了，此时接着看B的右子树，发现有结点E，重复上述操作，E也打印出来了，接着B的左右子树全部OK，那么再打印B，接着A的左子树就完事了，现在回到A，看到A的右子树，继续重复上述步骤，当A的右子树也遍历结束后，最后再打印A结点。 后序遍历左子树 后序遍历右子树 打印结点 所以最后的遍历顺序为：DEBFCA，不难发现，整棵二叉树（包括子树）根结点一定是在后面的，比如A在所有的结点的后面，B在其子节点D、E的后面，这一点恰恰和前序遍历相反（注意不是得到的结果相反，是规律相反） 所以，按照这个思路，我们来编写一下后序遍历： void postOrder(Node root){ if(root == NULL) return; postOrder(root->left); postOrder(root->right); printf(\"%c\", root->element); //时机延迟到最后 } 结果如下： 不过难点来了，后序遍历使用非递归貌似写不了啊？因为按照我们的之前的思路，最多也就实现中序遍历，我们没办法在一次循环中得知右子树是否完成遍历，难点就在这里。那么我们就要想办法先让右子树完成遍历，由于一个结点需要左子树全部完成+右子树全部完成，而目前只能明确左子树完成了遍历（也就是内层while之后，左子树一定结束了）所以我们可以不急着将结点出栈，而是等待其左右都完事了再出栈，这里我们需要稍微对结点的结构进行修改，添加一个标记变量，来表示已经完成左边还是左右都完成了： struct TreeNode { E element; struct TreeNode * left; struct TreeNode * right; int flag; //需要经历左右子树都被遍历才行，这里用flag存一下状态，0表示左子树遍历完成，1表示右子树遍历完成 }; T peekStack(SNode head){ //这里新增一个peek操作，用于获取栈顶元素的值，但是不出栈，仅仅是值获取 return head->next->element; } void postOrder(Node root){ struct StackNode stack; initStack(&stack); while (root || !isEmpty(&stack)){ //其他都不变 while (root) { pushStack(&stack, root); root->flag = 0; //首次入栈时，只能代表左子树遍历完成，所以flag置0 root = root->left; } root = peekStack(&stack); //注意这里只是获取到结点，并没有进行出栈操作，因为需要等待右子树遍历完才能出栈 if(root->flag == 0) { //如果仅仅遍历了左子树，那么flag就等于0 root->flag = 1; //此时标记为1表示遍历右子树 root = root->right; //这里跟之前是一样的 } else { printf(\"%c\", root->element); //当flag为1时走这边，此时左右都遍历完成了，这时再打印值出来 popStack(&stack); //这时再把对应的结点出栈，因为左右都完事了 root = NULL; //置为NULL，下一轮直接跳过while，然后继续取栈中剩余的结点，重复上述操作 } } } 所以，后序遍历的非递归写法的最大区别是将结点的出栈时机和打印时机都延后了。 最后我们来看层序遍历，实际上这种遍历方式是我们人脑最容易理解的，它是按照每一层在进行遍历： 层序遍历实际上就是按照从上往下每一层，从左到右的顺序打印每个结点，比如上面的这棵二叉树，那么层序遍历的结果就是：ABCDEF，像这样一层一层的挨个输出。 虽然理解起来比较简单，但是如果让你编程写出来，该咋搞？是不是感觉有点无从下手？ 我们可以利用队列来实现层序遍历，首先将根结点存入队列中，接着循环执行以下步骤： 进行出队操作，得到一个结点，并打印结点的值。 将此结点的左右孩子结点依次入队。 不断重复以上步骤，直到队列为空。 我们来分析一下，首先肯定一开始A在里面： 接着开始不断重复上面的步骤，首先是将队首元素出队，打印A，然后将A的左右孩子依次入队： 现在队列中有B、C两个结点，继续重复上述操作，B先出队，打印B，然后将B的左右孩子依次入队： 现在队列中有C、D、E这三个结点，继续重复，C出队并打印，然后将F入队： 我们发现，这个过程中，打印的顺序正好就是我们层序遍历的顺序，所以说队列还是非常有用的。 那么现在我们就来上代码吧： typedef char E; struct TreeNode { E element; struct TreeNode * left; struct TreeNode * right; int flag; }; typedef struct TreeNode * Node; //--------------- 队列 ---------------- typedef Node T; //还是将Node作为元素 struct QueueNode { T element; struct QueueNode * next; }; typedef struct QueueNode * QNode; struct Queue{ QNode front, rear; }; typedef struct Queue * LinkedQueue; _Bool initQueue(LinkedQueue queue){ QNode node = malloc(sizeof(struct QueueNode)); if(node == NULL) return 0; queue->front = queue->rear = node; return 1; } _Bool offerQueue(LinkedQueue queue, T element){ QNode node = malloc(sizeof(struct QueueNode)); if(node == NULL) return 0; node->element = element; queue->rear->next = node; queue->rear = node; return 1; } _Bool isEmpty(LinkedQueue queue){ return queue->front == queue->rear; } T pollQueue(LinkedQueue queue){ T e = queue->front->next->element; QNode node = queue->front->next; queue->front->next = queue->front->next->next; if(queue->rear == node) queue->rear = queue->front; free(node); return e; } //-------------------------------- void levelOrder(Node root){ struct Queue queue; //先搞一个队列 initQueue(&queue); offerQueue(&queue, root); //先把根节点入队 while (!isEmpty(&queue)) { //不断重复，直到队列空为止 Node node = pollQueue(&queue); //出队一个元素，打印值 printf(\"%c\", node->element); if(node->left) //如果存在左右孩子的话 offerQueue(&queue, node->left); //记得将左右孩子入队，注意顺序，先左后右 if(node->right) offerQueue(&queue, node->right); } } 可以看到结果就是层序遍历的结果： 当然，使用递归也可以实现，但是需要单独存放结果然后单独输出，不是很方便，所以说这里就不演示了。 二叉树练习题： 现在有一棵二叉树前序遍历结果为：ABCDE，中序遍历结果为：BADCE，那么请问该二叉树的后序遍历结果为？ 对二叉树的结点从1开始连续进行编号，要求每个结点的编号大于其左右孩子的编号，那么请问需要采用哪种遍历方式来实现？ A. 前序遍历 B. 中序遍历 C. 后序遍历 D. 层序遍历 高级树结构 高级树结构篇是对树结构的延伸扩展，有着特殊的定义和性质，在编写上可能会比较复杂，所以这一部分对于那些太过复杂的结构，就不进行代码编写了，只进行理论讲解。 线索化二叉树 前面我们学习了二叉树，我们知道一棵二叉树实际上可以由多个结点组成，每个结点都有一个左右指针，指向其左右孩子。我们在最后也讲解了二叉树的遍历，包括前序、中序、后序以及层序遍历。只不过在遍历时实在是太麻烦了，我们需要借助栈来帮助我们完成这项遍历操作。 实际上我们发现，一棵二叉树的某些结点会存在NULL的情况，我们可以利用这些为NULL的指针，将其线索化为某一种顺序遍历的指向下一个按顺序的结点的指针，这样我们在进行遍历的时候，就会很方便了。 例如，一棵二叉树的前序遍历顺序如下： 我们就可以将其进行线索化，首先还是按照前序遍历的顺序依次寻找： 线索化的规则为： 结点的左指针，指向其当前遍历顺序的前驱结点。 结点的右指针，指向其当前遍历顺序的后继结点。 所以在线索化之后，G的指向情况如下： 这样，G原本两个为NULL的指针就被我们利用起来了，但是现在有一个问题，我们怎么知道，某个结点的指针到底是指向的其左右孩子，还是说某种遍历顺序下的前驱或是后继结点呢？所以，我们还需要分别为左右添加一个标志位，来表示左右指针到底指向的是孩子还是遍历线索： typedef char E; typedef struct TreeNode { E element; struct TreeNode * left; struct TreeNode * right; int leftTag, rightTag; //标志位，如果为1表示这一边指针指向的是线索，不为1就是正常的孩子结点 } * Node; 接着是H结点，同样的，因为H结点的左右指针都是NULL，那么我们也可以将其线索化： 接着我们来看结点E，这个结点只有一个右孩子，没有左孩子，左孩子指针为NULL，我们也可以将其线索化： 最后，整棵二叉树完成线索化之后，除了遍历顺序的最后一个结点没有后续之外，其他为NULL的指针都被利用起来了： 我们可以发现，在利用上那些为NULL的指针之后，当我们再次进行前序遍历时，我们不需要再借助栈了，而是可以一路向前。 这里我们弄一个简单一点的线索化二叉树，来尝试对其进行遍历： 首先我们要对这棵二叉树进行线索化，将其变成一棵线索化二叉树： Node createNode(E element){ //单独写了个函数来创建结点 Node node = malloc(sizeof(struct TreeNode)); node->left = node->right = NULL; node->rightTag = node->leftTag = 0; node->element = element; return node; } int main() { Node a = createNode('A'); Node b = createNode('B'); Node c = createNode('C'); Node d = createNode('D'); Node e = createNode('E'); a->left = b; b->left = d; a->right = c; b->right = e; } 实际上要将其进行线索化，我们只需要正常按照对应的遍历顺序进行即可，不过在遍历过程中需要留意那些存在空指针的结点，我们需要修改其指针的指向： void preOrderThreaded(Node root){ //前序遍历线索化函数 if(root == NULL) return; //别急着写打印 preOrderThreaded(root->left); preOrderThreaded(root->right); } 首先还是老规矩，先把前序遍历写出来，然后我们需要进行判断，如果存在指针指向为NULL，那么就将其线索化： Node pre = NULL; //这里我们需要一个pre来保存后续结点的指向 void preOrderThreaded(Node root){ //前序遍历线索化函数 if(root == NULL) return; if(root->left == NULL) { //首先判断当前结点左边是否为NULL，如果是，那么指向上一个结点 root->left = pre; root->leftTag = 1; //记得修改标记 } if(pre && pre->right == NULL) { //然后是判断上一个结点的右边是否为NULL，如果是那么进行线索化，指向当前结点 pre->right = root; pre->rightTag = 1; //记得修改标记 } pre = root; //每遍历完一个，需要更新一下pre，表示上一个遍历的结点 if(root->leftTag == 0) //注意只有标志位是0才可以继续向下，否则就是线索了 preOrderThreaded(root->left); if(root->rightTag == 0) preOrderThreaded(root->right); } 这样，在我们进行二叉树的遍历时，会自动将其线索化，线索化完成之后就是一棵线索化二叉树了。 可以看到结点D的左右标记都是1，说明都被线索化了，并且D的左边指向的是其前一个结点B，右边指向的是后一个结点E，这样我们就成功将其线索化了。 现在我们成功得到了一棵线索化之后的二叉树，那么怎么对其进行遍历呢？我们只需要一个简单的循环就可以了： void preOrder(Node root){ //前序遍历一棵线索化二叉树非常简单 while (root) { //到头为止 printf(\"%c\", root->element); //因为是前序遍历，所以直接按顺序打印就行了 if(root->leftTag == 0) root = root->left; //如果是左孩子，那么就走左边 else root = root->right; //如果左边指向的不是孩子，而是线索，那么就直接走右边，因为右边无论是线索还是孩子，都要往这边走了 } } 我们接着来看看中序遍历的线索化二叉树，整个线索化过程我们只需要稍微调整位置就行了： Node pre = NULL; //这里我们需要一个pre来保存后续结点的指向 void inOrderThreaded(Node root){ //前序遍历线索化函数 if(root == NULL) return; if(root->leftTag == 0) inOrderThreaded(root->left); //------ 线索化 ------- 现在放到中间去，其他的还是一样的 if(root->left == NULL) { root->left = pre; root->leftTag = 1; } if(pre && pre->right == NULL) { pre->right = root; pre->rightTag = 1; } pre = root; //-------------------- if(root->rightTag == 0) inOrderThreaded(root->right); } 最后我们线索化完成之后，长这样了： 那么像这样的一棵树，我们怎么对其进行遍历呢？中序遍历要稍微麻烦一些： void inOrder(Node root){ while (root) { //因为中序遍历需要先完成左边，所以说要先走到最左边才行 while (root && root->leftTag == 0) //如果左边一直都不是线索，那么就一直往左找，直到找到一个左边是线索的为止，表示到头了 root = root->left; printf(\"%c\", root->element); //到最左边了再打印，中序开始 while (root && root->rightTag == 1) { //打印完就该右边了，右边如果是线索化之后的结果，表示是下一个结点，那么就一路向前，直到不是为止 root = root->right; printf(\"%c\", root->element); //注意按着线索往下就是中序的结果，所以说沿途需要打印 } root = root->right; //最后继续从右结点开始，重复上述操作 } } 最后我们来看看后序遍历的线索化，同样的，我们只需要在线索化时修改为后序就行了 Node pre = NULL; //这里我们需要一个pre来保存后续结点的指向 void inOrderThreaded(Node root){ //前序遍历线索化函数 if(root == NULL) return; if(root->leftTag == 0) inOrderThreaded(root->left); if(root->rightTag == 0) inOrderThreaded(root->right); //------ 线索化 ------- 现在这一坨移到最后，就是后序遍历的线索化了 if(root->left == NULL) { root->left = pre; root->leftTag = 1; } if(pre && pre->right == NULL) { pre->right = root; pre->rightTag = 1; } pre = root; //-------------------- } 线索化完成之后，变成一棵后续线索化二叉树： 后序遍历的结果看起来有点怪怪的，但是这就是后序，那么怎么对这棵线索化二叉树进行后续遍历呢？这就比较复杂了。首先后续遍历需要先完成左右，左边还好说，关键是右边，右边完事之后我们并不一定能找到对应子树的根结点，比如我们按照上面的线索，先从D开始，根据线索找到E，然后继续跟据线索找到B，但是此时B无法找到其兄弟结点C，所以说这样是行不通的，因此要完成后续遍历，我们只能对结点进行改造： typedef struct TreeNode { E element; struct TreeNode * left; struct TreeNode * right; struct TreeNode * parent; //指向双亲（父）结点 int leftTag, rightTag; } * Node; 现在每个结点都保存其父结点，这样就可以顺利地找上去了。现在我们来编写一下吧： Node pre = NULL; //这里我们需要一个pre来保存后续结点的指向 void postOrderThreaded(Node root){ //前序遍历线索化函数 if(root == NULL) return; if(root->leftTag == 0) { postOrderThreaded(root->left); if(root->left) root->left->parent = root; //左边完事之后，如果不为空，那么就设定父子关系 } if(root->rightTag == 0) { postOrderThreaded(root->right); if(root->right) root->right->parent = root; //右边完事之后，如果不为空，那么就设定父子关系 } //------ 线索化 ------- if(root->left == NULL) { root->left = pre; root->leftTag = 1; } if(pre && pre->right == NULL) { pre->right = root; pre->rightTag = 1; } pre = root; //-------------------- } 后序遍历代码如下： void postOrder(Node root){ Node last = NULL, node = root; //这里需要两个暂存指针，一个记录上一次遍历的结点，还有一个从root开始 while (node) { while (node->left != last && node->leftTag == 0) //依然是从整棵树最左边结点开始，和前面一样，只不过这里加入了防无限循环机制，看到下面就知道了 node = node->left; while (node && node->rightTag == 1) { //左边完了还有右边，如果右边是线索，那么直接一路向前，也是跟前面一样的 printf(\"%c\", node->element); //沿途打印 last = node; node = node->right; } if (node == root && node->right == last) { //上面的操作完成之后，那么当前结点左右就结束了，此时就要去寻找其兄弟结点了，我们可以 //直接通过parent拿到兄弟结点，但是如果当前结点是根结点，需要特殊处理，因为根结点没有父结点了 printf(\"%c\", node->element); return; //根节点一定是最后一个，所以说直接返回就完事 } while (node && node->right == last) { //如果当前结点的右孩子就是上一个遍历的结点，那么一直向前就行 printf(\"%c\", node->element); //直接打印当前结点 last = node; node = node->parent; } //到这里只有一种情况了，是从左子树上来的，那么当前结点的右边要么是线索要么是右子树，所以直接向右就完事 if(node && node->rightTag == 0) { //如果不是线索，那就先走右边，如果是，等到下一轮再说 node = node->right; } } } 至此，有关线索化二叉树，我们就讲解到这样。 二叉查找树 还记得我们开篇讲到的二分搜索算法吗？通过不断缩小查找范围，最终我们可以以很高的效率找到有序数组中的目标位置。而二叉查找树则利用了类似的思想，我们可以借助其来像二分搜索那样快速查找。 二叉查找树也叫二叉搜索树或是二叉排序树，它具有一定的规则： 左子树中所有结点的值，均小于其根结点的值。 右子树中所有结点的值，均大于其根结点的值。 二叉搜索树的子树也是二叉搜索树。 一棵二叉搜索树长这样： 这棵树的根结点为18，而其根结点左边子树的根结点为10，包括后续结点，都是满足上述要求的。二叉查找树满足左边一定比当前结点小，右边一定比当前结点大的规则，比如我们现在需要在这颗树种查找值为15的结点： 从根结点18开始，因为15小于18，所以从左边开始找。 接着来到10，发现10比15小，所以继续往右边走。 来到15，成功找到。 实际上，我们在对普通二叉树进行搜索时，可能需要挨个进行查看比较，而有了二叉搜索树，查找效率就大大提升了，它就像我们前面的二分搜索那样。 因为二叉搜索树要求比较严格，所以我们在插入结点时需要遵循一些规律，这里我们来尝试编写一下： #include #include typedef int E; typedef struct TreeNode { E element; struct TreeNode * left; struct TreeNode * right; } * Node; Node createNode(E element){ Node node = malloc(sizeof(struct TreeNode)); node->left = node->right = NULL; node->element = element; return node; } int main() { } 我们就以上面这颗二叉查找树为例，现在我们想要依次插入这些结点，我们需要编写一个特殊的插入操作，这里需要注意一下，二叉查找树不能插入重复元素，如果出现重复直接忽略： Node insert(Node root, E element){ if(root){ if(root->element > element) //如果插入结点值小于当前结点，那么说明应该放到左边去 root->left = insert(root->left, element); else if(root->element right = insert(root->right, element); } else { //当结点为空时，说明已经找到插入的位置了，创建对应结点 root = createNode(element); } return root; //返回当前结点 } 这样我们就可以通过不断插入创建一棵二叉查找树了： void inOrder(Node root){ if(root == NULL) return; inOrder(root->left); printf(\"%d \", root->element); inOrder(root->right); } int main() { Node root = insert(NULL, 18); //插入后，得到根结点 inOrder(root); //用中序遍历查看一下结果 } 我们按照顺序来，首先是根结点的左右孩子，分别是10和20，那么这里我们就依次插入一下： int main() { Node root = insert(NULL, 18); //插入后，得到根结点 insert(root, 10); insert(root, 20); inOrder(root); } 可以看到中序结果为： 比18小的结点在左边，大的在右边，满足二叉查找树的性质。接着是7、15、22： 最后再插入9就是我们上面的这棵二叉查找树了。当然我们直接写成控制台扫描的形式，就更方便了： int main() { Node root = NULL; while (1) { E element; scanf(\"%d\", &element); root = insert(root, element); inOrder(root); putchar('\\n'); } } 那么插入写好之后，我们怎么找到对应的结点呢？实际上也是按照规律来就行了： Node find(Node root, E target){ while (root) { if(root->element > target) //如果要找的值比当前结点小，说明肯定在左边 root = root->left; else if(root->element right; else return root; //等于的话，说明找到了，就直接返回 } return NULL; //都找到底了还没有，那就是真没有了 } Node findMax(Node root){ //查找最大值就更简单了，最右边的一定是最大的 while (root && root->right) root = root->right; return root; } 我们来尝试查找一下： int main() { Node root = insert(NULL, 18); //插入后，得到根结点 insert(root, 10); insert(root, 20); insert(root, 7); insert(root, 15); insert(root, 22); insert(root, 9); printf(\"%p\\n\", find(root, 17)); printf(\"%p\\n\", find(root, 9)); } 搜索17的结果为NULL，说明没有这个结点，而9则成功找到了。 最后我们来看看二叉查找树的删除操作，这个操作就比较麻烦了，因为可能会出现下面的几种情况： 要删除的结点是叶子结点。 要删除的结点是只有一个孩子结点。 要删除的结点有两个孩子结点。 首先我们来看第一种情况，这种情况实际上最好办，直接删除就完事了： 而第二种情况，就有点麻烦了，因为有一个孩子，就像一个拖油瓶一样，你离开了还不行，你还得对他负责才可以。当移除后，需要将孩子结点连接上去： 可以看到在调整后，依然满足二叉查找树的性质。最后是最麻烦的有两个孩子的情况，这种该怎么办呢？前面只有一个孩子直接上位就完事，但是现在两个孩子，到底谁上位呢？这就不好办了，为了保持二叉查找树的性质，现在有两种选择： 选取其左子树中最大结点上位 选择其右子树中最小结点上位 这里我们以第一种方式为例： 现在我们已经分析完三种情况了，那么我们就来编写一下代码吧： Node delete(Node root, E target){ if(root == NULL) return NULL; //都走到底了还是没有找到要删除的结点，说明没有，直接返回空 if(root->element > target) //这里的判断跟之前插入是一样的，继续往后找就完事，直到找到为止 root->left = delete(root->left, target); else if(root->element right = delete(root->right, target); else { //这种情况就是找到了 if(root->left && root->right) { //先处理最麻烦的左右孩子都有的情况 Node max = findMax(root->left); //寻找左子树中最大的元素 root->element = max->element; //找到后将值替换 root->left = delete(root->left, root->element); //替换好后，以同样的方式去删除那个替换上来的结点 } else { //其他两种情况可以一起处理，只需要删除这个结点就行，然后将root指定为其中一个孩子，最后返回就完事 Node tmp = root; if(root->right) { //不是左边就是右边 root = root->right; } else { root = root->left; } free(tmp); //开删 } } return root; //返回最终的结点 } 这样，我们就完成了二叉查找树的各种操作，当然目前为止我们了解的二叉树高级结构还比较简单，后面就开始慢慢复杂起来了。 平衡二叉树 前面我们介绍了二叉查找树，利用二叉查找树，我们在搜索某个值的时候，效率会得到巨大提升。但是虽然看起来比较完美，也是存在缺陷的，比如现在我们依次将下面的值插入到这棵二叉树中： 20 15 13 8 6 3 在插入完成后，我们会发现这棵二叉树竟然长这样： 因为根据我们之前编写的插入规则，小的一律往左边放，现在正好来的就是这样一串递减的数字，最后就组成了这样的一棵只有一边的二叉树，这种情况，与其说它是一棵二叉树，不如说就是一个链表，如果这时我们想要查找某个结点，那么实际上查找的时间并没有得到任何优化，直接就退化成线性查找了。 所以，二叉查找树只有在理想情况下，查找效率才是最高的，而像这种极端情况，就性能而言几乎没有任何的提升。我们理想情况下，这样的效率是最高的： 所以，我们在进行结点插入时，需要尽可能地避免这种一边倒的情况，这里就需要引入平衡二叉树的概念了。实际上我们发现，在插入时如果不去维护二叉树的平衡，某一边只会无限制地延伸下去，出现极度不平衡的情况，而我们理想中的二叉查找树左右是尽可能保持平衡的，平衡二叉树（AVL树）就是为了解决这样的问题而生的。 它的性质如下： 平衡二叉树一定是一棵二叉查找树。 任意结点的左右子树也是一棵平衡二叉树。 从根节点开始，左右子树都高度差不能超过1，否则视为不平衡。 可以看到，这些性质规定了平衡二叉树需要保持高度平衡，这样我们的查找效率才不会因为数据的插入而出现降低的情况。二叉树上节点的左子树高度 减去 右子树高度， 得到的结果称为该节点的平衡因子（Balance Factor），比如： 通过计算平衡因子，我们就可以快速得到是否出现失衡的情况。比如下面的这棵二叉树，正在执行插入操作： 可以看到，当插入之后，不再满足平衡二叉树的定义时，就出现了失衡的情况，而对于这种失衡情况，为了继续保持平衡状态，我们就需要进行处理了。我们可能会遇到以下几种情况导致失衡： 根据插入结点的不同偏向情况，分为LL型、LR型、RR型、RL型。针对于上面这几种情况，我们依次来看一下如何进行调整，使得这棵二叉树能够继续保持平衡： 动画网站：https://www.cs.usfca.edu/~galles/visualization/AVLtree.html（实在不理解可以看看动画是怎么走的） LL型调整（右旋） 首先我们来看这种情况，这是典型的LL型失衡，为了能够保证二叉树的平衡，我们需要将其进行旋转来维持平衡，去纠正最小不平衡子树即可。那么怎么进行旋转呢？对于LL型失衡，我们只需要进行右旋操作，首先我们先找到最小不平衡子树，注意是最小的那一个： 可以看到根结点的平衡因子是2，是目前最小的出现不平衡的点，所以说从根结点开始向左的三个结点需要进行右旋操作，右旋需要将这三个结点中间的结点作为新的根结点，而其他两个结点现在变成左右子树： 这样，我们就完成了右旋操作，可以看到右旋之后，所有的结点继续保持平衡，并且依然是一棵二叉查找树。 RR型调整（左旋） 前面我们介绍了LL型以及右旋解决方案，相反的，当遇到RR型时，我们只需要进行左旋操作即可： 操作和上面是一样的，只不过现在反过来了而已： 这样，我们就完成了左旋操作，使得这棵二叉树继续保持平衡状态了。 RL型调整（先右旋，再左旋） 剩下两种类型比较麻烦，需要旋转两次才行。我们来看看RL型长啥样： 可以看到现在的形状是一个回旋镖形状的，先右后左的一个状态，也就是RL型，针对于这种情况，我们需要先进行右旋操作，注意这里的右旋操作针对的是后两个结点： 其中右旋和左旋的操作，与之前一样，该怎么分配左右子树就怎么分配，完成两次旋转后，可以看到二叉树重新变回了平衡状态。 LR型调整（先左旋，再右旋） 和上面一样，我们来看看LR型长啥样，其实就是反着的： 形状是先向左再向右，这就是典型的LR型了，我们同样需要对其进行两次旋转： 这里我们先进行的是左旋，然后再进行的右旋，这样二叉树就能继续保持平衡了。 这样，我们只需要在插入结点时注意维护整棵树的平衡因子，保证其处于稳定状态，这样就可以让这棵树一直处于高度平衡的状态，不会再退化了。这里我们就编写一个插入结点代码来实现一下吧，首先还是结点定义： typedef int E; typedef struct TreeNode { E element; struct TreeNode * left; struct TreeNode * right; int height; //每个结点需要记录当前子树的高度，便于计算平衡因子 } * Node; Node createNode(E element){ Node node = malloc(sizeof(struct TreeNode)); node->left = node->right = NULL; node->element = element; node->height = 1; //初始化时，高度写为1就可以了 return node; } 接着我们需要先将左旋、右旋等操作编写出来，因为一会插入时可能需要用到： int max(int a, int b){ return a > b ? a : b; } int getHeight(Node root){ if(root == NULL) return 0; return root->height; } Node leftRotation(Node root){ //左旋操作，实际上就是把左边结点拿上来 Node newRoot = root->right; //先得到左边结点 root->right = newRoot->left; //将左边结点的左子树丢到原本根结点的右边去 newRoot->left = root; //现在新的根结点左边就是原本的跟结点了 root->height = max(getHeight(root->right), getHeight(root->left)) + 1; newRoot->height = max(getHeight(newRoot->right), getHeight(newRoot->left)) + 1; return newRoot; } Node rightRotation(Node root){ Node newRoot = root->left; root->left = newRoot->right; newRoot->right = root; root->height = max(getHeight(root->right), getHeight(root->left)) + 1; newRoot->height = max(getHeight(newRoot->right), getHeight(newRoot->left)) + 1; return newRoot; } Node leftRightRotation(Node root){ root->left = leftRotation(root->left); return rightRotation(root); } Node rightLeftRightRotation(Node root){ root->right = rightRotation(root->right); return leftRotation(root); } 最后就是我们的插入操作了，注意在插入时动态计算树的高度，一旦发现不平衡，那么就立即采取对应措施： Node insert(Node root, E element){ if(root == NULL) { //如果结点为NULL，说明找到了插入位置，直接创建新的就完事 root = createNode(element); }else if(root->element > element) { //和二叉搜索树一样，判断大小，该走哪边走哪边，直到找到对应插入位置 root->left = insert(root->left, element); if(getHeight(root->left) - getHeight(root->right) > 1) { //插入完成之后，需要计算平衡因子，看看是否失衡 if(root->left->element > element) //接着需要判断一下是插入了左子树的左边还是右边，如果是左边那边说明是LL，如果是右边那说明是LR root = rightRotation(root); //LL型得到左旋之后的结果，得到新的根结点 else root = leftRightRotation(root); //LR型得到先左旋再右旋之后的结果，得到新的根结点 } }else if(root->element right = insert(root->right, element); if(getHeight(root->left) - getHeight(root->right) right->element height = max(getHeight(root->left), getHeight(root->right)) + 1; return root; //最后返回root到上一级 } 这样，我们就完成了平衡二叉树的插入操作，当然删除操作比较类似，也是需要在删除之后判断是否平衡，如果不平衡同样需要进行旋转操作，这里就不做演示了。 红黑树 注意：本小节内容作为选学内容，不强制要求掌握。很多人都说红黑树难，其实就那几条规则，跟着我推一遍其实还是很简单的，当然前提是一定要把前面的平衡二叉树搞明白。 前面我们讲解了二叉平衡树，通过在插入结点时维护树的平衡，这样就不会出现极端情况使得整棵树的查找效率急剧降低了。但是这样是否开销太大了一点，因为一旦平衡因子的绝对值超过1那么就失衡，这样每插入一个结点，就有很大的概率会导致失衡，我们能否不这么严格，但同时也要在一定程度上保证平衡呢？这就要提到红黑树了。 在线动画网站：https://www.cs.usfca.edu/~galles/visualization/RedBlack.html 红黑树也是二叉查找树的一种，它大概长这样，可以看到结点有红有黑： 它并不像平衡二叉树那样严格要求高度差不能超过1，而是只需要满足五个规则即可，它的规则如下： 规则1：每个结点可以是黑色或是红色。 规则2：根结点一定是黑色。 规则3：红色结点的父结点和子结点不能为红色，也就是说不能有两个连续的红色。 规则4：所有的空结点都是黑色（空结点视为NIL，红黑树中是将空节点视为叶子结点） 规则5：每个结点到空节点（NIL）路径上出现的黑色结点的个数都相等。 它相比平衡二叉树，通过不严格平衡和改变颜色，就能在一定程度上减少旋转次数，这样的话对于整体性能是有一定提升的，只不过我们在插入结点时，就有点麻烦了，我们需要同时考虑变色和旋转这两个操作了，但是会比平衡二叉树更简单。 那么什么时候需要变色，什么时候需要旋转呢？我们通过一个简单例子来看看： 首先这棵红黑树只有一个根结点，因为根结点必须是黑色，所以说直接变成黑色。现在我们要插入一个新的结点了，所有新插入的结点，默认情况下都是红色： 所以新来的结点7根据规则就直接放到11的左边就行了，然后注意7的左右两边都是NULL，那么默认都是黑色，这里就不画出来了。同样的，我们往右边也来一个： 现在我们继续插入一个结点： 插入结点4之后，此时违反了红黑树的规则3，因为红色结点的父结点和子结点不能为红色，此时为了保持以红黑树的性质，我们就需要进行颜色变换才可以，那么怎么进行颜色变换呢？我们只需要直接将父结点和其兄弟结点同时修改为黑色（为啥兄弟结点也需要变成黑色？因为要满足性质5）然后将爷爷结点改成红色即可： 当然这里还需注意一下，因为爷爷结点正常情况会变成红色，相当于新来了个红色的，这时还得继续往上看有没有破坏红黑树的规则才可以，直到没有为止，比如这里就破坏了性质一，爷爷结点现在是根结点（不是根结点就不需要管了），必须是黑色，所以说还要给它改成黑色才算结束： 接着我们继续插入结点： 此时又来了一个插在4左边的结点，同样是连续红色，我们需要进行变色才可以讲解问题，但是我们发现，如果变色的话，那么从11开始到所有NIL结点经历的黑色结点数量就不对了： 所以说对于这种父结点为红色，父结点的兄弟结点为黑色（NIL视为黑色）的情况，变色无法解决问题了，那么我们只能考虑旋转了，旋转规则和我们之前讲解的平衡二叉树是一样的，这实际上是一种LL型失衡： 同样的，如果遇到了LR型失衡，跟前面一样，先左旋在右旋，然后进行变色即可： 而RR型和RL型同理，这里就不进行演示了，可以看到，红黑树实际上也是通过颜色规则在进行旋转调整的，当然旋转和变色的操作顺序可以交换。所以，在插入时比较关键的判断点如下： 如果整棵树为NULL，直接作为根结点，变成黑色。 如果父结点是黑色，直接插入就完事。 如果父结点为红色，且父结点的兄弟结点也是红色，直接变色即可（但是注意得继续往上看有没有破坏之前的结构） 如果父结点为红色，但父结点的兄弟结点为黑色，需要先根据情况（LL、RR、LR、RL）进行旋转，然后再变色。 在了解这些步骤之后，我们其实已经可以尝试去编写一棵红黑树出来了，当然代码太过复杂，这里就不演示了。其实红黑树难点并不在于如何构建和使用，而是在于，到底是怎么设计出来的，究竟要多么丰富的知识储备才能想到如此精妙的规则。 红黑树的发明者： 红黑树（Red Black Tree） 是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。 红黑树是在1972年由Rudolf Bayer发明的，当时被称为平衡二叉B树（symmetric binary B-trees）。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的“红黑树”。 在了解了后面的B树之后，相信我们就能揭开这层神秘面纱了。 其他树结构 前面我们介绍了各种各样的二叉树，其实还是比较简单的。我们接着来看一下其他的一些树结构，这一部分我们只做了解即可。 B树和B+树 前面我们介绍了多种多样的二叉树，有线索化二叉树，平衡二叉树等等，这些改造版二叉树无疑都是为了提高我们的程序运行效率而生的，我们接着来看一种同样为了提升效率的树结构。 这里首先介绍一下B树（Balance Tree），它是专门为磁盘数据读取设计的一种度为 m 的查找树（多用于数据库）它同样是一棵平衡树，但是不仅限于二叉了，之前我们介绍的这些的二叉树都是基于内存读取的优化，磁盘读取速度更慢，它同样需要优化，一棵度为4的（4阶）B树大概长这样： 第一眼看上去，感觉好像没啥头绪，不能发现啥规律，但是只要你仔细观察，你会发现，它和二叉查找树很相似，左边的一定比根节点小，右边的一定比根节点大，并且我们发现，每个结点现在可以保存多个值，每个结点可以连接多个子树，这些值两两组合划分了一些区间，比如60左边，一定是比60小的，60和80之间那么就是大于60小于80的值，以此类推，所以值有N个，就可以划分出N+1个区间，那么子树最多就可以有N+1个。它的详细规则如下： 树中每个结点最多含有m个孩子（m >= 2）比如上面就是m为4的4阶B树，最多有4个孩子。 除根结点和叶子结点外，其它每个结点至少有⌈m/2⌉个孩子，同理键值数量至少有⌈m/2⌉-1个。 若根结点不是叶子结点，则至少有2个孩子。 所有叶子结点都出现在同一层。 一个结点的包含多种信息（P0，K1，P1，K2，…，Kn，Pn），其中P为指向子树的指针，K为键值（关键字） Ki (i=1...n)为键值，也就是每个结点保存的值，且键值按顺序升序排序K(i-1) Pi为指向子树的指针，且指针Pi指向的子树中所有结点的键值均小于Ki，但都大于K(i-1) 键值的个数n必须满足： ⌈m/2⌉-1 在线动画网站：https://www.cs.usfca.edu/~galles/visualization/BTree.html 是不是感觉怎么要求这么多呢？我们通过感受一下B树的插入和删除就知道了，首先是B树的插入操作，这里我们以度为3的B树为例： 插入1之后，只有一个结点，我们接着插入一个2，插入元素满足以下规则： 如果该节点上的元素数未满，则将新元素插入到该节点，并保持节点中元素的顺序。 所以，直接放进去就行，注意顺序： 接着我们再插入一个3进去，但是此时因为度为3，那么键值最多只能有两个，肯定是装不下了： 如果该节点上的元素已满，则需要将该节点平均地分裂成两个节点： 首先从该节点中的所有元素和新元素中先出一个中位数作为分割值。 小于中位数的元素作为左子树划分出去，大于中位数的元素作为右子树划分。 分割值此时上升到父结点中，如果没有父结点，那么就创建一个新的（这里的上升不太好理解，一会我们推过去就明白了） 所以，当3来了之后，直接进行分裂操作： 就像爱情一样，两个人的世界容不下第三者，如果来了第三者，那么最后的结果大概率就是各自分道扬镳。接着我们继续插入4、5看看会发生什么，注意插入还是按照小的走左边，大的走右边的原则，跟我们之前的二叉查找树是一样的： 此时4、5来到了右边，现在右边这个结点又被撑爆了，所以说需要按照上面的规则，继续进行分割： 可能各位看着有点奇怪，为啥变成这样了，首先3、4、5三个都分开了，然后4作为分割值，3、5变成两个独立的树，此时4需要上升到父结点，所以直接跑到上面去了，然后3和5出现在4的左右两边。注意这里不是向下划分，反而有点向上划分的意思。为什么不向下划分呢？因为要满足B树第四条规则：所有叶子结点都出现在同一层。 此时我们继续插入6、7，看看会发生什么情况： 此时右下角结点又被挤爆了，右下角真是多灾多难啊，那么依然按照我们之前的操作进行分裂： 我们发现当新的分割值上升之后最上面的结点又被挤爆了，此时我们需要继续分裂： 在2、4、6中寻找一个新的分割值，分裂后将其上升到新的父结点中，就像上图那样了。在了解了B树的插入操作之后，是不是有一点感受到这种结构带来的便捷了？ 我们再来看看B树的删除操作，这个要稍微麻烦一些，这里我们以一颗5阶B树为例，现在我们想删除16结点： 删除后，依然满足B树的性质，所以说什么都不管用： 此时我们接着去删除15结点： 删除后，现在结点中只有14了，不满足B树的性质：除根结点和叶子结点外，其它每个结点至少有⌈m/2⌉个孩子，同理键值数量至少有⌈m/2⌉-1个，现在只有一个肯定是不行的。此时我们需向兄弟（注意只能找左右两边的兄弟）借一个过来： 此时我们继续删掉17，但是兄弟已经没办法再借给我们一个元素了，此时只能采取方案二，合并兄弟节点与分割键。这里我们就合并左边的这个兄弟吧： 现在他们三个又合并回去了，这下总满足了吧？但是我们发现，父结点此时只有一个元素了，又出问题了。同样的，还是先去找兄弟结点借一个，但是兄弟结点也借不了了，此时继续采取我们的方案二，合并： OK，这样才算是满足了B树的性质，现在我们继续删除4结点： 这种情况会导致失去分割值，那么我们得找一个新的分割值才行，这里取左边最大的： 不过此时虽然解决了分割值的问题，但是新的问题来了，左边结点不满足性质了，元素数量低于限制，于是需要找兄弟结点借，但是没得借了，兄弟也没有多的可以借了所以被迫合并了： 可以看到整个变换过程中，这颗B树所有子树的高度是一直维持在一个稳定状态的，查找效率能够持续保持。 删除操作可以总结为两大类： 若删除的是叶子结点的中元素： 正常情况下直接删除。 如果删除后，键值数小于最小值，那么需要找兄弟借一个。 要是没得借了，直接跟兄弟结点、对应的分割值合并。 若删除的是某个根结点中的元素： 一般情况会删掉一个分割值，删掉后需要重新从左右子树中找一个新分割值的拿上来。 要是拿上来之后左右子树中出现键值数小于最小值的情况，那么就只能合并了。 上述两个操作执行完后，还要继续往上看上面的结点是否依然满足性质，否则继续处理，直到稳定。 在了解了B树的相关操作之后，是不是感觉还是挺简单的，依然是动态维护树的平衡。正是得益于B树这种结点少，高度平衡且有序的性质，而硬盘IO速冻远低于内存，我们希望能够花费尽可能少的时间找到我们想要的数据，减少IO次数，B树就非常适合在硬盘上的保存数据，它的查找效率是非常高的。 注意：以下内容为选学部分： 此时此刻，我们回想一下之前提到的红黑树，我们来看看它和B树有什么渊源，这是一棵很普通的红黑树： 此时我们将所有红色节点上移到与父结点同一高度， 还是没看出来？没关系，我们来挨个画个框： woc，这不就是B树吗？没错，红黑树 和 4阶B树（2-3-4树）具有等价性，其中黑色结点就是中间的（黑色结点一定是父结点)，红色结点分别位于两边，通过将黑色结点与它的红色子节点融合在一起，形成1个B树节点，最后就像这样： 你会发现，红黑树的黑色节点个数总是与4阶B树的节点数相等。我们可以对比一下之前的红黑树插入和4阶B树的插入，比如现在我们想要插入一个新的14结点进来： 经过变色，最后得到如下的红黑树，此时又出现两个红色结点连续，因为父结点的兄弟结点依然是红色，继续变色： 最后因为根结点必须是黑色，所以说将60变为黑色，这样就插入成功了： 我们再来看看与其等价的B树插入14后会怎么样： 由于B树的左边被挤爆了，所以说需要分裂，因为是偶数个，需要选择中间偏右的那个数作为分割值，也就是25： 分裂后，分割值上升，又把父结点给挤爆了，所以说需要继续分裂： 现在就变成了这样，我们来对比一下红黑树： 不能说很像，只能说是一模一样啊。为什么呢？明明这两种树是不同的规则啊，为什么会出现等价的情况呢？ B树叶节点等深实际上体现在红黑树中为任一叶节点到达根节点的路径中，黑色路径所占的长度是相等的，因为黑色结点就是B树的结点分割值。 B树节点的键值数量不能超过N实际上体现在红黑树约定相邻红色结点接最多2条，也就是说不可能出现B树中元素超过3的情况，因为是4阶B树。 所以说红黑树跟4阶B树是有一定渊源的，甚至可以说它就是4阶B树的变体。 前面我们介绍了B树，现在我们就可以利用B树来高效存储数据了，当然我们还可以让它的查找效率更高。这里我们就要提到B+树了，B+树是B树的一种变体，有着比B树更高的查询性能。 有k个子树的中间结点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据（卫星数据，就是具体需要保存的内容）都保存在叶子结点。 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点按照从小到大的顺序连接。 所有的根结点元素都同时存在于子结点中，在子节点元素中是最大（或最小）元素。 我们来看看一棵B+树长啥样： 其中最后一层形成了一个有序链表，在我们需要顺序查找时，提供了极大的帮助。可以看到现在除了最后一层之外，其他结点中存放的值仅仅充当了一个指路人的角色，来告诉你你需要的数据在哪一边，比如根节点有10和18，因为这里是取得最大值，那么整棵树最大的元素就是18了，我们现在需要寻找一个小于18大于10的数，就可以走右边去查找。而具体的数据会放到最下面的叶子结点中，比如数据库就是具体的某一行数据（卫星数据）存放在最下面： 当然，目前可能你还没有接触过数据库，在以后的学习中，你一定会接触到它的，到时你就会发现新世界。 它不像B树那样，B树并不是只有最后一行会存储卫星数据，此时比较凌乱。因为只有最后一行存储卫星数据，使用B+树，同样大小的磁盘页可以容纳更多的节点元素，这就意味着，数据量相同的情况下B+树比B树高度更低，减小磁盘IO的次数。其次，B+树的查询必须最终查找到叶子节点，而B树做的是值匹配，到达结点之后并不一定能够匹配成功，所以B树的查找性能并不稳定，最好的情况是只查根节点即可，而最坏的情况则需要查到叶子节点，但是B+树每一次查找都是稳定的，因为一定在叶子结点。 并且得益于最后一行的链表结构，B+树在做范围查询时性能突出。很多数据库都在采用B+树作为底层数据结构，比如MySQL就默认选择B+Tree作为索引的存储数据结构。 至此，有关B树和B+树相关内容，就到这里。 哈夫曼树 最后我们来介绍一个比较重要的的树形结构，在开篇之前，我想问下，各位了解文件压缩吗？它是怎么做到的呢？我们都会在这一节进行探讨。 给定N个权值作为N个叶子结点，构造一棵二叉树，若该树的带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树（Huffman Tree） 乍一看好像没看懂，啥叫带权路径长度达到最小？就是树中所有的叶结点的权值乘上其到根结点根结点的路径长度（若根结点为0层，叶结点到根结点的路径长度为叶结点的层数） 这里我们分别将叶子结点ABCD都赋予一个权值，我们来尝试计算一下，计算公式如下： $$ WPL = \\sum_{i=1}^{n} (value(i) \\times depth(i)) $$ 那么左右两边的计算结果为： 左图： $WPL=5\\times2+7\\times2+2\\times2+13\\times2=54$ 右图：$WPL=5\\times3+2\\times3+7\\times2+13\\times1=48$ 通过计算结果可知，右图的带权路径长度最小，实际上右图是一棵哈夫曼树。 那么现在给了我们这些带权的叶子结点，我们怎么去构建一颗哈夫曼树呢？首先我们可以将这些结点视为4棵树，他们共同构成了一片森林： 首先我们选择两棵权值最小的树作为一颗新的树的左右子树，左右顺序不重要（因为哈夫曼编码不唯一，后面会说），得到的树根结点权值为这两个结点之和： 接着，我们需要将这这棵树放回到森林中，重复上面的操作，继续选择两个最小的出来组成一颗新的树，此时得到： 继续重复上述操作，直到森林里面只剩下一棵树为止： 这样，我们就得到了一棵哈夫曼树，因为只要保证越大的值越靠近根结点，那么出来的一定是哈夫曼树。所以，我们辛辛苦苦把这棵树构造出来干嘛呢？实际上哈夫曼树的一个比较重要应用就是对数据进行压缩，它是现代压缩算法的基础，我们常常可以看到网上很多文件都是以压缩包（.zip、.7z、.rar等格式）形式存在的，我们将文件压缩之后。 比如这一堆字符串：ABCABCD，现在我们想要将其进行压缩然后保存到硬盘上，此时就可以使用哈夫曼编码。那么怎么对这些数据进行压缩呢？这里我们就可以采用刚刚构建好的哈夫曼树，我们需要先对其进行标注： 向左走是0，向右走是1，比如现在我们要求出A的哈夫曼编码，那么就是根结点到A整条路径上的值拼接： A：110 B：0 C：111 D：10 这些编码看起来就像二进制的一样，也便于我们计算机的数据传输和保存，现在我们要对上面的这个字符串进行压缩，那么只需要将其中的每一个字符翻译为对应编码就行了： ABCABCD = 110 0 111 110 0 111 10 这样我们就得到了一堆压缩之后的数据了。那怎么解码回去呢，也很简单，只需要对照着写回去就行了： 110 0 111 110 0 111 10 = ABCABCD 我们来尝试编写一下代码实现一下哈夫曼树的构建和哈夫曼编码的获取把，因为构建哈夫曼树需要选取最小的两个结点，这里需要使用到优先级队列。 优先级队列与普通队列不同，它允许VIP插队（权值越大的元素优先排到前面去），当然出队还是一律从队首出来。 比如一开始4和9排在队列中，这时又来了个7，那么由于7比4大，所以说可以插队，直接排到4的前面去，但是由于9比7大，所以说不能再往前插队了： 这就是优先级队列，VIP插队机制，要实现这样的优先级队列，我们只需要修改一下入队操作即可： _Bool initQueue(LinkedQueue queue){ LNode node = malloc(sizeof(struct LNode)); if(node == NULL) return 0; queue->front = queue->rear = node; node->next = NULL; //因为下面用到了判断结点的下一个为NULL，所以说记得默认设定为NULL return 1; } _Bool offerQueue(LinkedQueue queue, T element){ LNode node = malloc(sizeof(struct LNode)); if(node == NULL) return 0; node->element = element; node->next = NULL; //因为下面用到了判断结点的下一个为NULL，所以说记得默认设定为NULL LNode pre = queue->front; //我们从头结点开始往后挨个看，直到找到第一个小于当前值的结点，或者到头为止 while (pre->next && pre->next->element >= element) pre = pre->next; if(pre == queue->rear) { //如果说找到的位置已经是最后了，那么直接插入就行，这里跟之前是一样的 queue->rear->next = node; queue->rear = node; } else { //否则开启VIP模式，直接插队 node->next = pre->next; pre->next = node; } return 1; } 我们来测试一下吧： int main(){ struct Queue queue; initQueue(&queue); offerQueue(&queue, 9); offerQueue(&queue, 4); offerQueue(&queue, 7); offerQueue(&queue, 3); offerQueue(&queue, 13); printQueue(&queue); } 这样我们就编写好了一个优先级队列，然后就可以开始准备构建哈夫曼树了： typedef char E; typedef struct TreeNode { E element; struct TreeNode * left; struct TreeNode * right; int value; //存放权值 } * Node; 首先按照我们前面的例子，构建出这四个带权值的结点： Node createNode(E element, int value){ //创建一个结点 Node node = malloc(sizeof(struct TreeNode)); node->element = element; node->left = node->right = NULL; node->value = value; return node; } _Bool offerQueue(LinkedQueue queue, T element){ LNode node = malloc(sizeof(struct LNode)); if(node == NULL) return 0; node->element = element; node->next = NULL; LNode pre = queue->front; while (pre->next && pre->next->element->value value) //注意这里改成权重的比较，符号改成小于 pre = pre->next; if(pre == queue->rear) { queue->rear->next = node; queue->rear = node; } else { node->next = pre->next; pre->next = node; } return 1; } 现在我们来测试一下吧： int main(){ struct Queue queue; initQueue(&queue); offerQueue(&queue, createNode('A', 5)); offerQueue(&queue, createNode('B', 16)); offerQueue(&queue, createNode('C', 8)); offerQueue(&queue, createNode('D', 13)); printQueue(&queue); } 已经是按照权重顺序在排队了，接着我们就可以开始构建哈夫曼树了： int main(){ struct Queue queue; initQueue(&queue); offerQueue(&queue, createNode('A', 5)); offerQueue(&queue, createNode('B', 16)); offerQueue(&queue, createNode('C', 8)); offerQueue(&queue, createNode('D', 13)); while (queue.front->next != queue.rear) { //如果front的下一个就是rear那么说明队列中只有一个元素了 Node left = pollQueue(&queue); Node right = pollQueue(&queue); Node node = createNode(' ', left->value + right->value); //创建新的根结点 node->left = left; node->right = right; offerQueue(&queue, node); //最后将构建好的这棵树入队 } Node root = pollQueue(&queue); //最后出来的就是哈夫曼树的根结点了 } 现在得到哈夫曼树之后，我们就可以对这些字符进行编码了，当然注意我们这里面只有ABCD这几种字符： char * encode(Node root, E e){ if(root == NULL) return NULL; //为NULL肯定就是没找到 if(root->element == e) return \"\"; //如果找到了就返回一个空串 char * str = encode(root->left, e); //先去左边找 char * s = malloc(sizeof(char) * 10); if(str != NULL) { s[0] = '0'; str = strcat(s, str); //如果左边找到了，那么就把左边的已经拼好的字符串拼接到当前的后面 } else { //左边不行那再看看右边 str = encode(root->right, e); if(str != NULL) { s[0] = '1'; str = strcat(s, str); //如果右边找到了，那么就把右边的已经拼好的字符串拼接到当前的后面 } } return str; //最后返回操作好的字符串给上一级 } void printEncode(Node root, E e){ printf(\"%c 的编码为：%s\", e, encode(root, e)); //编码的结果就是了 putchar('\\n'); } 最后测试一下吧： int main(){ struct Queue queue; initQueue(&queue); ... Node root = pollQueue(&queue); printEncode(root, 'A'); printEncode(root, 'B'); printEncode(root, 'C'); printEncode(root, 'D'); } 成功得到对应的编码： 堆和优先级队列 前面我们在讲解哈夫曼树时了解了优先级队列，它提供一种可插队的机制，允许权值大的结点排到前面去，但是出队顺序还是从队首依次出队。我们通过对前面的队列数据结构的插入操作进行改造，实现了优先级队列。 这节课我们接着来了解一下堆（Heap）它同样可以实现优先级队列。 首先必须是一棵完全二叉树，树中父亲都比孩子小的我们称为小根堆（小顶堆），树中父亲都比孩子大则是大根堆（注意不要跟二叉查找树搞混了，二叉查找树是左小右大，而堆只要是孩子一定小或者大），它是一颗具有特殊性质的完全二叉树。比如下面就是一个典型的大根堆： 因为完全二叉树比较适合使用数组才存储（因为是按序的）所以说一般堆都是以数组形式存放： 那么它是怎么运作的呢？比如现在我们想要往堆中插入一个新的元素8，那么： 因为是一棵完全二叉树，那么必须按照顺序，继续在当前这一行从左往右插入新的结点，其实就相当于在数组的后面继续加一个新的进来，是一样的。但是因为要满足大顶堆的性质，所以此时8加入之后，破坏了规则，我们需要进行对应的调整（堆化），很简单，我们只需要将其与父结点交换即可： 同样的，数组的形式的话，我们就行先计算出它的父结点，然后进行交换即可： 当然，还没完，我们还需要继续向上比较，直到稳定为止，此时7依然是小于8的，所以说需要继续交换： 现在满足性质了，堆化结束，可以看到最大的元素被排到了最前面，这不就是我们前面的优先级队列吗。 现在我们来试试看删除队首元素，也就相当于出队操作，删除最顶上的元素： 现在需要删除最顶上的元素但是我们需要保证删除之后依然是一棵完全二叉树，所以说我们先把排在最后面的拿上来顶替一下： 接着我们需要按照与插入相反的方向，从上往下进行堆化操作，规则是一样的，遇到大的就交换，直到不是为止： 这样，我们发现，即使完成了出队操作，依然是最大的元素排在队首，并且整棵树依然是一棵完全二叉树。 按照上面的操作，我们来编写一下代码吧，这里还是以大顶堆为例： typedef int E; typedef struct MaxHeap { E * arr; int size; int capacity; } * Heap; _Bool initHeap(Heap heap){ //初始化都是老套路了，不多说了 heap->size = 0; heap->capacity = 10; heap->arr = malloc(sizeof (E) * heap->capacity); return heap->arr != NULL; } int main(){ struct MaxHeap heap; initHeap(&heap); } 接着就是插入操作，首先还是需要判断是否已满： _Bool insert(Heap heap, E element){ if(heap->size == heap->capacity) return 0; //满了就不处理了，主要懒得写扩容了 int index = ++heap->size; //先计算出要插入的位置，注意要先自增，因为是从1开始的 //然后开始向上堆化，直到符合规则为止 while (index > 1 && element > heap->arr[index / 2]) { heap->arr[index] = heap->arr[index / 2]; index /= 2; } //现在得到的index就是最终的位置了 heap->arr[index] = element; return 1; } 我们来测试一下吧： void printHeap(Heap heap){ for (int i = 1; i size; ++i) printf(\"%d \", heap->arr[i]); } int main(){ struct MaxHeap heap; initHeap(&heap); insert(&heap, 5); insert(&heap, 2); insert(&heap, 3); insert(&heap, 7); insert(&heap, 6); printHeap(&heap); } 最后结果为： 插入完成之后，我们接着来写一下删除操作，删除操作实际上就是出队的操作： E delete(Heap heap){ E max = heap->arr[1], e = heap->arr[heap->size--]; int index = 1; while (index * 2 size) { //跟上面一样，开找，只不过是从上往下找 int child = index * 2; //先找到左孩子 //看看右孩子和左孩子哪个大，先选一个大的出来 if(child size && heap->arr[child] arr[child + 1]) child += 1; if(e >= heap->arr[child]) break; //如果子结点都不大于新结点，那么说明就是这个位置，结束就行了 else heap->arr[index] = heap->arr[child]; //否则直接堆化，换上去 index = child; //最后更新一下index到下面去 } heap->arr[index] = e; //找到合适位置后，放进去就行了 return max; } 最后我们来测试一下吧： int main(){ struct MaxHeap heap; initHeap(&heap); ... for (int i = 0; i 可以看到结果就是优先级队列的出队结果，这样，我们就编写好了大顶堆的插入和删除操作了。 当然，堆在排序上也有着非常方便的地方，在后面的排序算法篇中，我们还会再次说起它。 至此，有关树形结构篇的内容，我们就全部讲解完毕了，请务必认真掌握前面的二叉树和高级二叉树结构，这些都是重点内容，下一章我们将继续探讨散列表。 算法实战 二叉树相关的算法实战基本都是与递归相关的，因为它实在是太适合用分治算法了！ （简单）二叉查找树的范围和 本题来自LeetCode：938. 二叉搜索树的范围和 给定二叉搜索树的根结点 root，返回值位于范围 [low, high] 之间的所有结点的值的和。 示例 1： 输入：root = [10,5,15,3,7,null,18], low = 7, high = 15 （注意力扣上的输入案例写的是层序序列，含空节点） 输出：32 示例 2： 输入：root = [10,5,15,3,7,13,18,1,null,6], low = 6, high = 10 输出：23 这道题其实就是考察我们对于二叉查找树的理解，利用二叉查找树的性质，这道题其实很简单，只需要通过递归分治就可以解决了。 代码如下： int rangeSumBST(struct TreeNode* root, int low, int high){ if(root == NULL) return 0; if(root->val > high) //如果最大的值都比当前结点值小，那么肯定在左边才能找到 return rangeSumBST(root->left, low, high); else if(root->val right, low, high); else //这种情况肯定是在范围内了，将当前结点值加上左右的，再返回 return root->val + rangeSumBST(root->right, low, high) + rangeSumBST(root->left, low, high); } 这种问题比较简单，直接四行就解决了。 （中等）重建二叉树 本题来自LeetCode：剑指 Offer 07. 重建二叉树 输入某二叉树的前序遍历和中序遍历的结果，请构建该二叉树并返回其根节点。 假设输入的前序遍历和中序遍历的结果中都不含重复的数字。 示例 1: Input: preorder = [3,9,20,15,7], inorder = [9,3,15,20,7] Output: [3,9,20,null,null,15,7] 示例 2: Input: preorder = [-1], inorder = [-1] Output: [-1] 实际上这道题就是我们前面练习题的思路，现在给到我们的是前序和中序遍历的结果，我们只需要像之前一样逐步推导即可。 在中序遍历序列中找到根节点的位置后，这个问题就很好解决了，大致思路如下： 由于前序遍历首元素为根节点值，首先可以得到根节点值。 在中序遍历序列中通过根节点的值，寻找根节点的位置。 将左右两边的序列分割开来，并重构为根节点的左右子树。（递归分治） 在新的序列中，重复上述步骤，通过前序遍历再次找到当前子树的根节点，再次进行分割。 直到分割到仅剩下一个结点时，开始回溯，从而完成整棵二叉树的重建。 解题代码如下： struct TreeNode * createNode(int val){ //这个就是单纯拿来创建结点的函数 struct TreeNode * node = malloc(sizeof(struct TreeNode)); node->left = node->right = NULL; node->val = val; return node; } //核心递归分治实现 struct TreeNode* buildTreeCore(int * preorder, int * inorder, int start, int end, int index){ if(start > end) return NULL; //如果都超出范围了，肯定不行 if(start == end) return createNode(preorder[index]); //如果已经到头了，那么直接创建结点返回即可 struct TreeNode * node = createNode(preorder[index]); //先从前序遍历中找到当前子树的根结点值，然后创建对应的结点 int pos = 0; while (inorder[pos] != preorder[index]) pos++; //找到中序的对应位置，从这个位置开始左右划分 node->left = buildTreeCore(preorder, inorder, start, pos - 1, index+1); //当前结点的左子树按照同样的方式建立 //因为前序遍历的下一个结点就是左子树的根结点，所以说这里给index+1 node->right = buildTreeCore(preorder, inorder, pos+1, end, index+(pos-start)+1); //当前结点的右子树按照同样的方式建立 //最后一个index需要先跳过左子树的所有结点，才是右子树的根结点，所以说这里加了个pos-start，就是中序划分出来，左边有多少就减去多少 return node; //向上一级返回当前结点 } struct TreeNode* buildTree(int* preorder, int preorderSize, int* inorder, int inorderSize){ return buildTreeCore(preorder, inorder, 0, preorderSize - 1, 0); //这里传入了前序和中序序列，并且通过start和end指定当前中序序列的处理范围，最后的一个index是前序遍历的对应头结点位置 } （中等）验证二叉搜索树 本题来自LeetCode：98. 验证二叉搜索树（先说，这题老六行为过多，全站通过率只有36.5%，但是题目本身很简单） 给你一个二叉树的根节点 root ，判断其是否是一个有效的二叉搜索树。 有效 二叉搜索树定义如下： 节点的左子树只包含 小于 当前节点的数。 节点的右子树只包含 大于 当前节点的数。 所有左子树和右子树自身必须也是二叉搜索树。 示例 1： 输入：root = [2,1,3] 输出：true 示例 2： 输入：root = [5,1,4,null,null,3,6] 输出：false 解释：根节点的值是 5 ，但是右子节点的值是 4 。 这种题看起来好像还挺简单的，我们可以很快地写出代码： bool isValidBST(struct TreeNode* root){ if(root == NULL) return true; //到头了就直接返回真 if(root->left != NULL && root->left->val >= root->val) return false; //如果左边不是空，并且左边还比当前结点值小的话，那肯定不是了 if(root->right != NULL && root->right->val val) return false; //同上 return isValidBST(root->left) && isValidBST(root->right); //接着向下走继续判断左右两边子树，必须同时为真才是真 } 然后直接上力扣测试，嗯，没问题，提交，这把必过！于是光速打脸： 不可能啊，我们的逻辑判断没有问题的，我们的算法不可能被卡的啊？（这跟我当时打ACM一样的感觉，我这天衣无缝的算法不可能错的啊，哪个老六测试用例给我卡了）这其实是因为我们没有考虑到右子树中左子树比根结点值还要小的情况： 虽然这样错的很明显，但是按照我们上面的算法，这种情况确实也会算作真。所以说我们需要改进一下，对其上界和下界进行限定，不允许出现这种低级问题： bool isValid(struct TreeNode* root, long min, long max){ //这里上界和下界用long表示，因为它的范围给到整个int，真是个老六 if(root == NULL) return true; //这里还需要判断是否正常高于下界 if(root->left != NULL && (root->left->val >= root->val || root->left->val right != NULL && (root->right->val val || root->right->val >= max)) return false; return isValid(root->left, min, root->val) && isValid(root->right, root->val, max); //注意往左走更新上界，往右走更新下界 } bool isValidBST(struct TreeNode* root){ return isValid(root, -2147483649, 2147483648); //下界刚好比int少1，上界刚好比int多1 } 这样就没问题了。 （中等）求根到叶数字之和 本题来自LeetCode：129. 求根节点到叶节点数字之和 给你一个二叉树的根节点 root ，树中每个节点都存放有一个 0 到 9 之间的数字。 每条从根节点到叶节点的路径都代表一个数字： 例如，从根节点到叶节点的路径 1 -> 2 -> 3 表示数字 123 。 计算从根节点到叶节点生成的 所有数字之和 。 叶节点 是指没有子节点的节点。 示例 1： 输入：root = [1,2,3] 输出：25 解释： 从根到叶子节点路径 1->2 代表数字 12 从根到叶子节点路径 1->3 代表数字 13 因此，数字总和 = 12 + 13 = 25 示例 2： 输入：root = [4,9,0,5,1] 输出：1026 解释： 从根到叶子节点路径 4->9->5 代表数字 495 从根到叶子节点路径 4->9->1 代表数字 491 从根到叶子节点路径 4->0 代表数字 40 因此，数字总和 = 495 + 491 + 40 = 1026 这道题其实也比较简单，直接从上向下传递当前路径上已经组装好的值即可，到底时返回最终的组装结果： int sumNumbersImpl(struct TreeNode * root, int parent){ if(root == NULL) return 0; //如果到头了，直接返回0 int sum = root->val + parent * 10; //因为是依次向后拼接，所以说直接将之前的值x10然后加上当前值即可 if(!root->left && !root->right) //如果是叶子结点，那么直接返回结果 return sum; //否则按照同样的方式将左右的结果加起来 return sumNumbersImpl(root->left, sum) + sumNumbersImpl(root->right, sum); } int sumNumbers(struct TreeNode* root){ return sumNumbersImpl(root, 0); } （困难）结点之和的最大路径 本题来自LeetCode：剑指 Offer II 051. 节点之和最大的路径（这是一道Hard难度的题目，但是其实还好） 路径 被定义为一条从树中任意节点出发，沿父节点-子节点连接，达到任意节点的序列。同一个节点在一条路径序列中 至多出现一次 。该路径 至少包含一个 节点，且不一定经过根节点。 路径和 是路径中各节点值的总和。 给定一个二叉树的根节点 root ，返回其 最大路径和，即所有路径上节点值之和的最大值。 示例 1： 输入：root = [1,2,3] 输出：6 解释：最优路径是 2 -> 1 -> 3 ，路径和为 2 + 1 + 3 = 6 示例 2： 输入：root = [-10,9,20,null,null,15,7] 输出：42 解释：最优路径是 15 -> 20 -> 7 ，路径和为 15 + 20 + 7 = 42 首先，我们要知道，路径有很多种可能，要么从上面下来，要么从左边上来往右边走，要么只走右边，要么只走左边...我们需要寻找一个比较好的方法在这么多种可能性之间选择出最好的那一个。 int result = -2147483648; //使用一个全局变量来存储一下当前的最大值 int max(int a, int b){ //不想多说了 return a > b ? a : b; } int maxValue(struct TreeNode* root){ if(root == NULL) return 0; //先把左右两边走或是不走的情况计算一下，取出值最大的情况 int leftMax = max(maxValue(root->left), 0); int rightMax = max(maxValue(root->right), 0); //因为要么只走左边，要么只走右边，要么左右都走，所以说我们计算一下最大情况下的结果 int maxTmp = leftMax + rightMax + root->val; result = max(maxTmp, result); //更新一下最大值 //然后就是从上面下来的情况了，从上面下来要么左要么右，此时我们只需要返回左右最大的一个就行了 return max(leftMax, rightMax) + root->val; //注意还要加上当前结点的值，因为肯定要经过当前结点 } int maxPathSum(struct TreeNode* root){ maxValue(root); return result; //最后返回完事之后最终得到的最大值 } 这样，我们就成功解决了这种问题。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（二）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（二）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/算法/数据结构与算法（三）.html":{"url":"Java/算法/数据结构与算法（三）.html","title":"数据结构与算法（三）","keywords":"","body":" 散列表篇 在之前，我们已经学习了多种查找数据的方式，比如最简单的，如果数据量不大的情况下，我们可以直接通过顺序查找的方式在集合中搜索我们想要的元素；当数据量较大时，我们可以使用二分搜索来快速找到我们想要的数据，不过需要要求数据按照顺序排列，并且不允许中途对集合进行修改。 在学习完树形结构篇之后，我们可以利用二叉查找树来建立一个便于我们查找的树形结构，甚至可以将其优化为平衡二叉树或是红黑树来进一步提升稳定性。在最后我们还了解了B树和B+树，得益于它们的巧妙设计，我们可以以尽可能少的时间快速找到我们需要的元素，大大提升程序的运行效率。 这些都能够极大地帮助我们查找数据，而散列表，则是我们查找系列内容的最后一块重要知识。 散列查找 我们之前认识的查找算法，最快可以达到对数阶 $O(logN)$，那么我们能否追求极致，让查找性能突破到常数阶呢？这里就要介绍到我们的散列（也可以叫哈希 Hash）它采用直接寻址的方式，在理想情况下，查找的时间复杂度可以达到常数阶 $O(1)$。 散列（Hashing）通过散列函数（哈希函数）将要参与检索的数据与散列值（哈希值）关联起来，生成一种便于搜索的数据结构，我们称其为散列表（哈希表），也就是说，现在我们需要将一堆数据保存起来，这些数据会通过哈希函数进行计算，得到与其对应的哈希值，当我们下次需要查找这些数据时，只需要再次计算哈希值就能快速找到对应的元素了： 当然，如果一脸懵逼没关系，我们从哈希函数开始慢慢介绍。 散列函数 散列函数也叫哈希函数，哈希函数可以对一个目标计算出其对应的哈希值，并且，只要是同一个目标，无论计算多少次，得到的哈希值都是一样的结果，不同的目标计算出的结果介乎都不同。哈希函数在现实生活中应用十分广泛，比如很多下载网站都提供下载文件的MD5码校验，可以用来判别文件是否完整，哈希函数多种多样，目前应用最为广泛的是SHA-1和MD5，比如我们在下载IDEA之后，会看到有一个验证文件SHA-256校验和的选项，我们可以点进去看看： 点进去之后，得到： e54a026da11d05d9bb0172f4ef936ba2366f985b5424e7eecf9e9341804d65bf *ideaIU-2022.2.1.dmg 这一串由数字和小写字母随意组合的一个字符串，就是安装包文件通过哈希算法计算得到的结果，那么这个东西有什么用呢？我们的网络可能有时候会出现卡顿的情况，导致我们下载的文件可能会出现不完整的情况，因为哈希函数对同一个文件计算得到的结果是一样的，我们可以在本地使用同样的哈希函数去计算下载文件的哈希值，如果与官方一致，那么就说明是同一个文件，如果不一致，那么说明文件在传输过程中出现了损坏。 可见，哈希函数在这些地方就显得非常实用，在我们的生活中起了很大的作用，它也可以用于布隆过滤器和负载均衡等场景，这里不多做介绍了。 散列表 前面我们介绍了散列函数，我们知道可以通过散列函数计算一个目标的哈希值，那么这个哈希值计算出来有什么用呢，对我们的程序设计有什么意义呢？我们可以利用哈希值的特性，设计一张全新的表结构，这种表结构是专为哈希设立的，我们称其为哈希表（散列表） 我们可以将这些元素保存到哈希表中，而保存的位置则与其对应的哈希值有关，哈希值是通过哈希函数计算得到的，我们只需要将对应元素的关键字（一般是整数）提供给哈希函数就可以进行计算了，一般比较简单的哈希函数就是取模操作，哈希表长度是多少（长度最好是一个素数），模就是多少： 比如现在我们需要插入一个新的元素（关键字为17）到哈希表中： 插入的位置为计算出来的哈希值，比如上面是8，那么就在下标位置8插入元素，同样的，我们继续插入27： 这样，我们就可以将多种多样的数据保存到哈希表中了，注意保存的数据是无序的，因为我们也不清楚计算完哈希值最后会放到哪个位置。那么如果现在我们想要从哈希表中查找数据呢？比如我们现在需要查找哈希表中是否有14这个元素： 同样的，直接去看哈希值对应位置上看看有没有这个元素，如果没有，那么就说明哈希表中没有这个元素。可以看到，哈希表在查找时只需要进行一次哈希函数计算就能直接找到对应元素的存储位置，效率极高。 我们可以通过代码来实现一下： #define SIZE 9 typedef struct Element { //这里用一个Element将值包装一下 int key; //这里元素设定为int } * E; typedef struct HashTable{ //这里把数组封装为一个哈希表 E * table; } * HashTable; int hash(int key){ //哈希函数 return key % SIZE; } void init(HashTable hashTable){ //初始化函数 hashTable->table = malloc(sizeof(struct Element) * SIZE); for (int i = 0; i table[i] = NULL; } void insert(HashTable hashTable, E element){ //插入操作，为了方便就不考虑装满的情况了 int hashCode = hash(element->key); //首先计算元素的哈希值 hashTable->table[hashCode] = element; //对号入座 } _Bool find(HashTable hashTable, int key){ int hashCode = hash(key); //首先计算元素的哈希值 if(!hashTable->table[hashCode]) return 0; //如果为NULL那就说明没有 return hashTable->table[hashCode]->key == key; //如果有，直接看是不是就完事 } E create(int key){ //创建一个新的元素 E e = malloc(sizeof(struct Element)); e->key = key; return e; } int main() { struct HashTable hashTable; init(&hashTable); insert(&hashTable, create(10)); insert(&hashTable, create(7)); insert(&hashTable, create(13)); insert(&hashTable, create(29)); printf(\"%d\\n\", find(&hashTable, 1)); printf(\"%d\\n\", find(&hashTable, 13)); } 这样，我们就实现了一个简单的哈希表和哈希函数，通过哈希表，我们可以将数据的查找时间复杂度提升到常数阶。 哈希冲突 前面我介绍了哈希函数，通过哈希函数计算得到一个目标的哈希值，但是在某些情况下，哈希值可能会出现相同的情况： 比如现在同时插入14和23这两个元素，他们两个计算出来的哈希值是一样的，都需要在5号下标位置插入，这时就出现了打架的情况，那么到底是把哪一个放进去呢？这种情况，我们称为哈希碰撞（哈希冲突） 这种问题是很严重的，因为哈希函数的设计不同，难免会出现这种情况，这种情况是不可避免的，我们只能通过使用更加高级的哈希函数来尽可能避免这种情况，但是无法完全避免。当然，如果要完全解决这种问题，我们还需要去寻找更好的方法。 线性探测法 既然有可能出现哈希值重复的情况，那么我们可以选择退让，不去进行争抢（忍一时风平浪静，退一步海阔天空）我们可以去找找哈希表中相邻的位置上有没有为空的，只要哈希表没装满，那么我们肯定是可以找到位置装下这个元素的，这种类型的解决方案我们统称为线性探测法，开放定址法包含，线性探测法、平方探测法、双散列法等，这里我们以线性探测法为例。 既然第一次发生了哈希冲突，那么我们就继续去找下一个空位： $$ h_i(key) = (h(key) + d_i)\\space \\% \\space TableSize $$ 其中 $d_i$ 是随着哈希冲突次数增加随之增加的量，比如上面出现了一次哈希冲突，那么我就将其变成1表示发生了一次哈希冲突，然后我们可以继续去寻找下一个位置： 出现哈希冲突时，$d_i$自增，继续寻找下一个空位： 再次计算哈希值，成功得到对应的位置，注意 $d_i$ 默认为0，这样我们就可以解决冲突的情况了。 我们来通过代码实际使用一下，这里需要调整一下插入和查找操作的逻辑： void insert(HashTable hashTable, E element){ //插入操作，注意没考虑满的情况，各位小伙伴可以自己实现一下 int hashCode = hash(element->key), count = 0; while (hashTable->table[hashCode]) { //如果发现哈希冲突，那么需要继续寻找 hashCode = hash(element->key + ++count); } hashTable->table[hashCode] = element; //对号入座 } _Bool find(HashTable hashTable, int key){ int hashCode = hash(key), count = 0; //首先计算元素的哈希值 const int startIndex = hashCode; //记录一下起始位置，要是转一圈回来了得停 do { if(hashTable->table[hashCode]->key == key) return 1; //如果找到就返回1 hashCode = hash(key + ++count); } while (startIndex != hashCode && hashTable->table[hashCode]); //没找到继续找 return 0; } 这样当出现哈希冲突时，会自动寻找补位插入： int main() { struct HashTable hashTable; init(&hashTable); for (int i = 0; i key); } } 当然，如果采用这种方案删除会比较麻烦，因为有些元素可能是通过线性探测补到其他位置上的，如果删除元素，那么很有可能会影响到前面的查找操作： 此时删除关键字为45的元素，会出现截断的情况，当下次查找时，会出现严重问题： 可以看到，删除一个元素可能会导致原有的结构意外截断，无法正确找到对应的元素，所以，我们在删除元素时，为了防止出现这种截断的情况，我们需要对这个位置进行标记，表示之前有过元素，但是被删除了，当我们在查找时，如果发现曾经有过元素，依然需要继续向后寻找： 代码实现有点麻烦，这里就不编写代码了。 当然除了直接向后进行探测之外，我们也可以采用二次探测再散列法处理哈希冲突，因为有些时候可能刚好后面没有空位了，但是前面有，如果按照之前的方法，我们得转一圈回来才能找到对应的位置，实在是有点浪费时间，所以说我们可以左右开弓，同时向两个方向去寻找。 它的查找增量序列为：$1^2$、$-1^2$、$2^2$、$-2^2$、...、$q^2$、$-q^2$，其中$q 那么此时就需要进行处理了，这里我们采用上面的方式，先去寻找 $1^2$ 位置： 我们接着来插入： 实际上我们发现和之前是一样的，只要冲突就一直往下找就完事，只不过现在是左右横跳着找，这样可以进一步提升利用率。 链地址法 实际上常见的哈希冲突解决方案是链地址法，当出现哈希冲突时，我们依然将其保存在对应的位置上，我们可以将其连接为一个链表的形式： 当表中元素变多时，差不多就变成了这样，我们一般将其横过来看： 通过结合链表的形式，哈希冲突问题就可以得到解决了，但是同时也会出现一定的查找开销，因为现在有了链表，我们得挨个往后看才能找到，当链表变得很长时，查找效率也会变低，此时我们可以考虑结合其他的数据结构来提升效率。比如当链表长度达到8时，自动转换为一棵平衡二叉树或是红黑树，这样就可以在一定程度上缓解查找的压力了。 我们来编写代码尝试一下： #define SIZE 9 typedef struct ListNode { //结点定义 int key; struct ListNode * next; } * Node; typedef struct HashTable{ //哈希表 struct ListNode * table; //这个数组专门保存头结点 } * HashTable; void init(HashTable hashTable){ hashTable->table = malloc(sizeof(struct ListNode) * SIZE); for (int i = 0; i table[i].key = -1; //将头结点key置为-1，next指向NULL hashTable->table[i].next = NULL; } } int main(){ struct HashTable table; //创建哈希表 init(&table); } 接着是编写对应的插入操作，插入后直接往链表后面丢就完事了： int hash(int key){ //哈希函数 return key % SIZE; } Node createNode(int key){ //创建结点专用函数 Node node = malloc(sizeof(struct ListNode)); node->key = key; node->next = NULL; return node; } void insert(HashTable hashTable, int key){ int hashCode = hash(key); Node head = hashTable->table + hashCode; //先计算哈希值，找到位置后直接往链表后面插入结点就完事了 while (head->next) head = head->next; head->next = createNode(key); //插入新的结点 } 同样的，查找的话也是直接找到对应位置，看看链表里面有没有就行： _Bool find(HashTable hashTable, int key){ int hashCode = hash(key); Node head = hashTable->table + hashCode; while (head->next && head->key != key) //直到最后或是找到为止 head = head->next; return head->key == key; //直接返回是否找到 } 我们来测试一下吧： int main(){ struct HashTable table; init(&table); insert(&table, 10); insert(&table, 19); insert(&table, 20); printf(\"%d\\n\", find(&table, 20)); printf(\"%d\\n\", find(&table, 17)); printf(\"%d\\n\", find(&table, 19)); } 实际上这种方案代码写起来也会更简单，使用也更方便一些。 散列表习题： 下面关于哈希查找的说法，正确的是（ ） A 哈希函数构造的越复杂越好，因为这样随机性好，冲突小 B 除留余数法是所有哈希函数中最好的 C 不存在特别好与坏的哈希函数，要视情况而定 D 越简单的哈希函数越容易出现冲突，是最坏的 首先，衡量哈希函数好坏并没有一个确切的标准，而是需要根据具体情况而定，并不一定复杂的哈希函数就好，因为会带来时间上的损失。其实我们的生活中很多东西都像这样，没有好坏之分，只有适不适合的说法，所以说选择C选项 设有一组记录的关键字为{19，14，23，1，68，20，84，27，55，11，10，79}，用链地址法构造散列表，散列函数为H（key）=key MOD 13,散列地址为1的链中有（ ）个记录。 A 1 B 2 C 3 D 4 这种咱们得画图才知道了，答案是D 设哈希表长为14，哈希函数是H(key)=key%11，表中已有数据的关键字为15，38，61，84共四个，现要将关键字为49的元素加到表中，用二次探测再散列解决冲突，则放入的位置是（ ） A 8 B 3 C 5 D 9 咱们先把这个表给画出来吧，答案是D 选取哈希函数 H(key)=(key x 3)%11 用线性探测散列法和二次探测再散列法分别处理冲突。试在0~10的散列地址空间中，对关键字序列（22,41,53,46,30,13,1,67）构建哈希表，并求等概率情况下查找成功的平均查找长度。 其中平均查找长度（ASL）就是表中每一个元素需要查找次数之和的平均值，我们注意在插入元素时顺便记录计算次数即可，如果是链地址法，那么直接看层数就行，ASL =（第一层结点数量+第二层结点数量+第三层结点数量）/ 非头结点总数 算法实战 （简单）两数之和 本题来自LeetCode：1.两数之和（整个力扣的第一题） 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。 你可以按任意顺序返回答案。 示例 1： 输入：nums = [2,7,11,15], target = 9 输出：[0,1] 解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。 示例 2： 输入：nums = [3,2,4], target = 6 输出：[1,2] 示例 3： 输入：nums = [3,3], target = 6 输出：[0,1] 这道题很简单，实际上使用暴力枚举是可以完成的，我们只需要让每个数去寻找一个与其匹配的数即可，所以说直接循环就完事： int * result(int i, int j, int * returnSize){ *returnSize = 2; int * result = malloc(sizeof(int) * 2); result[0] = i; result[1] = j; return result; } int* twoSum(int* nums, int numsSize, int target, int* returnSize){ for (int i = 0; i 但是这样效率实在是太低了，可以看到我们的程序运行时间都好几百毫秒了，能不能优化一下呢？我们正好学习了散列表，是否可以利用一下散列表来帮助我们完成？ 因为每当我们遍历一个数时，实际上就是去寻找与其匹配的数是否存在，我们可以每遍历一个数都将其存放到散列表中，当下次遇到与其相匹配的数时，只要能够从散列表中找到这个数，那么就可以直接完成匹配了，这样就只需要遍历一次即可完成。比如： [2,7,11,15] ，targert = 9 第一次先将2放入散列表，接着往后看7，现在目标值时9，那么只需要去寻找 9 - 7 这个数，看看散列表中有没有即可，此时散列表中正好有2，所以说直接返回即可。 我们来尝试编写一下： #define SIZE 128 typedef int K; typedef int V; typedef struct LNode { //结点定义需要稍微修改一下，因为除了存关键字还需要存一下下标 K key; V value; struct LNode * next; } * Node; typedef struct HashTable{ //哈希表 struct LNode * table; //这个数组专门保存头结点 } * HashTable; void init(HashTable hashTable){ hashTable->table = malloc(sizeof(struct LNode) * SIZE); for (int i = 0; i table[i].key = -1; //将头结点key置为-1，value也变成-1，next指向NULL hashTable->table[i].value = -1; hashTable->table[i].next = NULL; } } int hash(unsigned int key){ //因为哈希表用的数组，要是遇到负数的key，肯定不行，咱先给它把符号扬了再算 return key % SIZE; } Node create(K key, V value){ //创建结点，跟之前差不多 Node node = malloc(sizeof(struct LNode)); node->key = key; node->value = value; node->next = NULL; return node; } void insert(HashTable hashTable, K key, V value){ int hashCode = hash(key); Node head = hashTable->table + hashCode; while (head->next) head = head->next; head->next = create(key, value); //这里同时保存关键字和对应的下标 } Node find(HashTable hashTable, K key){ int hashCode = hash(key); Node head = hashTable->table + hashCode; //直接定位到对应位置 while (head->next && head->next->key != key) //直接看有没有下一个结点，并且下一个结点不是key head = head->next; //继续往后找 return head->next; //出来之后要么到头了下一个是NULL，要么就是找到了，直接返回 } 哈希表编写完成后，我们就可以使用了： int * result(int i, int j, int * returnSize){ //跟上面一样 *returnSize = 2; int * result = malloc(sizeof(int) * 2); result[0] = i; result[1] = j; return result; } int* twoSum(int* nums, int numsSize, int target, int* returnSize){ struct HashTable table; //初始化哈希表 init(&table); for (int i = 0; i value, returnSize); insert(&table, nums[i], i); } return NULL; //无视就好 } 我们再次提交代码，时间直接来到了个位数： 采用哈希表，就是一种空间换时间的策略，在大多数情况下，我们也更推荐使用这种方案。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（三）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（三）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/算法/数据结构与算法（四）.html":{"url":"Java/算法/数据结构与算法（四）.html","title":"数据结构与算法（四）","keywords":"","body":" 图结构篇 图结构在我们的生活中实际上是非常常见的，其中最显著的就是我们的地图了，比如我的家乡重庆： 可以看到，地图盘根错节，错综复杂，不同的道路相互连接，我们可以自由地从这些道路通过，从一个地点到达另一个地点。当然除了地图，我们的计算机网络、你的人际关系网等等，这些都可以用图结构来表示。图结构也是整个数据结构中比较难的一部分，而这一章，我们将探讨图结构的性质与应用。 图也是由多个结点连接而成的，但是一个结点可以同时连接多个其他结点，多个结点也可以同时指向一个结点，跟我们之前讲解的树结构不同，它是一种多对多的关系： 它比树形结构更加复杂，没有明确的层次关系，结点与结点之间的连接关系更加自由，图结构是任意两个数据对象之间都有可能存在某种特定关系的数据结构。 基本概念 图（Graph）一般由两个集合共同构成，一个是非空但是有限的顶点集合V（Vertex），另一个是描述顶点之间连接关系的边集合E（Edge，边集合可以为空集，比如只有一个顶点的情况下，没得连啊），一个图实际上正是由这些结点（顶点）和对应的边组成的。因此，图可以表示为：$G = (V, E)$ 比如一个图我们可以表示为，集合$V = {A,B,C,D}$，集合$E = {(A,B),(B,C),(C,D),(D,A),(C,A)}$，图有两种基本形式，一种是上面那样的有向图（有向图表明了方向，从哪个点到哪个点），还有一种是无向图（无向图仅仅是连接，并不指明方向），比如我们上面这样表示就是一个无向图： 每个结点的度就是与其连接的边数，每条边是可以包含权值的，当前也可以不包含。 当然我们也可以将其表示为有向图，集合$V = {A,B,C,D}$，集合$E = {,,,,}$注意有向图的边使用尖括号<>表示。比如上面这个有向图，那么就长这样： 如果是无向图的一条边(A,B)，那么就称A、B互为邻接点；如果是有向图的一条边，那么就称起点A邻接到终点B。有向图的每个结点分为入度和出度，其中入度就是与顶点相连且指向该顶点的边的个数，出度就是从该顶点指向邻接顶点的边的个数。 只要我们的图中不出现自回路边或是重边，那么我们就可以称这个图为简单图，比如上面两张图都是简单图。而下面的则是典型的非简单图了，其中图一出现了自回路，而图二出现了重边： 如果在一个无向图中，任意两个顶点都有一条边相连，则称该图为无向完全图： 同样的，在一个有向图中，如果任意两顶点之间都有由方向互为相反的两条边连接，则称该图为有向完全图： 图通过边将顶点相连，这样我们就可以从一个顶点经过某条路径到达其他顶点了，比如我们现在想要从下面的V5点到达V1点： 那么我们可以有很多种路线，比如经过V2到达，经过V3到达等： 在一个无向图中，如果从一个顶点到另一个顶点有路径，那么就称这两个顶点是连通的。可以看到，要从V5到达V1我们可以有很多种选择，从V5可以到达V1（当然也可以反着来），所以，我们称V5和V1连通的。特别的，如果图中任意两点都是连通的，那么我们就称这个图为连通图。对于有向图，如果图中任意顶点A和B，既有从A到B的路径，也有B到A的路径，则称该有向图是强连通图。 对于图 $G = (V, E)$ 和 $G' = (V', E')$，若满足 $V'$ 是 $V$ 的子集，并且 $E'$ 是 $E$ 的子集，则称 $G'$ 是 $G$ 的子图，比如下面的两个图： 其中右边的图就满足上述性质，所以说右边的图是左边图的子图。 无向图的极大连通子图称为连通分量，有向图的极大连通子图称为强连通分量。那么什么是极大连通子图呢？首先连通子图就是原图的子图，并且子图也是连通图，同时应该具有最大的顶点数，即再加入原图中的其他顶点会导致子图不连通，拥有极大顶点数的同时也要包含依附于这点顶点所有的边才行，比如： 可以看到右侧图1、2、3都是左图的子图，但是它们并不都是原图的连通分量，首先我们来看图1，它也是一个连通图，并且包含极大顶点数和所有的边（也就是原图内部的这一块）所以说它是连通分量，我们接着来看图2，它虽然也是连通图，但是并没有包含极大顶点数（最多可以吧D也给加上，但是这里没加）所以说并不是。最后来看图3，它也是连通图，并且包含了极大顶点数和边，所以说是连通分量。 原图为连通图，那么连通分量就是其本身，有且仅有一个。 原图为非连通图，那么连通分量会有多个。 对于极小连通子图，我们会在后面的生成树部分进行讲解。 存储结构 前面我们介绍了图的一些基本概念，我们接着来看如何在程序中对图结构进行表示，这一部分可能会涉及到某些在《线性代数》这门课程中出现的概念。 邻接矩阵 邻接矩阵实际上就是用矩阵去表示图中各顶点之间的邻接关系和权值。假设有一个图 $G = (V, E)$，其中有N个顶点，那么我们就可以使用一个N×N的矩阵来表示，比如下面有A、B、C、D四个顶点的图： 此时我们需要使用邻接矩阵来表示它，就像下面这样： 对于一个不带权值的图来说： $$ G_{ij} = \\begin{cases} 1, 无向图的(v_i,v_j)或有向图的是图中的边\\ 0, 无向图的(v_i,v_j)或有向图的不是图中的边 \\end{cases} $$ 对于一个带权值的图来说，如果有边，则直接填写对应边的权值，如果没有，那么就填写0或是∞（因为某些图会认为0也是权值，所以说可以用∞，它可以是一个计算机允许的最大值大于所有边的权值的数）来进行表示： $$ G{ij} = \\begin{cases} w{ij}, 无向图的(v_i,v_j)或有向图的是图中的边\\ 0或∞, 无向图的(v_i,v_j)或有向图的不是图中的边 \\end{cases} $$ 所以说，对于上面的有向图，我们应该像这样填写： 那么我们来看看无向图的邻接矩阵呢？比如下面的这个图： 对于无向图来说，一条边两边是相互连接的，所以说，A连接B，那么B也连接A，所以说就像这样： 可以看到得到的矩阵用我们在《线性代数》中的定义来说就是一个对称矩阵（上半和下半都是一样的）因为没有自回路顶点，所以说主对角线上的元素全都是0。由于无向图没有方向之分，顶点之间是相互连接的，所以说无向图的邻接矩阵必定是一个对称矩阵。 我们可以来总结一下性质： 无向图的邻接矩阵一定是一个对称矩阵，因此，有时为了节省时间，我们可以只存放上半部分。 对于无向图，邻接矩阵的第i行非0（或非∞）的个数就是第i个顶点的度。 对于有向图，邻接矩阵的第i行非0（或非∞）的个数就是第i个顶点的出度（纵向就是入度了） 接着我们来看看如何通过代码实现，首先我们需要对结构体进行一下定义，这里我们以有向图为例： #define MaxVertex 5 typedef char E; //顶点存放的数据类型，这个不用我多说了吧 typedef struct MatrixGraph { int vertexCount; //顶点数 int edgeCount; //边数 int matrix[MaxVertex][MaxVertex]; //邻接矩阵 E data[MaxVertex]; //各个顶点对应的数据 } * Graph; 接着我们可以对其进行一下初始化创建后返回： Graph create(){ //创建时，我们可以指定图中初始有多少个结点 Graph graph = malloc(sizeof(struct MatrixGraph)); graph->vertexCount = 0; //顶点和边数肯定一开始是0 graph->edgeCount = 0; for (int i = 0; i matrix[i][j] = 0; return graph; } int main(){ Graph graph = create(); //这里咱们就搞一个 } 接着我们就可以编写一下添加顶点和添加边的函数了： void addVertex(Graph graph, E element){ if(graph->vertexCount >= MaxVertex) return; graph->data[graph->vertexCount++] = element; //添加新元素 } void addEdge(Graph graph, int a, int b){ //添加几号顶点到几号顶点的边 if(graph->matrix[a][b] == 0) { graph->matrix[a][b] = 1; //注意如果是无向图的话，需要[a][b]和[b][a]都置为1 graph->edgeCount++; } } 我们来尝试构建一下这个有向图： Graph graph = create(); for (int c = 'A'; c B addEdge(graph, 1, 2); //B -> C addEdge(graph, 2, 3); //C -> D addEdge(graph, 3, 0); //D -> A addEdge(graph, 2, 0); //C -> A 接着我们打印此领接矩阵，看看是否变成了我们预想中的那样： void printGraph(Graph graph){ for (int i = -1; i vertexCount; ++i) { for (int j = -1; j vertexCount; ++j) { if(j == -1) printf(\"%c\", 'A' + i); else if(i == -1) printf(\"%3c\", 'A' + j); else printf(\"%3d\", graph->matrix[i][j]); } putchar('\\n'); } } 最后得到： 可以看到结果跟我们上面推导得出的邻接矩阵一模一样，当然这里仅仅是演示了普通的有向图，我们也可以稍微将代码进行修改，将其变成一个无向图或是带权有向图，这里就不做演示了。 邻接表 前面我们介绍了领接矩阵，我们可以使用邻接矩阵在程序中保存一个图的边相关信息，它采用二维数组的形式，将对应边的连接关系进行存储，但是我们知道，数组存在容量上的局限性（学了这么多节课了，应该能体会到，数组需要一段连续空间，无论是申请还是用起来都很麻烦）同时，我们创建邻接矩阵后，如果图的边数较多（稠密图）利用率还是挺高的，但是一旦遇到边数很少的图（稀疏图）那么表中大量的位置实际上都是0，根本没有被利用起来，是很浪费的。 此时，我们可以考虑使用链式结构来解决这种问题，就像下面这样： 对于图中的每个顶点，建立一个数组，存放一个头结点，我们将与其邻接的顶点，通过一个链表进行记录（看着挺像前面讲的哈希表）这样，也可以表示一个图的连接关系，并且内存空间能够得到更加有效的利用。当然，对于无向图来说，跟之前一样，两边都需要进行保存： 我们来尝试编写一下代码实现，首先还是定义： #define MaxVertex 5 typedef char E; typedef struct Node { //结点和头结点分开定义，普通结点记录邻接顶点信息 int nextVertex; struct Node * next; } * Node; struct HeadNode { //头结点记录元素 E element; struct Node * next; }; typedef struct AdjacencyGraph { int vertexCount; //顶点数 int edgeCount; //边数 struct HeadNode vertex[MaxVertex]; } * Graph; 接着是对其进行初始化： Graph create(){ //创建时，我们可以指定图中初始有多少个结点 Graph graph = malloc(sizeof(struct AdjacencyGraph)); graph->vertexCount = graph->edgeCount = 0; return graph; //头结点数组一开始可以不用管 } 在添加边和顶点时，稍微麻烦一些： void addVertex(Graph graph, E element){ if(graph->vertexCount >= MaxVertex) return; //跟之前一样 graph->vertex[graph->vertexCount].element = element; //添加新结点时，再来修改也行 graph->vertex[graph->vertexCount].next = NULL; graph->vertexCount++; } void addEdge(Graph graph, int a, int b){ Node node = graph->vertex[a].next; Node newNode = malloc(sizeof(struct Node)); newNode->next = NULL; newNode->nextVertex = b; if(!node) { //如果头结点下一个都没有，那么直接连上去 graph->vertex[a].next = newNode; } else { //否则说明当前顶点已经连接了至少一个其他顶点了，有可能会出现已经连接过的情况，所以说要特别处理一下 do { if(node->nextVertex == b) return; //如果已经连接了对应的顶点，那么直接返回 if(node->next) node = node->next; //否则继续向后遍历 else break; //如果没有下一个了，那就找到最后一个结点了，直接结束 } while (1); node->next = newNode; } graph->edgeCount++; //边数计数+1 } 我们来将其构建一下吧，还是以上面的图为例： int main(){ Graph graph = create(); for (int c = 'A'; c B addEdge(graph, 1, 2); //B -> C addEdge(graph, 2, 3); //C -> D addEdge(graph, 3, 0); //D -> A addEdge(graph, 2, 0); //C -> A printGraph(graph); } 我们来打印看看效果： void printGraph(Graph graph){ for (int i = 0; i vertexCount; ++i) { printf(\"%d | %c\", i, graph->vertex[i].element); Node node = graph->vertex[i].next; while (node) { printf(\" -> %d\", node->nextVertex); node = node->next; } putchar('\\n'); } } 得到结果如下： 可以看到结果符合我们的预期。 不过虽然这样的方式看上去更加的简单高效，但是会给我们带来一些不必要的麻烦，比如上面创建的领接表，我们只能快速得到某个顶点指向了哪些顶点，也就是只能计算到顶点的出度，但是无法快速计算顶点的入度，只能将所有结点统计之后才能得到入度。所以说在表示有向图时，查找上并没有邻接矩阵来的方便。 为了解决这种问题，我们可以建立一个逆领接表，来表示所有指向当前顶点的顶点列表： 实际上就是反着来而已，通过建立这两个领接表，就能在一定程度上缓解不方便的情况。 图练习题： 在一个具有n个顶点的有向图中，若所有顶点的出度之和为s，则所有顶点的入度数之和为？ A. s B. s - 1 C. s + 1 D. 2s 有向图的所有出度实际上就是所有顶点连向其他顶点的边数，对于单个顶点来说，要么是自己指向别人（自己的出度，别人的入度），要么别人指向自己（别人的出度，自己的入度），这东西就是个相对的而已，而这些都可以一律看做出度，所以说所有顶点入度数之和就是所有顶点出度之和，所以选A 在一个具有n个顶点的无向完全图中，所含的边数为？ A. n B. n(n-1) C. n(n - 1)/2 D. n(n + 1)/2 首先回顾一下无向完全图的定义：在一个无向图中，任意两个顶点都有一条边相连，则称该图为无向完全图。既然任意两个顶点都有一个，那么每个结点都会有n-1条与其连接的边，所以说总数为 $n \\times (n-1)$ 但是由于是无向图，没有方向之分，所以说需要去掉一半的数量，得到 $\\frac {n \\times (n-1)} {2}$，选择C 若要把n个顶点连接为一个连通图，则至少需要几条边？ A. n B. n - 1 C. n + 1 D. 2n 连通图的定义是，每个顶点至少有一条到达其他顶点的路径，所以说我们只需要找一个最简单能够保证每个结点都有与其相连的就行了，也就是连成一根直线（或者是树）的情况，选择B 对于一个具有 n 个顶点和 e 条边的无向图，在其对应的邻接表中，所含边结点有多少个？ A. n B. ne C. e D. 2e 对于无向图，这结点个数等于边数的两倍，对于有向图，刚好等于边数，所以说选择 D 图的遍历 记得小时候每次去书店，都能看到迷宫书： 每次看到都想买一本，但是当时家里条件并不允许消费这么贵的书，所以都只能在书店多看几眼再回去。迷宫的解，实际上就是我们在一个复杂的地图中寻找一条能够从起点到达终点的路径。可以看到从起点开始，每到一个路口，可能都会出现多个分叉，可能有的分叉就会走进死胡同，有的分叉就会走到下一个路口。 那么我们人脑是怎么去寻找到正确的路径呢？ 我们首先还是会从起点开始看，我们会尝试去走分叉路的每一个方向，如果遇到死胡同，那么我们就退回到上一个路口，再去尝试其他方向，直到能一直往下走为止。经过不断重复上述的操作，最后我们就肯定能够到达迷宫的出口了。 而图的搜索，实际上也是类似于迷宫这样的形式，我们需要从图的某一个顶点出发，去寻找到图中对应顶点的位置，这一部分，我们将对图的搜索算法进行讨论。 深度优先搜索（DFS） 我们之前在学习二叉树的过程中，讲解了树的前序遍历，各位回想一下，我们当时是如何在进行遍历的？ 前序遍历就是勇往直前，直接走到底，然后再回去走其他的分支，而我们的图其实也可以像这样，我们可以一路向前，如果到了死胡同，那么就倒回去再走其他的方向，如果所有方向都走不通，继续再回到上一个路口（实际上就是我们人脑的思维）这样不断的寻找，肯定是可以找到的。 比如现在我们要从A开始寻找下图中的I： 那么我们的路线可以是这样的： 此时顶点B有三个方向，那么我们可以先随便选一个方向（当然，一般情况下为了规范，推荐按照字母排列顺序来走，这里为了演示，就随便走了）看看： 此时来到K，我们发现K已经是一个死胡同，没有其他路了，那么此时我们就需要回到上一个路口，继续去探索其他的路径： 此时我们接着往下一个相邻的顶点G走，发现G有其他的分叉，那么我们就继续向前： 此时走到F发现又是死路，那么退回到G，走其他的方向： 运气太垃了，又到死胡同了，同样的，回到G继续走其他方向： 走到C之后，我们有其他的路，我们继续往后走： 此时走到顶点H，发现H只有一条路，并且H再向前是已经走过的顶点B，那么此时不能再向前了，所以说直接退回到C，走另一边： 此时来到E，又有两条路，那么继续随便选一条走： 此时来到顶点J，发现又是死胡同，退回到E，继续走另一边： 好了，经过了这么多试错，终于是找到了I顶点，这种方式就是深度优先搜索了。 那么我们就来打个代码玩玩吧，这里我们构建一个简单一点的图： 这里我们使用邻接表表示图，因为邻接表直接保存相邻顶点，所以说到达顶点时遍历相邻顶点会更快（能够到达 $O(V + E)$ 线性阶）而如果使用邻接矩阵的话，我们得完整遍历整个二维数组，就比较费时间了（需要 $O(V^2)$ 平方阶）。 比如现在我们想从A开始查找顶点F，首先先把图给建好（注意有6个顶点，记得容量写好）： int main(){ Graph graph = create(); for (int c = 'A'; c B addEdge(graph, 1, 2); //B -> C addEdge(graph, 1, 3); //B -> D addEdge(graph, 1, 4); //D -> E addEdge(graph, 4, 5); //E -> F printGraph(graph); } 然后就是我们的深度优先搜索算法了： /** * 深度优先搜索算法 * @param graph 图 * @param startVertex 起点顶点下标 * @param targetVertex 目标顶点下标 * @param visited 已到达过的顶点数组 */ void dfs(Graph graph, int startVertex, int targetVertex, int * visited){ } 我们先将深度优先遍历写出来： /** * 深度优先搜索算法（无向图和有向图都适用） * @param graph 图 * @param startVertex 起点顶点下标 * @param targetVertex 目标顶点下标 * @param visited 已到达过的顶点数组 */ void dfs(Graph graph, int startVertex, int targetVertex, int * visited) { visited[startVertex] = 1; //走过之后一定记得mark一下 printf(\"%c -> \", graph->vertex[startVertex].element); //打印当前顶点值 Node node = graph->vertex[startVertex].next; //遍历当前顶点所有的分支 while (node) { if(!visited[node->nextVertex]) //如果已经到过（有可能是走其他分支到过，或是回头路）那就不继续了 dfs(graph, node->nextVertex, targetVertex, visited); //没到过就继续往下走，这里将startVertex设定为对于分支的下一个顶点，按照同样的方式去寻找 node = node->next; } } int main(){ ... int arr[graph->vertexCount]; for (int i = 0; i vertexCount; ++i) arr[i] = 0; dfs(graph, 0, 5, arr); } 深度优先遍历结果如下： 路线如下： 现在我们将需要查找的顶点进行判断： /** * 深度优先搜索 * @param graph 图 * @param startVertex 起点顶点下标 * @param targetVertex 目标顶点下标 * @param visited 已到达过的顶点数组 * @return 搜索结果，如果找到返回1，没找到返回0 */ _Bool dfs(Graph graph, int startVertex, int targetVertex, int * visited) { visited[startVertex] = 1; printf(\"%c -> \", graph->vertex[startVertex].element); if(startVertex == targetVertex) return 1; //如果当前顶点就是要找的顶点，直接返回 Node node = graph->vertex[startVertex].next; while (node) { if(!visited[node->nextVertex]) if(dfs(graph, node->nextVertex, targetVertex, visited)) //如果查找成功，直接返回1，不用再看其他分支了 return 1; node = node->next; } return 0; //while结束那肯定是没找到了，直接返回0 } int main(){ ... int arr[graph->vertexCount]; for (int i = 0; i vertexCount; ++i) arr[i] = 0; printf(\"\\n%d\", dfs(graph, 0, 5, arr)); } 得到结果如下： 再来找一下顶点D呢： 可以看到到D之后就停止了，因为已经找到了。那么要是去寻找一个没有连接到图中的结点呢？ 可以看到整个图按照深度优先遍历找完了都没找到。 广度优先搜索（BFS） 前面我们介绍了深度优先搜索，我们接着来看另一种方案。还记得我们在前面二叉树中学习的层序遍历吗？ 层序遍历实际上是优先将每一层进行遍历，而不是像前序遍历那样勇往直前，而图的搜索其实也可以采用这种方案，我们可以先探索顶点所有的分支，然后再依次去看这些分支的所有分支： 首先咱还是从A来到B，此时B有三条分叉路，我们依次访问这三条路的各个顶点： 我们先记录一下这三个顶点，同样需要使用队列来完成：H、G、K 注意访问之后不要再继续向下了，接着我们从这三个里面的第一个顶点H开始，按照同样的方法继续： 此时因为只有一个分支，所以说找到C，继续记录，将C也添加进去：G、K、C 注意此时需要回去，继续看之前三个顶点的第二个顶点G： 此时C已经看过了，接着就找到了F和D，也是记录一下：K、C、F、D 然后，我们继续看之前三个结点的最后一个： 此时K已经是死胡同了，那么就结束，然后继续看下一个C： 此时继续将E给记录进去：F、D、E，接着看D和F，也没有后续了，那么最后就只有E了： 成功找到目标I顶点，实际上广度优先遍历就是尽可能地扩展范围，多去探索广阔的土地，而不是死拽着一根不放，就像爱情，实在得不到就算了吧，她至始至终就没爱过你，不要继续在她身上浪费感情了，多去结交新的朋友，相信你会遇到更好的。 那么按照这个思路，我们就来尝试代码实现一下，首先把队列搬过来： typedef int T; //这里将顶点下标作为元素 struct QueueNode { T element; struct QueueNode * next; }; typedef struct QueueNode * QNode; struct Queue{ QNode front, rear; }; typedef struct Queue * LinkedQueue; _Bool initQueue(LinkedQueue queue){ QNode node = malloc(sizeof(struct QueueNode)); if(node == NULL) return 0; queue->front = queue->rear = node; return 1; } _Bool offerQueue(LinkedQueue queue, T element){ QNode node = malloc(sizeof(struct QueueNode)); if(node == NULL) return 0; node->element = element; queue->rear->next = node; queue->rear = node; return 1; } _Bool isEmpty(LinkedQueue queue){ return queue->front == queue->rear; } T pollQueue(LinkedQueue queue){ T e = queue->front->next->element; QNode node = queue->front->next; queue->front->next = queue->front->next->next; if(queue->rear == node) queue->rear = queue->front; free(node); return e; } 我们还是以上面的图为例： /** * 广度优先遍历 * @param graph 图 * @param startVertex 起点顶点下标 * @param targetVertex 目标顶点下标 * @param visited 已到达过的顶点数组 * @param queue 辅助队列 */ void bfs(Graph graph, int startVertex, int targetVertex, int * visited, LinkedQueue queue) { offerQueue(queue, startVertex); //首先把起始位置顶点丢进去 visited[startVertex] = 1; //起始位置设置为已走过 while (!isEmpty(queue)) { int next = pollQueue(queue); printf(\"%c -> \", graph->vertex[next].element); //从队列中取出下一个顶点，打印 Node node = graph->vertex[next].next; //同样的，把每一个分支都遍历一下 while (node) { if(!visited[node->nextVertex]) { //如果没有走过，那么就直接入队 offerQueue(queue, node->nextVertex); visited[node->nextVertex] = 1; //入队时就需要设定为1了 } node = node->next; } } } 我们来测试一下吧： int main(){ ... int arr[graph->vertexCount]; struct Queue queue; initQueue(&queue); for (int i = 0; i vertexCount; ++i) arr[i] = 0; bfs(graph, 0, 5, arr, &queue); } 成功得到结果： 如果要指定查找的话，就更简单了： _Bool bfs(Graph graph, int startVertex, int targetVertex, int * visited, LinkedQueue queue) { offerQueue(queue, startVertex); visited[startVertex] = 1; while (!isEmpty(queue)) { int next = pollQueue(queue); printf(\"%c -> \", graph->vertex[next].element); Node node = graph->vertex[next].next; while (node) { if(node->nextVertex == targetVertex) return 1; //如果就是我们要找的，直接返回1 if(!visited[node->nextVertex]) { offerQueue(queue, node->nextVertex); visited[node->nextVertex] = 1; } node = node->next; } } return 0; //找完了还没有，那就返回0 } 这样，我们就实现了图的广度优先搜索。 图练习题： 若一个图的边集为：{(A, B),(A, C),(B, D),(C, F),(D, E),(D, F)}，对该图进行深度优先搜索，得到的顶点序列可能是： A. ABCFDE B. ACFDEB C. ABDCFE D. ABDFEC 这种题直接把图画出来，因为边集是圆括号，说是肯定是一个无向图，图先画出来再说： 因为这四个选项都是A开始的，所以说我们从A开始看，因为A连接了B和C，所以说A后面紧跟B或是C都可以，接着往下看，先看走B的情况，因为B只连接了一个D，所以说选项A直接排除，接着往下看，D链接了E和F，所以说选项C直接排除，此时只有选项D了，我们接着往后看，此时我们走F，紧接着的只有C，D也不满足，所以选择B（当然你怕不稳的话把B选项也推出来就行了） 若一个图的边集为：{(A, B),(A, C),(B, D),(C, F),(D, E),(D, F)}，对该图进行广度优先搜索，得到的顶点序列可能是： A. ABCDEF B. ABCFDE C. ABDCEF D. ACBFDE 跟上面是同样的思路，只要各位小伙伴听懂了BFS和DFS的思路，肯定没问题的，选择 D 如下图所示的无向连通图，从顶点A开始对该图进行广度优先遍历，得到的顶点序列可能是： 同样的思路，选择D 图应用 前面我们介绍了图的相关性质，以及图的遍历方式，这一部分我们接着来看图的相关应用。 生成树和最小生成树 在开始讲解最小生成树之前，我们先来回顾一下之前讲解的连通分量。 对于无向图来说，如果图中任意两点都是连通的，那么我们就称这个图为连通图。 对于有向图来说，如果图中任意顶点A和B，既有从A到B的路径，也有B到A的路径，则称该有向图是强连通图。 而连通分量则要求是某个图的子图（子图可以是只包原图含部分顶点和边的图，也可以就是原图本身，因为定义只是子集，不是真子集），并且子图也要是连通的才可以，还有一个重要条件是必须拥有极大顶点数（能够保证图连通的且包含原图最大的顶点数）并且包含所有依附于这些顶点的边（这个极大更偏向于顶点数的极大），我们就称这个子图为极大连通子图。 无向图的极大连通子图称为连通分量。 有向图的极大强连通子图称为强连通分量。 比如下面的有向图，这个图本身并不是连通的： 其中图1和图2都满足上述条件，都是强连通分量，本身就是连通并且已经到达最大的顶点数和边数了（只要再加入其他的顶点和边就会导致不连通）但是图3并不是子图（A到B的边缺失）并且不是强连通的，所以说不是强连通分量。 又比如下面这个无向图，这个图本身也是不连通的： 其中图1和图3都满足条件，都是连通分量，但是图2并没有到达最大的顶点数和边数，所以说不是连通分量。 当然上面都是原图不连通的情况，如果原图就是一个连通图，包含其所有顶点和边的子图就已经满足条件了，所以其本身就是一个连通分量；同样的，如果原图就是一个强连通图，那么其本身就是一个强连通分量。 总结如下： 如果原图本身不连通，那么其连通分量（强连通分量）不止一个。 如果原图本身连通，那么其连通分量（强连通分量）就是其本身。 极大连通子图我们回顾完了，那么我们接着来讨论一下极小连通子图。这里的极小主要是说的边数的极小，首先依然要是原图的子图并且是连通的，但是此时要求具有最大的顶点数和最小的边数，也就是说再去掉任意一条边会导致图不连通（直接理解为极大连通子图尽可能去掉能去掉的边就行了） 针对于极小连通子图，我们一般只讨论无向图（对于有向图，不存在极小强连通子图的说法，因为主要是讨论生成树）我们依然将原图就是连通图和原图不是连通图分开分析，首先是原图本身就是连通图的情况： 原图本身就是连通图，那么其极大连通子图就是其本身，此时我们需要尽可能去掉那些“不必要”的边，依然能够保证其是连通的，也就是极小连通子图。可以看到右边两幅图，跟左边这幅图包含了同样的顶点数量，但是边数被去掉了一些，并且如果再继续去掉任意一条边的话，那么就会导致不连通，所以说左边两幅图都是右边这幅图的极小连通图（当然，就像上面这样，可能会出现多种方案，极小连通图不唯一） 我们发现，无论是去掉哪些边的情况，到最后一定是只留下 N-1 条边（其中N是顶点数）每个顶点有且仅有一条路径相连，也就是包含原图全部N个顶点的极小连通子图，我们一般称其为：生成树，为什么叫生成树呢，因为结点数和边数正好满足树的定义（且不存在回路的情况），我们可以将其调整为一棵树： 当然，这是原图本身就连通的情况，如果原图本身不连通的话，那么就会出现多个连通分量，此时就会得到一片生成森林，森林中的树的数量就是其连通分量的数量。 那么我们在程序中要怎么才能得到一个有向图的生成树呢？我们可以使用前面讲解的两种图的遍历方式来进行生成，我们以下图为例，这是一个普通的无向连通图： 我们如果按照深度优先遍历的方式，从G开始，那么就会得到下面的顺序： 按照顺序我们就可以得到一棵生成树： 虽然看着很奇怪，但是按照我们的顺序，得到的树就是这样的，可以发现，因为我们的深度优先搜索不会去走那些回头路，相当于直接把哪些导致回路和多余的边给去掉了，最后遍历得到的结果就是一颗生成树了。 同样的，我们来看看如果是按照广度优先遍历的方式，又会得到什么结果呢？ 最后得到的生成树为： 实际上我们发现，在广度优先遍历下得到的生成树，也是按照每一层在进行排列的，非常清晰。当然，因为深度优先遍历和广度优先遍历本身的顺序就不是唯一的，所以最后得到的生成树也不是唯一的。 生成树讨论完成之后，我们接着来讨论一下最小生成树，那么这个最小指的是什么最小呢？如果我们给一个无向图的边都加上权值（网图）现在要求生成树边的权值总和最小，我们就称这棵树为最小生成树（注意最小生成树不唯一，因为有可能出现多种方案都是最小的情况）比如下面的就是最后得到的最小生成树了： 构建最小生成树有两种算法，一种是普利姆（Prim）算法，还有一种是克鲁斯卡尔（Kruskal）算法，我们先来讨论第一种： 我们以下图为例： 普利姆算法的核心就是从任意一个顶点开始，不断成长为一棵树，每次都会选择尽可能小的方向去进行延伸，比如我们一开始还是从顶点A开始： 此时与A相连的边有B和E，A的延伸方向有两个，此时我们只需要选择一个最小的就可以了： 此时我们已经构建出了由A、E组成的一棵树，同样的，我们需要去寻找与当前树中A、E顶点相连的所有顶点，包括B、G、H，哪一个最小，那么下一个延伸的就是哪一个，此时发现H和E之间最小，继续延伸： 现在已经变成了由A、E、H组成的一棵树，同样的，按照之前的思路继续寻找一个最小的方向进行延伸： 继续进行延伸，发现F、K之间最小： 此时K、B和K、D和K、H的权重都是4，其中H顶点已经走过了，不能出现回路，所以说不考虑，此时随便选择K、B或是K、D都可以，不会影响后续结果： 此时依然是K、D为最小，所以说直接选择： 紧接着，我们发现最小权重的来到了5，此时权重为5的边有B、E和H、I和B、D，但是由于E、D已经走过，此时直接选择H、I即可： 接着，我们发现I、G也是5，直接选择即可： 然后最小权重此时就是6了，选择H、J和I、J都可以，随便选择一个即可： 此时，整个图的所有顶点就遍历完成了，现在我们去掉那些没用被采用的边，得到的结果就是我们的最小生成树了： 虽然样子有点丑，但是把它捋一捋就好了。可以看到省去的边都是尽可能大的边，或是那种导致回路的边，留下的边基本都是权重小的边，得到的就是最小生成树了（注意考试的时候只要按照我们的思路推是肯定没问题的，但是千万要仔细看，不要把边给看漏了，不然会出大问题） 我们接着来看另一种，克鲁斯卡尔算法，它的核心思想就是我们主动去选择那些小的边，而不是像上面一样被动地扩展延伸。 在一开始的时候，直接去掉所有的边，我们从这些边中一个一个选择出来（注意是任意一条边都可以选择，并不是只有选择的顶点旁边才能选择，这个过程中可能会出现多棵树，但是最后一定会连成一棵树的），最后形成一颗最小生成树，假设一开始什么都没选择，被选中的边我们一会用橙色标注： 首先我们直接找到最小边，K、F，它的权值为2，所以说直接选择就行： 紧接着就是F、H的边，权重为3，目前最小的了： 此时最小的权重就只有4了，目前有4条边都可以进行选择，但是K、H这条边因为K和H都已经在树中了，所以说不能考虑，其他三条边都是没问题的，我们随便选择一条就行了： 继续选择权重为4的边： 此时权重就来到了5，那么权重为5的顶点我们也可以随便选择一条，只要不会导致出现回路就行了： 此时连接G、I，我们发现出现了两棵树，没关系的，最后会连成一棵树的，我们继续选择其他权重为5的边： 此时我们选择A、E这条边，然后是H、I这条边，虽然这条边上的H和I顶点都已经在树中了，但是它们并不属于同一棵树，这种情况也是可以连接的，然后我们继续选择权重为6的顶点： 此时选择I、J或是H、J都可以（最小生成树不唯一）现在我们已经连接上所有的顶点了，最小生成树构建完成，我们把那些没有选择都边都扔了： 其实无论是哪种算法，最后都能够得到一棵最小生成树，有关实现代码，由于太过复杂，这里就不进行编写了。 最短路径问题 前面我们介绍了最小生成树，通过两种算法就能够从众多的边中选择那些尽可能小的边得到一个权重最小的树，这一块我们将继续讨论最小开销相关的问题。 地铁线路错综复杂，我们想要从一个站点坐到另一个站点，其实是有很多种方案的，比如我们可以选择少的换乘数放的方案，或是距离近的方案，不同的方案可能坐的站点数就不同，而最后我们出站时，始终是按照从A地点到B地点最小经过的站点数进行收费的（比如从A到B有两种方案，前者要坐11个站，后者要坐7个站，但是最后只会按7个站进行收费），那么这么多线路，我们要如何计算得到一条最短的路径呢？ 我们首先从最简单的单源最短路径进行讨论，所谓单源最短路径，就是一个顶点出发，到其他顶点的最短路径，比如下面的这张图： 要解决这种问题，我们可以采用迪杰斯特拉（Dijkstra）算法，下面我们来看看迪杰斯特拉算法是如何让计算机来计算最短路径的，它跟普利姆算法求最小生成树有着很多相似之处，我们就从A出发，这里我们需要一个表来记录： dist这一行记录A到其他顶点的最短路径，path这一行记录的是最短路径所邻接的顶点，我们首先还是从A开始，与A直接相邻的两个分别是B和D，其中B的距离是2，D的距离是5，那么我们就先进行一下记录： 因为都是从A过来的，所以说直接记录为A即可，接着我们继续找到当前A路径最短的一个顶点B，此时顶点B可以到达C、D、A，因为不能走回头路，不考虑A，那么目前从A到达C的最短距离就是经过B到达的，相当于A->B加上B->C的距离： 然后我们来看顶点D，此时我们发现，除了A直接到D之外，从B也可以到达D，那么我们就可以比较一下，看是从B到D更短一些，还是从A直接到D更短一些 $min(2 + 2, 5)$ ，通过比较，我们发现从B绕过去会更短一些，只需要4即可，所以说我们将其更新一下： 接着我们继续找到下一个离A最近的顶点D，D与顶点E和J相连，直接更新即可，比如E的最短路径就是相当于是A到D的最短路径加上D到E的路径，D到J也是同理： 此时继续找到表中下一个距离A最近的顶点J，J可以到达H或者是E，按照同样的方式，我们看看是从D直接到E更短，还是从J到E更短，进行比较 $min(6 + 3, 8)$ ，得到结果是D直接过去更短，所以说不需要更新。然后H更新为J过去的最短路径： 我们接着来看下一个距离A最近的顶点C，此时C可以到达F和E，我们先来看E，还是对其进行比较，如果从C到达E更短，那么就更新为新的值，$min(7 + 4, 8)$，最后仍然是从D到E最短，所以说不变，接着我们把F的值更新一下： 然后我们来看下一个距离A最近的顶点E，E连接的就比较多了，此时E最短路径是从D过来的，那么我们就不考虑D，我们来依次看看与其相连的C、F、G、H、J（注意这里比较的是从E到这些顶点，之前比较的是从这些顶点到E，不要以为是一样的了） 从E到达顶点C：$min(8 + 4, 7)$，故C继续采用原方案。 从E到达顶点F：$min(8 + 2, 15)$，此时从E到达F路径更短，更新F。 从E到达顶点G：直接更新。 从E到达顶点H：$min(8 + 6, 13)$，故H继续采用原方案。 从E到达顶点J：$min(8 + 3, 6)$，故J继续采用原方案。 最后得到： 我们继续来到下一个离A最近的顶点F，F连接了G和E，但是由于当前最短路径是从E过来的，不能走回头路，所以说直接去看G，比较 $min(10 + 5, 17)$，得到从F到达G会更短，所以说更新G： 然后我们接着看到下一个最短的顶点H，此时H与G和I相连，我们先来看G，$min(13 + 3, 15)$，维持原方案。然后是I，直接更新即可： 虽然此时表已经填完了，但是我们还没有把所有的顶点都遍历完，有可能还会存在更短的路径，所以说别着急，我们还得继续看。此时继续选择下一个离A最近的顶点G，它与E、F、H、I相连，由于其实从F过来的，排除掉F，我们来看看其他三个： 从G到达顶点E：$min(15 + 9, 8)$，显然选择原方案就行。 从G到达顶点H：$min(15 + 3, 13)$，依然是选择原方案更短。 从G到达顶点I：$min(15 + 4, 21)$，从G到达I更短，更新。 最后得到： 此时我们来看最后一个顶点I，与其连接的有G和H，因为是从G过来的，直接比较H就行了，$min(19 + 8, 13)$，维持原方案就行，至此，迪杰斯特拉算法结束。最后得到的表，就是最终的A到达各个顶点的最短路径值了，并且根据path这一栏的数据，我们就可以直接推出一条路径出来。 当然，这只是解决了单源最短路径问题，现在我们将问题的难度提升一下，比如我们现在想要求得图中每一对顶点之间的最短路径，那么该如何进行计算呢？最简单的办法就是，我们可以将所有的顶点都执行一次迪杰斯特拉算法，这样我们就可以求到所有顶点之间的最短距离了。只不过这种方式并不是最好的选择，对于这种问题，我们可以选择弗洛伊德（Floyd）算法。 比如下面的有向网图（权值别出现负数了，不然要出大问题）： 我们可以很轻松地得到它的邻接矩阵： 而弗洛伊德算法则是根据最初的邻接矩阵进行推导得出的。规则如下： 从1开始，一直到n（n就是顶点数）的一个矩阵序列A1、A2、...An，我们需要从最初的邻接矩阵开始，从A1开始不断往后推。 每一轮，我们都会去更新那些非对角线（对角线都是0，更新了还是0，所以说没必要看）、i行i列以外的元素，判断水平和垂直方向投影的两个元素之和是否比原值小，如果是，那就更新为新的值。迭代公式为：$Ak(i,j)=min(A{k−1}(i,j), A{k−1}(i,k)+A{k−1}(k,j))$ 经历n轮后，最后得到的就是最终的最短距离了。 我们从第一轮开始，第一轮是基于原有的邻接矩阵来进行处理的： 此时我们看到，除了对角线以外，就是B->C和C->B的这两个位置，我们按照上面的规则，进行计算： 同样的，我们继续看到C->B这个为止，按照同样的方式进行更新： 最后更新完成得到的结果如下： 实际上我们发现，我们计算的和相当于是绕路的结果与当前直接走的结果相比较得到的。按照的同样的方式，我们开始第二轮： 更新完成之后，C->A的距离变成了5： 我们接着来看最后一轮： 此时我们将A->B的距离也更新一下： 最后我们得到的矩阵，存放的就是所有顶点之间的最短距离了，当然这里我们只计算了最短距离，没有去记录从哪个方向到达此顶点的，各位小伙伴也可以在计算的同时单独在另一个表中记录一下从哪个顶点过去计算出来的最小距离，这里就不演示了。实际上这个算法对我们来说是更好理解的一种算法，并且在编写程序时也会很简单，我们以下图为例： 代码如下： #define INF 210000000 #define N 4 int min(int a, int b){ return a > b ? b : a; } void floyd(int matrix[N][N], int n){ for (int k = 0; k 最后得到的结果为： 经过对比，确实是最短的路径了。 拓扑排序 我们接着来看拓扑排序，实际上我们生活中可能会遇到下面的问题： 比如我们的大学课程的学习，一些课程开启可能需要修完一些前置课程，比如数据结构开课需要先修完C语言程序设计，Java开课需要修完计算机网络、计算机组成原理等课程，我们在到达某个阶段之前，需要完成一些前置条件才可以解锁。包括我们游戏中的任务，需要先完成哪些主线任务，完成哪些支线任务，才能解锁新的阶段。 我们可以将这些任务都看做是一个顶点，最后就能够连接成一个有向图： 因为始终是由前置条件来解锁后续，所以说整个图中是不可以出现循环的（要是有循环的话就没办法继续了，就像先有鸡还是先有蛋的问题一样）所以说构建出来的这种图我们也称为有向无环图（DAG），其实按照我们通俗的话来说，它就是个流程图罢了，我们只需要按照这个流程图来进行即可。像这种顶点表示活动或任务的图也称为AOV图。 拓扑排序（Topological Order）是指，将一个有向无环图（Directed Acyclic Graph）进行排序进而得到一个有序的线性序列。 比如上图的拓扑排序可以是以下的几种： A,B,C,D,E,F,G,H,I,J A,C,D,B,E,F,G,H,I,J A,D,C,B,E,F,G,H,I,J A,B,D,C,E,F,G,H,I,J 只要我们保证前置任务在后续任务之前完成即可，前置任务的完成顺序不做要求，所以拓扑排序不唯一。 那么我们在程序中如何对一个有向无环图进行拓扑排序呢？以上图为例，其实很简单，我们还是利用队列来完成，我们每次只需要将那些入度为0的顶点，丢进队列中（注意丢进去之后记得更新一下图中其他顶点的入度）首先从A： 此时队列中有A这个顶点，接着我们来看看图中剩余的顶点，哪些又是入度为0的顶点，可以看到D也是： 当目前所有度数为0的顶点进入队列之后，我们开始出队，正式开始拓扑排序，在出队时直接打印，并且查看，当此顶点离开图之后，图中会不会有其他顶点的入度变为0，如果有，将其他顶点入队。比如此时A出队之后，那么A要从图中移除，现在B也变成了入度为0的顶点，所以说将B丢进队列： 接着，我们继续让D出队，我们发现D出队之后，E变成了入度为0的顶点，所以说将E入队： 接着我们继续出队，B出队之后，我们发现没有任何顶点入度变为0了，所以说不管，继续： 继续将E出队，在E出队之后，顶点F、C都变成了入度为0的顶点，统统入队： 此时继续将C出队，我们发现没有任何顶点入队变为0，我们继续来看F： 当F出队后，顶点G变成了入度为0的顶点，此时将G入队： 剩下就是把G出队，然后F入队F再出队了： 最后得到的拓扑序列为：ADBECFGH，其实思路还是比较简单的，当然，其实我们利用拓扑排序算法可以检测一个有向图是否为有向无环图，也就是说顶点还没遍历完队列就空了的话，说明一定出现了回路。 关键路径计算 经过前面的学习，我们知道一个任务可能会存在前置任务，只不过我们仅仅是简单讨论了任务的完成顺序，如果此时我们为每个任务添加一个权重，表示任务所需要花费的时间，那么我们的后续任务就需要前置任务全部按时间完成之后才能继续： 比如A代表某个任务（事件），B代表另一个任务，我们需要先花费2天时间完成A之后，才能开始B，活动包括时间用边来表示，我们将边作为活动的图称为AOE图，每个事件对应着多个活动（多条边）它就像一个大工程一样，从A开始，中间需要经过各种各样的步骤，最后到H完工作为结束。 而我们需要计算的是那些最拖延工期的活动，比如要开始任务C，那么需要完成A、B才可以，完成A需要7天，完成B需要5天，由于C需要同时完成A和B才能继续，所以说A就变成了最拖延工期的任务，因为它的时间比B还长，B都完工了，还需要等待A完成才可以。只要计算出这些最拖延工期的任务，得到一条关键路径，我们就可以得到完成整个工程最早的时间以及各项任务可以在什么时候开工了。 我们来看看如何进行计算，我们以下图为例： 我们需要计算两个东西，一个是事件最早完成时间（也就是要完成这个事件最快要多久），还有一个是事件最晚开始时间（就是这个事件在不影响工期的情况下最晚可以多久开始）： 我们依然是按照之前的拓扑排序的顺序进行，首先一开始是A，因为只有一个起点A肯定是可以直接开始的，所以说最早和最晚时间都是0（注意如果出现多个起点的话，最晚开始时间就不一定了），我们接着AOE图的工作顺序，来计算任务B和C的最早和最晚时间： 接着就是D和E，首先D需要B和C同时完工之后才能继续，那么也就是说需要选择B和C过来时间最长的那一个： 最后就是F，到达F一共有三条路径，我们依然是选择最长的那一条，从D过来总共需要8天时间： 故整个工程的最早完成时间为8天，我们接着来看活动的最晚开始时间，现在我们要从终点倒着往回看： 首先终点一定是8，因为工期最快是在8天结束的，我们继续倒着往回走，先来看E，E需要6天才能到达，但是只需要1天就可以结束，所以 8 - 1 = 7，最晚可以在第7天时动工： 然后是D，因为D到F需要2天时间，而D已经是第6天了，总时间8天，所以说D刻不容缓，第6天就需要马上开工： 然后是C，C比较复杂，因为C有两个活动，一个是指向D的，一个是指向F的，我们需要单独计算每一个活动： C -> F：用F的最晚开始时间减去任务时间 = 8 - 3 = 5，此时C最晚可以从第5天开始。 C -> D：用D的最晚开始时间减去任务时间 = 6 - 4 = 2，此时因为C的最早开始时间就是2，所以说C不能晚点开始。 综上，C不能晚点开始，只能从第2天就开始，因为要满足D的条件： 最后是B，B也是有两个任务，一个是指向E一个是指向D： B -> E：用E的最晚开始时间减去任务时间 = 7 - 3 = 4，此时B最晚可以第4天开工。 B -> D：用D的最晚开始时间减去任务时间 = 6 - 2 = 4，同上。 所以，B的最晚开始时间可以是第4天： 当然最后我们也可以计算一下A -> B和A -> C，但是由于只有这一个起点，所以说算出来肯定是0，当然如果出现多个起点的情况，还需要进行计算得到的。 计算完成之后，我们就可以得到关键路径了，也就是那些最早和最晚时间都一样的顶点（说明是刻不容缓的，时间很紧）这些顶点连成的路线，就是我们要找的关键路径了：A -> C -> D -> F，这条路径被安排的满满当当。关键路径上的所有活动都是关键活动，整个工期就是由这些活动在决定的，因此，我们可通过适当加快关键活动来缩短整个项目的工期，但是注意不能加快得太猛，因为如果用力过猛可能会导致关键路径发生变化。当然，关键路径并不是唯一的，可能会出现一样的情况。 至此，有关图结构相关的内容，我们就讲解到这里。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（四）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（四）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Java/算法/数据结构与算法（五）.html":{"url":"Java/算法/数据结构与算法（五）.html","title":"数据结构与算法（五）","keywords":"","body":" 排序算法篇 恭喜各位小伙伴来到最后一部分：排序算法篇，数据结构与算法的学习也接近尾声了，坚持就是胜利啊！ 一个数组中的数据原本是凌乱的，但是由于需要，我们需要使其有序排列，要实现对数组进行排序我们之前已经在C语言程序设计篇中讲解过冒泡排序和快速排序（选学），而这一部分，我们将继续讲解更多种类型的排序算法。 在开始之前，我们还是从冒泡排序开始回顾。 基础排序 冒泡排序 冒泡排序在C语言程序设计篇已经讲解过了，冒泡排序的核心就是交换，通过不断地进行交换，一点一点将大的元素推向一端，每一轮都会有一个最大的元素排到对应的位置上，最后形成有序。算法演示网站：https://visualgo.net/zh/sorting?slide=2-2 设数组长度为N，详细过程为： 共进行N轮排序。 每一轮排序从数组的最左边开始，两两元素进行比较，如果左边元素大于右边的元素，那么就交换两个元素的位置，否则不变。 每轮排序都会将剩余元素中最大的一个推到最右边，下次排序就不再考虑这些已经在对应位置的元素。 比如下面的数组： 那么在第一轮排序时，首先比较前两个元素： 我们发现前者更大，那么此时就需要交换，交换之后，继续向后比较后面的两个元素： 我们发现后者更大，不变，继续看后两个： 此时前者更大，交换，继续比较后续元素： 还是后者更大，继续交换，然后向后比较： 依然是后者更大，我们发现，只要是最大的元素，它会在每次比较中被一直往后丢： 最后，当前数组中最大的元素就被丢到最前面去了，这一轮排序结束，因为最大的已经排到对应的位置上了，所以说第二轮我们只需要考虑其之前的这些元素即可： 这样，我们就可以不断将最大的丢到最右边了，最后N轮排序之后，就是一个有序的数组了。 程序代码如下： void bubbleSort(int arr[], int size){ for (int i = 0; i arr[j + 1]) { //如果后面比前面的小，那么就交换 int tmp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = tmp; } } } } 只不过这种代码还是最原始的冒泡排序，我们可以对其进行优化： 实际上排序并不需要N轮，而是N-1轮即可，因为最后一轮只有一个元素未排序了，相当于已经排序了，所以说不需要再考虑了。 如果整轮排序中都没有出现任何的交换，那么说明数组已经是有序的了，不存在前一个比后一个大的情况。 所以，我们来改进一下： void bubbleSort(int arr[], int size){ for (int i = 0; i arr[j + 1]) { flag = 0; //如果发生交换，说明不是有序的，把标记变成0 int tmp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = tmp; } } if(flag) break; //如果没有发生任何交换，flag一定是1，数组已经有序，所以说直接结束战斗 } } 这样，我们才算编写完了一个优化版的冒泡排序。 当然，最后我们还需要介绍一个额外的概念：排序的稳定性，那么什么是稳定性呢？如果说大小相同的两个元素在排序之前和排序之后的先后顺序不变，这个排序算法就是稳定的。我们刚刚介绍的冒泡排序只会在前者大于后者的情况下才会进行交换，所以说不会影响到原本相等的两个元素顺序，因此冒泡排序是稳定的排序算法。 插入排序 我们来介绍一种新的排序算法，插入排序，准确地说应该叫直接插入排序，它的核心思想就像我们玩斗地主一样。 相信各位应该都玩过，每一轮游戏在开始之前，我们都要从牌堆去摸牌，那么摸到牌之后，在我们手中的牌顺序可能是乱的，这样肯定不行啊，牌都没理顺我们怎么知道哪些牌有多少呢？为了使得其有序，我们就会根据牌的顺序，将新摸过来的牌插入到对应的位置上，这样我们后面就不用再整理手里的牌了。 而插入排序实际上也是一样的原理，我们默认前面的牌都是已经排好序的（一开始就只有第一张牌是有序状态），剩余的部分我们会挨着遍历，然后将其插到前面对应的位置上去，动画演示地址：https://visualgo.net/zh/sorting 设数组长度为N，详细过程为： 共进行N轮排序。 每轮排序会从后面依次选择一个元素，与前面已经处于有序的元素，从后往前进行比较，直到遇到一个不大于当前元素的的元素，将当前元素插入到此元素的前面。 插入元素后，后续元素则全部后移一位。 当后面的所有元素全部遍历完成，全部插入到对应的位置之后，排序完成。 比如下面的数组： 此时我们默认第一个元素已经是处于有序状态，我们从第二个元素开始看： 将其取出，从后往前，与前面的有序序列依次进行比较，首先比较的是4，发现比4小，继续向前，发现已经到头了，所以说直接放到最前面即可，注意在放到最前面之前，先将后续元素后移，腾出空间： 接着插入即可： 目前前面两个元素都是有序的状态了，我们继续来看第三个元素： 依然是从后往前看，我们发现上来就遇到了7小的4，所以说直接放到这个位置： 现在前面三个元素都是有序状态了，同样的，我们继续来看第四个元素： 依次向前比较，发现到头了都没找到比1还小的元素，所以说将前面三个元素全部后移： 将1插入到对应的位置上去： 现在前四个元素都是有序的状态了，我们只需要按照同样的方式完成后续元素的遍历，最后得到的就是有序的数组了，我们来尝试编写一下代码： void insertSort(int arr[], int size){ for (int i = 1; i 0 && arr[j - 1] > tmp) { //只要j>0并且前一个还大于当前待插入元素，就一直往前找 arr[j] = arr[j - 1]; //找的过程中需要不断进行后移操作，把位置腾出来 j--; } arr[j] = tmp; //j最后在哪个位置，就是是哪个位置插入 } } 当然，这个代码也是可以改进的，因为我们在寻找插入位置上逐个比较，花费了太多的时间，因为前面一部分元素已经是有序状态了，我们可以考虑使用二分搜索算法来查找对应的插入位置，这样就可以节省查找插入点的时间了： int binarySearch(int arr[], int left, int right, int target){ int mid; while (left j; k--) arr[k] = arr[k - 1]; //依然是将后面的元素后移 arr[j] = tmp; } } 我们最后还是来讨论一下，插入排序算法的稳定性。那么没有经过优化的插入排序，实际上是不断向前寻找到一个不大于待插入元素的元素，所以说遇到相等的元素时只会插入到其后面，并没有更改相同元素原本的顺序，所以说插入排序也是稳定的排序算法（不过后面使用了二分搜索优化之后就不稳定了，比如有序数组中连续两个相等的元素，现在又来了一个相等的元素，此时中间的正好找到的是排在最前面的相等元素，返回其后一个位置，新插入的元素会将原本排在第二个的相等元素挤到后面去了） 选择排序 我们来看看最后一种选择排序（准确的说应该是直接选择排序），这种排序也比较好理解，我们每次都去后面找一个最小的放到前面即可，算法演示网站：https://visualgo.net/zh/sorting 设数组长度为N，详细过程为： 共进行N轮排序。 每轮排序会从后面的所有元素中寻找一个最小的元素出来，然后与已经排序好的下一个位置进行交换。 进行N轮交换之后，得到有序数组。 比如下面的数组： 第一次排序需要从整个数组中寻找一个最小的元素，并将其与第一个元素进行交换： 交换之后，第一个元素已经是有序状态了，我们继续从剩下的元素中寻找一个最小的： 此时2正好在第二个位置，假装交换一下，这样前面两个元素都已经是有序的状态了，我们接着来看剩余的： 此时发现3是最小的，所以说直接将其交换到第三个元素位置上： 这样，前三个元素都是有序的了，通过不断这样交换，最后我们得到的数组就是一个有序的了，我们来尝试编写一下代码： void selectSort(int arr[], int size){ for (int i = 0; i arr[j]) min = j; int tmp = arr[i]; //找出最小的元素之后，开始交换 arr[i] = arr[min]; arr[min] = tmp; } } 当然，对于选择排序，我们也可以进行优化，因为每次都需要选一个最小的出来，我们不妨再顺手选个最大的出来，小的往左边丢，大的往右边丢，这样就能够有双倍的效率完成了。 void swap(int * a, int * b){ int tmp = *a; *a = *b; *b = tmp; } void selectSort(int arr[], int size){ int left = 0, right = size - 1; //相当于左端和右端都是已经排好序的，中间是待排序的，所以说范围不断缩小 while (left arr[max]) max = i; } swap(&arr[max], &arr[right]); //这里先把大的换到右边 //注意大的换到右边之后，有可能被换出来的这个就是最小的，所以说需要判断一下 //如果遍历完发现最小的就是当前右边排序的第一个元素 //此时因为已经被换出来了，所以说需要将min改到换出来的那个位置 if (min == right) min = max; swap(&arr[min], &arr[left]); //接着把小的换到左边 left++; //这一轮完事之后，缩小范围 right--; } } 最后我们来分析一下选择排序的稳定性，首先选择排序是每次选择最小的那一个，在向前插入时，会直接进行交换操作，比如原序列为 3,3,1，此时选择出1是最小的元素，与最前面的3进行交换，交换之后，原本排在第一个的3跑到最后去了，破坏了原有的顺序，所以说选择排序是不稳定的排序算法。 我们来总结一下上面所学的三种排序算法，假设需要排序的数组长度为n： 冒泡排序（优化版）： 最好情况时间复杂度：$O(n)$，如果本身就是有序的，那么我们只需要一次遍历，当标记检测到没有发生交换，直接就结束了，所以说一遍就搞定。 最坏情况时间复杂度：$O(n^2)$，也就是硬生生把每一轮都吃满了，比如完全倒序的数组就会这样。 空间复杂度：因为只需要一个变量来暂存一下需要交换的变量，所以说空间复杂度为 $O(1)$ 稳定性：稳定 插入排序： 最好情况时间复杂度：$O(n)$，如果本身就是有序的，因为插入的位置也是同样的位置，当数组本身就是有序的情况下时，每一轮我们不需要变动任何其他元素。 最坏情况时间复杂度：$O(n^2)$，比如完全倒序的数组就会这样，每一轮都得完完整整找到最前面插入。 空间复杂度：同样只需一个变量来存一下抽出来的元素，所以说空间复杂度为 $O(1)$ 稳定性：稳定 选择排序： 最好情况时间复杂度：$O(n^2)$，即使数组本身就是有序的，每一轮还是得将剩余部分挨个找完之后才能确定最小的元素，所以说依然需要平方阶。 最坏情况时间复杂度：$O(n^2)$，不用多说了吧。 空间复杂度：每一轮只需要记录最小的元素位置即可，所以说空间复杂度为 $O(1)$ 稳定性：不稳定 表格如下，建议记住： 排序算法 最好情况 最坏情况 空间复杂度 稳定性 冒泡排序 $O(n)$ $O(n^2)$ $O(1)$ 稳定 插入排序 $O(n)$ $O(n^2)$ $O(1)$ 稳定 选择排序 $O(n^2)$ $O(n^2)$ $O(1)$ 不稳定 进阶排序 前面我们介绍了三种基础排序算法，它们的平均情况时间复杂度都到达了 $O(n^2)$，那么能否找到更快的排序算法呢？这一部分，我们将继续介绍前面三种排序算法的进阶版本。 快速排序 在C语言程序设计篇，我们也介绍过快速排序，快速排序是冒泡排序的进阶版本，在冒泡排序中，进行元素的比较和交换是在相邻元素之间进行的，元素每次交换只能移动一个位置，所以比较次数和移动次数较多，效率相对较低。而在快速排序中，元素的比较和交换是从两端向中间进行的，较大的元素一轮就能够交换到后面的位置，而较小的元素一轮就能交换到前面的位置，元素每次移动的距离较远，所以比较次数和移动次数较少，就像它的名字一样，速度更快。 实际上快速排序每一轮的目的就是将大的丢到基准右边去，小的丢到基准左边去。 设数组长度为N，详细过程为： 在一开始，排序范围是整个数组 排序之前，我们选择整个排序范围内的第一个元素作为基准，对排序范围内的元素进行快速排序 先从最右边向左看，依次将每一个元素与基准元素进行比较，如果发现比基准元素小，那么就与左边遍历位置上的元素（一开始是基准元素的位置）进行交换，此时保留右边当前遍历的位置。 交换后，转为从左往右开始遍历元素，如果发现比基准元素大，那么就与之前保留的右边遍历的位置上的元素进行交换，同样保留左边当前的位置，循环执行上一个步骤。 当左右遍历撞到一起时，本轮快速排序完成，最后在最中间的位置就是基准元素的位置了。 以基准位置为中心，划分左右两边，以同样的方式执行快速排序。 比如下面的数组： 首先我们选择第一个元素4作为基准元素，一开始左右指针位于两端： 此时从右往左开始看，直到遇到一个比4小的元素，首先是6，肯定不是，将指针往后移动： 此时继续让3和4进行比较，发现比4小，那么此时直接将3交换（其实直接覆盖过去就行了）到左边指针所指向的元素位置： 此时我们转为从左往右看，如果遇到比4大的元素，就交换到右边指针处，3肯定不是了，因为刚刚才缓过来，接着就是2： 2也没有4大，所以说继续往后看，此时7比4要大，那么继续交换： 接着，又开始从右往左看： 此时5是比4要大的，继续向前，发现1比4要小，所以说继续交换： 接着又转为从左往右看，此时两个指针撞到一起了，排序结束，最后两个指针所指向的位置就是给基准元素的位置了： 本轮快速排序结束后，左边不一定都是有序的，但是一定比基准元素要小，右边一定比基准元素大。接着我们以基准为中心，分成两个部分再次进行快速排序： 这样，我们最后就可以使得整个数组有序了，当然快速排序还有其他的说法，有些是左右都找到了再交换，我们这里的是只要找到就丢过去。既然现在思路已经清楚了，我们就来尝试实现一下快速排序吧： void quickSort(int arr[], int start, int end){ if(start >= end) return; //范围不可能无限制的划分下去，要是范围划得都没了，肯定要结束了 int left = start, right = end, pivot = arr[left]; //这里我们定义两个指向左右两个端点的指针，以及取出基准 while (left = pivot) right--; //从右向左看，直到遇到比基准小的 arr[left] = arr[right]; //遇到比基准小的，就丢到左边去 while (left 这样，我们就实现了快速排序。我们还是来分析一下快速排序的稳定性，快速排序是只要遇到比基准小或者大的元素就直接交换，比如原数组就是：2,2,1，此时第一个元素作为基准，首先右边1会被丢过来，变成：1,2,1，然后从左往右，因为只有遇到比基准2更大的元素才会换，所以说最后基准会被放到最后一个位置：1,2,2，此时原本应该在前面的2就跑到后面去了，所以说快速排序算法，是一种不稳定的排序算法。 双轴快速排序（选学） 这里需要额外补充个快速排序的升级版，双轴快速排序，Java语言中的数组工具类则是采用的此排序方式对大数组进行排序的。我们来看看它相比快速排序，又做了哪些改进。首先普通的快速排序算法在遇到极端情况时可能会这样： 整个数组正好是倒序的，那么相当于上来就要把整个数组找完，然后把8放到最后一个位置，此时第一轮结束： 由于8直接跑到最右边了，那么此时没有右半部分，只有做半部分，此时左半部分继续进行快速排序： 此时1又是最小的一个元素，导致最后遍历完了，1都还是在那个位置，此时没有左半部分，只有右半部分： 此时基准是7，又是最大的，真是太倒霉了，排完之后7跑到最左边，还是没有右半部分： 我们发现，在这种极端情况下，每一轮需要完整遍历整个范围，并且每一轮都会有一个最大或是最小的元素被推向两边，这不就是冒泡排序吗？所以说，在极端情况下，快速排序会退化为冒泡排序，因此有些快速排序会随机选取基准元素。为了解决这种在极端情况下出现的问题，我们可以再添加一个基准元素，这样即使出现极端情况，除非两边都是最小元素或是最大元素，否则至少一个基准能正常进行分段，出现极端情况的概率也会减小很多： 此时第一个元素和最后一个元素都作为基准元素，将整个返回划分为三段，假设基准1小于基准2，那么第一段存放的元素全部要小于基准1，第二段存放的元素全部要不小于基准1同时不大于基准2，第三段存放的元素全部要大于基准2： 因此，在划分为三段之后，每轮双轴快排结束后需要对这三段分别继续进行双轴快速排序，最后就可以使得整个数组有序了，当然这种排序算法更适用于哪些量比较大的数组，如果量比较小的话，考虑到双轴快排要执行这么多操作，其实还不如插入排序来的快。 我们来模拟一下双轴快速排序是如何进行的: 首先取出首元素和尾元素作为两个基准，然后我们需要对其进行比较，如果基准1大于基准2，那么需要先交换两个基准，只不过这里因为4小于6，所以说不需要进行交换。 此时我们需要创建三个指针： 因为有三个区域，其中蓝色指针位置及其左边的区域都是小于基准1的，橙色指针左边到蓝色指针之间的区域都是不小于基准1且不大于基准2的，绿色指针位置及其右边的区域都是大于基准2的，橙色指针和绿色指针之间的区域，都是待排序区域。 首先我们从橙色指针所指元素开始进行判断，分三种情况： 如果小于基准1，那么需要先将蓝色指针向后移，把元素交换换到蓝色指针那边去，然后橙色指针也向后移动。 如果不小于基准1且不大于基准2，那么不需要做什么，直接把橙色指针向前移动即可，因为本身就是这个范围。 如果大于基准2，那么需要丢到右边去，先将右边指针左移，不断向前找到一个不比基准2大的，这样才能顺利地交换过去。 首先我们来看看，此时橙色指针指向的是2，那么2是小于基准1的，我们需要先将蓝色指针后移，然后交换橙色和蓝色指针上的元素，只不过这里由于是同一个，所以说不变，此时两个指针都后移了一位： 同样的，我们继续来看橙色指针所指元素，此时为7，大于基准2，那么此时需要在右边找到一个不大于基准2的元素： 绿色指针从右开始向左找，此时找到3，直接交换橙色指针和蓝色指针元素： 下一轮开始继续看橙色指针元素，此时发现是小于基准1的，所以说先向前移动蓝色指针，发现和橙色又在一起了，交换了跟没交换一样，此时两个指针都后移了一位： 新的一轮继续来看橙色指针所指元素，此时我们发现1也是小于基准1的，先移动蓝色指针，再交换，在移动橙色指针，跟上面一样，交换个寂寞： 此时橙色指针指向8，大于基准2，那么同样需要在右边继续找一个不大于基准2的进行交换： 此时找到5，满足条件，交换即可： 我们继续来看橙色指针，发现此时橙色指针元素不小于基准1且不大于基准2，那么根据前面的规则，只需要向前移动橙色指针即可： 此时橙色指针和绿色指针撞一起了，没有剩余待排序元素了，最后我们将两个位于两端点基准元素与对应的指针进行交换，基准1与蓝色指针交换，基准2与绿色指针进行交换： 此时分出来的三个区域，正好满足条件，当然这里运气好，直接整个数组就有序了，不过按照正常的路线，我们还得继续对这剩下的三个区域进行双轴快速排序，最后即可排序完成。 现在我们来尝试编写一下双轴快速排序的代码： void dualPivotQuickSort(int arr[], int start, int end) { if(start >= end) return; //首先结束条件还是跟之前快速排序一样，因为不可能无限制地分下去，分到只剩一个或零个元素时该停止了 if(arr[start] > arr[end]) //先把首尾两个基准进行比较，看看谁更大 swap(&arr[start], &arr[end]); //把大的换到后面去 int pivot1 = arr[start], pivot2 = arr[end]; //取出两个基准元素 int left = start, right = end, mid = left + 1; //因为分了三块区域，此时需要三个指针来存放 while (mid pivot2 && right > mid); //此时我们需要找一个右边的位置来存放需要换过来的元素，注意先移动右边指针 if(mid >= right) break; //要是把剩余元素找完了都还没找到一个比基准2小的，那么就直接结束，本轮排序已经完成了 swap(&arr[mid], &arr[right]); //如果还有剩余元素，说明找到了，直接交换right指针和mid指针所指元素 } } swap(&arr[start], &arr[left]); //最后基准1跟left交换位置，正好左边的全部比基准1小 swap(&arr[end], &arr[right]); //最后基准2跟right交换位置，正好右边的全部比基准2大 dualPivotQuickSort(arr, start, left - 1); //继续对三个区域再次进行双轴快速排序 dualPivotQuickSort(arr, left + 1, right - 1); dualPivotQuickSort(arr, right + 1, end); } 此部分仅作为选学，不强制要求。 希尔排序 希尔排序是直接插入排序的进阶版本（希尔排序又叫缩小增量排序）插入排序虽然很好理解，但是在极端情况下会出现让所有已排序元素后移的情况（比如刚好要插入的是一个特别小的元素）为了解决这种问题，希尔排序对插入排序进行改进，它会对整个数组按照步长进行分组，优先比较距离较远的元素。 这个步长是由一个增量序列来定的，这个增量序列很关键，大量研究表明，当增量序列为 dlta[k] = 2^(t-k+1)-1（0时，效率很好，只不过为了简单，我们一般使用 $\\frac {n} {2}$、$\\frac {n} {4}$、$\\frac {n} {8}$、...、1 这样的增量序列。 设数组长度为N，详细过程为： 首先求出最初的步长，n/2即可。 我们将整个数组按照步长进行分组，也就是两两一组（如果n为奇数的话，第一组会有三个元素） 我们分别在这些分组内进行插入排序。 排序完成后，我们将步长/2，重新分组，重复上述步骤，直到步长为1时，插入排序最后一遍结束。 这样的话，因为组内就已经调整好了一次顺序，小的元素尽可能排在前面，即使在最后一遍排序中出现遇到小元素要插入的情况，也不会有太多的元素需要后移。 我们以下面的数组为例： 首先数组长度为8，直接整除2，得到34，那么步长就是4了，我们按照4的步长进行分组： 其中，4、8为第一组，2、5 为第二组，7、3为第三组，1、6为第四组，我们分别在这四组内进行插入排序，组内排序之后的结果为： 可以看到目前小的元素尽可能地在往前面走，虽然还不是有序的，接着我们缩小步长，4/2=2，此时按照这个步长划分： 此时4、3、8、7为一组，2、1、5、6为一组，我们继续在这两个组内进行排序，得到： 最后我们继续将步长/2，得到2/2=1，此时步长变为1，也就相当于整个数组为一组，再次进行一次插入排序，此时我们会发现，小的元素都靠到左边来了，此时再进行插入排序会非常轻松。 我们现在就来尝试编写一下代码： void shellSort(int arr[], int size){ int delta = size / 2; while (delta >= 1) { //这里依然是使用之前的插入排序，不过此时需要考虑分组了 for (int i = delta; i = delta && arr[j - delta] > tmp) { //注意这里比较需要按步长往回走，所以说是j - delta，此时j必须大于等于delta才可以，如果j - delta小于0说明前面没有元素了 arr[j] = arr[j - delta]; j -= delta; } arr[j] = tmp; } delta /= 2; //分组插排完事之后，重新计算步长 } } 虽然这里用到了三层循环嵌套，但是实际上的时间复杂度可能比 $O(n^2)$ 还小，因为能够保证小的元素一定往左边靠，所以排序次数实际上并没有我们想象中的那么多，由于证明过程过于复杂，这里就不列出了。 那么希尔排序是不是稳定的呢？因为现在是按步长进行分组，有可能会导致原本相邻的两个相同元素，后者在自己的组内被换到前面去了，所以说希尔排序是不稳定的排序算法。 堆排序 我们来看最后一种，堆排序也是选择排序的一种，但是它能够比直接选择排序更快。还记得我们前面讲解的大顶堆和小顶堆吗？我们来回顾一下： 对于一棵完全二叉树，树中父亲结点都比孩子结点小的我们称为小根堆（小顶堆），树中父亲结点都比孩子结点大则是大根堆 得益于堆是一棵完全二叉树，我们可以很轻松地使用数组来进行表示： 我们通过构建一个堆，就可以将一个无序的数组依次输入，最后存放的序列是一个按顺序排放的序列，利用这种性质，我们可以很轻松地利用堆进行排序，我们先来写一个小顶堆： typedef int E; typedef struct MinHeap { E * arr; int size; int capacity; } * Heap; _Bool initHeap(Heap heap){ heap->size = 0; heap->capacity = 10; heap->arr = malloc(sizeof (E) * heap->capacity); return heap->arr != NULL; } _Bool insert(Heap heap, E element){ if(heap->size == heap->capacity) return 0; int index = ++heap->size; while (index > 1 && element arr[index / 2]) { heap->arr[index] = heap->arr[index / 2]; index /= 2; } heap->arr[index] = element; return 1; } E delete(Heap heap){ E max = heap->arr[1], e = heap->arr[heap->size--]; int index = 1; while (index * 2 size) { int child = index * 2; if(child size && heap->arr[child] > heap->arr[child + 1]) child += 1; if(e arr[child]) break; else heap->arr[index] = heap->arr[child]; index = child; } heap->arr[index] = e; return max; } 接着我们只需要将这些元素挨个插入到堆中，然后再挨个拿出来，得到的就是一个有序的顺序了： int main(){ int arr[] = {3, 5, 7, 2, 9, 0, 6, 1, 8, 4}; struct MinHeap heap; //先创建堆 initHeap(&heap); for (int i = 0; i 最后得到的结果为： 虽然这样用起来比较简单，但是需要额外 $O(n)$ 的空间来作为堆，所以我们可以对其进行进一步的优化，减少其空间上的占用。那么怎么进行优化呢，我们不妨换个思路，直接对给定的数组进行堆的构建。 设数组长度为N，详细过程为： 首先将给定的数组调整为一个大顶堆 进行N轮选择，每次都选择大顶堆顶端的元素从数组末尾开始向前存放（交换堆顶和堆的最后一个元素） 交换完成后，重新对堆的根结点进行调整，使其继续满足大顶堆的性质，然后重复上述操作。 当N轮结束后，得到的就是从小到大排列的数组了。 我们先将给定数组变成一棵完全二叉树，以下面数组为例： 此时，这棵二叉树还并不是堆，我们的首要目标是将其变成一个大顶堆。那么怎么将这棵二叉树变成一个大顶堆呢？我们只需要从最后一个非叶子结点（从上往下的顺序）开始进行调整即可，比如此时1是最后一个非叶子结点，所以说就从1开始，我们需要进行比较，如果其孩子结点大于它，那么需要将最大的那个孩子交换上来，此时其孩子结点6大于1，所以说需要交换： 接着我们来看倒数第二个非叶子结点，也就是7，那么此时两个孩子都是小于它的，所以说不需要做任何调整，我们接着来看倒数第三个非叶子结点2，此时2的两个孩子6、8都大于2，那么我们选择两个孩子里面一个最大的交换上去： 最后就剩下根结点这一个非叶子结点了，此时我们4的左右孩子都大于4，那么依然需要进行调整： 在调整之后，还没有结束，因为此时4换下去之后依然不满足大顶堆的性质，此时4的左孩子大于4，我们还需要继续向下看： 交换之后，此时整个二叉树就满足大顶堆的性质了，我们第一次初始调整也就完成了。 此时开始第二步，我们需要一个一个地将堆顶元素往后面进行交换，相当于每次都去取一个最大的出来，直到取完，首先交换堆顶元素和最后一个元素： 此时整个数组中最大的元素已经排到对应的位置上了，然后我们不再考虑最后一个元素，此时将前面的剩余元素继续看做一棵完全二叉树，对根结点重新进行一次堆化（只需要调整根结点即可，因为其他非叶子结点的没有变动），使得其继续满足大顶堆的性质： 还没完，继续调整： 此时第一轮结束，接着第二轮，重复上述操作，首先依然是将堆顶元素丢到倒数第二个位置上，相当于将倒数第二大的元素放到对应的位置上去： 此时已经有两个元素排好序了，同样的，我们继续将剩余元素看做一个完全二叉树，继续对根结点进行堆化操作，使得其继续满足大顶堆性质： 第三轮同样的思路，将最大的交换到后面去： 通过N轮排序，最后每一个元素都可以排到对应的位置上了，根据上面的思路，我们来尝试编写一下代码： //这个函数就是对start顶点位置的子树进行堆化 void makeHeap(int* arr, int start, int end) { while (start * 2 + 1 arr[start]) //如果上面选出来的孩子，比父结点大，那么就需要交换，大的换上去，小的换下来 swap(&arr[child], &arr[start]); start = child; //继续按照同样的方式前往孩子结点进行调整 } } void heapSort(int arr[], int size) { for(int i= size/2 - 1; i >= 0; i--) //我们首选需要对所有非叶子结点进行一次堆化操作，需要从最后一个到第一个，这里size/2计算的位置刚好是最后一个非叶子结点 makeHeap(arr, i, size - 1); for (int i = size - 1; i > 0; i--) { //接着我们需要一个一个把堆顶元素搬到后面，有序排列 swap(&arr[i], &arr[0]); //搬运实际上就是直接跟倒数第i个元素交换，这样，每次都能从堆顶取一个最大的过来 makeHeap(arr, 0, i - 1); //每次搬运完成后，因为堆底元素被换到堆顶了，所以需要再次对根结点重新进行堆化 } } 最后我们来分析一下堆排序的稳定性，实际上堆排序本身也是在进行选择，每次都会选择堆顶元素放到后面，只不过堆是一直在动态维护的。实际上从堆顶取出元素时，都会与下面的叶子进行交换，有可能会出现： 所以说堆排序是不稳定的排序算法。 最后我们还是来总结一下上面的三种排序算法的相关性质： 排序算法 最好情况 最坏情况 空间复杂度 稳定性 快速排序 $O(nlogn)$ $O(n^2)$ $O(logn)$ 不稳定 希尔排序 $O(n^{1.3})$ $O(n^2)$ $O(1)$ 不稳定 堆排序 $O(nlogn)$ $O(nlogn)$ $O(1)$ 不稳定 其他排序方案 除了我们前面介绍的几种排序算法之外，还有一些其他类型的排序算法，我们都来认识一下吧。 归并排序 归并排序利用递归分治的思想，将原本的数组进行划分，然后首先对划分出来的小数组进行排序，然后最后在合并为一个有序的大数组，还是很好理解的： 我们以下面的数组为例： 在一开始我们先不急着进行排序，我们先一半一半地进行划分： 继续进行划分： 最后会变成这样的一个一个的元素： 此时我们就可以开始归并排序了，注意这里的合并并不是简简单单地合并，我们需要按照从小到大的顺序，依次对每个元素进行合并，第一组树4和2，此时我们需要从这两个数组中先选择小的排到前面去: 排序完成后，我们继续向上合并： 最后我们再将这两个数组合并到原有的规模： 最后就能得到一个有序的数组了。 实际上这种排序算法效率也很高，只不过需要牺牲一个原数组大小的空间来对这些分解后的数据进行排序，代码如下： void merge(int arr[], int tmp[], int left, int leftEnd, int right, int rightEnd){ int i = left, size = rightEnd - left + 1; //这里需要保存一下当前范围长度，后面使用 while (left = end) return; //依然是使用递归，所以说如果范围太小，就不用看了 int mid = (start + end) / 2; //先找到中心位置，一会分两半 mergeSort(arr, tmp, start, mid); //对左半和右半分别进行归并排序 mergeSort(arr, tmp, mid + 1, end); merge(arr, tmp, start, mid, mid + 1, end); //上面完事之后，左边和右边都是有序状态了，此时再对整个范围进行一次归并排序即可 } 因为归并排序最后也是按照小的优先进行合并，如果遇到相等的，也是优先将前面的丢回原数组，所以说排在前面的还是排在前面，因此归并排序也是稳定的排序算法。 桶排序和基数排序 在开始讲解桶排序之前，我们先来看看计数排序，它要求是数组长度为N，且数组内的元素取值范围是0 - M-1 之间（M小于等于N） 算法演示网站：https://visualgo.net/zh/sorting?slide=1 比如下面的数组，所有的元素范围是 1-6之间： 我们先对其进行一次遍历，统计每个元素的出现次数，统计完成之后，我们就能够明确在排序之后哪个位置可以存放值为多少的元素了： 我们来分析一下，首先1只有一个，那么只会占用一个位置，2也只有一个，所以说也只会占用一个位置，以此类推： 所以说我们直接根据统计的结果，把这些值挨个填进去就行了，而且还是稳定的，按顺序，有几个填几个就可以了： 是不是感觉很简单，而且只需要遍历一次进行统计就行了。 当然肯定是有缺点的： 当数组中最大最小值差距过大时，我们得申请更多的空间来进行计数，所以不适用于计数排序。 当数组中元素值不是离散的（也就是不是整数的情况下）就没办法统计了。 我们接着来看桶排序，它是计数排序的延伸，思路也比较简单，它同样要求是数组长度为N，且数组内的元素取值范围是0 - M-1 之间（M小于等于N），比如现在有1000个学生，现在需要对这些学生按照成绩进行排序，因为成绩的范围是0-100，所以说我们可以建立101个桶来分类存放。 比如下面的数组： 此数组中包含1-6的元素，所以说我们可以建立 6个桶来进行统计： 这样，我们只需要遍历一次，就可以将所有的元素分类丢到这些桶中，最后我们只需要依次遍历这些桶，然后把里面的元素拿出来依次存放回去得到的就是有序的数组了： 只不过桶排序虽然也很快，但是同样具有与上面计数排序一样的限制，我们可以将每个桶接纳一定范围内的元素，来减小桶的数量，但是这样会导致额外的时间开销。 我们最后来看看基数排序，基数排序依然是一种依靠统计来进行的排序算法，但是它不会因为范围太大而导致无限制地申请辅助空间。它的思路是，分出10个基数出来（从0 - 9）我们依然是只需要遍历一次，我们根据每一个元素的个位上的数字，进行分类，因为现在有10个基数，也就是10个桶。个位完事之后再看十位、百位... 算法演示网站：https://visualgo.net/zh/sorting 先按照个位数进行统计，然后排序，再按照十位进行统计，然后排序，最后得到的结果就是最终的结果了： 然后是十位数： 最后再次按顺序取出来： 成功得到有序数组。 最后我们来总结一下所有排序算法的相关性质： 排序算法 最好情况 最坏情况 空间复杂度 稳定性 冒泡排序 $O(n)$ $O(n^2)$ $O(1)$ 稳定 插入排序 $O(n)$ $O(n^2)$ $O(1)$ 稳定 选择排序 $O(n^2)$ $O(n^2)$ $O(1)$ 不稳定 快速排序 $O(nlogn)$ $O(n^2)$ $O(logn)$ 不稳定 希尔排序 $O(n^{1.3})$ $O(n^2)$ $O(1)$ 不稳定 堆排序 $O(nlogn)$ $O(nlogn)$ $O(1)$ 不稳定 归并排序 $O(nlogn)$ $O(nlogn)$ $O(n)$ 稳定 计数排序 $O(n + k)$ $O(n + k)$ $O(k)$ 稳定 桶排序 $O(n + k)$ $O(n^2)$ $O(k + n)$ 稳定 基数排序 $O(n \\times k)$ $O(n \\times k)$ $O(k+n)$ 稳定 猴子排序 猴子排序比较佛系，因为什么时候能排完，全看运气！ 无限猴子定理最早是由埃米尔·博雷尔在1909年出版的一本谈概率的书籍中提到的，此书中介绍了“打字的猴子”的概念。无限猴子定理是概率论中的柯尔莫哥洛夫的零一律的其中一个命题的例子。大概意思是，如果让一只猴子在打字机上随机地进行按键，如果一直不停的这样按下去，只要时间达到无穷时，这只猴子就几乎必然可以打出任何给定的文字，甚至是莎士比亚的全套著作也可以打出来。 假如现在有一个长度为N的数组： 我们每次都随机从数组中挑一个元素，与随机的一个元素进行交换： 只要运气足够好，那么说不定几次就可以搞定，要是运气不好，说不定等到你孙子都结婚了都还没排好。 代码如下： _Bool checkOrder(int arr[], int size){ for (int i = 0; i arr[i + 1]) return 0; return 1; } int main(){ int arr[] = {3,5, 7,2, 9, 0, 6,1, 8, 4}, size = 10; int counter = 0; while (1) { int a = rand() % size, b = rand() % size; swap(&arr[a], &arr[b]); if(checkOrder(arr, size)) break; counter++; } printf(\"在第 %d 次排序完成！\", counter); } 可以看到在10个元素的情况下，这边第7485618次排序成功了： 但是不知道为什么每次排序出来的结果都是一样的，可能是随机数取得还不够随机吧。 排序算法 最好情况 最坏情况 空间复杂度 稳定性 猴子排序 $O(1)$ ∞ $O(1)$ 不稳定 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（五）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Java/算法/数据结构与算法（五）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/":{"url":"Linux/","title":"Linux","keywords":"","body":"window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Linux/README.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Linux/README.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Docker容器技术.html":{"url":"Linux/Docker容器技术.html","title":"Docker容器技术","keywords":"","body":" Docker容器技术 Docker是一门平台级别的技术，涉及的范围很广，所以，在开始之前，请确保你完成：Java SpringBoot 篇（推荐完成SpringCloud篇再来）视频教程及之前全部路线，否则学习会非常吃力，另外推荐额外掌握：《计算机网络》、《操作系统》相关知识。学一样东西不能完全靠记忆来完成，而是需要结合自己所学的基础知识加以理解，一般来说，单凭记忆能够掌握的东西往往是最廉价的。 Docker官网： https://www.docker.com 课前准备：配置2C2G以上Linux服务器一台，云服务器、虚拟机均可。 容器技术入门 随着时代的发展，Docker也逐渐走上了历史舞台，曾经我们想要安装一套环境，需要花费一下午甚至一整天来配置和安装各个部分（比如运行我们自己的SpringBoot应用程序，可能需要安装数据库、安装Redis、安装MQ等，各种各样的环境光是安装就要花费很多时间，真的是搞得心态爆炸），而有了Docker之后，我们的程序和环境部署就变得非常简单了，我们只需要将这些环境一起打包成一个镜像。而到服务器上部署时，可以直接下载镜像实现一键部署，是不是很方便？ 包括我们在学习SpringCloud需要配置的各种组件，可能在自己电脑的环境中运行会遇到各种各样的问题（可能由于电脑上各种环境没配置，导致无法运行），而现在只需要下载镜像就能直接运行，所有的环境全部在镜像中配置完成，开箱即用。 真的有这么神奇吗？我们来试试看。 环境安装和部署 首先我们还是先将Docker环境搭建好（建议和我同一个环境，不然出了问题只能自己想办法了），这里我们使用： Ubuntu 22.04 操作系统 Docker分为免费的CE（Community Edition）社区版本和EE（Enterprise Edition）企业级付费版本，所以我们这里选择docker-ce进行安装。官方安装文档：https://docs.docker.com/engine/install/ubuntu/ 首先安装一些工具： sudo apt-get install ca-certificates curl gnupg lsb-release 不过在Ubuntu22.04已经默认安装好了。接着安装官方的GPG key： sudo mkdir -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg 最后将Docker的库添加到apt资源列表中： echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null 接着我们更新一次apt： sudo apt update 最后安装Docker CE版本： sudo apt install docker-ce 等待安装完成就可以了： 可以看到安装成功后版本是20.10.17，当然可能你们安装的时候就是更新的版本了。最后我们将当前用户添加到docker用户组中，不然每次使用docker命令都需要sudo执行，很麻烦： sudo usermod -aG docker 配置好后，我们先退出SSH终端，然后重新连接就可以生效了。 这样我们Docker 的学习环境就配置好了，现在我们就尝试通过Docker来部署一个Nginx服务器试试看，使用很简单，只需要一个命令就可以了（当然现在看不懂没关系，我们后面会细嗦）： sudo docker run -d -p 80:80 nginx 首选它会从镜像仓库中下载对应的镜像，国内访问速度还行，不需要单独配置镜像源。接着下载完成后，就会在后台运行了，我们可以使用浏览器访问试试看： 可以看到，Nginx服务器已经成功部署了，但是实际上我们并没有在Ubuntu中安装Nginx，而是通过Docker运行的镜像来进行服务器搭建的，是不是感觉玩法挺新奇的。除了Nginx这种简单的应用之外，我们还可以通过Docker来部署复杂应用，之后我们都会一一进行讲解的。 从虚拟机到容器 前面我们成功安装了Docker学习环境，以及浅尝了一下Docker为我们带来的应用快速部署。在正式进入学习之前，我们就先从Docker的发展开始说起。 在Docker出现之前，虚拟化技术可以说是占据了主导地位。首先我们来谈谈为什么会出现虚拟化技术，我们知道在企业中服务器可以说是必不可少的一种硬件设施了，服务器也是电脑，但是不像我们的家用电脑，服务器的配置是非常高的，我们家用电脑的CPU可能最高配也就20核了，内存很少有超过128G的电脑，64G内存的家用电脑可以算奢侈了。而服务器不一样，服务器级别的CPU动辄12核，甚至服务器还能同时安装多块CPU，能直接堆到好几十核： 我们家用级CPU一般是AMD的锐龙系列和Intel的酷睿系列（比如i3 i5 i7 i9），而服务器CPU一般是Intel的志强（Xeno）系列，这种CPU的特点就是核心数非常多： 并且服务器CPU相比家用CPU的功耗也会更大，因此服务器CPU的发热量非常高，如果你有幸去过机房，你会听见散热风扇猛烈转动的声音（但是服务器CPU的频率没有家用级CPU高，一般大型游戏要求的是高频率而不是核心数，而且功耗也比较大，所以并不适合做家用电脑，所以以后在网上买台式机，看到什么“i9级”CPU千万别买，是这些黑心商家把国外服务器上淘汰下来的服务器CPU（洋垃圾）装成电脑卖给你，所以会很便宜，同时核心数又能媲美i9，所以还是一分钱一分货实在） 服务器无论是CPU资源还是内存资源都远超家用电脑，而我们编写的Java后端项目，最后都会运行在这些服务器上，不过有一个问题，服务器既然有这么丰富的硬件资源，就跑咱们这一个小Java后端，是不是有点核弹炸蚊子的感觉了？可能顶多就用了服务器5%的硬件资源，服务器这么牛就运行个这也太浪费了吧。 所以，为了解决这种资源利用率只有5%-15%的情况，咱们能不能想个办法，把这一台服务器分成多个小服务器使用，每个小服务器只分配一部分的资源，比如分一个小服务器出去，只给2个CPU核心和4G内存。但是由于设计上的问题，我们的电脑只能同时运行一个操作系统，那么怎么办呢？此时虚拟化技术就开始兴起了。 虚拟化使用软件来模拟硬件并创建虚拟计算机系统。这样一来，企业便可以在单台服务器上运行多个虚拟系统，也就是运行多个操作系统和应用，而这可以实现规模经济以及提高效益。比如我们电脑上经常使用的VMware就是一种民用级虚拟化软件： 我们可以使用VMware来创建虚拟机，这些虚拟机实际上都是基于我们当前系统上的VMware软件来运行的，当然VMware也有服务器专用的虚拟化软件，有了虚拟化之后，我们的服务器就像这样： 相当于通过虚拟机模拟了很多来电脑出来，这样我们就可以在划分出来的多台虚拟机上分别安装系统和部署我们的应用程序了，并且我们可以自由分配硬件资源，合理地使用。一般在企业中，不同的应用程序可能会被分别部署到各个服务器上，隔离开来，此时使用虚拟机就非常适合。 实际上我们在什么腾讯云、阿里云租的云服务器，都是经过虚拟化技术划分出来的虚拟机而已。 那么，既然虚拟机都这么方便了，容器又是怎么杀出一条血路的呢？我们先来看看什么是容器。 容器和虚拟机比较类似，都可以为应用提供封装和隔离，都是软件，但是容器中的应用运行是寄托于宿主操作系统的，实际上依然是在直接使用操作系统的资源，当然应用程序之间环境依然是隔离的，而虚拟机则是完全模拟一台真正的电脑出来，直接就是两台不同的电脑。 因此容器相比虚拟机就简单多了，并且启动速度也会快很多，开销小了不少。 不过容器火的根本原因还是它的集装箱思想，我们知道，如果我们要写一个比如论坛、电商这类的Java项目，那么数据库、消息队列、缓存这类中间件是必不可少的，因此我们如果想要将一个服务部署到服务器，那么实际上还要提前准备好各种各样的环境，先安装好MySQL、Redis、RabbitMQ等应用，配置好了环境，再将我们的Java应用程序启动，整个流程下来，光是配置环境就要浪费大量的时间，如果是大型的分布式项目，可能要部署很多台机器，那岂不是我们得一个一个来？项目上个线就要花几天时间，显然是很荒唐的。 而容器可以打包整个环境，比较MySQL、Redis等以及我们的Java应用程序，可以被一起打包为一个镜像，当我们需要部署服务时，只需要像我们之前那样，直接下载镜像运行即可，不需要再进行额外的配置了，整个镜像中环境是已经配置好的状态，开箱即用。 而我们要重点介绍的就是Docker了，可以看到它的图标就是一只鲸鱼，鲸鱼的上面是很多个集装箱，每个集装箱就是我们的整个环境+应用程序，Docker可以将任何应用及其依赖打包为一个轻量级，可移植，自包含的容器，容器可以运行在几乎所有的操作系统上。 容器工作机制简述 我们先来看看Docker的整体架构： 实际上分为三个部分： Docker 客户端：也就是我们之前使用的docker命令，都是在客户端上执行的，操作会发送到服务端上处理。 Docker 服务端：服务端就是启动容器的主体了，一般是作为服务在后台运行，支持远程连接。 Registry：是存放Docker镜像的仓库，跟Maven一样，也可以分公有和私有仓库，镜像可以从仓库下载到本地存放。 当我们需要在服务器上部署一个已经打包好的应用和环境，我们只需要下载打包好的镜像就可以了，我们前面执行了： sudo docker run -d -p 80:80 nginx 实际上这个命令输入之后： Docker客户端将操作发送给服务端，告诉服务端我们要运行nginx这个镜像。 Docker服务端先看看本地有没有这个镜像，发现没有。 接着只能从公共仓库Docker Hub去查找下载镜像了。 下载完成，镜像成功保存到本地。 Docker服务端加载Nginx镜像，启动容器开始正常运行（注意容器和其他容器之间，和外部之间，都是隔离的，互不影响） 所以，整个流程中，Docker就像是一搜运输船，镜像就像是集装箱，通过运输船将世界各地的货物送往我们的港口，货物到达港口后，Docker并不关心集装箱里面的是什么，只需要创建容器开箱即用就可以了。相比我们传统的手动安装配置环境，不知道方便了几个层次。 不过容器依然是寄托于宿主主机的运行的，所以一般在生产环境下，都是通过虚拟化先创建多台主机，然后再到各个虚拟机中部署Docker，这样的话，运维效率就大大提升了。 从下一章开始，我们就正式地来学习一下Docker的各种操作。 容器与镜像 要启动容器最关键的就是镜像，我们来看看镜像相关的介绍。 初识容器镜像 首先我们来了解一下镜像的相关操作，比如现在我们希望把某个镜像从仓库下载到本地，这里使用官方的hello-world镜像： docker pull hello-world 只需要输入pull命令，就可以直接下载到指定的镜像了： 可以看到对上面一行有一句Using default tag，实际上一个镜像的名称是由两部分组成的，一个是repository，还有一个是tag，一般情况下约定repository就是镜像名称，tag作为版本，默认为latest，表示最新版本。所以指定版本运行的话： docker pull 名称:版本 之后为了教学方便，我们就直接使用默认的tag，不去指定版本了。 镜像下载之后会存放在本地，要启动这个镜像的容器，实际上就像我们之前那样，输入run命令就可以了： docker run hello-world 当然如果仅仅是只想创建而不想马上运行的话，可以使用create命令： docker create hello-world 可以看到成功启动了： 启动之后，会使用当前镜像自动创建一个容器，我们可以输入ps命令来查看当前容器的容器列表： docker ps -a 注意后面要加一个-a表示查看所有容器（其他选项可以使用-h查看），如果不加的话，只会显示当前正在运行的容器，而HelloWorld是一次性的不是Nginx那样的常驻程序，所以容器启动打印了上面的内容之后，容器就停止运行了： 可以看到容器列表中有我们刚刚创建的hello-world以及我们之前创建的nginx（注意同一个镜像可以创建多个容器），每个容器都有一个随机生成的容器ID写在最前面，后面是容器的创建时间以及当前的运行状态，最后一列是容器的名称，在创建容器时，名称可以由我们指定也可以自动生成，这里就是自动生成的。 我们可以手动指定名称启动，在使用run命令时，添加--name参数即可： docker run --name=lbwnb hello-world 我们可以手动开启处于停止状态的容器： docker start 注意启动的对象我们要填写容器的ID或是容器的名称才可以，容器ID比较长，可以不写全只写一半，但是你要保证你输入的不完全容器ID是唯一的。 如果想要停止容器直接输入stop命令就可以了： docker stop 或是重启： docker restart 如果我们不需要使用容器了，那么可以将容器删除，但是注意只有容器处于非运行状态时才可以删除： docker rm 当然如果我们希望容器在停止后自动删除，我们可以在运行时添加--rm参数： docker run --rm 镜像名称 删除后，容器将不复存在，当没有任何关于nginx的容器之后，我们可以删除nginx的本地镜像： 我们可以使用images命令来检查一下当前本地有那些镜像： docker images 至此，我们已经了解了Docker的简单使用，在后面的学习中，我们还会继续认识更多的玩法。 镜像结构介绍 前面我们了解了Docker的相关基本操作，实际上容器的基石就是镜像，有了镜像才能创建对应的容器实例，那么我们就先从镜像的基本结构开始说起，我们来看看镜像到底是个什么样的存在。 我们在打包项目时，实际上往往需要一个基本的操作系统环境，这样我们才可以在这个操作系统上安装各种依赖软件，比如数据库、缓存等，像这种基本的系统镜像，我们称为base镜像，我们的项目之后都会基于base镜像进行打包，当然也可以不需要base镜像，仅仅是基于当前操作系统去执行简单的命令，比如我们之前使用的hello-world就是。 一般base镜像就是各个Linux操作系统的发行版，比如我们正在使用的Ubuntu，还有CentOS、Kali等等。这里我们就下载一下CentOS的base镜像： docker pull centos 可以看到，CentOS的base镜像就已经下载完成，不像我们使用完整系统一样，base镜像的CentOS省去了内核，所以大小只有272M，这里需要解释一下base镜像的机制： Linux操作体系由内核空间和用户空间组成，其中内核空间就是整个Linux系统的核心，Linux启动后首先会加bootfs文件系统，加载完成后会自动卸载掉，之后会加载用户空间的文件系统，这一层是我们自己可以进行操作的部分： bootfs包含了BootLoader和Linux内核，用户是不能对这层作任何修改的，在内核启动之后，bootfs会自动卸载。 rootfs则包含了系统上的常见的目录结构，包括/dev、/proc、 /bin等等以及一些基本的文件和命令，也就是我们进入系统之后能够操作的整个文件系统，包括我们在Ubuntu下使用的apt和CentOS下使用的yum，都是用户空间上的。 base镜像底层会直接使用宿主主机的内核，也就是说你的Ubuntu内核版本是多少，那么base镜像中的CentOS内核版本就是多少，而rootfs则可以在不同的容器中运行多种不同的版本。所以，base镜像实际上只有CentOS的rootfs，因此只有300M大小左右，当然，CentOS里面包含多种基础的软件，还是比较臃肿的，而某些操作系统的base镜像甚至都不到10M。 使用uname命令可以查看当前内核版本： 因此，Docker能够同时模拟多种Linux操作系统环境，就不足为奇了，我们可以尝试启动一下刚刚下载的base镜像： docker run -it centos 注意这里需要添加-it参数进行启动，其中-i表示在容器上打开一个标准的输入接口，-t表示分配一个伪tty设备，可以支持终端登录，一般这两个是一起使用，否则base容器启动后就自动停止了。 可以看到使用ls命令能够查看所有根目录下的文件，不过很多命令都没有，连clear都没有，我们来看看内核版本： 可以看到内核版本是一样的（这也是缺点所在，如果软件对内核版本有要求的话，那么此时使用Docker就直接寄了），我们输入exit就可以退出容器终端了，可以看到退出后容器也停止了： 当然我们也可以再次启动，注意启动的时候要加上-i才能进入到容器进行交互，否则会在后台运行： 基于base镜像，我们就可以在这基础上安装各种各样的软件的了，几乎所有的镜像都是通过在base镜像的基础上安装和配置需要的软件构建出来的： 每安装一个软件，就在base镜像上一层层叠加上去，采用的是一种分层的结构，这样多个容器都可以将这些不同的层次自由拼装，比如现在好几个容器都需要使用CentOS的base镜像，而上面运行的软件不同，此时分层结构就很爽了，我们只需要在本地保存一份base镜像，就可以给多个不同的容器拼装使用，是不是感觉很灵活？ 我们看到除了这些软件之外，最上层还有一个可写容器层，这个是干嘛的呢，为什么要放在最上面？ 我们知道，所有的镜像会叠起来组成一个统一的文件系统，如果不同层中存在相同位置的文件，那么上层的会覆盖掉下层的文件，最终我们看到的是一个叠加之后的文件系统。当我们需要修改容器中的文件时，实际上并不会对镜像进行直接修改，而是在最顶上的容器层（最上面一般称为容器层，下面都是镜像层）进行修改，不会影响到下面的镜像，否则镜像就很难实现多个容器共享了。所以各个操作如下： 文件读取：要读取一个文件，Docker会最上层往下依次寻找，找到后则打开文件。 文件创建和修改：创建新文件会直接添加到容器层中，修改文件会从上往下依次寻找各个镜像中的文件，如果找到，则将其复制到容器层，再进行修改。 删除文件：删除文件也会从上往下依次寻找各个镜像中的文件，一旦找到，并不会直接删除镜像中的文件，而是在容器层标记这个删除操作。 也就是说，我们对整个容器内的文件进行的操作，几乎都是在最上面的容器层进行的，我们是无法干涉到下面所有的镜像层文件的，这样就很好地保护了镜像的完整性，才能实现多个容器共享使用。 构建镜像 前面我们已经了解了Docker镜像的结构，实际上所有常用的应用程序都有对应的镜像，我们只需要下载这些镜像然后就可以使用了，而不需要自己去手动安装，顶多需要进行一些特别的配置。当然要是遇到某些冷门的应用，可能没有提供镜像，这时就要我们手动去安装，接着我们就来看看如何构建我们自己的Docker镜像。构建镜像有两种方式，一种是使用commit命令来完成，还有一种是使用Dockerfile来完成，我们先来看第一种。 这里我们就做一个简单的例子，比如我们现在想要在Ubuntu的base镜像中安装Java环境，并将其打包为新的镜像（这个新的镜像就是一个包含Java环境的Ubuntu系统镜像） 咱们先启动Ubuntu镜像，然后使用yum命令（跟apt比较类似）来安装Java环境，首先是run命令： docker pull ubuntu 接着启动： 直接使用apt命令来安装Java环境，在这之前先更新一下，因为是最小安装所以本地没有任何软件包： 接着输入： apt install openjdk-8-jdk 等待安装完成： 这样，我们就完成了对Java环境的安装了，接着我们就可以退出这个镜像然后将其构建为新的镜像： 使用commit命令可以将容器保存为新的镜像： docker commit 容器名称/ID 新的镜像名称 可以看到安装了软件之后的镜像大小比我们原有的大小大得多，这样我们就可以通过这个镜像来直接启动一个带Java环境的Ubuntu操作系统容器了。不过这种方式虽然自定义度很高，但是Docker官方并不推荐，这样的话使用者并不知道镜像是如何构建出来的，是否里面带了后门都不知道，并且这样去构建效率太低了，如果要同时构建多种操作系统的镜像岂不是要一个一个去敲？我们作为普通用户实际上采用Dokcerfile的方式会更好一些。 我们来看看如何使用Dockerfile的形式创建一个带Java环境的Ubuntu系统镜像。首先直接新建一个名为Dockerfile的文件： touch Dockerfile 接着我们来进行编辑，Dockerfile内部需要我们编写多种指令来告诉Docker我们的镜像的相关信息： FROM 首先我们需要使用FROM指令来选择当前镜像的基础镜像（必须以这个指令开始），这里我们直接使用ubuntu作为基础镜像即可，当然如果不需要任何基础镜像的话，直接使用scratch表示从零开始构建，这里就不演示了。 基础镜像设定完成之后，我们就需要在容器中运行命令来安装Java环境了，这里需要使用RUN指令： RUN apt update RUN apt install -y openjdk-8-jdk 每条指令执行之后，都会生成一个新的镜像层。 OK，现在我们的Dockerfile就编写完成了，只需要完成一次构建即可： docker build -t 执行后，Docker会在构建目录中寻找Dockerfile文件，然后开始依次执行Dockerfile中的指令： 构建过程的每一步都非常清晰地列出来了，一共三条指令对应三步依次进行，我们稍微等待一段时间进行安装，安装过程中所以的日志信息会直接打印到控制台（注意Docker镜像构建有缓存机制，就算你现在中途退出了，然后重新进行构建，也会直接将之前已经构建好的每一层镜像，直接拿来用，除非修改了Dockerfile文件重新构建，只要某一层发生变化其上层的构建缓存都会失效，当然包括pull时也会有类似的机制） 最后成功安装，会出现在本地： 可以看到安装出来的大小跟我们之前的是一样的，因为做的事情是一模一样的。我们可以使用history命令来查看构建历史： 可以看到最上面两层是我们通过使用apt命令生成的内容，就直接作为当前镜像中的两层镜像，每层镜像都有一个自己的ID，不同的镜像大小也不一样。而我们手动通过commit命令来生成的镜像没有这个记录： 如果遇到镜像ID为missing的一般是从Docker Hub中下载的镜像会有这个问题，但是问题不大。用我们自己构建的镜像来创建容器就可以直接体验带Java环境的容器了： 有关Dockerfile的其他命令，我们还会在后续的学习中逐步认识。 发布镜像到远程仓库 前面我们学习了如何构建一个Docker镜像，我们可以将自己的镜像发布到Docker Hub中，就像Git远程仓库一样，我们可以将自己的镜像上传到这里：https://hub.docker.com/repositories，没有账号的先去进行注册。 点击右上角的创建仓库，然后填写信息： 创建完成后，我们就有了一个公共的镜像仓库，我们可以将本地的镜像上传了，上传之前我们需要将镜像名称修改得规范一点，这里使用tag命令来重新打标签： docker tag ubuntu-java-file:latest 用户名/仓库名称:版本 这里我们将版本改成1.0版本吧，不用默认的latest了。 修改完成后，会创建一个新的本地镜像，名称就是我们自己定义的了。接着我们需在本地登录一下： 登录成功后我们就可以上传了： docker push nagocoler/ubuntu-java:1.0 哈哈，500M的东西传上去，还是有点压力的，如果实在太慢各位可以重新做一个简单点的镜像。上传完成后，打开仓库，可以看到已经有一个1.0版本了： 注意公共仓库是可以被搜索和下载的，所以我们这里把本地的镜像全部删掉，去下载我们刚刚上传好的镜像。这里我们先搜索一下，搜索使用search命令即可： docker search nagocoler/ubuntu-java 我们可以使用pull命令将其下载下来： docker pull nagocoler/ubuntu-java:1.0 上传之后的镜像是被压缩过的，所以下载的内容就比较少一些。运行试试看： 当然各位也可以让自己的同学或是在其他机器上尝试下载自己的镜像，看看是不是都可以正常运行。 Docker Hub也可以自行搭建私服，但是这里就不多做介绍了，至此，有关容器和镜像的一些基本操作就讲解得差不多了。 实战：使用IDEA构建SpringBoot程序镜像 这里我们创建一个新的SpringBoot项目，现在我们希望能够使用Docker快速地将我们的SpringBoot项目部署到安装了Docker的服务器上，我们就可以将其打包为一个Docker镜像。 先创建好一个项目让它跑起来，可以正常运行就没问题了，接着我们需要将其打包为Docker镜像，这里创建一个新的Dockerfile： FROM ubuntu RUN apt update && apt install -y openjdk-8-jdk 首先还是基于ubuntu构建一个带Java环境的系统镜像，接着我们先将其连接到我们的Docker服务器进行构建，由于IDEA自带了Docker插件，所以我们直接点击左上角的运行按钮，选择第二项 “为Dockerfile构建镜像”： 这里需要配置Docker的服务器，也就是我们在Ubuntu服务器安装的Docker，这里我们填写服务器相关信息，我们首选需要去修改一下Docker的一些配置，开启远程客户端访问： sudo vim /etc/systemd/system/multi-user.target.wants/docker.service 打开后，添加高亮部分： 修改完成后，重启Docker服务，如果是云服务器，记得开启2375 TCP连接端口： sudo systemctl daemon-reload sudo systemctl restart docker.service 现在接着在IDEA中进行配置： 在引擎API URL处填写我们Docker服务器的IP地址： tcp://IP:2375 显示连接成功后，表示配置正确，点击保存即可，接着就开始在我们的Docker服务器上进行构建了： 最后成功构建： 可以看到，Docker服务器上已经有了我们刚刚构建好的镜像： 不过名称没有指定，这里我们重新配置一下： 重新进行构建，就是我们自定义的名称了： 我们来创建一个容器试试看： 好了，现在基本环境搭建好了，我们接着就需要将我们的SpringBoot项目打包然后再容器启动时运行了，打开Maven执行打包命令： 接着我们需要编辑Dockerfile，将我们构建好的jar包放进去： COPY target/DockerTest-0.0.1-SNAPSHOT.jar app.jar 这里需要使用COPY命令来将文件拷贝到镜像中，第一个参数是我们要拷贝的本地文件，第二个参数是存放在Docker镜像中的文件位置，由于还没有学习存储管理，这里我们直接输入app.jar直接保存在默认路径即可。 接着我们就需要指定在启动时运行我们的Java程序，这里使用CMD命令来完成： FROM ubuntu RUN apt update && apt install -y openjdk-8-jdk COPY target/DockerTest-0.0.1-SNAPSHOT.jar app.jar CMD java -jar app.jar # EXPOSE 8080 CMD命令可以设定容器启动后执行的命令，EXPOSE可以指定容器需要暴露的端口，但是现在我们还没有学习网络相关的知识，所以暂时不使用，这里指定为我们启动Java项目的命令。配置完成后，重新构建： 可以看到历史中已经出现新的步骤了： 接着启动我们的镜像，我们可以直接在IDEA中进行操作，不用再去敲命令了，有点累： 启动后可以在右侧看到容器启动的日志信息： 但是我们发现启动之后并不能直接访问，这是为什么呢？这是因为容器内部的网络和外部网络是隔离的，我们如果想要访问容器内的服务器，需要将对应端口绑定到宿主机上，让宿主主机也开启这个端口，这样才能连接到容器内： docker run -p 8080:8080 -d springboot-test:1.0 这里-p表示端口绑定，将Docker容器内的端口绑定到宿主机的端口上，这样就可以通过宿主的8080端口访问到容器的8080端口了（有关容器网络管理我们还会在后面进行详细介绍），-d参数表示后台运行，当然直接在IDEA中配置也是可以的： 配置好后，点击重新创建容器： 重新运行后，我们就可以成功访问到容器中运行的SpringBoot项目了： 当然，为了以后方便使用，我们可以直接将其推送到Docker Hub中，这里我们还是创建一个新的公开仓库： 这次我们就使用IDEA来演示直接进行镜像的上传，直接点击： 接着我们需要配置一下我们的Docker Hub相关信息： OK，远程镜像仓库配置完成，直接推送即可，等待推送完成。 可以看到远程仓库中已经出现了我们的镜像，然后IDEA中也可以同步看到： 这样，我们就完成了使用IDEA将SpringBoot项目打包为Docker镜像。 容器网络管理 注意：本小节学习需要掌握部分《计算机网络》课程中的知识。 前面我们学习了容器和镜像的一些基本操作，了解了如何通过镜像创建容器、然后自己构建容器，以及远程仓库推送等，这一部分我们接着来讨论容器的网络管理。 容器网络类型 Docker在安装后，会在我们的主机上创建三个网络，使用network ls命令来查看： docker network ls 可以看到默认情况下有bridge、host、none这三种网络类型（其实有点像虚拟机的网络配置，也是分桥接、共享网络之类的），我们先来依次介绍一下，在开始之前我们先构建一个镜像，默认的ubuntu镜像由于啥软件都没有，所以我们把一会网络要用到的先提前装好： docker run -it ubuntu apt update apt install net-tools iputils-ping curl 这样就安装好了，我们直接退出然后将其构建为新的镜像： docker commit lucid_sammet ubuntu-net OK，一会我们就可以使用了。 none网络：这个网络除了有一个本地环回网络之外，就没有其他的网络了，我们可以在创建容器时指定这个网络。 这里使用--network参数来指定网络： docker run -it --network=none ubuntu-net 进入之后，我们可以直接查看一下当前的网络： ifconfig 可以看到只有一个本地环回lo网络设备： 所以这个容器是无法连接到互联网的： “真”单机运行，可以说是绝对的安全，没人能访问进去，存点密码这些还是不错的。 bridge网络：容器默认使用的网络类型，这是桥接网络，也是应用最广泛的网络类型： 实际上我们在宿主主机上查看网络信息，会发现有一个名为docker0的网络设备： 这个网络设备是Docker安装时自动创建的虚拟设备，它有什么用呢？我们可以来看一下默认创建的容器内部的情况： docker run -it ubuntu-net 可以看到容器的网络接口地址为172.17.0.2，实际上这是Docker创建的虚拟网络，就像容器单独插了一根虚拟的网线，连接到Docker创建的虚拟网络上，而docker0网络实际上作为一个桥接的角色，一头是自己的虚拟子网，另一头是宿主主机的网络。 网络拓扑类似于下面这样： 通过添加这样的网桥，我们就可以对容器的网络进行管理和控制，我们可以使用network inspect命令来查看docker0网桥的配置信息： docker network inspect bridge 这里的配置的子网是172.17.0.0，子网掩码是255.255.0.0，网关是172.17.0.1，也就是docker0这个虚拟网络设备，所以我们上面创建的容器就是这个子网内分配的地址172.17.0.2了。 之后我们还会讲解如何管理和控制容器网络。 host网络：当容器连接到此网络后，会共享宿主主机的网络，网络配置也是完全一样的： docker run -it --network=host ubuntu-net 可以看到网络列表和宿主主机的列表是一样的，不知道各位有没有注意到，连hostname都是和外面一模一样的： 只要宿主主机能连接到互联网，容器内部也是可以直接使用的： 这样的话，直接使用宿主的网络，传输性能基本没有什么折损，而且我们可以直接开放端口等，不需要进行任何的桥接： apt install -y systemctl nginx systemctl start nginx 安装Nginx之后直接就可以访问了，不需要开放什么端口： 相比桥接网络就方便得多了。 我们可以根据实际情况，来合理地选择这三种网络使用。 用户自定义网络 除了前面我们介绍的三种网络之外，我们也可以自定义自己的网络，让容器连接到这个网络。 Docker默认提供三种网络驱动：bridge、overlay、macvlan，不同的驱动对应着不同的网络设备驱动，实现的功能也不一样，比如bridge类型的，其实就和我们前面介绍的桥接网络是一样的。 我们可以使用network create来试试看： docker network create --driver bridge test 这里我们创建了一个桥接网络，名称为test： 可以看到新增了一个网络设备，这个就是一会负责我们容器网络的网关了，和之前的docker0是一样的： docker network inspect test 这里我们创建一个新的容器，使用此网络： docker run -it --network=test ubuntu-net 成功得到分配的IP地址，是在这个网络内的，注意不同的网络之间是隔离的，我们可以再创建一个容器试试看： 可以看到不同的网络是相互隔离的，无法进行通信，当然我们也为此容器连接到另一个容器所属的网络下： docker network connect test 容器ID/名称 这样就连接了一个新的网络： 可以看到容器中新增了一个网络设备连接到我们自己定义的网络中，现在这两个容器在同一个网络下，就可以相互ping了： 这里就不介绍另外两种类型的网络了，他们是用于多主机通信的，目前我们只学习单机使用。 容器间网络 我们首先来看看容器和容器之间的网络通信，实际上我们之前已经演示过ping的情况了，现在我们创建两个ubuntu容器： docker run -it ubuntu-net 先获取其中一个容器的网络信息： 我们可以直接在另一个容器中ping这个容器： 可以看到能够直接ping通，因为这两个容器都是使用的bridge网络，在同一个子网中，所以可以互相访问。 我们可以直接通过容器的IP地址在容器间进行通信，只要保证两个容器处于同一个网络下即可，虽然这样比较方便，但是大部分情况下，容器部署之后的IP地址是自动分配的（当然也可以使用--ip来手动指定，但是还是不方便），我们无法提前得知IP地址，那么有没有一直方法能够更灵活一些呢？ 我们可以借助Docker提供的DNS服务器，它就像是一个真的DNS服务器一样，能够对域名进行解析，使用很简单，我们只需要在容器启动时给个名字就行了，我们可以直接访问这个名称，最后会被解析为对应容器的IP地址，但是注意只会在我们用户自定义的网络下生效，默认的网络是不行的： docker run -it --name=test01 --network=test ubuntu-net docker run -it --name=test02 --network=test ubuntu-net 接着直接ping对方的名字就可以了： 可以看到名称会自动解析为对应的IP地址，这样的话就不用担心IP不确定的问题了。 当然我们也可以让两个容器同时共享同一个网络，注意这里的共享是直接共享同一个网络设备，两个容器共同使用一个IP地址，只需要在创建时指定： docker run -it --name=test01 --network=container:test02 ubuntu-net 这里将网络指定为一个容器的网络，这样两个容器使用的就是同一个网络了： 可以看到两个容器的IP地址和网卡的Mac地址是完全一样的，它们的网络现在是共享状态，此时在容器中访问，localhost，既是自己也是别人。 我们可以在容器1中，安装Nginx，然后再容器2中访问： apt install -y systemctl nginx systemctl start nginx 成功访问到另一个容器中的Nginx服务器。 容器外部网络 前面我们介绍了容器之间的网络通信，我们接着来看容器与外部网络的通信。 首先我们来看容器是如何访问到互联网的，在默认的三种的网络下，只有共享模式和桥接模式可以连接到外网，共享模式实际上就是直接使用宿主主机的网络设备连接到互联网，这里我们主要来看一下桥接模式。 通过前面的学习，我们了解到桥接模式实际上就是创建一个单独的虚拟网络，让容器在这个虚拟网络中，然后通过桥接器来与外界相连，那么数据包是如何从容器内部的网络到达宿主主机再发送到互联网的呢？实际上整个过程中最关键的就是依靠NAT（Network Address Translation）将地址进行转换，再利用宿主主机的IP地址发送数据包出去。 这里我们就来补充一下《计算机网络》课程中学习的NAT： 实际上NAT在我们生活中也是经常见到的，比如我们要访问互联网上的某个资源，要和服务器进行通信，那么就需要将数据包发送出去，同时服务器也要将数据包发送回来，我们可以知道服务器的IP地址，也可以直接去连接，因为服务器的IP地址是暴露在互联网上的，但是我们的局域网就不一样了，它仅仅局限在我们的家里，比如我们连接了家里的路由器，可以得到一个IP地址，但是你会发现，这个IP公网是无法直接访问到我们的，因为这个IP地址仅仅是一个局域网的IP地址，俗称内网IP，既然公网无法访问到我们，那服务器是如何将数据包发送给我们的呢？ 实际上这里就借助了NAT在帮助我们与互联网上的服务器进行通信，通过NAT，可以实现将局域网的IP地址，映射为对应的公网IP地址，而NAT设备一端连接外网，另一端连接内网的所有设备，当我们想要与外网进行通信时，就可以将数据包发送给NAT设备，由它来将数据包的源地址映射为它在外网上的地址，这样服务器就能够发现它了，能够直接与它建立通信。当服务器发送数据回来时，也是直接交给NAT设备，然后再根据地址映射，转发给对应的内网设备（当然由于公网IP地址有限，所以一般采用IP+端口结合使用的形式ANPT） 所以你打开百度直接搜IP，会发现这个IP地址并不是你本地的，而是NAT设备的公网地址： 实际上我们家里的路由器一般都带有NAT功能，默认开启NAT模式，包括我们的小区也是有一个NAT设备在进行转换的，这样你的电脑才能在互联网的世界中遨游。当然NAT也可以保护内网的设备不会直接暴露在公网，这样也会更加的安全，只有当我们主动发起连接时，别人才能知道我们。 当然，我们的Docker也是这样的，实际上内网的数据包想要发送到互联网上去，那么就需要经过这样的一套流程： 这样，Docker容器使用的内网就可以和外网进行通信了。 但是这样有一个问题，单纯依靠NAT的话，只有我们主动与外界联系时，外界才能知道我们，但是现在我们的容器中可能会部署一些服务，需要外界来主动连接我们，此时该怎么办呢？ 我们可以直接在容器时配置端口映射，还记得我们在第一节课部署Nginx服务器吗？ docker run -d -p 80:80 nginx 这里的-p参数实际上是进行端口映射配置，端口映射可以将容器需要对外提供服务的端口映射到宿主主机的端口上，这样，当外部访问到宿主主机的对应端口时，就会直接转发给容器内映射的端口了。规则为宿主端口:容器端口，这里配置的是将容器的80端口映射到宿主主机的80端口上。 一旦监听到宿主主机的80端口收到了数据包，那么会直接转发给对应的容器。所以配置了端口映射之后，我们才可以从外部正常访问到容器内的服务： 我们也可以直接输入docker ps查看端口映射情况： 至此，有关容器的网络部分，就到此为止，当然这仅仅是单机下的容器网络操作，在以后的课程中，我们还会进一步学习多主机下的网络配置。 容器存储管理 前面我们介绍了容器的网络管理，我们现在已经了解了如何配置容器的网络，以及相关的一些原理。还有一个比较重要的部分就是容器的存储，在这一小节我们将深入了解容器的存储管理。 容器持久化存储 我们知道，容器在创建之后，实际上我们在容器中创建和修改的文件，实际上是被容器的分层机制保存在最顶层的容器层进行操作的，为了保护下面每一层的镜像不被修改，所以才有了这样的CopyOnWrite特性。但是这样也会导致容器在销毁时数据的丢失，当我们销毁容器重新创建一个新的容器时，所有的数据全部丢失，直接回到梦开始的地方。 在某些情况下，我们可能希望对容器内的某些文件进行持久化存储，而不是一次性的，这里就要用到数据卷（Data Volume）了。 在开始之前我们先准备一下实验要用到的镜像： docker run -it ubuntu apt update && apt install -y vim 然后打包为我们一会要使用的镜像： docker commit 我们可以让容器将文件保存到宿主主机上，这样就算容器销毁，文件也会在宿主主机上保留，下次创建容器时，依然可以从宿主主机上读取到对应的文件。如何做到呢？只需要在容器启动时指定即可： mkdir test 我们现在用户目录下创建一个新的test目录，然后在里面随便创建一个文件，再写点内容： vim test/hello.txt 接着我们就可以将宿主主机上的目录或文件挂载到容器的某个目录上： docker run -it -v ~/test:/root/test ubuntu-volume 这里用到了一个新的参数-v，用于指定文件挂载，这里是将我们刚刚创建好的test目录挂在到容器的/root/test路径上。 这样我们就可以直接在容器中访问宿主主机上的文件了，当然如果我们对挂载目录中的文件进行编辑，那么相当于编辑的是宿主主机的数据： vim /root/test/test.txt 在宿主主机的对应目录下，可以直接访问到我们刚刚创建好的文件。 接着我们来将容器销毁，看看当容器不复存在时，挂载的数据时候还能保留： 可以看到，即使我们销毁了容器，在宿主主机上的文件依然存在，并不会受到影响，这样的话，当我们下次创建新的镜像时，依然可以使用这些保存在外面的文件。 比如我们现在想要部署一个Nginx服务器来代理我们的前端，就可以直接将前端页面保存到宿主主机上，然后通过挂载的形式让容器中的Nginx访问，这样就算之后Nginx镜像有升级，需要重新创建，也不会影响到我们的前端页面。这里我们来测试一下，我们先将前端模板上传到服务器： scp Downloads/moban5676.zip 192.168.10.10:~/ 然后在服务器上解压一下： unzip moban5676.zip 接着我们就可以启动容器了： docker run -it -v ~/moban5676:/usr/share/nginx/html/ -p 80:80 -d nginx 这里我们将解压出来的目录，挂载到容器中Nginx的默认站点目录/usr/share/nginx/html/（由于挂在后位于顶层，会替代镜像层原有的文件），这样Nginx就直接代理了我们存放在宿主主机上的前端页面，当然别忘了把端口映射到宿主主机上，这里我们使用的镜像是官方的nginx镜像。 现在我们进入容器将Nginx服务启动： systemctl start nginx 然后通过浏览器访问看看是否代理成功： 可以看到我们的前端页面直接被代理了，当然如果我们要编写自定义的配置，也是使用同样的方法操作即可。 注意如果我们在使用-v参数时不指定宿主主机上的目录进行挂载的话，那么就由Docker来自动创建一个目录，并且会将容器中对应路径下的内容拷贝到这个自动创建的目录中，最后挂在到容器中，这种就是由Docker管理的数据卷了（docker managed volume）我们来试试看： docker run -it -v /root/abc ubuntu-volume 注意这里我们仅仅指定了挂载路径，没有指定宿主主机的对应目录，继续创建： 创建后可以看到root目录下有一个新的abc目录，那么它具体是在宿主主机的哪个位置呢？这里我们依然可以使用inspect命令： docker inspect bold_banzai 可以看到Sorce指向的是/var/lib中的某个目录，我们可以进入这个目录来创建一个新的文件，进入之前记得提升一下权限，权限低了还进不去： 我们来创一个新的文本文档： 实际上和我们之前是一样的，也是可以在容器中看到的，当然删除容器之后，数据依然是保留的。当我们不需要使用数据卷时，可以进行删除： 当然有时候为了方便，可能并不需要直接挂载一个目录上去，仅仅是从宿主主机传递一些文件到容器中，这里我们可以使用cp命令来完成： 这个命令支持从宿主主机复制文件到容器，或是从容器复制文件到宿主主机，使用方式类似于Linux自带的cp命令。 容器数据共享 前面我们通过挂载的形式，将宿主主机上的文件直接挂载到容器中，这样容器就可以直接访问到宿主主机上的文件了，并且在容器删除时也不会清理宿主主机上的文件。 我们接着来看看如何实现容器与容器之间的数据共享，实际上按照我们之前的思路，我们可以在宿主主机创建一个公共的目录，让这些需要实现共享的容器，都挂载这个公共目录： docker run -it -v ~/test:/root/test ubuntu-volume 由于挂载的是宿主主机上的同一块区域，所以内容可以直接在两个容器中都能访问。当然我们也可以将另一个容器挂载的目录，直接在启动容器时指定使用此容器挂载的目录： docker run -it -v ~/test:/root/test --name=data_test ubuntu-volume docker run -it --volumes-from data_test ubuntu-volume 这里使用--volumes-from指定另一个容器（这种用于给其他容器提供数据卷的容器，我们一般称为数据卷容器） 可以看到，数据卷容器中挂载的内容，在当前容器中也是存在的，当然就算此时数据卷容器被删除，那么也不会影响到这边，因为这边相当于是继承了数据卷容器提供的数据卷，所以本质上还是让两个容器挂载了同样的目录实现数据共享。 虽然通过上面的方式，可以在容器之间实现数据传递，但是这样并不方便，可能某些时候我们仅仅是希望容器之间共享，而不希望有宿主主机这个角色直接参与到共享之中，此时我们就需要寻找一种更好的办法了。其实我们可以将数据完全放入到容器中，通过构建一个容器，来直接将容器中打包好的数据分享给其他容器，当然本质上依然是一个Docker管理的数据卷，虽然还是没有完全脱离主机，但是移植性就高得多了。 我们来编写一个Dockerfile： FROM ubuntu ADD moban5676.tar.gz /usr/share/nginx/html/ VOLUME /usr/share/nginx/html/ 这里我们使用了一个新的指令ADD，它跟COPY命令类似，也可以复制文件到容器中，但是它可以自动对压缩文件进行解压，这里只需要将压缩好的文件填入即可，后面的VOLUME指令就像我们使用-v参数一样，会创建一个挂载点在容器中： cd test tar -zcvf moban5676.tar.gz * mv moban5676.tar.gz .. cd .. 接着我们直接构建： docker build -t data . 现在我们运行一个容器看看： 可以看到所有的文件都自动解压出来了（除了中文文件名称乱码了之外，不过无关紧要）我们退出容器，可以看到数据卷列表中新增了我们这个容器需要使用的： 这个位置实际上就是数据存放在当前主机上的位置了，不过是由Docker进行管理而不是我们自定义的。现在我们就可以创建一个新的容器直接继承了： docker run -p 80:80 --volumes-from=data_test -d nginx 访问一下Nginx服务器，可以看到成功代理： 这样我们就实现了将数据放在容器中进行共享，我们不需要刻意去指定宿主主机的挂载点，而是Docker自行管理，这样就算迁移主机依然可以快速部署。 容器资源管理 前面我们已经完成Docker的几个主要模块的学习，最后我们来看看如何对容器的资源进行管理。 容器控制操作 在开始之前，我们还是要先补充一些我们前面没有提到的其他容器命令。 首先我们的SpringBoot项目在运行是，怎么查看输出的日志信息呢？ docker logs test 这里使用log命令来打印容器中的日志信息： 当然也可以添加-f参数来持续打印日志信息。 现在我们的容器已经启动了，但是我们想要进入到容器监控容器的情况怎么办呢？我们可以是attach命令来附加到容器启动命令的终端上： docker attach 容器ID/名称 注意现在就切换为了容器内的终端，如果想要退出的话，需要先按Ctrl+P然后再按Ctrl+Q来退出终端，不能直接使用Ctrl+C来终止，这样会直接终止掉Docker中运行的Java程序的。 退出后，容器依然是处于运行状态的。 我们也可以使用exec命令在容器中启动一个新的终端或是在容器中执行命令： docker exec -it test bash -it和run命令的操作是一样的，这里执行后，会创建一个新的终端（当然原本的程序还是在正常运行）我们会在一个新的终端中进行交互： 当然也可以仅仅在容器中执行一条命令： 执行后会在容器中打开一个新的终端执行命令，并输出结果。 前面我们还学习了容器的停止操作，通过输入stop命令来停止容器，但是此操作并不会立即停止，而是会等待容器处理善后，那么怎么样才能强制终止容器呢？我们可以直接使用kill命令，相当于给进程发送SIGKILL信号，强制结束。 docker kill test 相比stop命令，kill就没那么温柔了。 有时候可能只是希望容器暂时停止运行，而不是直接终止运行，我们希望在未来的某个时间点，恢复容器的运行，此时就可以使用pause命令来暂停容器： docker pause test 暂停容器后，程序暂时停止运行，无法响应浏览器发送的请求： 此时处于爱的魔力转圈圈状态，我们可以将其恢复运行，使用unpause命令： docker unpause test 恢复运行后，瞬间就响应成功了。 物理资源管理 对于一个容器，在某些情况下我们可能并不希望它占据所有的系统资源来运行，我们只希望分配一部分资源给容器，比如只分配给容器2G内存，最大只允许使用2G，不允许再占用更多的内存，此时我们就需要对容器的资源进行限制。 docker run -m 内存限制 --memory-swap=内存和交换分区总共的内存限制 镜像名称 其中-m参数是对容器的物理内存的使用限制，而--memory-swap是对内存和交换分区总和的限制，它们默认都是-1，也就是说没有任何的限制（如果在一开始仅指定-m参数，那么交换内存的限制与其保持一致，内存+交换等于-m的两倍大小）默认情况下跟宿主主机一样，都是2G内存，现在我们可以将容器的内存限制到100M试试看，其中物理内存50M，交换内存50M，尝试启动一下SpringBoot程序： docker run -it -m 50M --memory-swap=100M nagocoler/springboot-test:1.0 可以看到，上来就因为内存不足无法启动了： 当然除了对内存的限制之外，我们也可以对CPU资源进行限额，默认情况下所有的容器都可以平等地使用CPU资源，我们可以调整不同的容器的CPU权重（默认为1024），来按需分配资源，这里需要使用到-c选项，也可以输入全名--cpu-share： docker run -c 1024 ubuntu docker run -c 512 ubuntu 这里容器的CPU权重比例为16比8，也就是2比1（注意多个容器时才会生效），那么当CPU资源紧张时，会按照此权重来分配资源，当然如果CPU资源并不紧张的情况下，依然是有机会使用到全部的CPU资源的。 这里我们使用一个压力测试工具来进行验证： docker run -c 1024 --name=cpu1024 -it ubuntu docker run -c 512 --name=cpu512 -it ubuntu 接着我们分别进入容器安装stress压力测试工具： apt update && apt install -y stress 接着我们分别在两个容器中都启动压力测试工具，产生4个进程不断计算随机数的平方根： stress -c 4 接着我们进入top来看看CPU状态（看完之后记得赶紧去kill掉容器，不然CPU拉满很卡的）： 可以看到权重高的容器中，分配到了更多的CPU资源，而权重低的容器中，只分配到一半的CPU资源。 当然我们也可以直接限制容器使用的CPU数量： docker run -it --cpuset-cpus=1 ubuntu --cpuset-cpus选项可以直接限制在指定的CPU上运行，比如现在我们的宿主机是2核的CPU，那么就可以分0和1这两个CPU给Docker使用，限制后，只会使用CPU 1的资源了： 可以看到，4个进程只各自使用了25%的CPU，加在一起就是100%，也就是只能占满一个CPU的使用率。如果要分配多个CPU，则使用逗号隔开： docker run -it --cpuset-cpus=0,1 ubuntu 这样就会使用这两个CPU了： 当然也可以直接使用--cpus来限制使用的CPU资源数： docker run -it --cpus=1 ubuntu 限制为1后，只能使用一个CPU提供的资源，所以这里加载一起只有一个CPU的资源了。当然还有更精细的--cpu-period和--cpu-quota，这里就不做介绍了。 最后我们来看一下对磁盘IO读写性能的限制，我们首先使用dd命令来测试磁盘读写速度： dd if=/dev/zero of=/tmp/1G bs=4k count=256000 oflag=direct 可以不用等待跑完，中途Ctrl+C结束就行： 可以看到当前的读写速度为86.4 MB/s，我们可以通过--device-read/write-bps和--device-read/write-iops参数对其进行限制。 这里要先说一下区别： bps：每秒读写的数据量。 iops：每秒IO的次数。 为了直观，这里我们直接使用BPS作为限制条件： docker run -it --device-write-bps=/dev/sda:10MB ubuntu 因为容器的文件系统是在/dev/sda上的，所以这我们就/dev/sda:10MB来限制对/dev/sda的写入速度只有10MB/s，我们来测试一下看看： 可以看到现在的速度就只有10MB左右了。 容器监控 最后我们来看看如何对容器的运行状态进行实时监控，我们现在希望能够对容器的资源占用情况进行监控，该怎么办呢？ 我们可以使用stats命令来进行监控： docker stats 可以实时对容器的各项状态进行监控，包括内存使用、CPU占用、网络I/O、磁盘I/O等信息，当然如果我们限制内存的使用的话： docker run -d -m 200M nagocoler/springboot-test:1.0 可以很清楚地看到限制情况： 除了使用stats命令来实时监控情况之外，还可以使用top命令来查看容器中的进程： docker top 容器ID/名称 当然也可以携带一些参数，具体的参数与Linux中ps命令参数一致，这里就不多做介绍了。 但是这样的监控是不是太原始了一点？有没有那种网页面板可以进行实时监控和管理的呢？有的。 我们需要单独部署一个Docker网页管理面板应用，一般比较常见的有：Portainer，我们这里可以直接通过Docker镜像的方式去部署这个应用程序，搜索一下，发现最新版维护的地址为：https://hub.docker.com/r/portainer/portainer-ce CE为免费的社区版本，当然也有BE商业版本，这里我们就直接安装社区版就行了，官方Linux安装教程：https://docs.portainer.io/start/install/server/docker/linux，包含一些安装前需要的准备。 首先我们需要创建一个数据卷供Portainer使用： docker volume create portainer_data 接着通过官方命令安装启动： docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest 注意这里需要开放两个端口，一个是8000端口，还有一个是9443端口。 OK，开启成功，我们可以直接登录后台面板：https://IP:9443/，这里需要HTTPS访问，浏览器可能会提示不安全，无视就行： 进入后就需要我们进行注册了，这里我们只需输入两次密码即可，默认用户名就是admin，填写完成后，我们就可以开始使用了： 点击Get Started即可进入到管理页面，我们可以看到目前有一个本地的Docker服务器正在运行： 我们可以点击进入，进行详细地管理，不过唯一缺点就是没中文，挺难受的，也可以使用非官方的汉化版本：https://hub.docker.com/r/6053537/portainer-ce。 单机容器编排 最后我们来讲解一下Docker-Compose，它能够对我们的容器进行编排。比如现在我们要在一台主机上部署很多种类型的服务，包括数据库、消息队列、SpringBoot应用程序若干，或是想要搭建一个MySQL集群，这时我们就需要创建多个容器来完成来，但是我们希望能够实现一键部署，这时该怎么办呢？我们就要用到容器编排了，让多个容器按照我们自己的编排进行部署。 官方文档：https://docs.docker.com/get-started/08_using_compose/，视频教程肯定不可能把所有的配置全部介绍完，所以如果各位小伙伴想要了解更多的配置，有更多需求的话，可以直接查阅官方文档。 快速开始 在Linux环境下我们需要先安装一下插件： sudo apt install docker-compose-plugin 接着输入docker compose version来验证一下是否安装成功。 这里我们就以部署SpringBoot项目为例，我们继续使用之前打包好的SpringBoot项目，现在我们希望部署这个SpringBoot项目的同时，部署一个MySQL服务器，一个Redis服务器，这时我们SpringBoot项目要运行的整个完整环境，先获取到对应的镜像： docker pull mysql/mysql-server docker pull redis 接着，我们需要在自己的本地安装一下DockerCompose，下载地址：https://github.com/docker/compose/releases，下载自己电脑对应的版本，然后在IDEA中配置： 下载完成后，将Docker Compose可执行文件路径修改为你存放刚刚下载的可执行文件的路径，Windows直接设置路径就行，MacOS下载之后需要进行下面的操作： mv 下载的文件名称 docker-compose sudo chmod 777 docker-compose sudo mv docker-compose /usr/local/bin 配置完成后就可以正常使用了，否则会无法运行，接着我们就可以开始在IDEA中编写docker-compose.yml文件了。 这里点击右上角的“与服务工具窗口同步”按钮，这样一会就可以在下面查看情况了。 我们现在就从头开始配置这个文件，现在我们要创建三个服务，一个是MySQL服务器，一个是Redis服务器，还有一个是SpringBoot服务器，需要三个容器来分别运行，首先我们先写上这三个服务： version: \"3.9\" #首先是版本号，别乱写，这个是和Docker版本有对应的 services: #services里面就是我们所有需要进行编排的服务了 spring: #服务名称，随便起 container_name: app_springboot #一会要创建的容器名称 mysql: container_name: app_mysql redis: container_name: app_redis 这样我们就配置好了一会要创建的三个服务和对应的容器名称，接着我们需要指定一下这些容器对应的镜像了，首先是我们的SpringBoot应用程序，可能我们后续还会对应用程序进行更新和修改，所以这里我们部署需要先由Dockerfile构建出镜像后，再进行部署： spring: container_name: app_springboot build: . #build表示使用构建的镜像，.表示使用当前目录下的Dockerfile进行构建 我们这里修改一下Dockerfile，将基础镜像修改为已经打包好JDK环境的镜像： FROM adoptopenjdk/openjdk8 COPY target/DockerTest-0.0.1-SNAPSHOT.jar app.jar CMD java -jar app.jar 接着是另外两个服务，另外两个服务需要使用对应的镜像来启动容器： mysql: container_name: app_mysql image: mysql/mysql-server:latest #image表示使用对应的镜像，这里会自动从仓库下载，然后启动容器 redis: container_name: app_redis image: redis:latest 还没有结束，我们还需要将SpringBoot项目的端口进行映射，最后一个简单的docker-compose配置文件就编写完成了： version: \"3.9\" #首先是版本号，别乱写，这个是和Docker版本有对应的 services: #services里面就是我们所有需要进行编排的服务了 spring: #服务名称，随便起 container_name: app_springboot #一会要创建的容器名称 build: . ports: - \"8080:8080\" mysql: container_name: app_mysql image: mysql/mysql-server:latest redis: container_name: app_redis image: redis:latest 现在我们就可以直接一键部署了，我们点击下方部署按钮： 看到 Running 4/4 就表示已经部署成功了，我们现在到服务器这边来看看情况： 可以看到，这里确实是按照我们的配置，创建了3个容器，并且都是处于运行中，可以正常访问： 如果想要结束的话，我们只需要点击停止就行了： 当然如果我们不再需要这套环境的话，可以直接点击下方的按钮，将整套编排给down掉，这样的话相对应的容器也会被清理的： 注意在使用docker-compose部署时，会自动创建一个新的自定义网络，并且所有的容器都是连接到这个自定义的网络里面： 这个网络默认也是使用bridge作为驱动： 这样，我们就完成了一个简单的配置，去部署我们的整套环境。 部署完整项目 前面我们学习了使用docker-compose进行简单部署，但是仅仅只是简单启动了服务，我们现在来将这些服务给连起来。首先是SpringBoot项目，我们先引入依赖： org.springframework.boot spring-boot-starter-jdbc mysql mysql-connector-java 接着配置一下数据源，等等，我们怎么知道数据库的默认密码是多少呢？所以我们先配置一下MySQL服务： mysql: container_name: app_mysql image: mysql/mysql-server:latest environment: #这里我们通过环境变量配置MySQL的root账号和密码 MYSQL_ROOT_HOST: '%' #登陆的主机，这里直接配置为'%' MYSQL_ROOT_PASSWORD: '123456.root' #MySQL root账号的密码，别设定得太简单了 MYSQL_DATABASE: 'study' #在启动时自动创建的数据库 TZ: 'Asia/Shanghai' #时区 ports: - \"3306:3306\" #把端口暴露出来，当然也可以不暴露，因为默认所有容器使用的是同一个网络 有关MySQL的详细配置请查阅：https://registry.hub.docker.com/_/mysql 接着我们将数据源配置完成： spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://app_mysql:3306/study #地址直接输入容器名称，会自动进行解析，前面已经讲过了 username: root password: 123456.root 然后我们来写点测试的代码吧，这里我们使用JPA进行交互： org.springframework.boot spring-boot-starter-data-jpa org.projectlombok lombok @Data @AllArgsConstructor @NoArgsConstructor @Entity @Table(name = \"db_account\") public class Account { @Column(name = \"id\") @Id long id; @Column(name = \"name\") String name; @Column(name = \"password\") String password; } @Repository public interface AccountRepository extends JpaRepository { } @RestController public class MainController { @Resource AccountRepository repository; @RequestMapping(\"/\") public String hello(){ return \"Hello World!\"; } @GetMapping(\"/get\") public Account get(@RequestParam(\"id\") long id){ return repository.findById(id).orElse(null); } @PostMapping(\"/post\") public Account get(@RequestParam(\"id\") long id, @RequestParam(\"name\") String name, @RequestParam(\"password\") String password){ return repository.save(new Account(id, name, password)); } } 接着我们来修改一下配置文件： spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://app_mysql:3306/study username: root password: 123456.root jpa: database: mysql show-sql: true hibernate: ddl-auto: update #这里自动执行DDL创建表，全程自动化，尽可能做到开箱即用 现在代码编写完成后，我们可以将项目打包了，注意执行我们下面的打包命令，不要进行测试，因为连不上数据库： mvn package -DskipTests 重新生成jar包后，我们修改一下docker-compose配置，因为MySQL的启动速度比较慢，我们要一点时间等待其启动完成，如果连接不上数据库导致SpringBoot项目启动失败，我们就重启： spring: #服务名称，随便起 container_name: app_springboot #一会要创建的容器名称 build: . ports: - \"8080:8080\" depends_on: #这里设置一下依赖，需要等待mysql启动后才运行，但是没啥用，这个并不是等到启动完成后，而是进程建立就停止等待 - mysql restart: always #这里配置容器停止后自动重启 然后我们将之前自动构建的镜像删除，等待重新构建： 现在我们重新部署docker-compos吧： 当三个服务全部为蓝色时，就表示已经正常运行了，现在我们来测试一下吧： 接着我们来试试看向数据库传入数据： 可以看到响应成功，接着我们来请求一下： 这样，我们的项目和MySQL基本就是自动部署了。 接着我们来配置一下Redis： org.springframework.boot spring-boot-starter-data-redis 接着配置连接信息： spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://app_mysql:3306/study username: root password: 123456.root jpa: database: mysql show-sql: true hibernate: ddl-auto: update redis: host: app_redis //再加两个Redis操作进来 @Resource StringRedisTemplate template; @GetMapping(\"/take\") public String take(@RequestParam(\"key\") String key){ return template.opsForValue().get(key); } @PostMapping(\"/put\") public String put(@RequestParam(\"key\") String key, @RequestParam(\"value\") String value){ template.opsForValue().set(key, value); return \"操作成功！\"; } 最后我们来配置一下docker-compose的配置文件： redis: container_name: app_redis image: redis:latest ports: - \"6379:6379\" OK，按照之前的方式，我们重新再部署一下，然后测试： 这样我们就完成整套环境+应用程序的配置了，我们在部署整个项目时，只需要使用docker-compose配置文件进行启动即可，这样就大大方便了我们的操作，实现开箱即用。甚至我们还可以专门使用一个平台来同时对多个主机进行一次性配置，大规模快速部署，而这些就留到以后的课程中再说吧。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Linux/Docker容器技术.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/Linux/Docker容器技术.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/":{"url":"other/","title":"其他","keywords":"","body":"window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/README.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/README.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:12 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/C语言程序设计/":{"url":"other/C语言程序设计/","title":"C语言程序设计","keywords":"","body":"April 项目组文档仓库 这是一个用于存储文档的仓库，可以方便地共享和管理各种文档。本仓库的文档类型不限，可以包括但不限于技术文档、设计文档、需求文档、用户手册等。 如何使用 你可以通过以下几种方式使用本仓库： 查看文档：在本仓库中找到你需要的文档，点击进入查看。 下载文档：在文档页面中点击下载按钮，即可下载文档。 提交文档：如果你想上传一个新文档或修改已有文档，可以先 Fork 本仓库，然后在你的仓库中进行修改，最后发起 Pull Request 即可。 贡献 如果你想为本仓库贡献文档，欢迎进行如下操作： Fork 本仓库 在你的仓库中添加或修改文档 发起 Pull Request 我们会及时审核并合并你的贡献。为了保证贡献质量，建议你在提交贡献前，仔细阅读贡献指南。 贡献指南 为了保证本仓库的贡献质量，我们制定了如下的贡献指南： 文档内容应当真实可靠，不得包含虚假信息。 文档格式应当规范，建议使用 Markdown 格式。 文档应当具有实用性和参考价值，不得过于简单或复杂。 代码示例应当可执行，并应当注明相关依赖库的版本号。 如有图片、视频等附件，建议使用外部链接或专门的存储仓库。 版权声明 本仓库的所有文档均属于原作者版权所有，未经授权不得进行商业使用。在 Fork 和提交贡献时，请务必尊重原作者的版权，并注明出处。 联系我们 如果你有任何问题或建议，可以通过以下方式联系我们： 邮箱：mobaijun8@163.com GitHub Issues：https://github.com/april-projects/.docs/issues window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/C语言程序设计/README.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/C语言程序设计/README.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:12 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/C语言程序设计/C语言（一）.html":{"url":"other/C语言程序设计/C语言（一）.html","title":"C语言（一）","keywords":"","body":" 温馨提示：所有的笔记（需要使用Typora软件打开）在视频下方简介中直接获取，纯个人录制，不用加什么公众号这些，各位小伙伴直接网盘自取吧。 计算机思维导论 计算机自1946年问世以来，几乎改变了整个世界。 现在我们可以通过电脑来做很多事情，比如我们常常听到的什么人工智能、电子竞技、大数据等等，都和计算机息息相关，包括我们现在的手机、平板等智能设备，也是计算机转变而来的。各位可以看看最顶上的这张图片，如果你在小时候接触过计算机，那么一定对这张图片（照片拍摄于1996年，在美国加利福尼亚州加利福尼亚州的锁诺玛县）印象深刻，这张壁纸作为WindowsXP系统的默认壁纸，曾经展示在千家万户的电脑屏幕上。 也许你没有接触过计算机，也许你唯一接触计算机就是用来打游戏，也有可能你曾经捣鼓过计算机，在学习C语言之前，先让我们来了解一下计算机的世界。 计算机的世界 计算机虽然名字听着很高级，不过它也是由一个个简单电路组成的。 这是我们在初中就学习过的电路图，不过这种电路太过简单，只能完成一些很基础的的操作，比如点亮小灯泡等。 很明显想要实现计算机怎么高级的运算机器，肯定是做不到的，这时我们就需要引入更加强大的数字电路了。 用数字信号完成对数字量进行算术运算和逻辑运算的电路称为数字电路，或数字系统。由于它具有逻辑运算和逻辑处理功能，所以又称数字逻辑电路。现代的数字电路由半导体工艺制成的若干数字集成器件构造而成。逻辑门是数字逻辑电路的基本单元。 计算机专业一般会在大一开放《数字电路》这门课程，会对计算机底层的数字电路实现原理进行详细介绍。 数字电路引入了逻辑判断，我们来看看简单的数字电路： 数字电路中，用电压的高低来区分出两种信号，低电压表示0，高电压表示1，由于只能通过这种方式表示出两种类型的信号，所以计算机采用的是二进制。 二进制是计算技术中广泛采用的一种数制。二进制数据是用0和1两个数码来表示的数。它的基数为2，进位规则是“逢二进一”，借位规则是“借一当二”。 比如我们一般采用的都是十进制表示，比如9再继续加1的话，就需要进位了，变成10，在二进制中，因为只有0和1，所以当1继续加1时，就需要进位了，就变成10了（注意这不是十，读成一零就行了） 当然，仅仅有两种信号还不够，我们还需要逻辑门来辅助我们完成更多的计算，最基本的逻辑关系是与、或、非，而逻辑门就有相应的是与门、或门和非门，可以用电阻、电容、二极管、三极管等分立原件构成（具体咋构成的咱这里就不说了） 比如与操作，因为只有两种类型，我们一般将1表示为真，0表示为假，与操作（用&表示）要求两个数参与进来，比如： 1 & 1 = 1 必须两边都是真，结果才为真。 1 & 0 = 0 两边任意一个或者都不是真，结果为假。 或运算（用 | 表示）： 1 | 0 = 1 两边只要有一个为真，结果就为真 0 | 0 = 0 两边同时为假，结果才是假 非运算实际上就是取反操作（可以是 ! 表示） !1 = 0 !0 = 1 非运算会将真变成假，假变成真 有了这些运算之后，我们的电路不仅仅可以实现计算，也可以实现各种各样的逻辑判断，最终才能发展成我们的计算机。 前面我们大概介绍一下计算机的底层操作原理，接着我们来看看计算机的基本组成。 相信各位熟知的计算机都是一个屏幕+一个主机的形式，然后配上我们的键盘鼠标，就可以开始使用了，但是实际上标准的计算机结构并没有这么简单，我们来看看： 我们电脑最核心的部件，当属CPU，因为几乎所有的运算都是依靠CPU进行（各种各样的计算电路已经在CPU中安排好了，我们只需要发送对应的指令就可以进行对应的运算），它就像我们人的大脑一样，有了大脑才能进行思考。不过光有大脑还不行，还要有一些其他的部分来辅助工作，比如我们想向电脑里面打字，那么就需要连接一个键盘才能输入，我们想要点击桌面上的图标，那么就需要一个鼠标来操作光标，这些都是输入设备。我们的电脑开机之后显示器上会显示出画面，实际上显示器就是输出设备。 当然除了这些内容之外，我们的电脑还需要内存来保存运行时的一些数据，以及外存来保存文件（比如硬盘）等。我们常说的iPhone13 512G，这个512G并不是指的内存，而是指的外存，准确的说是用于存放文件硬盘大小，而真正的内存是我们常说的4G/6G/8G运行内存，内存的速度远高于外存的速度，所以1G内存的价格远超1G硬盘的价格。 计算机包括五大部件：运算器、控制器、存储器、输入和输出设备。有了这一套完整的硬件环境，我们的电脑才算是有了一个完整的身体。 问题：我们上面提到的这些硬件设备哪些是属于外设？ 操作系统概述 前面我们了解了一下计算机的大致原理和组成结构，但是光有这一套硬件可不行，如何让这一套硬件按照我们想要的方式运作起来，也是非常重要的，这时我们就需要介绍操作系统了。 操作系统（operating system，简称OS）是管理计算机硬件与软件资源的计算机程序。操作系统需要处理如管理与配置内存、决定系统资源供需的优先次序、控制输入设备与输出设备、操作网络与管理文件系统等基本事务。操作系统也提供一个让用户与系统交互操作的界面。 一般在计算机专业大二，会开放《操作系统》课程，会详细讲解操作系统的底层运作机制和调度。 一般我们电脑上都安装了Windows操作系统（苹果笔记本安装的是MacOS操作系统），现在主流的电脑都已经预装Windows11了： 有了操作系统，我们的电脑才能真正运行起来，我们就可以轻松地通过键盘和鼠标来操作电脑了。 不过操作系统最开始并不是图形化界面，它类似于Windows中的命令提示符： 没有什么图标这些概念，只有一个简简单单的黑框让我们进行操作，通过输入命令来进行一些简单的使用，程序的运行结果也会在黑框框（命令行）中打印出来，不过虽然仅仅是一个黑框，但是能运行的程序可是非常非常多的，只需要运行我们编写好的程序，就能完成各种各样复杂的计算任务，并且计算机的计算速度远超我们的人脑。 中国超级计算机系统天河二号，计算速度达到每秒5.49亿亿次。 当然，除了我们常见的Windows和MacOS系统之外，还有我们以后需要经常打交道的Linux操作系统，这种操作系统是开源的，意思是所有的人都可以拿到源代码进行修改，于是就出现了很多发行版： 这些发行版有带图形化界面的，也有不带图形化界面的，不带图形化界面的Linux将是我们以后学习的重点。 不同操作系统之间的软件并不是通用的，比如Windows下我们的软件一般是.exe后缀名称，而MacOS下则不是，并且也无法直接运行.exe文件，这是因为不同操作系统的具体实现会存在一些不同，程序编译（我们之后会介绍到）之后的格式也会不同，所以是无法做到软件通用的。 正是因为有了操作系统，才能够组织我们计算机的底层硬件（包括CPU、内存、输入输出设备等）进行有序工作，没有操作系统电脑就如同一堆废铁，只有躯壳没有灵魂。 计算机编程语言 现在我们大致了解了我们的电脑的运作原理，实际上是一套完整的硬件+一个成形的操作系统共同存在的。接着我们就可以开始了解一下计算机的编程语言了。我们前面介绍的操作系统也是由编程语言写出来的，操作系统本身也算是一个软件。 那么操作系统是如何让底层硬件进行工作的呢？实际上就是通过向CPU发送指令来完成的。 计算机指令就是指挥机器工作的指示和命令，程序就是一系列按一定顺序排列的指令，执行程序的过程就是计算机的工作过程。指令集，就是CPU中用来计算和控制计算机系统的一套指令的集合，而每一种新型的CPU在设计时就规定了一系列与其他硬件电路相配合的指令系统。而指令集的先进与否，也关系到CPU的性能发挥，它也是CPU性能体现的一个重要标志。 我们电脑中的CPU有多种多样的，不同的CPU之间可能也会存在不同的架构，比如现在最常用的是x86架构，还有我们手机平板这样的移动设备使用的arm架构，不同的架构指令集也会有不同。 我们知道，计算机底层硬件都是采用的0和1这样的二进制表示，所以指令也是一样的，比如（这里随便写的）： 000001 - 代表开机 000010 - 代表关机 000011 - 代表进行加法运算 当我们通过电路发送给CPU这样的二进制指令，CPU就能够根据我们的指令执行对应的任务，而我们编写的程序保存在硬盘中也是这样的二进制形式，我们只需要将这些指令组织好，按照我们的思路一条一条执行对应的命令，就能够让计算机计算任何我们需要的内容了，这其实就是机器语言。 不过随着时代的进步，指令集越来越大，CPU支持的运算类型也越来越多，这样的纯二进制编写实在是太累了，并且越来越多的命令我们根本记不住，于是就有了汇编语言。汇编语言将这些二进制的操作码通过助记符来替换： MOV 传送字或字节。 MOVSX 先符号扩展,再传送。 MOVZX 先零扩展,再传送。 PUSH 把字压入堆栈。 把这些原有的二进制命令通过一个单词来代替，这样是不是就好记多了，在程序编写完成后，我们只需要最后将这些单词转换回二进制指令就可以了，这也是早期出现的低级编程语言。 不过虽然通过这些助记符就能够很轻松地记住命令，但是还是不够方便，因为可能我们的程序需要完成一个很庞大的任务，但是如果还是这样一条一条指令进行编写，是不是太慢了点，有时候可能做一个简单的计算，都需要好几条指令来完成。于是，高级编程语言——C语言，终于诞生了。 C语言诞生于美国的贝尔实验室，由丹尼斯·里奇（Dennis MacAlistair Ritchie）以肯尼斯·蓝·汤普森（Kenneth Lane Thompson）设计的B语言为基础发展而来，在它的主体设计完成后，汤普森和里奇用它完全重写了UNIX操作系统，且随着UNIX操作系统的发展，C语言也得到了不断的完善。 高级语言不同于低级语言，低级语言的主要操作对象是指令本身，而高级语言却更加符合我们人脑的认知，更像是通过我们人的思维，去告诉计算机你需要做什么，包括语法也会更加的简单易懂。下面是一段简单的C语言代码： int main() { int a = 10; //定义一个a等于10 int b = 10; //定义一个b等于10 int c = a + b; //语义非常明确，c就是a加上b计算出来的结果。 return 0; } 不过现在看不懂没关系，我们后面慢慢学。 C语言虽然支持按照我们更容易理解的方式去进行编程，但是最后还是会编译成汇编指令最后变成计算机可以直接执行的指令，不过具体的编译过程，我们不需要再关心了，我们只需要去写就可以了，而对我们代码进行编译的东西，称为编译器。 当然，除了C语言之外，还有很多其他的高级语言，比如Java、Python、C#、PHP等等，相比其他编程语言，C算是比较古老的一种了，但是时隔多年直至今日，其他编程语言也依然无法撼动它的王者地位： 可以看到在2021年9月，依然排在编程语言排行榜的第一名（Python和Java紧随其后），可见这门语言是多么的不可撼动，很多操作系统、高级编程语言底层实现，几乎都是依靠C语言去编写的（包括Java的底层也是C/C++实现的）所以学习这一门语言，对于理工科尤其是计算机专业极为重要，学好C语言你甚至可以融汇贯通到其他语言，学起来也会轻松很多。 那么从下节课开始，我们就先做好一些环境上的准备。 C语言开发环境部署 完成开发环境部署之后，我们就可以使用C语言来将一句话输出到控制台了，成功编译运行下面的简单程序： #include int main() { printf(\"Hello, World!\\n\"); return 0; } 首先，我们既然要将我们编写的C语言代码进行编译，那么肯定得找到一个合适的编译器才行，现代的集成开发环境IDE一般都包含了这些编译器，所以我们不需要进行单独的安装。 我们只需要找一个集成开发环境去安装就行了，目前功能比较完善的集成开发环境有： Codeblocks（支持Windows、Linux、MacOS操作系统） Visual Studio（支持Windows、MacOS操作系统） CLion（支持Windows、Linux、MacOS操作系统） 这里我们就使用CLion作为我们的开发工具使用（这个IDE是收费的，但是学生可以申请免费使用，别担心，大学四年肯定是够你用了，选这个是考虑到后面同学们可能会继续学习Java，Java语言的推荐IDE也是同一个公司的产品，界面都长得差不多）当然如果你想要使用其他的开发工具，也可以，但是这里我们就不演示了。 首先前往官网下载：CLion: A Cross-Platform IDE for C and C++ by JetBrains 下载完成后我们直接点击安装： 如果你不是很熟悉，建议直接点Next安装到C盘默认路径，不要去修改，当然如果确实C盘没有空间，那可以自行修改为其他路径，但是注意最好路径中不要出现中文。 勾选一下创建快捷方式，然后继续点Next等待安装就行了： 安装完成后，我们可以直接打开： 这里会提示我们激活，点击按钮去官网注册一个账号。注册完成后，推荐去申请一下学生授权，因为试用只有30天：Jetbrains学生授权获取指南 - 知乎 (zhihu.com) 这里我们点击开始试用，然后就可以点击Continue了，现在成功来到主界面： 由于是英文，使用不太方便，所以我们安装一下中文插件： 现在我们就成功安装好CLion集成开发环境了。 现在我们来创建我们的第一个C语言项目（我们的程序是以一个项目的形式进行管理的，这里知道怎么创建就行了）： 这里选择C可执行文件，然后项目的保存位置可以自行修改，配置完成后点击创建： 可以看到，在创建之后，会自动为我们生成一段示例代码，而之后我们要编写的代码，都在生成的main.c中进行编写，除了这个文件，其他的全部不要去修改，也不用管是什么意思，后面我们会慢慢介绍。 接着我们需要配置一下工具链，选择捆绑的MinGW（如果已经有了就不需要配置了） 那么这段示例代码有了，我们如何编译运行呢？ 我们可以点击代码旁边的绿色三角形符号或是右上角的绿色三角形，就可以直接编译运行我们的代码了。运行的结果是在控制台输出一个“HelloWorld！”，当然我们也可以直接运行编译出来的可执行文件： 我们可以看到，这里生成了一个项目名称.exe文件，这种就是Windows环境下可以直接运行的应用程序，我们可以打开这个文件夹，直接使用cmd来运行： 运行出来的效果是一样的，这种程序实际上就是最原始的命令行程序，输入和输出都是在这种黑框框中进行的，而我们的主要学习目标也是这种命令行程序。 这样我们就配置好了开发环境，然后就不要去动其他的东西了，一般新手最容易遇到一些奇奇怪怪的问题。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/C语言程序设计/C语言（一）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/C语言程序设计/C语言（一）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:12 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/C语言程序设计/C语言（三）.html":{"url":"other/C语言程序设计/C语言（三）.html","title":"C语言（三）","keywords":"","body":" C语言高级特性 前面我们了解了C语言的相关基础内容，我们来看看C语言的高级部分。这一章的学习难道会比较大，尤其是指针板块，因为需要理解计算机内存模型，所以说是很多初学者的噩梦。 函数 其实函数我们在一开始就在使用了： int main() { //这是定义函数 ... } 我们程序的入口点就是main函数，我们只需要将我们的程序代码编写到主函数中就可以运行了，不够这个函数只是由我们来定义，而不是我们自己来调用。当然，除了主函数之外，我们一直在使用的printf也是一个函数，不过这个函数是标准库中已经实现好了的，现在是我们在调用这个函数： printf(\"Hello World!\"); //直接通过 函数名称(参数...) 的形式调用函数 那么，函数的具体定义是什么呢？ 函数是完成特定任务的独立程序代码单元。 其实简单来说，函数时为了完成某件任务而生的，可能我们要完成某个任务并不是一行代码就可以搞定的，但是现在可能会遇到这种情况： #include int main() { int a = 10; printf(\"H\"); //比如下面这三行代码就是我们要做的任务 printf(\"A\"); a += 10; if(a > 20) { printf(\"H\"); //这里我们还需要执行这个任务 printf(\"A\"); a += 10; } switch (a) { case 30: printf(\"H\"); //这里又要执行这个任务 printf(\"A\"); a += 10; } } 我们每次要做这个任务时，都要完完整整地将任务的每一行代码都写下来，如果我们的程序中多处都需要执行这个任务，每个地方都完整地写一遍，实在是太臃肿了，有没有一种更好的办法能优化我们的代码呢？ 这时我们就可以考虑使用函数了，我们可以将我们的程序逻辑代码全部编写到函数中，当我们执行函数时，实际上执行的就是函数中的全部内容，也就是按照我们制定的规则执行对应的任务，每次需要做这个任务时，只需要调用函数即可。 我们来看看，如何创建和使用函数。 创建和使用函数 首先我们来看看如何创建一个函数，其实创建一个函数是很简单的，格式如下： 返回值类型 函数名称([函数参数...]); 其中函数名称也是有要求的，并不是所有的字符都可以用作函数名称，它的命名规则与变量的命名规则基本一致，所以这里就不一一列出了。 函数不仅仅需要完成我们的任务，可能某些函数还需要告诉我们结果，比如我们之前认识的getchar函数，这个函数实际上返回了一个int值作为结果（也就是我们输入的字符）我们同样可以将函数返回的结果赋值给变量或是参与运算等等。 当然如果我们的函数只需要完成任务，不需要告诉我们结果，返回值类型可以写成void表示为空。 函数参数我们放在下一个小节中讲解，所以这里我们不使用任何参数，所以这里也将参数设定为void表示没有参数（当然为了方便，我们也可以直接什么都不写） #include void test(void); //定义函数原型，因为C语言是从上往下的，所以如果要在下面的主函数中使用这个函数，一定要定义到它的上面。 int main() { } void test(void){ //函数具体定义，添加一个花括号并在其中编写程序代码，就和我们之前在main中编写一样 printf(\"我是测试函数!\"); } 或是直接在上方写上函数的具体定义： #include void test(void){ //函数具体定义，添加一个花括号并在其中编写程序代码，就和我们之前在main中编写一样 printf(\"我是测试函数!\"); } int main() { } 那么现在我们将函数定义好之后，该如何去使用呢？ int main() { test(); //这里我们只需要使用 函数名称(); 就可以调用函数了 printf(\"Hello World!\"); //实际上printf也是一个函数，功能是向控制台打印字符串，只不过这个函数是系统提供的，已经提前实现好了，其中的参数我们后续还会进行介绍。 } 这样，我们就可以很好解决上面的代码复用性的问题，我们只需要将会重复使用的逻辑代码定义到函数中，当我们需要执行时，直接调用编写好的函数就可以了，这样是不是简单多了？ int main() { int a = 10; test(); //多次使用的情况下，函数会让我们的程序简单很多 if(a > 20) test(); switch (a) { case 30: test(); } } 当然函数除了可以实现代码的复用之外，也可以优化我们的程序，让我们的代码写得更有层次感，我们的程序可能会有很多很多的功能，需要写很多的代码，但是谁愿意去看一个几百行上千行的main函数呢？我们可以将每个功能都写到一个对应的函数中，这样就可以大大减少main函数中的代码量了。 int main() { func1(); //直接把多行代码写到一个函数中，在main中调用对应的函数，这样能够大幅度减少代码量 func2(); func3(); } 而我们从一开始就在编写main函数实际上是一种比较特殊的函数，C语言规定程序一律从主函数开始执行，所以这也是为什么我们一定要写成int main()的形式。 全局变量和局部变量 现在我们已经了解了如何创建和调用函数，在继续学习后续内容之前，我们需要先认识一下全局变量和局部变量这两个概念（啊这，变量就变量，还分这么细啊？） 我们首先来看看局部变量，实际上我们之前使用的都是局部变量，比如： int main() { int i = 10; //这里定义的变量i实际上是main函数中的局部变量，它的作用域只能是main函数中，也就是说其他地方是无法使用的 } 局部变量只会在其作用域中生效： 可以看到在其他函数中，无法使用main函数中的变量，因为局部变量的作用域是有限的，比如位于某个函数内部的变量，那么它的作用域就是整个函数内部，而在其他位置均无法访问。又比如我们之前学习的for循环，当我们这样定义时： 可以看到，在for循环中定义的变量i，只能在for循环内部使用，而出了这个花括号之后就用不了了，当然由于作用域不同，所以下面这种写法是完全没问题的： int main() { for (int i = 0; i 所以，清楚了局部变量的作用域之后，我们在编写程序的时候就很清楚了： 那么如果现在我们想要在任何位置都能使用一个变量，该怎么办呢？这时就要用到全局变量了： #include void test(); int a = 10; //我们可以直接将变量定义放在外面，这样所有的函数都可以访问了 int main() { a += 10; test(); //现在各位觉得，这两个操作完成后，a会是多少呢？ printf(\"%d\", a); } void test(){ a += 10; } 因为现在所有函数都能使用全局变量，所以这个结果不难得到。 函数参数和返回 我们的函数可以接受参数来完成任务，比如我们现在想要实现用一个函数计算两个数的和并输出到控制台。 这种情况我们就需要将我们需要进行加法计算的两个数，告诉函数，这样函数才能对这两个数求和，那么怎么才能告诉函数呢？我们可以通过设定参数： #include void test(int, int); //函数原型中需要写上需要的参数类型，多个参数用逗号隔开，比如这里我们需要的就是两个int类型的参数 int main() { } void test(int a, int b){ //函数具体定义中也要写上，这里的a和b我们称为形式参数（形参），等价于函数中的局部变量，作用域仅限此函数 printf(\"%d\", a + b); } 那么现在定义完成了，该如何使用这个函数呢，还记得我们怎么使用printf函数的吗？我们只需要把它所需要的参数填入即可： int main() { test(10, 20); //这里直接填写一个常量、变量或是运算表达式都是可以的，我们称实际传入的值为实际参数（实参） } 可以看到，成功计算出结果： 实际上我们传入的实参在进入到函数时，会自动给函数中形参（局部变量）进行赋值，这样我们在函数中就可以得到外部传入的参数值了。 我们来看看printf函数是怎么写的： int printf(const char * __restrict, ...) __printflike(1, 2); //看起来比较高级 这里我们主要关心它的两个参数，一个是char *由于还没有学习指针，这里就把它当做const char[]就行了，表示一个不可修改的字符串，而第二个参数我们看到是...，这三个点是个啥？ 我们知道，如果我们想要填写具体需要打印的值时，可以一直往后写： printf(\"%d, %d\", 1, 2); //参数可以一直写 正常情况下我们函数的参数列表都是固定的，怎么才能像这样写很多个呢？这就要用到可变长参数了，不过可变长参数的使用比较麻烦，这里我们就不做讲解了。 这里给大家提一个问题，如果我们修改形式参数的值，外面的实参值会跟着发生修改吗？ #include void swap(int, int); int main() { int a = 10, b = 20; swap(a, b); printf(\"a = %d, b = %d\", a, b); //最后会得到什么结果？ } void swap(int a, int b){ int tmp = a; //这里对a和b的值进行交换 a = b; b = tmp; } 通过结果发现，虽然调用了函数对a和b的值进行交换，但貌似并没有什么卵用。这是为什么呢？ 还记得我们前面说的吗，函数的形参实际上就是函数内的局部变量，它的作用域仅仅是这个函数，而我们外面传入的实参，仅仅知识将值赋值给了函数内的形参而已，并且外部的变量跟函数内部的变量作用域都不同，所以半毛钱关系都没有，这里交换的仅仅是函数内部的两个形参变量值，跟外部作实参的变量没有任何关系。 那么，怎么样才能实现通过函数交换两个变量的值呢？这个问题我们会在指针部分进行讨论。 不过数组却不受限制，我们在函数中修改数组的值，是直接可以生效的： #include void test(int arr[]); int main() { int arr[] = {4, 3, 8, 2, 1, 7, 5, 6, 9, 0}; test(arr); printf(\"%d\", arr[0]); //打印的是修改后的值了 } void test(int arr[]) { arr[0] = 999; //数组就可以做到这边修改，外面生效 } 我们再来看一个例子： #include void test(int a){ a += 10; printf(\"%d\\n\", a); } int main() { int a = 10; test(a); test(a); //连续两次调用，那么这两次的结果会是什么？ } 可以看到结果都是20，（如果猜对了可以直接跳过，如果你猜测的是20和30的话，需要听我解释了）注意每次调用函数都是单独进行的，并不是复用函数中的形参，不要认为第一次调用函数test就将函数的局部变量变成20了，再次调用就是20+10变成30。实际上这两次调用都是单独进行的，形参a都是在一开始的时候被赋值为实参的值的，这两次调用没有任何关系，并且函数执行完毕后就自动销毁了。 那要是我就希望每次调用函数时保留变量的值呢？我们可以使用静态变量： #include void test(); int main() { test(); test(); } void test() { static int a = 20; //静态变量并不会在函数结束时销毁其值，而是保持 a += 20; printf(\"%d \", a); } 我们接着来看函数的返回值，并不是所有的函数都是执行完毕就结束了的，可能某些时候我们需要函数告诉我们执行的结果如何，这时我们就需要用到返回值了，比如现在我们希望实现一个函数计算a+b的值： #include int sum(int ,int ); //现在我们要返回a和b的和（那么肯定也是int类型）所以这里需要将返回值类型修改为int int main() { int a = 10, b = 20; //计算a和b的和 int result = sum(a, b); //函数执行后，会返回一个int类型的结果，我们可以接收它，也可以像下面一样直接打印，当然也可以参与运算等等。 printf(\"a+b=%d\", sum(a, b)); } int sum(int a, int b) { return a + b; //通过return关键字来返回计算的结果 } 我们接着来看下一个例子，现在我们希望你通过函数找到数组中第一个小于0的数字并将其返回，如果没有找到任何小于0的数，就返回0即可： #include int findMin(int arr[], int len); //需要两个参数，一个是数组本身，还有一个是数组的长度 int main() { int arr[] = {1, 4, -9, 2, -4, 7}; int min = findMin(arr, 6); printf(\"第一个小于0的数是：%d\", min); } int findMin(int arr[], int len) { for (int i = 0; i 这里我们使用了return关键字来返回结果，注意当我们的程序走到return时，无论还有什么内容没执行完，整个函数都将结束，并返回结果。注意带返回值（非void）的函数中的所有情况都需要有一个对应的返回值： int test(int a) { if (a > 0) { return 10; //当a大于0时有返回语句 } else{ //但是当a不大于0时就没有返回值了，这样虽然可以编译通过，但是会有警告（黄标），运行后可能会出现一些无法预知的问题 } } 如果是没有返回值的函数，我们也可以调用return来返回，不过默认情况下是可以省略的： void test(int a){ if(a == 10) return; //因为是void，所以什么都不需要加，直接return printf(\"%d\", a); } 递归调用 我们的函数除了在其他地方被调用之外，也可以自己调用自己（好家伙，套娃是吧），这种玩法我们称为递归。 #include void test(){ printf(\"Hello World!\\n\"); test(); //函数自己在调用自己，这样的话下一轮又会进入到这个函数中 } int main() { test(); } 我们可以尝试运行一下上面的程序，会发现程序直接无限打印Hello World!这个字符串，这是因为函数自己在调用自己，不断地重复进入到这个函数，理论情况下，它将永远都不会结束，而是无限地执行这个函数的内容。 但是到最后我们的程序还是终止了，这是因为函数调用有最大的深度限制，因为计算机不可能放任函数无限地进行下去。 （选学）我们来大致了解一下函数的调用过程，实际上在程序运行时会有一个叫做函数调用栈的东西，它用于控制函数的调用： #include //我们以下面的调用关系为例 void test2(){ printf(\"giao\"); } void test(){ test2(); //main -> test -> test2 printf(\"giao\"); } int main() { test(); printf(\"giao\"); } 其实我们可以很轻易地看出整个调用关系，首先是从main函数进入，然后调用test函数，在test函数中又调用了test2函数，此时我们就需要等待test2函数执行完毕，test才能继续，而main则需要等待test执行完毕才能继续。而实际上这个过程是由函数调用栈在控制的： 而当test2函数执行完毕后，每个栈帧又依次从栈中出去： 当所有的栈全部出去之后，程序结束。 所以这也就不难解释为什么无限递归会导致程序出现错误，因为栈的空间有限，而函数又一直在进行自我调用，所以会导致不断地有新的栈帧进入，最后塞满整个栈的空间，就爆炸了，这种问题我们称为栈溢出（Stack Overflow） 当然，如果我们好好地按照规范使用递归操作，是非常方便的，比如我们现在需要求某个数的阶乘： #include int test(int n); int main() { printf(\"%d\", test(3)); } int test(int n){ if(n == 1) return 1; //因为不能无限制递归下去，所以我们这里添加一个结束条件，在n = 1时返回 return test(n - 1) * n; //每次都让n乘以其下一级的计算结果，下一级就是n-1了 } 通过给递归调用适当地添加结束条件，这样就不会无限循环了，并且我们的程序看起来无比简洁，那么它是如何执行的呢： 它看起来就像是一个先走到底部，然后拿到问题的钥匙后逐步返回的一个过程，并在返回的途中不断进行计算最后得到结果（妙啊） 所以，合理地使用递归反而是一件很有意思的事情。 实战：斐波那契数列解法其三 前面我们介绍了函数的递归调用，我们来看一个具体的实例吧，我们还是以解斐波那契数列为例。 既然每个数都是前两个数之和，那么我们是否也可以通过递归的形式不断划分进行计算呢？我们依然可以借鉴之前动态规划的思想，通过划分子问题，分而治之来完成计算。 实战：汉诺塔 什么是汉诺塔？ 汉诺塔（Tower of Hanoi），又称河内塔，是一个源于印度古老传说的益智玩具。大梵天创造世界的时候做了三根金刚石柱子，在一根柱子上从下往上按照大小顺序摞着64片黄金圆盘。大梵天命令婆罗门把圆盘从下面开始 按大小顺序重新摆放在另一根柱子上。并且规定，在小圆盘上不能放大圆盘，在三根柱子之间一次只能移动一个圆盘。 这三根柱子我们就依次命名为A、B、C，现在请你设计一个C语言程序，计算N阶（n片圆盘）汉诺塔移动操作的每一步。 这个问题看似很难，实际上我们也可以对每一步进行推理： 当汉诺塔只有1阶的情况下：直接把A上的圆盘移动到C，搞定。 当汉诺塔只有2阶的情况下：我们的最终目标还是需要将A柱最下面的圆盘丢到C，不过现在多了圆盘，我们得先把这个圆盘给处理了，所以我们得把这上面的1个圆盘丢到B上去，这样才能把A最下面的圆盘丢给C。然后再把B上面的1个圆盘丢到C上去 当汉诺塔只有3阶的情况下：我们的最终目标还是需要将A柱最下面的圆盘丢到C，不过现在多了圆盘，我们得先把这个圆盘给处理了，所以我们得把这上面的2个圆盘丢到B上去，这样才能把A最下面的圆盘丢给C。然后再把B上面的2个圆盘丢到C上 实际上我们发现，把A移动到C是一定要进行的，而在进行之前需要先把压在上面全部的圆盘全部放到B去。而移动之后也要把B上的圆盘全部移动到C上去。其实所有的情况下最终都会有一个n=1的情况，将A上的最后一个圆盘移动到C，只是多了一个前面的步骤和后面的步骤。 不过难点就是，怎么把A上的n-1个圆盘移动到B去呢？其实这时我们可以依靠C作为中间商，来帮助我们移动（比如n = 3，那么先把最上面的移动到C，然后把第二大的移动到B，再从C上把最小的移动到B上，这样就借助了C完成了两个圆盘的转移），而最后又怎么把B上的圆盘全部移到C去呢，这时就可以依靠A作为中间商，方法同理；实际上大问题最后都会变成n = 2时这样的小问题，只不过是要移动目标不同罢了。 只要想通了怎么去借助中间商进行移动，就很好写出程序了。 递归函数如下设计： //a存放圆盘的初始柱子，b作为中间柱子存放使用，c作为目标柱子，n表示要从a移动到c的圆盘数 void hanoi(char a, char b, char c, int n){ } 现在我们来实现一下吧。 void move(char start, char end, int n){ //用于打印移动操作到控制台，start是起始柱子，end是结束柱子，n是哪一个圆盘 printf(\"第%d个圆盘：%c --> %c\\n\", n, start, end); } void hanoi(char a, char b, char c, int n){ //刚进来的时候，B作为中间柱子，C作为目标柱子，要移动A上的n个圆盘到C去 if(n == 1) { move(a, c, n); //无论a,b,c如何变换，通过递归，最后都会变成一个n = 1的问题，直接移动就完事了 } else{ hanoi(a, c ,b, n - 1); //首要目标是先把上面n-1个圆盘全部放到B去，这里就变换一下，让B作为目标柱子，C作为中间 move(a, c, n); //现在A上只剩下一个最大的圆盘了，接着把A最下方的一个圆盘移到C去 hanoi(b, a, c, n - 1); //最后需要把B上的全部搬到C上去，这里就可以以C为目标柱子，A为中间柱子 } } 简化一波： void hanoi(char a, char b, char c, int n){ if(n == 0) return; hanoi(a, c ,b, n - 1); printf(\"第%d个圆盘：%c --> %c\\n\", n, a, c); hanoi(b, a, c, n - 1); } 看似如此复杂的问题，其实只需要4行就可以解决了。 实战：快速排序算法（选学） 有一个数组： int arr[] = {4, 3, 8, 2, 1, 7, 5, 6, 9, 0}; 现在请你设计一个C语言程序，对数组按照从小到大的顺序进行排序。这里我们使用冒泡排序的进阶版本——快速排序来完成，它的核心思想是分而治之，每一轮排序都会选出一个基准，一轮排序完成后，所以比基准小的数一定在左边，比基准大的数一定在右边，在分别通过同样的方法对左右两边的数组进行排序，不断划分，最后完成整个数组的排序。它的效率相比冒泡排序的双重for循环有所提升。 #include void quickSort(int arr[], int left, int right){ //arr是数组，left是起始下标，right是结束下标 //请实现这一部分 } int main() { int arr[] = {4, 3, 8, 2, 1, 7, 5, 6, 9, 0}; quickSort(arr, 0, 9); //10个数字下标就是0-9 for (int i = 0; i 不过虽然这种排序算法很快，但是极端情况下（比如遇到了刚好倒序的数组）还是会退化成冒泡排序的。 指针 指针可以说是整个C语言中最难以理解的部分了，不过其实说简单也简单，你会发现也并没有想象中的那么难，你与它的距离可能只差了那么一些基础知识，这一部分都会及时进行补充的。 什么是指针 还记得我们在上一个部分谈到的通过函数交换两个变量的值吗？ #include void swap(int, int); int main() { int a = 10, b = 20; swap(a, b); printf(\"a = %d, b = %d\", a, b); //最后会得到什么结果？ } void swap(int a, int b){ int tmp = a; //这里对a和b的值进行交换 a = b; b = tmp; } 实际上这种写法是错误的，因为交换的并非是真正的a和b，而是函数中的局部变量。那么有没有办法能够直接对函数外部的变量进行操作呢？这就需要指针的帮助了。 我们知道，程序中使用的变量实际上都在内存中创建的，每个变量都会被保存在内存的某一个位置上（具体在哪个位置是由系统分配的），就像我们最终会在这个世界上的某个角落安家一样，所有的变量在对应的内存位置上都有一个地址（地址是独一无二的），而我们可以通过这个地址寻找到这个变量本体，比如int占据4字节，因此int类型变量的地址就是这4个字节的起始地址，后面32个bit位全部都是用于存放此变量的值的。 这里的0x是十六进制的表示形式（10-15用字母A - F表示）如果我们能够知道变量的内存地址，那么无论身在何处，都可以通过地址找到这个变量了。而指针的作用，就是专门用来保存这个内存地址的。 我们来看看如何创建一个指针变量用于保存变量的内存地址： #include int main(){ int a = 10; //指针类型需要与变量的类型相同，且后面需要添加一个*符号（注意这里不是乘法运算）表示是对于类型的指针 int * p = &a; //这里的&并不是进行按位与运算，而是取地址操作，也就是拿到变量a的地址 printf(\"a在内存中的地址为：%p\", p); //地址使用%p表示 } 可以看到，我们通过取地址操作&，将变量a的地址保存到了一个地址变量p中。 拿到指针之后，我们可以很轻松地获取指针所指地址上的值： #include int main(){ int a = 666; int * p = &a; printf(\"内存%p上存储的值为：%d\", p, *p); //我们可以在指针变量前添加一个*号（间接运算符，也可以叫做解引用运算符）来获取对应地址存储的值 } 注意这里访问指针所指向地址的值时，是根据类型来获取的，比如int类型占据4个字节，那么就读取地址后面4个字节的内容作为一个int值，如果指针是char类型的，那么就只读取地址后面1个字节作为char类型的值。 同样的，我们也可以直接像这样去修改对应地址存放的值： #include int main(){ int a = 666; int * p = &a; *p = 999; //通过*来访问对应地址的值，并通过赋值运算对其进行修改 printf(\"a的值为：%d\", a); } 实际上拿到一个变量的地址之后，我们完全不需要再使用这个变量，而是可以通过它的指针来对其进行各种修改。因此，现在我们想要实现对两个变量的值进行交换的函数就很简单了： #include // 这里是两个指针类型的形参，其值为实参传入的地址， // 虽然依然是值传递，但是这里传递的可是地址啊， // 只要知道地址改变量还不是轻轻松松？ void swap(int * a, int * b){ int tmp = *a; //先暂存一下变量a地址上的值 *a = *b; //将变量b地址上的值赋值给变量a对应的位置 *b = tmp; //最后将a的值赋值给b对应位置，OK，这样就成功交换两个变量的值了 } int main(){ int a = 10, b = 20; swap(&a, &b); //只需要把a和b的内存地址给过去就行了，这里取一下地址 printf(\"a = %d, b = %d\", a, b); } 通过地址操作，我们就轻松实现了使用函数交换两个变量的值了。 了解了指针的相关操作之后，我们再来看看scanf函数，实际上就很好理解了： #include int main(){ int a; scanf(\"%d\", &a); //这里就是取地址，我们需要告诉scanf函数变量的地址，这样它才能通过指针访问变量的内存地址，对我们变量的值进行修改，这也是为什么scanf里面的变量（除数组外）前面都要进行一个取地址操作 printf(\"%d\", a); } 当然，和变量一样，要是咱们不给指针变量赋初始值的话，就不知道指的哪里了，因为指针变量也是变量，存放的其他变量的地址值也在内存中保存，如果不给初始值，那么存放别人地址的这块内存可能在其他地方使用过，这样就不知道初始值是多少了（那么指向的地址可能是一个很危险的地址，随意使用可能导致会出现严重错误），所以一定要记得给个初始值或是将其设定为NULL，表示空指针，不指向任何内容。 #include int main(){ int * a = NULL; } 我们接着来看看const类型的指针，这种指针比较特殊： #include int main(){ int a = 9, b = 10; const int * p = &a; *p = 20; //这里直接报错，因为被const标记的指针，所指地址上的值不允许发生修改 p = &b; //但是指针指向的地址是可以发生改变的 } 我们再来看另一种情况： #include int main(){ int a = 9, b = 10; int * const p = &a; //const关键字被放在了类型后面 *p = 20; //允许修改所指地址上的值 p = &b; //但是不允许修改指针存储的地址值，其实就是反过来了。 } 当然也可以双管齐下： #include int main(){ int a = 9, b = 10; const int * const p = &a; *p = 20; //两个都直接报错，都不让改了 p = &b; } 指针与数组 前面我们介绍了指针的基本使用，我们来回顾一个问题，为什么数组可以以原身在函数之间进行传递呢？先说结论，数组表示法实际上是在变相地使用指针，你甚至可以将其理解为数组变量其实就是一个指针变量，它存放的就是数组中第一个元素的起始地址。 为什么这么说？ #include int main(){ char str[] = \"Hello World!\"; char * p = str; //？？？啥情况，为什么能直接把数组作为地址赋值给指针变量p？？？ printf(\"%c\", *p); //还能正常使用，打印出第一个字符？？？ } 你以为这就完了？还能这样玩呢： int main(){ char str[] = \"Hello World!\"; char * p = str; printf(\"%c\", p[1]); //？？？怎么像在使用数组一样用指针？？？ } 太迷了吧，怎么数组和指针还能这样混着用呢？我们先来看看数组在内存中是如何存放的： 数组在内存中是一块连续的空间，所以为什么声明数组一定要明确类型和大小，因为这一块连续的内存空间生成后就固定了。 而我们的数组变量实际上存放的就是首元素的地址，而实际上我们之前一直使用的都是数组表示法来操作数组，这样可以很方便地让我们对内存中的各个元素值进行操作： int main(){ char str[] = \"Hello World!\"; printf(\"%c\", str[0]); //直接在中括号中输入对应的下标就能访问对应位置上的数组了 } 而我们知道实际上str表示的就是数组的首地址，所以我们完全可以将其赋值给一个指针变量，因为指针变量也是存放的地址： char str[] = \"Hello World!\"; char * p = str; //直接把str代表的首元素地址给到p 而使用指针后，实际上我们可以使用另一种表示法来操作数组，这种表示法叫做指针表示法： int main(){ char str[] = \"Hello World!\"; char * p = str; printf(\"第一个元素值为：%c，第二个元素值为：%c\", *p, *(p+1)); //通过指针也可以表示对应位置上的值 } 比如我们现在需要表示数组中的第二个元素： 数组表示法：str[1] 指针表示法：*(p+1) 虽然写法不同，但是他们表示的意义是完全相同的，都代表了数组中的第二个元素，其中指针表示法使用了p+1的形式表示第二个元素，这里的+1操作并不是让地址+1，而是让地址+ 一倍的对应类型大小，也就是说地址后移一个char的长度，所以正好指向了第二个元素，然后通过*取到对应的值（注意这种操作仅对数组是有意义的，如果是普通的变量，虽然也可以通过这种方式获得后一个char的长度的数据，但是毫无意义） *(p+i) str[i] //实际上就是可以相互转换的 这两种表示法都可以对内存中存放的数组内容进行操作，只是写法不同罢了，所以你会看到数组和指针混用也就不奇怪了。了解了这些东西之后，我们来看看下面的各个表达式分别代表什么： *p //数组的第一个元素 p //数组的第一个元素的地址 p == str //肯定是真，因为都是数组首元素地址 *str //因为str就是首元素的地址，所以这里对地址加*就代表第一个元素，使用的是指针表示法 &str[0] //这里得到的实际上还是首元素的地址 *(p + 1) //代表第二个元素 p + 1 //第二个元素的内存地址 *p + 1 //注意*的优先级比+要高，所以这里代表的是首元素的值+1，得到字符'K' 所以不难理解，为什么printf函数的参数是一个const char *了，实际上就是需要我们传入一个字符串而已，只不过这里采用的是指针表示法而已。 当然指针也可以进行自增和自减操作，比如： #include int main(){ char str[] = \"Hello World!\"; char * p = str; p++; //自增后相当于指针指向了第二个元素的地址 printf(\"%c\", *p); //所以这里打印的就是第二个元素的值了 } 一维数组看完了，我们来看看二维数组，那么二维数组在内存中是如何表示的呢？ int arr[2][3] = { {1, 2, 3}, {4, 5, 6}}; 这是一个2x3的二维数组，其中存放了两个能够容纳三个元素的数组，在内存中，是这样的： 所以虽然我们可以使用二维数组的语法来访问这些元素，但其实我们也可以使用指针来进行访问： #include int main(){ int arr[][3] = { {1, 2, 3}, {4, 5, 6} }; int * p = arr[0]; //因为是二维数组，注意这里要指向第一个元素，来降一个维度才能正确给到指针 //同理如果这里是arr[1]的话那么就表示指向二维数组中第二个数组的首元素 printf(\"%d = %d\", *(p + 4), arr[1][1]); //实际上这两种访问形式都是一样的 } 多级指针 我们知道，实际上指针本身也是一个变量，它存放的是目标的地址，但是它本身作为一个变量，它也要将地址信息保存到内存中，所以，实际上当我们有指针之后： 实际上，我们我们还可以继续创建一个指向指针变量地址的指针，甚至可以创建更多级（比如指向指针的指针的指针）比如现在我们要创建一个指向指针的指针： 落实到咱们的代码中： #include int main(){ int a = 20; int * p = &a; //指向普通变量的指针 //因为现在要指向一个int *类型的变量，所以类型为int* 再加一个* int ** pp = &p; //指向指针的指针（二级指针） int *** ppp = &pp; //指向指针的指针的指针（三级指针） } 那么我们如何访问对应地址上的值呢？ #include int main(){ int a = 20; int * p = &a; int ** pp = &p; printf(\"p = %p, a = %d\", *pp, **pp); //使用一次*表示二级指针指向的指针变量，继续使用一次*会继续解析成指针变量所指的普通变量 } 本质其实就是一个套娃而已，只要把各个层次分清楚，实际上还是很好理解的。 特别提醒：一级指针可以操作一维数组，那么二级指针是否可以操作二维数组呢？不能！因为二级指针的含义都不一样了，它是表示指针的指针，而不是表示某个元素的指针了。下面我们会认识数组指针，准确的说它才更贴近于二维数组的形式。 指针数组与数组指针 前面我们了解了指针的一些基本操作，包括它与数组的一些关系。我们接着来看指针数组和数组指针，这两词语看着就容易搞混，不过哪个词在后面就哪个，我们先来看指针数组，虽然名字很像数组指针，但是它本质上是一个数组，不过这个数组是用于存放指针的数组。 #include int main(){ int a, b, c; int * arr[3] = {&a, &b, &c}; //可以看到，实际上本质还是数组，只不过存的都是地址 } 因为这个数组中全都是指针，比如现在我们想要访问数组中第一个指针指向的地址： #include int main(){ int a, b, c; int * arr[3] = {&a, &b, &c}; *arr[0] = 999; //[]运算符的优先级更高，所以这里先通过[0]取出地址，然后再使用*将值赋值到对应的地址上 printf(\"%d\", a); } 当然我们也可以用二级指针变量来得到指针数组的首元素地址： #include int main(){ int * p[3]; //因为数组内全是指针 int ** pp = p; //所以可以直接使用指向指针的指针来指向数组中的第一个指针元素 } 实际上指针数组还是很好理解的，那么数组指针呢？可以看到指针在后，说明本质是一个指针，不过这个指针比较特殊，它是一个指向数组的指针（注意它的目标是整个数组，和我们之前认识的指针不同，之前认识的指针是指向某种类型变量的指针） 比如： int * p; //指向int类型的指针 而数组指针则表示指向整个数组： int (*p)[3]; //注意这里需要将*p括起来，因为[]的优先级更高 注意它的目标是整个数组，而不是普通的指针那样指向的是数组的首个元素： int arr[3] = {111, 222, 333}; int (*p)[3] = &arr; //直接对整个数组再取一次地址（因为数组指针代表的是整个数组的地址，虽然和普通指针都是指向首元素地址，但是意义不同） 那么现在已经取到了指向整个数组的指针，该怎么去使用呢？ #include int main(){ int arr[3] = {111, 222, 333}; int (*p)[3] = &arr; //直接对整个数组再取一次地址 printf(\"%d, %d, %d\", *(*p+0), *(*p+1), *(*p+2)); //要获取数组中的每个元素，稍微有点麻烦 } 注意此时： p代表整个数组的地址 *p表示所指向数组中首元素的地址 *p+i表示所指向数组中第i个（0开始）元素的地址（实际上这里的*p就是指向首元素的指针） *(*p + i)就是取对应地址上的值了 虽然在处理一维数组上感觉有点麻烦，但是它同样也可以处理二维数组： int arr[][3] = { {111, 222, 333}, {444, 555, 666} }; int (*p)[3] = arr; //二维数组不需要再取地址了，因为现在维度提升，数组指针指向的是二维数组中的其中一个元素（因为元素本身就是一个数组） 比如现在我们想要访问第一个数组的第二个元素，根据上面p各种情况下的意义： printf(\"%d\", *(*p+1)); //因为上面直接指向的就是第一个数组，所以想要获取第一个元素和之前是一模一样的 那么要是我们现在想要获取第二个数组中的最后一个元素呢？ printf(\"%d\", *(*(p+1)+2); //首先*(p+1)为一个整体，表示第二个数组（因为是数组指针，所以这里+1一次性跳一个数组的长度），然后再到外层+2表示数组中的第三个元素，最后再取地址，就是第二个数组的第三个元素了 当然也可以使用数组表示法： printf(\"%d\", p[1][2]); //好家伙，这不就是二维数组的用法吗，没错，看似很难，你甚至可以认为这两用着是同一个东西 指针函数与函数指针 我们的函数可以返回一个指针类型的结果，这种函数我们就称为指针函数。 #include int * test(int * a){ //函数的返回值类型是int *指针类型的 return a; } int main(){ int a = 10; int * p = test(&a); //使用指针去接受函数的返回值 printf(\"%d\", *p); printf(\"%d\", *test(&a)); //当然也可以直接把间接运算符在函数调用前面表示直接对返回的地址取地址上的值 } 不过要注意指针函数不要尝试去返回一个局部变量的地址： #include int * test(int a){ int i = a; return &i; //返回局部变量i的地址 } int main(){ int * p = test(20); //连续调用两次test函数 test(30); printf(\"%d\", *p); //最后结果可能并不是我们想的那样 } 为什么会这样呢？还记得我们前面说的吗？函数一旦返回，那么其中的局部变量就会全部销毁了，至于这段内存之后又会被怎么去使用，我们也就不得而知了。 局部变量其实是存放在栈帧中的，如果前面的选学部分听了之后，你就知道为什么这里得到的是第二次的30了，因为第二次调用的栈帧入栈后就覆盖了这段内存，又因为是同一个函数所以栈帧结构是一样的，最后在同样的位置就存放了新的30这个值。 我们接着来看函数指针，实际上指针除了指向一个变量之外，也可以指向一个函数，当然函数指针本身还是一个指针，所以依然是用变量表示，但是它代表的是一个函数的地址（编译时系统会为函数代码分配一段存储空间，这段存储空间的首地址称为这个函数的地址） 我们来看看如何定义： #include int sum(int a, int b) { return a + b; } int main(){ //类型 (*指针变量名称)(函数参数...) //注意一定要把*和指针变量名称括起来，不然优先级不够 int (*p)(int, int) = sum; printf(\"%p\", p); } 这样我们就拿到了函数的地址，既然拿到函数的地址，那么我们就可以通过函数的指针调用这个函数了： #include int sum(int a, int b) { return a + b; } int main(){ int (*p)(int, int) = sum; int result = (*p)(1, 2); //就像我们正常使用函数那样，(*p)表示这个函数，后面依然是在小括号里面填上实参 int result = p(1, 2); //当然也可以直接写函数指针变量名称，效果一样（咋感觉就是给函数换了个名呢） printf(\"%d\", result); } 有了函数指针，我们就可以编写函数回调了（所谓回调就让别人去调用我们提供的函数，而不是我们主动来调别人的函数），比如现在我们定义了一个函数，不过这个函数需要参数通过一个处理的逻辑才能正常运行： int sum(int (*p)(int, int), int a, int b){ //将函数指针作为参数传入 //函数回调 return p(a, b); //就像你进了公司然后花钱请别人帮你写代码，工资咱们五五开，属于是直接让别人帮你实现 } 于是我们就还要给他一个其他函数的地址： #include int sum(int (*p)(int, int), int a, int b){ return p(a, b); } int sumImpl(int a, int b){ //这个函数实现了a + b return a + b; } int main(){ int (*p)(int, int) = sumImpl; //拿到实现那个函数的地址 printf(\"%d\", sum(p, 10, 20)); } 当然，函数指针也可以保存一组函数的地址，成为函数指针数组，但是这里就不多说了，相信各位已经快顶不住了吧。 实战：合并两个有序数组 来源：力扣 No.88 合并两个有序数组：https://leetcode.cn/problems/merge-sorted-array/ 给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。 请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。 注意：最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。 示例 1： 输入：nums1 = [1,2,3,0,0,0], m = 3, nums2 = [2,5,6], n = 3 输出：[1,2,2,3,5,6] 解释：需要合并 [1,2,3] 和 [2,5,6] 。 合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。 示例 2： 输入：nums1 = [1], m = 1, nums2 = [], n = 0 输出：[1] 解释：需要合并 [1] 和 [] 。 合并结果是 [1] 。 示例 3： 输入：nums1 = [0], m = 0, nums2 = [1], n = 1 输出：[1] 解释：需要合并的数组是 [] 和 [1] 。 合并结果是 [1] 。 注意，因为 m = 0 ，所以 nums1 中没有元素。nums1 中仅存的 0 仅仅是为了确保合并结果可以顺利存放到 nums1 中。 现在请你设计一个C语言程序，实现下面的函数（要求全程使用指针，不允许出现数组用法）： void merge(int* nums1, int nums1Size, int m, int* nums2, int nums2Size, int n){ } 实战：二维数组中的查找 来源：剑指Offer 04. 二维数组中的查找：https://leetcode.cn/problems/er-wei-shu-zu-zhong-de-cha-zhao-lcof/ 在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 示例: 现有矩阵 matrix 如下： [ [1, 4, 7, 11, 15], [2, 5, 8, 12, 19], [3, 6, 9, 16, 22], [10, 13, 14, 17, 24], [18, 21, 23, 26, 30] ] 给定 target = 5，返回 true。 给定 target = 20，返回 false。 现在请你设计一个C语言程序，实现下面的函数（要求全程使用指针，不允许出现数组用法）： /* * 输入 **matrix 是长度为 matrixSize 的数组指针的数组，其中每个元素（也是一个数组） * 的长度组成 *matrixColSize 数组作为另一输入，*matrixColSize 数组的长度也为 matrixSize */ bool findNumberIn2DArray(int** matrix, int matrixSize, int* matrixColSize, int target){ } 结构体、联合体和枚举 终于熬过了最难的一个部分，后面的内容就相对简单多了，我们接着来看结构体。 我们之前认识过很多种数据类型，包括整数、小数、字符、数组等，通过使用对应的数据类型，我们就可以很轻松地将我们的数据进行保存了，但是有些时候，这种简单类型很难去表示一些复杂结构。 创建和使用结构体 比如现在我们要保存100个学生的信息（学生信息包括学号、姓名、年龄）我们发现似乎找不到一种数据类型能够同时保存这三种数据（数组虽然能保存一些列的元素，但是只能保存同种类型的）。但是如果把它们拆开单独存在，就可以使用对应的类型存放了，不过这样也太不方便了吧，这些数据应该是捆绑在一起的，而不是单独地去存放。所以，为了解决这种问题，C语言提供了结构体类型，它能够将多种类型的数据集结到一起，让他们形成一个整体。 struct Student { //使用 (struct关键字 + 结构体类型名称) 来声明结构体类型，这种类型是我们自己创建的（同样也可以作为函数的参数、返回值之类的） int id; //结构体中可以包含多个不同类型的数据，这些数据共同组成了整个结构体类型（当然结构体内部也能包含结构体类型的变量） int age; char * name; //用户名可以用指针指向一个字符串，也可以用char数组来存，如果是指针的话，那么数据不会存在结构体中，只会存放字符串的地址，但是如果是数组的话，数据会存放在结构体中 }; int main() { struct Student { //也可以以局部形式存在 }; } 定义好结构体后，我们只需要使用结构体名称作为类型就可以创建一个结构体变量了： #include struct Student { int id; int age; char * name; }; int main() { //类型需要写为struct Student，后面就是变量名称 struct Student s = {1, 18, \"小明\"}; //结构体包含多种类型的数据（它们是一个整体），只需要把这些数据依次写好放在花括号里面就行了 } struct Student { int id; int age; char * name; } s; //也可以直接在花括号后面写上变量名称（多个用逗号隔开），声明一个全局变量 这样我们就创建好了一个结构体变量，而这个结构体表示的就是学号为1、年龄18、名称为小明的结构体数据了。 当然，结构体的初始化需要注意： struct Student s = {1, 18}; //如果只写一半，那么只会初始化其中一部分数据，剩余的内容相当于没有初始值，跟数组是一样的 struct Student s = {1, .name = \"小红\"}; //也可以指定去初始化哪一个属性 .变量名称 = 初始值 那么现在我们拿到结构体变量之后，怎么去访问结构体内部存储的各种数据呢？ printf(\"id = %d, age = %d, name = %s\", s.id, s.age, s.name); //结构体变量.数据名称 (这里.也是一种运算符) 就可以访问结构体中存放的对应的数据了 是不是很简单？当然我们也可以通过同样的方式对结构体中的数据进行修改： int main() { struct Student s = {1, 18, \"小明\"}; s.name = \"小红\"; s.age = 17; printf(\"id = %d, age = %d, name = %s\", s.id, s.age, s.name); } 那么结构体在内存中占据的大小是如何计算的呢？比如下面的这个结构体 struct Object { int a; short b; char c; }; 这里我们可以借助sizeof关键字来帮助我们计算： int main() { printf(\"int类型的大小是：%lu\", sizeof(int)); //sizeof能够计算数据在内存中所占据的空间大小（字节为单位） } 当然也可以计算变量的值占据的大小： int main() { int arr[10]; printf(\"int arr[10]占据的大小是：%lu\", sizeof (arr)); //在判断非类型时，sizeof 括号可省 } 同样的，它也能计算我们的结构体类型会占用多少的空间： #include struct Object { char a; int b; short c; }; int main() { printf(\"%lu\", sizeof(struct Object)); //直接填入struct Object作为类型 } 可以看到结果是8，那么，这个8字节是咋算出来的呢？ int（4字节）+ short（2字节）+ char（1字节） = 7字节（这咋看都算不出来12啊？） 实际上结构体的大小是遵循下面的规则来进行计算的： 结构体中的各个数据要求字节对齐，规则如下： 规则一：结构体中元素按照定义顺序依次置于内存中，但并不是紧密排列的。从结构体首地址开始依次将元素放入内存时，元素会被放置在其自身对齐大小的整数倍地址上（0默认是所有大小的整数倍） 规则二：如果结构体大小不是所有元素中最大对齐大小的整数倍，则结构体对齐到最大元素对齐大小的整数倍，填充空间放置到结构体末尾。 规则三：基本数据类型的对齐大小为其自身的大小，结构体数据类型的对齐大小为其元素中最大对齐大小元素的对齐大小。 这里我们以下面的为例： struct Object { char a; //char占据1个字节 int b; //int占据4个字节，因为前面存了一个char，按理说应该从第2个字节开始存放，但是根据规则一，必须在自己的整数倍位置上存放，所以2不是4的整数倍位置，这时离1最近的下一个整数倍地址就是4了，所以前面空3个字节的位置出来，然后再放置 short c; //前面存完int之后，就是从8开始了，刚好满足short（2字节）的整数倍，但是根据规则二，整个结构体大小必须是最大对齐大小的整数倍（这里最大对齐大小是int，所以是4），存完short之后，只有10个字节，所以屁股后面再补两个空字节，这样就可以了 }; 这样，就不难得出为什么结构体的大小是12了。 结构体数组和指针 前面我们介绍了结构体，现在我们可以将各种类型的数据全部安排到结构体中一起存放了。 不过仅仅只是使用结构体，还不够，我们可能需要保存很多个学生的信息，所以我们需要使用结构体类型的数组来进行保存： #include struct Student { int id; int age; char * name; }; int main() { struct Student arr[3] = { {1, 18, \"小明\"}, //声明一个结构体类型的数组，其实和基本类型声明数组是一样的 {2, 17, \"小红\"}, //多个结构体数据用逗号隔开 {3, 18, \"小刚\"} }; } 那么现在如果我们想要访问数组中第二个结构体的名称属性，该怎么做呢？ int main() { struct Student arr[3] = { {1, 18, \"小明\"}, {2, 17, \"小红\"}, {3, 18, \"小刚\"} }; printf(\"%s\", arr[1].name); //先通过arr[1]拿到第二个结构体，然后再通过同样的方式 .数据名称 就可以拿到对应的值了 } 当然，除了数组之外，我们可以创建一个指向结构体的指针。 int main() { struct Student student = {1, 18, \"小明\"}; struct Student * p = &student; //同样的，类型后面加上*就是一个结构体类型的指针了 } 我们拿到结构体类型的指针后，实际上指向的就是结构体对应的内存地址，和之前一样，我们也可以通过地址去访问结构体中的数据： int main() { struct Student student = {1, 18, \"小明\"}; struct Student * p = &student; printf(\"%s\", (*p).name); //由于.运算符优先级更高，所以需要先使用*p得到地址上的值，然后再去访问对应数据 } 不过这样写起来太累了，我们可以使用简便写法： printf(\"%s\", p->name); //使用 -> 运算符来快速将指针所指结构体的对应数据取出 我们来看看结构体作为参数在函数之间进行传递时会经历什么： void test(struct Student student){ student.age = 19; //我们对传入的结构体中的年龄进行修改 } int main() { struct Student student = {1, 18, \"小明\"}; test(student); printf(\"%d\", student.age); //最后会是修改后的值吗？ } 可以看到在其他函数中对结构体内容的修改并没有对外面的结构体生效，因此，实际上结构体也是值传递。我们修改的只是另一个函数中的局部变量而已。 所以如果我们需要再另一个函数中处理外部的结构体，需要传递指针： void test(struct Student * student){ //这里使用指针，那么现在就可以指向外部的结构体了 student->age = 19; //别忘了指针怎么访问结构体内部数据的 } int main() { struct Student student = {1, 18, \"小明\"}; test(&student); //传递结构体的地址过去 printf(\"%d\", student.age); } 当然一般情况下推荐传递结构体的指针，而不是直接进行值传递，因为如果结构体非常大的话，光是数据拷贝就需要花费很大的精力，并且某些情况下我们可能根本用不到结构体中的所有数据，所以完全没必要浪费空间，使用指针反而是一种更好的方式。 联合体 联合体也可以在内部定义很多种类型的变量，但是它与结构体不同的是，所以的变量共用同一个空间。？？？？啥意思？ union Object { //定义一个联合体类型唯一不同的就是前面的union了 int a; char b; float c; }; 我们来看看一个神奇的现象： #include union Object { int a; char b; float c; }; int main() { union Object object; object.a = 66; //先给a赋值66 printf(\"%d\", object.b); //访问b } ？？？？ 我修改的是a啊，怎么b也变成66了？这是因为它们共用了内存空间，实际上我们先将a修改为66，那么就将这段内存空间上的值修改为了66，因为内存空间共用，所以当读取b时，也会从这段内存空间中读取一个char长度的数据出来，所以得到的也是66。 int main() { union Object object; object.a = 128; printf(\"%d\", object.b); } 因为：128 = 10000000，所以用char读取后，由于第一位是符号位，于是就变成了-128。 那么联合体的大小又是如何决定的呢？ union Object { int a; char b; float c; }; int main() { printf(\"%lu\", sizeof(union Object)); } 实际上，联合体的大小至少是其内部最大类型的大小，这里是int所以就是4，当然，当最大成员大小不是最大对齐数的整数倍的时候，就要对齐到最大对齐数的整数倍。 当然联合体的其他使用基本与结构体差不多，这里就不提了。 枚举 最后我们来看一下枚举类型，枚举类型一般用于表示一些预设好的整数常量，比如我们风扇有低、中、高三个档位，我们总是希望别人使用我们预设好的这三个档位，而不希望使用其他的档位，因为我们风扇就只设计了这三个档位。 这时我们就可以告诉别人，我们的风扇有哪几个档位，这种情况使用枚举就非常适合。在我们的程序中，只能使用基本数据类型对这三种档位进行区分，这样显然可读性不够，别人怎么知道哪个代表哪个档位呢？而使用枚举就没有这些问题了： /** * 比如现在我们设计： * 1 = 低档位 * 2 = 中档位 * 3 = 高档位 */ enum status {low = 1, middle = 2, high = 3}; //enum 枚举类型名称 {枚举 = 初始值, 枚举...} 我们可以创建多个自定义名称的枚举，命名规则和变量差不多。我们可以当每一个枚举对应一个整数值，这样的话，我们就不需要去记忆每个数值代表的是什么档位了，我们可以直接根据枚举的名称来进行分辨，是不是很方便？ 使用枚举也非常地方便： enum status {low = 1, middle = 2, high = 3}; int main() { enum status a = low; //和之前一样，直接定义即可，类型为enum + 枚举名称，后面是变量名称，值可以直接写对应的枚举 printf(\"%d\", a); } int main() { enum status a = high; if(a == low) { //判断起来就方便多了 printf(\"低档位\"); } else if (a == high){ printf(\"高档位\"); } else { printf(\"中档位\"); } } 当然也可以直接加入到switch语句中： int main() { enum status a = high; switch (a) { case low: case high: case middle: default: ; } } 不过在枚举变量定义时需要注意： enum status {low, middle, high}; //如果不给初始值的话，那么会从第一个枚举开始，默认值为0，后续依次+1 所以这里的low就是0，middle就是1，high就是2了。 如果中途设定呢？ enum status {low, middle = 6, high}; //这里我们给middle设定为6 这时low由于是第一个，所以还是从0开始，不过middle这里已经指定为6了，所以紧跟着的high初始值就是middle的值+1了，因此low现在是0，middle就是6，high就是7了。 typedef关键字 这里最后还要提一下typedef关键字，这个关键字用于给指定的类型起别名。怎么个玩法呢？ typedef int lbwnb; //食用方式：typedef 类型名称 自定义类型别名 比如这里我们给int起了一个别名，那么现在我们不仅可以使用int来表示一个int整数，而且也可以使用别名作为类型名称了： #include typedef int lbwnb; int main() { lbwnb i = 666; //类型名称直接写成别名，实际上本质还是int printf(\"%d\", i); } typedef const char * String; //const char * 我们就起个名称为String表示字符串 int main() { String str = \"Hello World!\"; //是不是有Java那味了 printf(str); } 当然除了这种基本类型之外，包括指针、结构体、联合体、枚举等等都可以使用这个关键字来完全起别名操作： #include typedef struct test { int age; char name[10]; } Student; //为了方便可以直接写到后面，当然也可以像上面一样单独声明 int main() { Student student = {18, \"小明\"}; //直接使用别名，甚至struct关键字都不用加了 } 在数据结构的学习总，typedef使用会更加地频繁。 预处理 虽然我们的C语言学习已经快要接近尾声了，但是有一个东西迟迟还没有介绍，就是我们一直在写的： #include 这到底是个什么东西，为什么每次都要加上呢？这一部分，我们将详细讨论它缘由。 #include实际上是一种预处理指令，在我们的程序运行之前，会有一个叫做\"C预处理器\"的东西，根据我们程序中的预处理指令，预处理器能把对应的指令替换为指令想要表示的内容。我们先来看看#include做了什么。 文件包含 当预处理器发现#include指令时，会查看后面的文件名并把文件的内容包含到当前文件中，来替换掉#include指令。比如： int main() { printf(\"Hello World!\"); //一个很普通的printf打印函数 } 我们说了，这个函数是由系统为我们提供的函数，实际上这个函数实在其他源文件中定义好的，而定义这个函数的源文件，就是stdio.h，我们可以点进去看看： 除了printf之外，我们看到还有很多很多的函数原型定义，他们都写到这个源文件中，而这个文件并不是以.c结尾的，而是以.h结尾的，这种文件我们称为头文件。头文件一般仅包含定义一类的简单信息，只要能让编译器认识就行了。 而#include则是将这些头文件中提供的信息包含到我们的C语言源文件中，这样我们才能使用定义好的printf函数，如果我们不添加这个指令的话，那么会： 直接不认识了，printf是啥，好吃吗？说白了就是，我们如果不告诉编译器我们的这个函数是从哪来的，它怎么知道这个函数的具体定义什么是，程序又该怎么执行呢？ #include的具体使用格式如下： #include 当然也可以写成： #include \"文件名称\" 这两种写法虽然都能引入头文件，但是区别还是有的： 尖括号：引用的是编译器的库路径里面的头文件。 双引号：引用的是程序目录中相对路径中的头文件，如果找不到再去上面的库里面找。 可以看到系统已经为我们提供好了多种多样的头文件了，通过这些系统提供的库，我们就可以做很多的事情了。 当然我们也可以自己编写一个头文件，直接在项目根目录下创建一个新的C/C++头文件： // // Created by Nago Coler on 2023/6/26. // #ifndef UNTITLED_TEST_H #define UNTITLED_TEST_H #endif //UNTITLED_TEST_H 可以看到系统自动为我们生成好了这些内容，只不过现在还没学到（后面会介绍），现在直接删掉： int test(int a, int b); 我们直接在头文件中随便声明一个函数原型，接着我们就可以引入这个头文件了： #include #include \"test.h\" //因为是我们自己项目目录中的，所以需要使用双引号 int main() { int c = test(1, 2); //这样就可以使用头文件中声明的函数了 } 通过导入头文件，我们就可以使用定义好的各种内容了，当然，不仅仅局限于函数。 不过现在还没办法执行，因为我们这里只是引入了头文件中定义的函数原型，具体的函数实现我们一般还是使用.c源代码文件去进行编写，这里我们创建一个同名的C源文件（不强制要求同名，但是这样看着整齐一点）去实现一下： #include \"test.h\" //这里也需要把定义引入 int test(int a, int b) { //编写函数具体实现 return a + b; } 这样，我们再次运行程序就可以正确得到结果了： 实际上预处理器正是通过头文件得到编译代码时所需的一些信息，然后才能把我们程序需要的内容（比如这里要用到的test函数）替换到我们的源文件中，最后才能正确编译为可执行程序。 比如现在我们要做一个学生管理库，这个库中提供了学生结构体的定义，以及对学生信息相关操作： struct stu { //学生结构体定义 int id; int age; char name[20]; } typedef Student; void print(Student * student); //打印学生信息 void modifyAge(Student * student, int newAge); //修改年龄 void modifyId(Student * student, int newId); //修改学号 #include //函数具体实现源文件 #include \"student.h\" void print(Student * student) { printf(\"ID: %d, 姓名: %s, 年龄: %d岁\\n\", student->id, student->name, student->age); } void modifyAge(Student * student, int newAge) { student->age = newAge; } void modifyId(Student * student, int newId) { student->id = newId; } 最后我们就可以愉快地使用了： #include \"student.h\" int main() { Student student = {1, 18, \"小明\"}; modifyAge(&student, 19); print(&student); //打印 } 通过使用#include我们就可以将我们的项目拆分成多个模块去进行编写了。 系统库介绍 前面我们了解了如何使用#include引入其他文件，我们接着来了解一下系统为我们提供的一些常用库。实际上我们已经用过不少官方库提供的内容了： #include int main() { int a; scanf(\"%d\", &a); printf(\"%d\", a); getchar(); putchar('A'); ... } 包括前面我们在实战中用到了一次string.h中提供的计算字符串长度的函数： #include #include int main() { char * c = \"Hello World!\"; printf(\"%lu\", strlen(c)); //使用strlen计算长度，注意返回值类型是size_t（别名而已，本质上就是unsigned long） } 当然除了这个函数之外，实际上还有很多实用的字符串处理函数，都在这里定义了： #include #include int main() { char a[20] = \"Hello\",* b = \"World!\"; //现在有两个字符串，但是我们希望把他们拼接到一起 //注意不能这样写 char * a = \"Hello\",* b = \"World!\"; 如果直接用指针指向字符串常量，是无法进行拼接的，因为大小已经固定了 //这里需要两个参数，第一个是目标字符串，一会会将第二个参数的字符串拼接到第一个字符串中（注意要装得下才行） strcat(a, b); printf(\"%s\", a); } int main() { char str[10], * c = \"Hello\"; strcpy(str, c); //使用cpy会直接将后面的字符串拷贝到前面的字符串数组中（同样需要前面装得下才行） printf(\"%s\", str); } int main() { char * a = \"AAA\", * b = \"AAB\"; int value = strcmp(a, b); //strcmp会比较两个字符串，并返回结果 printf(\"%d\", value); } 这里需要说一下的比较规则：把字符串str1和str2从首字符开始逐个字符的进行比较，直到某个字符不相同或者其中一个字符串比较完毕才停止比较，字符的比较按照ASCII码的大小进行判断。 比较完成后，会返回不匹配的两个字符的ASCII码之差： 我们接着来看用于处理数学问题的相关库： #include 这里要用到math.h，它提供了我们场景的数学计算函数，比如求算术平方根、三角函数、对数等。 #include #include int main() { int a = 2; double d = sqrt(a); //使用sqrt可以求出非负数的算术平方根（底层采用牛顿逼近法计算） printf(\"%lf\", d); } 当然能够开根，也可以做乘方： int main() { int a = 2; double d = pow(a, 3); //使用pow可以快速计算乘方，这里求的是a的3次方 printf(\"%lf\", d); } 有了这个函数，写个水仙花数更简单了： int main() { for (int i = 0; i 当然也可以计算三角函数： int main() { printf(\"%f\", tan(M_PI)); //这里我们使用正切函数计算tan180度的值，注意要填入的是弧度值 //M_PI也是预先定义好的π的值，非常精确 } 当然某些没有不存在的数可能算出来会得到一个比较奇怪的结果： int main() { printf(\"%f\", tan(M_PI / 2)); //这里计算tan90°，我们知道tan90° = sin90°/cos90° = 1/0 不存在 } 当然还有两个比较常用的函数： int main() { double x = 3.14; printf(\"不小于x的最小整数：%f\\n\", ceil(x)); printf(\"不大于x的最大整数：%f\\n\", floor(x)); } 当然也有快速求绝对值的函数： int main() { double x = -3.14; printf(\"x的绝对值是：%f\", fabs(x)); } 我们最后再来介绍一下通用工具库stdlib，这个库里面为我们提供了大量的工具函数： #include #include int main() { int arr[] = {5, 2, 4, 0, 7, 3, 8, 1, 9, 6}; //工具库已经为我们提供好了快速排序的实现函数，直接用就完事 //参数有点多，第一个是待排序数组，第二个是待排序的数量（一开始就是数组长度），第三个是元素大小，第四个是排序规则（我们提供函数实现） qsort(); } 当然在开始使用之前我们还要先补充一点知识，我们发现qsort的原型定义，使用的是void类型的指针。 怎么void还有指针呢？void不是空吗？ void 指针是一种特殊的指针，表示为“无类型指针”，由于 void 指针没有特定的类型，因此它可以指向任何类型的数据。也就是说，任何类型的指针都可以直接赋值给 void 指针，而无需进行其他相关的强制类型转换。 所以这里之所以需要void指针，其实就是为了可以填入任何类型的数组，而我们发现第三个参数实际上就是因为是void指针不知道具体给进来的类型是什么，所以需要我们来告诉函数我们使用的类型所占大小是多少。 而最后一个参数实际上就是我们前面介绍的函数回调了，因为函数不知道你的比较规则是什么，是从小到大还是从大到小呢？所以我们需要编写一个函数来对两个待比较的元素进行大小判断。 好了，现在了解了之后，我们就可以开始填入参数了： #include #include int compare(const void * a, const void * b) { //参数为两个待比较的元素，返回值负数表示a比b小，正数表示a比b大，0表示相等 int * x = (int *) a, * y = (int *) b; //这里因为判断的是int所以需要先强制类型转换为int *指针 return *x - *y; //其实直接返回a - b就完事了，因为如果a比b大的话算出来一定是正数，反之同理 } int main() { int arr[] = {5, 2, 4, 0, 7, 3, 8, 1, 9, 6}; //工具库已经为我们提供好了快速排序的实现函数，直接用就完事 //参数有点多，第一个是待排序数组，第二个是待排序的数量（一开始就是数组长度），第三个是元素大小，第四个是排序规则（我们提供函数实现） qsort(arr, 10, sizeof(int), compare); for (int i = 0; i 这样，我们就可以对数组进行快速排序了。 当然工具库中还提供了exit函数用于终止程序： #include int main() { exit(EXIT_SUCCESS); //直接终止程序，其中参数是传递给父进程的（但是现在我们只是简单程序） } 不过乍一看，貌似和我直接在main里面return没啥区别，反正都会结束。 当然还有两个我们会在后续学习数据结构中用的较多的函数： int main() { int * p = (int *) malloc(sizeof(int)); //我们可以使用malloc函数来动态申请一段内存空间 //申请后会返回申请到的内存空间的首地址 *p = 128; printf(\"%d\", *p); } malloc用于向系统申请分配指定size个字节的内存空间，返回类型是 void * 类型，如果申请成功返回首地址，如果失败返回NULL空地址（比如系统内存不足了就可能会申请失败） 申请到一段内存空间后，这段内存空间我们就可以往上面随便读写数据了，实际上就是和变量一样，只不过这个内存空间是我们自主申请的，并不是通过创建变量得到的，但是使用上其实没啥大的区别。 不过要注意，这段内存使用完之后记得清理，就像函数执行完会自动销毁其中的局部变量一样，如果不清理那么这段内存会被一直占用： int main() { int * p = (int *)malloc(sizeof(int)); *p = 128; printf(\"%d\", *p); free(p); //使用free函数对内存空间进行释放，归还给系统，这样这段内存又可以被系统分配给别人用了 p = NULL; //指针也不能再指向那个地址了，因为它已经被释放了 } 内存资源是很宝贵的（不像硬盘几个T随便用，我们的电脑可能32G的内存都算高配了），不能随便浪费，所以一般情况下malloc和free都是一一对应的，这样才能安全合理地使用内存。 宏定义 我们前面认识了#include指令，我们接着来看#define指令，它可以实现宏定义。我语文不好，宏是啥意思？ 把参数批量替换到文本中，这种实现通常称为宏（macro）或定义宏 (define macro) 我们可以通过#define来定义宏，规则如下： #define 宏名(记号) 内容 比如现在我们想通过宏定义一个PI： #define PI 3.1415926 这样就可以了，那么怎么去使用它呢？ #include #define PI 3.1415926 int main() { printf(\"π的值为：%f\", PI); //就像使用变量一样，我们可以直接将PI放到这个位置 } 在编译时，预处理程序会进行宏替换操作，也就是将程序中所有的PI全部替换为3.1415926，注意这个跟类型无关，是赤裸裸的纯文本替换，也就是相当于把我们的代码修改了，PI那里直接变成3.1415926，当然如果你定义为其他任意的内容，同样会替换到那个位置，但是至于替换之后程序还正不正常就不知道了。 我们通过下面这个例子来加深对文本替换这句话的理解： #include #define M a + b int main() { int a = 10, b = 20; printf(\"%d\", M * a); //各位觉得计算结果会是多少呢？ } 如果按照我们的正常思维，M是a+b，那么替换上去之后应该就是30了吧？然后30 x 10最后得到的应该是300才对。 不过最后貌似并不是这样的，怎么会算出来是210的呢？ 实际上还是那句话，在编译时仅仅是做了文本替换，相当于最后我们的代码是： printf(\"%d\", a + b * a); 所以先计算的是a x b然后再加a，最后结果就是210了。 当然任何地方都可以使用宏替换，包括类型，反正最后都会变成被替换的内容： #define lbwnb long int main() { lbwnb a = 10L; } 当然除了这种简单的替换之外我们还可以添加参数，就像函数那样： #include #define MUL(x) x * x int main() { printf(\"%d\", MUL(9)); } 虽然这里搞得像函数一样，但是最后还是会被替换为x x，而这个x就是我们填写的参数，所以最后会变成 9 9 替换上去，程序运行出来的结果就是81了。 直接调函数肯定也是没问题的，反正就纯替换： #include #define bb(i) printf(\"我是宏替换的：%d\", i); int main() { bb(666); } 那要是我想在字符串里面加一个宏定义中的参数呢？ #include #define bb(str) printf(\"我是宏替换的：\"#str\" 当然还可以替换宏中的部分： #define TEST(n) x ##n //##会使用参数进行拼接 int main() { int TEST(1) = 10; //这里传入1，那么实际上就是被替换为x1 x1 = 20; //所以上面其实是int x1 = 10 } 宏既然可以定义出来，那么也可以取消定义，我们可以使用#undef来取消已有的宏定义： 可以看到在使用#undef之后，直接不认识了。 当然除了我们自己可以去定义之外，系统也为我们提供了一些预定义的宏： 宏名称 含义 DATE 当前的日期，格式为类似 Jun 27 2023 的字符串 TIME 当前的时间，格式为类似 10:23:12 的字符串 FILE 当前源代码文件的名称（含路径）的字符串 LINE 当前所处的行号是多少就替换为多少，整数 这里只列出了一部分。 条件编译 我们来看看条件编译，我们还可以根据条件，选择性地对某些内容进行忽略。 收我们我们来认识一下#ifdef、#else、#endif这三种条件编译指令： #include #ifdef PI //ifdef用于判断是否定义了符号PI，如果没有的话则处理以下的指令 #define M 666 #else //如果定义了符号PI，那么就处理这个分支的语句 #define M 777 #endif //最后需要以endif指令结束整个判断 int main() { printf(\"%d\", M); //最后打印M } 可以看到，在我们没有定义PI的情况下，执行的是#define M 777，那要是现在定义了呢？我们编写一个新的头文件： #define PI 3.1415 现在我们引入这个头文件，那么对应的预编译指令也会跟着包含进来： #include #include \"test.h\" #ifdef PI #define M 666 #else #define M 777 #endif int main() { printf(\"%d\", M); } 可以看到此时得到的结果就是666了，因为现在PI在引入的头文件中已经定义了（当然直接在当前源文件中定义也是一样的） 那如果我现在希望判断某个符号没定义呢？没错，还有#ifndef表示判断是否未定义某个符号： #include #ifndef PI //ifndef 就是 if not define，跟ifdef反着的 #define M 666 #else #define M 777 #endif int main() { printf(\"%d\", M); } 当然，除了判断某个符号是否存在之外，我们也可以像条件语句那样直接进行逻辑判断，这里需要使用到#if和#elif指令： #define M 666 #if M == 666 //若M等于666那么定义K = 999 #define K 999 #elif M == 777 //等同于else if语句 #define K 888 #else //else语句 #define K 000 #endif 并且这些分支还支持嵌套使用： #define M 666 #if M == 666 #ifdef L #include \"test.h\" #endif #elif M == 777 #define K = 888 #else #define K = 000 #endif 文件输入/输出（选学） 注意：本小节作为选学内容，不强制要求。 我们的电脑上其实存放了多种多样的文件，比如我们办公经常需要打交道的Word文档、PPT幻灯片、Excel表格等，包括我们的C程序源文件，图片、视频等等，这些都是文件，由于文件需要被长期保存，所以它们被统一存放到我们电脑上的硬盘中。硬盘不像内存，虽然它们都可以存放数据，但是内存中的数据断电即失（在学习完数字电路中的锁存器后，你就知道为什么了）而硬盘却支持长期保存数据，当然也是以二进制的形式进行保存的。 文本读写操作 现代计算机使用的硬盘大致分为固态硬盘和机械硬盘两种，其中固态硬盘的读写速度远超机械硬盘，但是寿命（硬盘是有读写次数限制的，如果读写次数超标，那么就无法使用了）不如机械硬盘，所以一般重要数据都是在机械硬盘中存放，而系统文件一般是在固态硬盘中存放，这样电脑的启动速度会很快。 不过文件并不是随便在硬盘中进行保存的，而是根据不同的文件系统按规则进行存放的，比如Windows下采用的就是NTFS文件系统，而MacOS采用的是APFS文件系统。 文件系统是操作系统用于明确存储设备（常见的是磁盘，也有基于NAND Flash的固态硬盘）或分区上的文件的方法和数据结构；即在存储设备上组织文件的方法。 其中某些文件是以文本格式存储的，比如我们的C语言源文件、普通的文本文档等；而有些文件是二进制格式，比如图片、视频、应用程序等，但是他们最终都是以二进制的形式存储到硬盘上的。当然，普通的文本文件我们直接打开记事本都可以直接进行编辑，而图片这类二进制文件，需要使用专门读取图片的软件来查看，根据格式的不同（图片有png、jpg等格式）对文件的解读方式也不一样，但是最后都会被专门的图片查看软件展示出来。 通过使用C语言，我们也可以读取硬盘上的文件，这里我们先创建一个简单的文本文件： 接着我们可以使用stdio.h中为我们提供的函数打开一个文件： #include int main() { FILE * file = fopen(\"hello.txt\", \"rw\"); //使用fopen函数来打开一个文件 } 这里我们先来介绍一下参数： 第一个参数：文件的名称，这里我填写的是相对路径，也可以写成绝对路径 第二个参数：打开文件的模式，其中模式有以下这些： 模式字符串 含义 “r” 以读模式打开文件 “w” 以写模式打开文件，把现有文件的长度截为0，如果文件不存在，则创建一个新文件 “a” 以写模式打开文件，在现有文件末尾添加内容，如果文件不存在，则创建一个新文件 “r+” 以更新模式打开文件（即可以读写文件）该文件必须存在 “w+” 以更新模式打开文件（即可以读写文件），如果文件存在，则将其长度截为0；如果文件不存在，则创建一个新文件 “a+” 以更新模式打开文件（即，读写），在现有文件的末尾添加内容，如果文件不存在则创建一个新文件；可以读整个文件，但是只能从末尾添加内容 “rb”,“wb”,“ab”,“ab+”,“a+b”,“wb+”,“w+b” 与“a+”模式类似，但是以二进制模式打开文件而不是以文本模式打开文件 具体的不同打开模式会影响到后续的操作，我们后面再说。这里我们使用r表示可读。 然后这个函数返回的是一个FILE结构体指针： typedef struct __sFILE { unsigned char *_p; /* current position in (some) buffer */ int _r; /* read space left for getc() */ ... } FILE; 定义非常复杂，这里我们就不详细介绍了，这样我们就成功打开了这个文件，那么如何对文件进行读取操作呢？ 我们可以使用getc来快速读取文件中的字符： #include int main() { FILE * file = fopen(\"hello.txt\", \"r\"); int c; while ((c = getc(file)) != EOF) { //通过一个while循环来不断读取文件，使用getc从文件中读取一个字符，如果到末尾了，那么会返回一个特殊值EOF putchar(c); //使用putchar来快速打印字符到控制台 } } 可以看到成功输出： 当然如果没有这个文件或是文件打开失败的话，可能会返回一个空指针，所以我们需要进一步判断： #include int main() { FILE * file = fopen(\"hello.txt\", \"r\"); if(file != NULL) { //如果打开失败会返回NULL int c; while ((c = getc(file)) != EOF) { putchar(c); } } else{ puts(\"文件打开失败！\"); } } 最后我们在使用完文件后，记得关闭文件来释放资源，不然一直会被占用： fclose(file); //fclose用于关闭文件 那么读取文件我们知道了，写入呢？写入我们同样可以使用putc来完成： #include int main() { FILE * file = fopen(\"hello.txt\", \"w\"); //注意这里需要修改为写模式 if(file != NULL) { for (int i = 0; i 可以看到最后我们的文件变成了： 原来的文本被覆盖为了我们输入的新文本，那要是我们现在不想覆盖原来的，而是希望在后面追加输入呢？ FILE * file = fopen(\"hello.txt\", \"a\"); //我们可以将其修改为a表示append追加输入 这样就不会覆盖原有内容而是追加填写了： 不过这里要补充一下，文件的读写实际上并不是直接对文件进行操作的，在这之间还有一个缓冲区： 我们所有的读操作，首先是从文件读取到缓冲区中，再从缓冲区中读取到程序中的；写操作就是先写入到缓冲区，然后再从缓冲区中写入到文件中。这样做的目的是，因为内存和硬盘的速度差距有点大，为了解决这种速度差异导致的性能问题，所以设定一个缓冲区，这样就算速度不一样，但是内容被放在缓冲区中慢慢消化就没问题了。 虽然缓冲区能够解决这些问题，但是也会带来一些不便之处，比如下面的例子： #include int main() { FILE * file = fopen(\"hello.txt\", \"a+\"); //注意这里需要修改为写模式 if(file != NULL) { while (1) { int c = getchar(); //不断从控制台读取字符 if(c == 'q') break; putc(c, file); //写入到文件中 } fclose(file); } } 我们发现当我们敲了一个字符之后，可能并不会马上更新到文件中，这就是由于缓冲区没有及时同步到文件中，所以我们需要调用一个函数来刷新缓冲区，将那些缓冲区的没有同步的数据全部同步到文件中： #include int main() { FILE * file = fopen(\"hello.txt\", \"a+\"); if(file != NULL) { while (1) { int c = getchar(); if(c == 'q') break; putc(c, file); fflush(file); //使用fflush来刷新缓冲区 } fclose(file); } } 这样我们就可以看到输入一个字符马上就能同步更新了。当然我们也可以手动设定缓冲区的大小： char buf[3]; setvbuf(file, buf, _IOFBF, 3); 其中： _IONBF：表示不使用缓冲区 _IOFBF：表示只有缓冲区填满了才会更新到文件 _IOLBF：表示遇到换行就更新到文件 除了使用getc之外，标准库中还提供了fprintf和fgets系列函数： #include int main() { FILE * file = fopen(\"hello.txt\", \"a+\"); if(file != NULL) { fprintf(file, \"树脂%d\", 666); //fprintf就像普通的打印一样，但是它并不是打印到控制台，而是文件中 fclose(file); } } #include int main() { FILE * file = fopen(\"hello.txt\", \"w\"); if(file != NULL) { fputs(\"小黑子苏珊\", file); //就像使用puts一样，同样是输出到文件中 fclose(file); } } 这样，对于文本文件的基础读写操作就讲解到这里。 随机访问 前面我们介绍了文本文件的基础读写操作，我们接着来看随机访问。首先什么是随机访问？ 我们在前面读取文件时，实际上是按照顺序，每次读取都会往后移动一个字符继续读取，那么如果现在我希望直接跳到某个位置进行读取是否可以实现呢？ 我们可以使用fseek来跳转到指定位置： #include int main() { FILE * file = fopen(\"hello.txt\", \"r\"); if(file != NULL) { fseek(file, -2L, SEEK_SET); //第二个参数为偏移量，根据后面的参数而定 putchar(getc(file)); fclose(file); } } 这里介绍一下起始点： SEEK_SET：从文件开始处开始 SEEK_CUR：从当前位置开始（就是已经读到哪个位置就是哪个位置） SEEK_END：从文件末尾开始 而上面的使用的是SEEK_SET，那么就是从文件开始，往后偏移2个字符的位置，也就是字符l。 那么我们怎么知道当前已经读取到文件第几个字符了呢？ #include int main() { FILE * file = fopen(\"hello.txt\", \"r\"); if(file != NULL) { fseek(file, 2L, SEEK_SET); printf(\"%ld\", ftell(file)); //可以使用ftell来直接返回当前位置，返回类型为long fclose(file); } } 当然除了fseek和ftell之外，还有fgetpos和fsetpos这两个函数，它们也可以获取位置和设定位置： #include int main() { FILE * file = fopen(\"hello.txt\", \"r\"); if(file != NULL) { fpos_t pos; //位置需要使用fpos_t进行存储（主要用于处理大文件） fgetpos(file, &pos); //获取位置，并设定给pos，此时位置为0 fseek(file, -2L, SEEK_END); //通过fseek移动到倒数第二个位置 fsetpos(file, &pos); //设定位置为pos位置 printf(\"%ld\", ftell(file)); //最后得到的就是经过fsetpos设定的新位置了 fclose(file); } } 了解了这些函数，这样我们就可以实现对文件的随机读写了。 前面我都是对文本文件进行操作，我们接着来看如何直接读写二进制文件，比如现在我们想要复制一个文件： #include int main() { FILE * file = fopen(\"hello.txt\", \"r\"); FILE * target = fopen(\"hello2.txt\", \"w\"); if(file != NULL) { char buf[1024]; //这里我们使用char类型的数组作为暂存 size_t s; while ((s = fread(buf, sizeof(char), 1024, file)) > 0) { //使用fread函数进行读取，每次都会从文件中读取指定大小的数据到暂存数组中，返回值为实际读取的值，如果读取的值小于0表示读完了 fwrite(buf, sizeof(char), s, target); //使用fwrite将数据写入到指定文件中 } fclose(file); } } 可以看到我们成功将hello.txt中的内容复制到另一个文本文件中了。当然我们也可以用来拷贝大型文件： #include int main() { FILE * file = fopen(\"22000.318.211104-1236.co_release_svc_refresh_CLIENTCONSUMER_RET_A64FRE_zh-cn.iso\", \"r\"); FILE * target = fopen(\"22000.318.211104-1236.co_release_svc_refresh_CLIENTCONSUMER_RET_A64FRE_zh-cn-2.iso\", \"w\"); if(file != NULL) { //计算文件的大小 fseek(file, 0L, SEEK_END); long size = ftell(file); fseek(file, 0L, SEEK_SET); char buf[1024 * 1024]; size_t s, all = 0; while ((s = fread(buf, sizeof(char), 1024, file)) > 0) { fwrite(buf, sizeof(char), s, target); all += s; printf(\"当前进度 %.1f%%\\n\", (double) all / (double) size * 100); } fclose(file); } } 是不是感觉有内味了： 这样我们就实现了文件的拷贝。 程序编译和调试（选学） 注意：本小节作为选学内容，不强制要求。 有关C语言语言层面的教学基本就结束了，最后让我们来了解一下如何不借助IDE，通过最原始的方式手动完成程序的编译。 C语言程序的编译 在开始之前，我们需要介绍一个编译器： GCC原名为GNU C语言编译器（GNU C Compiler），只能处理C语言。但其很快扩展，变得可处理C++，后来又扩展为能够支持更多编程语言，如Fortran、Pascal、Objective -C、Java、Ada、Go以及各类处理器架构上的汇编语言等，所以改名GNU编译器套件（GNU Compiler Collection） 那么gcc编译器是如何将我们的程序一步步编译为可执行文件的呢？ 预处理（Pre-Processing）：首先会经过预处理器将程序中的预编译指令进行处理，然后把源文件中的注释这些没用的东西都给扬了。 编译（Compiling）：处理好之后，就可以正式开始编译，首先会编译为汇编代码。 汇编（Assembling）：接着就该将汇编代码编译为机器可以执行的二进制机器指令了，会得到一个二进制目标文件。 链接（Linking）：最后需要将这个二进制目标文件与系统库和其他库的OBJ文件、库文件链接起来，最终生成了可以在特定平台运行的可执行文件。 比如在Windows操作系统下完成这四步，就会生成一个Windows的.exe可执行文件。 我们来一步一步尝试一下，首先我们把CLion自带的GCC工具目录配置到环境变量中（Mac系统直接自带，不需要任何配置）： 位置在你的CLion安装目录/bin/mingw/bin，打开高级系统设置，添加环境变量： 配置完成后，打开CLion，我们随便编写一点内容： #include int main() { printf(\"Hello, World!\\n\"); return 0; } 然后我们点击IDE下方的终端面板： 可以看到这里打开的是Windows自带的PowerShell终端，如果不是的可以在设置中修改： 现在我们就可以手动开始对我们的C源文件进行编译了，首先是第一步，我们需要对源文件进行预处理： gcc -E main.c -o main.i 其中 -E 后面的是我们的源文件名称，-o 是我们预处理后生成的文件名称： 生成后，我们可以直接查看这个文件（因为此时依然是普通文本）可以看到，我们的代码在经过预处理之后，#include 中的内容都替换过来了。最下面大约1000行左右的位置就是我们的代码了： 现在我们已经完成了预处理，接着就可以将其编译为汇编程序了： gcc -S main.i -o main.s 这里的-S就是预处理之后的文件，我们可以直接将其编译为汇编代码： 可以看到这里都是汇编代码，各种各样的汇编指令。接着我们就可以将这个汇编代码继续编译为二进制文件了： gcc -c main.s -o main.o 这里-c后的就是我们的汇编程序，直接生成为二进制文件： 不过现在我们还没办法直接运行它，因为还需要进一步链接，变成Windows操作系统可以执行的程序： gcc main.o -o main 这里直接将刚刚生成的目标文件编译为可执行文件，我们就可以直接运行了： 成功生成.exe文件，我们直接在控制台输入它的名字就可以运行了： 这样我们就实现了手动编译一个C语言程序。当然如果我们要更快速一点地完成编译，可以直接将源文件进行编译： gcc main.c -o main 当然这种只是简单的单源文件下的编译，要是遇到多文件的情况下呢？ void swap(int * a, int * b); #include \"test.h\" void swap(int * a, int * b) { int tmp = *a; *a = *b; *b = tmp; } #include #include \"test.h\" int main() { int arr[] = {4, 2, 1, 9, 5, 0, 3, 8, 7, 6}; for (int i = 0; i arr[j + 1]) swap(&arr[j], &arr[j + 1]); } } for (int i = 0; i 我们还是按照刚刚的方式直接进行编译： 可以看到，编译错误，无法识别到swap这个函数，说明肯定还需要把引入的其他文件也给一起带上，所以： gcc main.c test.c -o main 或是将两个文件单独编译为对应的二进制文件，最后再放到一起编译也是可以的： gcc main.o test.o -o main OK，现在多个文件就可以在一起编译了，最后同样生成了一个可执行文件： 使用Make和CMake进行构建 我们的项目可能会有很多很多的内容需要去进行编译，如何去进行组织成了一个大问题，比如让谁先编译，谁后编译，这时，我们就需要一个构建工具来帮助我们对程序的构建流程进行组织。 Make是最常用的构建工具，诞生于1977年，主要用于C语言的项目。但是实际上 ，任何只要某个文件有变化，就要重新构建的项目，都可以用Make构建。 要使用Make对我们的项目进行构建，我们需要先告诉Make我们的程序应该如何去进行构建，这时我们就要编写一下Makefile了： 我们只需要把需要执行的命令按照我们想要的顺序全部写到里面就可以了，但是需要遵循以下格式： targets : prerequisites command 一个Makefile中可以有很多个目标，比如我们现在要分别编译main.c和test.c，那么就需要创建两个目标： targets：构建的目标，可以是一个普通的标签、文件名称等 prerequisites：前置条件，可以设定要求完成其他目标才能开始构建当前目标 command：构建需要执行的命令 比如现在我们想要分别先编译test.c和main.c，最后将他们变成一个可执行文件，那么makefile可以这样编写： main.exe: test.o main.o #目标1：构建最终的程序，要求完成下面两个目标（注意最终目标需要写在第一个） gcc test.o main.o -o main main.o: main.c #目标2：构建目标为main.o，前置要求必须有main.c文件 gcc -E main.c -o main.i gcc -S main.i -o main.s gcc -c main.s -o main.o test.o: test.c #目标3：同样的，要求必须有test.c文件才能开始 gcc -E test.c -o test.i gcc -S test.i -o test.s gcc -c test.s -o test.o 接着我们只需要在控制台输入make命令（CLion自带环境需要输入mingw32-make命令，Mac下直接输入make）就可以进行编译了： 命令执行的每一步都会详细打印出来，我们可以看到构建确实是按照我们的顺序在进行，并且成功编译出最终目标： 当然，如果我们没有做任何的修改，那么再次执行make命令不会做任何事情： 但是如果我们修改一下源文件的话，执行make将会重新构建目标： 再次执行： 通过使用Make，即使没有如此高级的IDE，哪怕我们纯靠记事本写C代码，都可以很方便地完成对一个项目的构建了。当然这只是Make的简单使用，它还支持使用变量、逻辑判断等高级玩法，这里我们就不多做介绍了。 虽然使用Make可以很方便地对项目构建流程进行配置，但是貌似CLion并没有采用这种方式来组织我们的项目进行构建，而是使用了CMake，我们来看看它又是做什么的。 CMake是一个跨平台的安装（编译）工具，可以用简单的语句来描述所有平台的安装(编译过程)。他能够输出各种各样的makefile或者project文件，能测试编译器所支持的C++特性,类似UNIX下的automake。 简而言之， CMake是一个跨平台的Makefile生成工具! 实际上当我们创建一个项目后，CLion会自动为我们配置CMake，而具体的配置都是写在CMakeList.txt中的： cmake_minimum_required(VERSION 3.22) project(untitled C) set(CMAKE_C_STANDARD 99) add_executable(untitled main.c test.c test.h) 我们逐行来进行解读： 第一行使用cmake_minimum_required来指定当前项目使用的CMake最低版本，如果使用的CMake程序低于此版本是无法构建的。 第二行project指定项目名称，名称随意，后面的是项目使用的语言，这里是C。 第三行set用于设定一些环境变量等，这里设定的是C 99标准。 第四行add_executable用于指定一个编译出来的可执行文件，这里名称为untitled，后面的都是需要编译的源文件（头文件可以不写） 当然除了这些语法之外，还有各种各样的设定，比如设定库目录或是外部动态连接库等，这里就不多说了，感兴趣的可以自行了解。 这里我们来手动执行一下cmake： 首先还是添加环境变量，添加完成后重启CLion，我们输入cmake命令进行生成： cmake -S . -B test -G \"MinGW Makefiles\" 其中-S后面的是源文件目录，这里.表示当前目录，-B后面是构建目录，一会构建的文件都在这里面存放，最后-G是选择生成器（生成器有很多，甚至可以直接生成一个VS项目，我们可以直接使用Visual Studio打开），这里我们需要生成Makefile，所以填写\"MinGW Makefiles\"： 可以看到已经成功在我们的构建目录中生成了： 只不过它这个自动生成的Makefile写的就比较复杂了，我们也不需要去关心，接着我们像之前一样直接使用make就可以编译了： 这里要先进入一下test目录，使用cd test命令修改当前工作目录： 可以看到它生成的Makefile还是挺高级的，还能输出进度，现在我们的程序就构建好了，直接启动把： 当然CLion并没有使用Makefile的编译方式，而是Ninja，并且生成的构建文件默认存放在cmake-build-debug中，跟make比较类似，但是速度会更快一些，不过最后都会成功构建出我们的可执行程序。 这下，我们就清楚整个项目中个个文件是干嘛的了。 使用LLDB调试工具 最后我们来说一下LLDB调试工具（与之类似的还有GDB），首先还是配置一下环境变量： LLDB调试工具用于对我们的程序进行逐步调试使用，实际上我们之前也使用调试，只不过是在IDE中的图形化界面中操作的，那么如果没有IDE呢，我们可以使用LLDB调试工具来进行调试： lldb .\\untitled.exe 注意在编译时需要需要添加-g参数来附带调试信息，这样才可以使用gdb进行调试，否则不能（CLion默认生成的是可以调试的程序，所以直接使用就行了） 进入后，可以看到是这样的一个界面，我们需要输入命令来进行逐步调试，输入r就可以开始运行了： 成功运行出结果，那么具体怎么进行断点调试呢？我们可以使用b 行号的形式在对应的行号打上断点，比如这里对第9行进行断点： 接着我们再输入r之后，程序会暂时卡在断点位置，此时我们可以通过输入v来查看当前所有的局部变量信息： 可以看到现在是冒泡排序的第一轮，所以i和j都还是0，并且数组是乱序的，我们输入c可以继续运行： 继续运行一轮后，此时j就变成1了，因为内层循环执行了一次，我们可以通过p来打印变量的值： 当我们不需要再调试时，可以直接结束掉程序： 当然这仅仅是展示lldb的简单使用，通过使用lldb我们就可以很轻松地在控制台进行调试了。 至此，包括编译、构建、调试的所有操作，我们完全可以脱离IDE纯靠命令行进行操作了（其实在没有图形化界面的年代基本上都是这样写代码的） 结束语 到这里，我们C语言的学习就结束了，感谢各位小伙伴一直以来的支持，希望在下一期视频中，还能见到各位的身影。 之后我们还会开放C语言系列数据结构篇教程，敬请期待。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/C语言程序设计/C语言（三）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/C语言程序设计/C语言（三）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:12 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"other/C语言程序设计/C语言（二）.html":{"url":"other/C语言程序设计/C语言（二）.html","title":"C语言（二）","keywords":"","body":" C语言基础 前面我们已经搭建好了基本的学习环境，现在就让我们开始C语言的学习吧！ C语言的语法层面内容相比其他语言来说，其实算少的了，但是它的难点在于很多概念上的理解，这也是为什么上一章一直在说一些计算机基础相关内容（包括这一章还会继续补一点），这样会有助于各位对于语言的理解，C语言可以说是步入编程领域的分水岭，跨过了这道坎，后续其他编程语言的学习都会无比轻松。 学习编程的过程可能会很枯燥，但是请各位一定不要心急，一步一个脚印，相信大家一定能通关。 C程序基本格式 前面我们在创建项目之后自动生成了一个.c文件，这个就是我们编写的程序代码文件： #include int main() { printf(\"Hello World!\"); return 0; } 操作系统需要执行我们的程序，但是我们的程序中可能写了很多很多的代码，那么肯定需要知道从哪里开始执行才可以，也就是程序的入口，所以我们需要提供一个入口点，我们的C语言程序入口点就是main函数（不过现在还没有讲到函数，所以各位就理解为固定模式即可）它的写法是： int main() { //所有的符号一律采用英文的，别用中文 程序代码... } 注意是int后面空格跟上main()，我们的程序代码使用花括号{}进行囊括（有的人为了方便查阅，会把前半个花括号写在下面） 然后我们看到，如果我们需要打印一段话到控制台，那么就需要使用printf(内容)来完成，这其实就是一种函数调用，但是现在我们还没有接触到，我们注意到括号里面的内容就是我们要打印到控制台的内容： printf(\"Hello World!\"); //注意最后需要添加;来结束这一行，注意是英文的分号，不是中文的！ 我们要打印的内容需要采用双引号进行囊括，被双引号囊括的这一端话，我们称为字符串，当然我们现在还没有学到，所以各位也是记固定模式就好，当我们需要向控制台打印一段话时，就要用双引号囊括这段话，然后放入printf即可。我们会在后续的学习中逐渐认识printf函数。 最顶上还有一句： #include 这个是引入系统库为我们提供的函数，包括printf在内，所以我们以后编写一个C语言程序，就按照固定模式： #include int main() { 程序代码 } 除了程序代码部分我们会进行编写之外，其他的地方采用固定模式就好。 我们在写代码的过程中可以添加一些注释文本，这些文本内容在编译时自动忽略，所以比如我们想边写边记点笔记，就可以添加注释，注释的格式为： #include //引入标准库头文件 int main() { //主函数，程序的入口点 printf(\"Hello World!\"); //向控制台打印字符串 } 当然我们也可以添加多行注释： #include /* * 这是由IDE自动生成的测试代码 * 还是可以的 */ int main() { printf(\"Hello World!\"); //最后还有一句 return 0; 但是我们可以不用写，编译器会自动添加，所以后面讲到之后我们再来说说这玩意。 } OK，基本的一些内容就讲解完毕了。 基本数据类型 我们的程序离不开数据，比如我们需要保存一个数字或是字母，这时候这些东西就是作为数据进行保存，不过不同的数据他们的类型可能不同，比如1就是一个整数，0.5就是一个小数，A就是一个字符，C语言提供了多种数据类型供我们使用，我们就可以很轻松的使用这些数据了。 不同的数据类型占据的空间也会不同，这里我们需要先提一个概念，就是字、字节是什么？ 我们知道，计算机底层实际上只有0和1能够表示，这时如果我们要存储一个数据，比如十进制的3，那么就需要使用2个二进制位来保存，二进制格式为11，占用两个位置，再比如我们要表示十进制的15，这时转换为二进制就是1111占用四个位置（4个bit位）来保存。一般占用8个bit位表示一个字节（B），2个字节等于1个字，所以一个字表示16个bit位，它们是计量单位。 我们常说的内存大小1G、2G等，实际上就是按照下面的进制进行计算的： 8 bit = 1 B ，1024 B = 1KB，1024 KB = 1 MB，1024 MB = 1GB，1024 GB = 1TB，1024TB = 1PB（基本上是1024一个大进位，但是有些硬盘生产厂商是按照1000来计算的，所以我们买电脑的硬盘容量可能是512G的但是实际容量可能会缩水） 在不同位数的系统下基本数据类型的大小可能会不同，因为现在主流已经是64位系统，本教程统一按照64位系统进行讲解。 原码、反码和补码 原码 上面我们说了实际上所有的数字都是使用0和1这样的二进制数来进行表示的，但是这样仅仅只能保存正数，那么负数怎么办呢？ 比如现在一共有4个bit位来保存我们的数据，为了表示正负，我们可以让第一个bit位专门来保存符号，这样，我们这4个bit位能够表示的数据范围就是： 最小：1111 => - (2^2+2^1+2^0) => -7 最大：0111 => + (2^2+2^1+2^0) => +7 => 7 虽然原码表示简单，但是原码在做加减法的时候，很麻烦！以4bit位为例： 1+(-1) = 0001 + 1001 = 怎么让计算机去计算？（虽然我们知道该去怎么算，但是计算机不知道，计算机顶多知道1+1需要进位！） 我们得创造一种更好的表示方式！于是我们引入了反码： 反码 正数的反码是其本身 负数的反码是在其原码的基础上, 符号位不变，其余各个位取反 经过上面的定义，我们再来进行加减法： 1+(-1) = 0001 + 1110 = 1111 => -0 （直接相加，这样就简单多了！） 思考：1111代表-0，0000代表+0，在我们实数的范围内，0有正负之分吗？ 0既不是正数也不是负数，那么显然这样的表示依然不够合理！ 补码 根据上面的问题，我们引入了最终的解决方案，那就是补码，定义如下： 正数的补码就是其本身 （不变！） 负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1) 其实现在就已经能够想通了，-0其实已经被消除了！我们再来看上面的运算： 1+(-1) = 0001 + 1111 = (1)0000 => +0 （现在无论你怎么算，也不会有-0了！） 所以现在，4bit位能够表示的范围是：-8~+7（C使用的就是补码！） 整数类型 我们首先来看看整数类型，整数就是不包含小数点的数据，比如1，99，666等数字，整数包含以下几种类型： int - 占用 4 个字节，32个bit位，能够表示 -2,147,483,648 到 2,147,483,647 之间的数字，默认一般都是使用这种类型 long - 占用 8 个字节，64个bit位。 short - 占用2个字节，16个bit位。 浮点类型 浮点类一般用于保存小数，不过为啥不叫小数类型而是浮点类型呢？因为我们的一个小数分为整数部分和小数部分，我们需要用一部分的bit位去表示整数部分，而另一部分去表示小数部分，至于整数部分和小数部分各自占多少并不是固定的，而是浮动决定的（在计算机组成原理中会深入学习，这里就不多介绍了） float - 单精度浮点，占用4个字节，32个bit位。 double - 双精度浮点，占用8个字节，64个bit位。 字符类型 除了保存数字之外，C语言还支持字符类型，我们的每一个字符都可以使用字符类型来保存： char - 占用1个字节（-128~127），可以表示所有的ASCII码字符，每一个数字对应的是编码表中的一个字符： 编码表中包含了所有我们常见的字符，包括运算符号、数字、大小写字母等（注意只有英文相关的，没有中文和其他语言字符，包括中文的标点符号也没有） 某些无法直接显示的字符（比如换行，换行也算一个字符）需要使用转义字符来进行表示： 有关基本类型的具体使用我们放到下一节进行讲解。 变量 前面我们了解了C语言中的基本类型，那么我们如何使用呢？这时我们就可以创建不同类型的变量了。 变量的使用 变量就像我们在数学中学习的x，y一样，我们可以直接声明一个变量，并利用这些变量进行基本的运算，声明变量的格式为： 数据类型 变量名称 = 初始值; //其中初始值可以不用在定义变量时设定 // = 是赋值操作，可以将等号后面的值赋值给前面的变量，等号后面可以直接写一个数字（常量）、变量名称、算式 比如我们现在想要声明一个整数类型的变量： int a = 10; //变量类型为int（常用），变量名称为a，变量的初始值为10 int a = 10, b = 20; //多个变量可以另起一行编写，也可以像这样用逗号隔开，注意类型必须是一样的 其中，变量的名称并不是随便什么都可以的，它有以下规则： 不能重复使用其他变量使用过的名字。 只能包含英文字母或是下划线、数字，并且严格区分大小写，比如a和A不算同一个变量。 虽然可以包含数字，但是不能以数字开头。 不能是关键字（比如我们上面提到的所有基本数据类型，当然还有一些关键字我们会在后面认识） （建议）使用英文单词，不要使用拼音，多个词可以使用驼峰命名法或是通过下划线连接。 初始值可以是一个常量数据（比如直接写10、0.5这样的数字）也可以是其他变量，或是运算表达式的结果，这样会将其他变量的值作为初始值。 我们可以使用变量来做一些基本的运算： #include int main() { int a = 10; //将10作为a的值 int b = 20; int c = a + b; //注意变量一定要先声明再使用，这里是计算a + b的结果（算式），并作为c的初始值 } 这里使用到了+运算符（之后我们还会介绍其他类型的运算符）这个运算符其实就是我们数学中学习的加法运算，会将左右两边的变量值加起来，得到结果，我们可以将运算结果作为其他变量的初始值，还是很好理解的。 但是现在虽然做了运算，我们还不知道运算的具体结果是什么，所以这里我们通过前面认识的printf函数来将结果打印到控制台： #include int main() { int a = 10; int b = 20; int c = a + b; printf(c); //直接打印变量c } 但是我们发现这样似乎运行不出来结果，不对啊，前面你不是说把要打印到控制台的内容写到printf中吗，怎么这里不行呢？实际上printf是用于格式化打印的，我们来看看如何进行格式化打印，输出我们的变量值： printf(\"c的结果是：%d\", ); //使用%d来代表一个整数类型的数据（占位符），在打印时会自动将c的值替换上去 我们来看看效果： 这样，我们就知道该如何打印我们变量的值了，当然，除了使用%d打印有符号整数之外，还有其他的： 格式控制符 说明 %c 输出一个单一的字符 %hd、%d、%ld 以十进制、有符号的形式输出 short、int、long 类型的整数 %hu、%u、%lu 以十进制、无符号的形式输出 short、int、long 类型的整数 %ho、%o、%lo 以八进制、不带前缀、无符号的形式输出 short、int、long 类型的整数 %#ho、%#o、%#lo 以八进制、带前缀、无符号的形式输出 short、int、long 类型的整数 %hx、%x、%lx %hX、%X、%lX 以十六进制、不带前缀、无符号的形式输出 short、int、long 类型的整数。如果 x 小写，那么输出的十六进制数字也小写；如果 X 大写，那么输出的十六进制数字也大写。 %#hx、%#x、%#lx %#hX、%#X、%#lX 以十六进制、带前缀、无符号的形式输出 short、int、long 类型的整数。如果 x 小写，那么输出的十六进制数字和前缀都小写；如果 X 大写，那么输出的十六进制数字和前缀都大写。 %f、%lf 以十进制的形式输出 float、double 类型的小数 %e、%le %E、%lE 以指数的形式输出 float、double 类型的小数。如果 e 小写，那么输出结果中的 e 也小写；如果 E 大写，那么输出结果中的 E 也大写。 %g、%lg %G、%lG 以十进制和指数中较短的形式输出 float、double 类型的小数，并且小数部分的最后不会添加多余的 0。如果 g 小写，那么当以指数形式输出时 e 也小写；如果 G 大写，那么当以指数形式输出时 E 也大写。 %s 输出一个字符串 比如现在我们要进行小数的运算，还记得我们前面介绍的小数类型有哪些吗？ #include int main() { double a = 0.5; float b = 2.5f; //注意直接写2.5默认表示的是一个double类型的值，我们需要再后面加一个f或是F表示是flaot类型值 printf(\"a + b的结果是：%f\", a + b); //根据上表得到，小数类型需要使用%f表示，这里我们可以直接将a + b放入其中 } 可以看到，结果也是正确的： 当然，我们也可以一次性打印多个，只需要填写多个占位符表示即可： #include int main() { double a = 0.5; float b = 2.5f; //整数类型默认是int，如果要表示为long类型的值，也是需要在最后添加一个l或L printf(\"a = %f, b = %f\", a, b); //后面可以一直添加（逗号隔开），但是注意要和前面的占位符对应 } 结果也是正常的： 我们再来看看字符类型： char c = 'A'; //字符需要使用单引号囊括，且只能有一个字符，不能写成'AA'，这就不是单个字符了 //注意这里的A代表的是A这个字符，对应的ASCII码是65，实际上c存储的是65这个数字 我们也可以通过格式化打印来查看它的值： #include int main() { char c = 'A'; printf(\"变量c的值为：%c 对应的ASCII码为：%d\", c, c); //这里我们使用%c来以字符形式输出，%d输出的是变量数据的整数形式，其实就是对应的ASCII码 } 当然，我们也可以直接让char存储一个数字（ASCII码），同样也可以打印出对应的字符： #include int main() { char c = 66; printf(\"变量c的值为：%c 对应的ASCII码为：%d\", c, c); } 那么现在请各位小伙伴看看下面这段代码会输出什么： #include int main() { int a = 10; char c = 'a'; printf(\"变量c的ASCII码为：%d\", c); } 没错，这里得到的结果就是字符a的ASCII码值，注意千万不要认为c得到的是变量a的值，这里使用的是字符a，跟上面的变量a半毛钱关系都没有： 但是如果我们去掉引号，就相当于把变量a的值给了c，c现在的ASCII码就是10了，所以这里一定要分清楚。 对于某些无法表示的字符，比如换行这类字符，我们没办法直接敲出来，只能使用转义字符进行表示： char c = '\\n'; 详细的转义字符表参见前面的基本数据类型章节。 变量除了有初始值之外，也可以在后续的过程中得到新的值： #include int main() { short s = 10; s = 20; //重新赋值为20，注意这里就不要再指定类型了，指定类型只有在声明变量时才需要 printf(\"%d\", s); //打印结果 } 可以看到，得到的是我们最后一次对变量修改的结果： 那要是我们不对变量设定初始值呢？那么变量会不会有默认值： #include int main() { int a, b, c, d; printf(\"%d,%d,%d,%d\", a, b, c, d); } 可以看到，虽然定义变量但是我们没有为其设定初始值，那么它的值就是不确定的了（千万注意并不是不设定值默认就是0）： 所以各位小伙伴以后在使用时一定要注意这个问题，至于为什么不是0，这是因为内存分配机制，我们在下一章高级篇再进行讲解。 我们再来看一个例子： #include int main() { char c = 127; //已经到达c的最大值了 c = c + 1; //我不管，我就要再加 printf(\"%d\", c); //这时会得到什么结果？ } 怎么127加上1还变成-128了呢？这是由于位数不够，导致运算结果值溢出： 127 + 1= 01111111 + 1 由于现在是二进制，满2进1，所以最后变成 10000000 = 补码形式的 -128 所以，了解上面这些计算机底层原理是很重要的，我们能够很轻松地知道为什么会这样。 在我们的运算中，可能也会存在一些一成不变的值，比如π的值永远都是3.1415....，在我们的程序中，也可以使用这样不可变的变量，我们成为常量。 定义常量和变量比较类似，但是需要在前面添加一个const关键字，表示这是一个常量： 可以看到，常量在一开始设定初始值后，后续是不允许进行修改的。 无符号数 我们知道，所有的数据底层都是采用二进制来进行保存的，而第一位则是用于保存符号位，但是如果我们不考虑这个符号位，那么所有的数都是按照正数来表示，比如考虑了符号位的char类型： 考虑符号表示范围：-128~127 不考虑符号：0~255 我们也可以直接使用这些不带符号位的数据类型： int main() { unsigned char c = -65; //数据类型前面添加unsigned关键字表示采用无符号形式 printf(\"%u\", c); //%u以无符号形式输出十进制数据 } 可以看到这里给了无符号char类型c一个-65的值，但是现在很明显符号位也是作为数值的表示部分，所以结果肯定不是-65： 结合我们前面学习的基础知识，我们来看看为什么得到的是191这个数字。首先char类型占据一个字节，8个bit位： 00000000 -> 现在赋值-65 -> -65的补码形式 -> 10111111 由于现在没有符号位，一律都是正数，所以，10111111 = 128 + 32 + 16 + 8 + 4 + 2 + 1 = 191 我们也可以直接以无符号数形式打印： #include int main() { int i = -1; printf(\"%u\", i); //%u以无符号形式输出十进制数据 } 得到无符号int的最大值。 类型转换 一种类型的数据可以转换为其他类型的数据，这种操作我们称为类型转换，类型转换分为自动类型转换和强制类型转换，比如我们现在希望将一个short类型的数据转换为int类型的数据： #include int main() { short s = 10; int i = s; //直接将s的值传递给i即可，但是注意此时s和i的类型不同 } 这里其实就是一种自动类型转换，自动类型转换就是编译器隐式地进行的数据类型转换，这种转换不需要我们做什么，我们直接写就行，会自动进行转换操作。 float a = 3; //包括这里我们给的明明是一个int整数3但是却可以赋值给float类型，说明也是进行了自动类型转换 如果我们使用一个比转换的类型最大值都还要大的值进行类型转换，比如： #include int main() { int a = 511; char b = a; //最大127 printf(\"%d\", b); } 很明显char类型是无法容纳大于127的数据的，因为只占一个字节，而int占4个字节，如果需要进行转换，那么就只能丢掉前面的就只保留char所需要的那几位了，所以这里得到的就是-1： 511 = int -> 00000000 00000000 00000001 11111111 char -> 11111111 -> -1 我们也可以将整数和小数类型的数据进行互相转换： #include int main() { int a = 99; double d = a; printf(\"%f\", d); } 不过这里需要注意的是，小数类型在转换回整数类型时，会丢失小数部分（注意，不是四舍五入，是直接丢失小数！）： #include int main() { double a = 3.14; int b = a; //这里编译器还提示了黄标，我们可以通过之后讲到的强制类型转换来处理 printf(\"%d\", b); } 除了赋值操作可以进行自动类型转换之外，在运算中也会进行自动类型转换，比如： #include int main() { float a = 2; int b = 3; double c = b / a; // \"/\" 是除以的意思，也就是我们数学中的除法运算，这里表示a除以b printf(\"%f\", c); } 可以看到，这里得到的结果是小数1.5，但是参与运算的既有整数类型，又有浮点类型，结果为什么就确定为浮点类型了呢？这显然是由于类型转换导致的。那么规则是什么呢？ 不同的类型优先级不同（根据长度而定） char和short类型在参与运算时一律转换为int再进行运算。 浮点类型默认按双精度进行计算，所以就算有float类型，也会转换为double类型参与计算。 当有一个更高优先级的类型和一个低优先级的类型同时参与运算时，统一转换为高优先级运算，比如int和long参与运算，那么int转换为long再算，所以结果也是long类型，int和double参与运算，那么先把int转换为double再算。 我们接着来看看强制类型转换，我们可以为手动去指定类型，强制类型转换格式如下： (强制转换类型) 变量、常量或表达式; 比如： #include int main() { int a = (int) 2.5; //2.5是一个double类型的值，但是我们可以强制转换为int类型赋值给a，强制转换之后小数部分丢失 printf(\"%d\", a); } 我们也可以对一个算式的结果进行类型转换： #include int main() { double a = 3.14; int b = (int) (a + 2.8); //注意得括起来表示对整个算式的结果进行类型转换（括号跟数学中的挺像，也是提升优先级使用的，我们会在运算符部分详细讲解），不然强制类型转换只对其之后紧跟着的变量生效 printf(\"%d\", b); } 在我们需要得到两个int相除之后带小数的结果时，强制类型转换就显得很有用： #include int main() { int a = 10, b = 4; double c = a / b; //不进行任何的类型转换，int除以int结果仍然是int，导致小数丢失 double d = (double) a / b; //对a进行强制类型转换，现在是double和int计算，根据上面自动类型转换规则，后面的int自动转换为double，结果也是double了，这样就是正确的结果了 printf(\"不进行类型转换: %f, 进行类型转换: %f\", c, d); } 合理地使用强制类型转换，能够解决我们很多情况下的计算问题。 运算符 前面我们了解了如何声明变量以及变量的类型转换，那么我们如何去使用这些变量来参与计算呢？这是我们本小节的重点。 基本运算符 基本运算符包含我们在数学中常用的一些操作，比如加减乘除，分别对应： 加法运算符：+ 减法运算符：- 乘法运算符：* 除法运算符：/（注意不是“\\”，看清楚一点） 当然，还有我们之前使用的赋值运算符=，我们先来看看赋值运算符的使用，其实在之前我们已经学习过了： 变量 = 值 //其中，值可以直接是一个数字、一个变量、表达式的结果等 实际上等号左边的内容准确的说应该是一个左值，不过大部分情况下都是变量，这里就不展开左值和右值的话题了（感兴趣的小伙伴可以去详细了解，有助于后面学习C++理解右值引用） 最简单的用法就是我们前面所说的，对一个变量进行赋值操作： int a = 10; 也可以连续地使用赋值操作，让一连串的变量都等于后面的值： int a, b; a = b = 20; //从右往左依次给b和a赋值20 可以看出，实际上=运算除了赋值之外，和加减乘除运算一样也是有结果的，比如上面的 a = 就是b = 20 运算的结果（可以看着一个整体），只不过运算的结果就是b被赋值的值，也就是20。 我们接着来看加减法，这个就和我们数学中的是一样的了： #include int main() { int a = 10, b = 5; printf(\"%d\", a + b); //打印 a + b 的结果 } 当然也可以像数学中那样写在一个数或是变量的最前面，表示是正数： int a = +10, b = +5; 不过默认情况下就是正数，所以没必要去写一个+号。减法运算符其实也是一样的： #include int main() { int a = 10, b = 5; printf(\"%d\", a - b); //打印 a - b 的结果 } #include int main() { int a = -10; //等于 -10 printf(\"%d\", -a); //输出 -a 的值，就反着来嘛 } 接着我们来看看乘法和除法运算： #include int main() { int a = 20, b = 10; printf(\"%d, %d\", a * b, a / b); //使用方式和上面的加减法是差不多的 } 还有一个比较有意思的取模运算： #include int main() { int a = 20, b = 8; printf(\"%d\", a % b); //取模运算实际上就是计算a除以b的余数 } 不过很遗憾，在C中没有指数相关的运算符（比如要计算5的10次方），在后面学习了循环语句之后，我们可以尝试来自己实现一个指数运算。 运算符优先级 和数学中一样，运算符是有优先级的： #include int main() { int a = 20, b = 10; printf(\"%d\", a + a * b); //如果没有优先级，那么结果应该是400 } 很明显这里的结果是考虑了优先级的： 在数学中，加减运算的优先级是没有乘除运算优先级高的，所以我们需要先计算那些乘除法，最后再来进行加减法的计算，而C语言中也是这样，运算符之间存在优先级概念。我们在数学中，如果需要优先计算加减法再计算乘除法，那么就需要使用括号来提升加减法的优先级，C语言也可以： #include int main() { int a = 20, b = 10; printf(\"%d\", (a + a) * b); //优先计算 a + a 的结果，再乘以 b } 那要是遇到多重的呢？类似于下面的这种： 数学上的写法：[1 - (3 + 4)] x (-2 ÷ 1) = ? 那么我们在C中就可以这样编写： #include int main() { printf(\"%d\", (1 - (3 + 4)) * (-2 / 1)); //其实写法基本差不多，只需要一律使用小括号即可 } 这样，我们就可以通过()运算符，来提升运算优先级了。 我们来总结一下，上面运算符优先级如下，从左往右依次递减： () > + - (做符号表示，比如-9) > * / % > + - (做加减运算) > = 根据上面的优先级，我们来看看下面a的结果是什么： int c; int a = (3 + (c = 2)) * 6; int b, c; int a = (b = 5, c = b + 8); //逗号运算符从前往后依次执行，赋值结果是最后边的结果 自增自减运算符 我们可以快速使用自增运算符来将变量的值+1，正常情况下我们想要让一个变量值自增需要： int a = 10; a = a + 1; 现在我们只需要替换为： int a = 10; ++a; //使用自增运算符，效果等价于 a = a + 1 并且它也是有结果的，除了做自增运算之外，它的结果是自增之后的值： #include int main() { int a = 10; //int b = a = a + 1; 下面效果完全一致 int b = ++a; printf(\"%d\", b); } 当然我们也可以将自增运算符写到后面，和写在前面的区别是，它是先返回当前变量的结果，再进行自增的，顺序是完全相反的： #include int main() { int a = 10; int b = a++; //写在后面和写在前面是有区别的 printf(\"a = %d, b = %d\", a, b); } 重点内容：自增运算符++在前，那么先自增再出结果；自增运算符++在后，那么先出结果再自增。各位小伙伴可以直接记运算符的位置，来方便记忆。 那要是现在我们不想自增1而是自增2或是其他的数字呢？我们可以使用复合赋值运算符，正常情况下依然是使用普通的赋值运算符： int a = 10; a = a + 5; 但是现在我们可以简写： int a = 10; a += 5; 效果和上面是完全一样的，并且得到的结果也是在自增之后的： #include int main() { int a = 10; int b = a += 5; printf(\"a = %d\", b); } 复合赋值运算符不仅仅支持加法，还支持各种各样的运算： #include int main() { int a = 10; a %= 3; //可以复合各种运算，比如加减乘除、模运算、包括我们我们还要讲到的位运算等 printf(\"a = %d\", a); } 当然，除了自增操作之外，还有自减操作： #include int main() { int a = 10; a--; //--是自减操作，相当于a = a - 1，也可以在前后写，规则和上面的自增是一样的 printf(\"a = %d\", a); } 注意自增自减运算符和+、-做符号是的优先级一样，仅次于()运算符，所以在编写时一定要注意： #include int main() { int a = 10; int b = 5 * --a; printf(\"b = %d\", b); } 位运算符 前面我们学习了乘法运算符*，当我们想要让一个变量的值变成2倍，只需要做一次乘法运算即可： int a = 10; a *= 2; //很明显算完之后a就是20了 但是我们现在可以利用位运算来快速进行计算： int a = 10; a = a 我们会发现这样运算之后得到的结果居然也是20，这是咋算出来的呢？实际上是让所有的bit位进行左移操作，上面就是左移1位，我们可以来看看： 10 = 00001010 现在所以bit位上的数据左移一位 00010100 = 20 是不是感觉特别神奇？就像我们在十进制中，做乘以10的操作一样：22乘以10那么就直接左移了一位变成220，而二进制也是一样的，如果让这些二进制数据左移的话，那么相当于在进行乘2的操作。 比如： #include int main() { int a = 6; a = a 当然能左移那肯定也可以右移： #include int main() { int a = 6; a = a >> 1; //右移其实就是除以2的操作 printf(\"a = %d\", a); } 当然除了移动操作之外，我们也可以进行按位比较操作，先来看看按位与操作： #include int main() { int a = 6, b = 4; int c = a & b; //按位与操作 printf(\"c = %d\", c); } 按位与实际上也是根据每个bit位来进行计算的： 4 = 00000100 6 = 00000110 按位与实际上就是让两个数的每一位都进行比较，如果两个数对应的bit位都是1，那么结果的对应bit位上就是1，其他情况一律为0 所以计算结果为：00000100 = 4 除了按位与之外，还有按位或运算： int a = 6, b = 4; int c = a | b; 4 = 00000100 6 = 00000110 按位与实际上也是让两个数的每一位都进行比较，如果两个数对应bit位上其中一个是1，那么结果的对应bit位上就是1，其他情况为0。 所以计算结果为：00000110 = 6 还有异或和按位非（按位否定）： int a = 6, b = 4; int c = a ^ b; //注意^不是指数运算，表示按位异或运算，让两个数的每一位都进行比较，如果两个数对应bit位上不同时为1或是同时为0，那么结果就是1，否则结果就是0，所以这里的结果就是2 a = ~a; //按位否定针对某个数进行操作，它会将这个数的每一个bit位都置反，0变成1，1变成0，猜猜会变成几 按位运算都是操作数据底层的二进制位来进行的。 逻辑运算符 最后我们来看一下逻辑运算符，逻辑运算符主要用到下一节的流程控制语句中。 逻辑运算符用于计算真和假，比如今天要么下雨要么不下雨，现在我们想要在程序中判断一下是否下雨了，这时就需要用到逻辑运算符，我们来举个例子： #include int main() { int a = 10; _Bool c = a 实际上在C语言中，0一般都表示为假，而非0的所有值（包括正数和负数）都表示为真，上面得到1表示真，0表示假。 除了小于符号可以判断大小之外，还有：、、>=、> 比如我们现在想要判断字符C是否为大写字母： #include int main() { char c = 'D'; printf(\"c是否为大写字母：%d\", c >= 'A'); //由于底层存储的就是ASCII码，这里可以比较ASCII码，也可以写成字符的形式 } 但是我们发现，现在我们的判断只能判断一个条件，也就是说只能判断c是否是大于等于'A'的，但是不能同时判断c的值是否是小于等于'Z'的，所以这时，我们就需要利用逻辑与和逻辑或来连接两个条件了： #include int main() { char c = 'D'; printf(\"c是否为大写字母：%d\", c >= 'A' && c 又比如现在我们希望判断c是否不是大写字母： #include int main() { char c = 'D'; printf(\"c是否不为大写字母：%d\", c 'Z'); //使用||表示逻辑或，只要两边其中一个为真或是都为真，结果就是真 } 当然我们也可以判断c是否为某个字母： #include int main() { char c = 'D'; printf(\"c是否为字母A：%d\", c == 'A'); //注意判断相等时使用==双等号 } 判断不相等也可以使用： printf(\"c是否不为字母A：%d\", c != 'A'); 我们也可以对某个结果取反： #include int main() { int i = 20; printf(\"i是否不小于20：%d\", !(i 这里要注意一下!如果直接作用于某个变量或是常量，那么会直接按照上面的规则（0表示假，非0表示真）非0一律转换为0，0一律转换为1。 这里我们可以结合三目运算符来使用这些逻辑运算符： #include int main() { int i = 0; char c = i > 10 ? 'A' : 'B'; //三目运算符格式为：expression ? 值1 : 值2，返回的结果会根据前面判断的结果来的 //这里是判断i是否大于10，如果大于那么c的值就是A，否则就是B printf(\"%d\", c); } 最后，我们来总结一下前面认识的所有运算符的优先级，从上往下依次降低： 运算符 解释 结合方式 () 同数学中的括号，直接提升到最高优先级 由左向右 ! ~ ++ -- + - 否定，按位否定，增量，减量，正负号 由右向左 * / % 乘，除，取模 由左向右 + - 加，减 由左向右 > 左移，右移 由左向右 = > 小于，小于等于，大于等于，大于 由左向右 == != 等于，不等于 由左向右 & 按位与 由左向右 ^ 按位异或 由左向右 \\ 按位或 由左向右 && 逻辑与 由左向右 \\ \\ 逻辑或 由左向右 ? : 条件 由右向左 = += -= *= /= &= ^= \\ = >= 各种赋值 由右向左 , 逗号（顺序） 由左向右 流程控制 前面我们学习了运算符，知道该如何使用运算符来计算我们想要的内容，但是仅仅依靠计算我们的程序还没办法实现丰富多样的功能，我们还得加点额外的控制操作。 分支语句 - if 我们可能会有这样的一个需求，就是判断某个条件，当满足此条件时，才执行某些代码，那这个时候该怎么办呢？我们可以使用if语句来实现： #include int main() { int i = 0; if(i > 20) { //我们只希望i大于20的时候才执行下面的打印语句 printf(\"Hello World!\"); } printf(\"Hello World?\"); //后面的代码在if之外，无论是否满足if条件，都跟后面的代码无关，所以这里的代码任何情况下都会执行 } if语句的标准格式如下： if(判断条件) { 执行的代码 } 当然如果只需要执行一行代码的话，可以省略花括号： if(判断条件) 一行执行的代码 //注意这样只有后一行代码生效，其他的算作if之外的代码了 现在我们需求升级了，我们需要判断某个条件，当满足此条件时，执行某些代码，而不满足时，我们想要执行另一段代码，我们就可以结合else语句来实现： #include int main() { int i = 0; if(i > 20) { printf(\"Hello World!\"); //满足if条件才执行 } else { printf(\"LBWNB\"); //不满足if条件才执行 } } 但是这样可能还是不够用，比如我们现在希望判断学生的成绩，不同分数段打印的等级不一样，比如90以上就是优秀，70以上就是良好，60以上是及格，其他的都是不及格，那么这种我们又该如何判断呢？要像这样进行连续判断，我们需要使用else-if来完成： #include int main() { int score = 2; if(score >= 90) { printf(\"优秀\"); } else if (score >= 70) { printf(\"良好\"); } else if (score >= 60){ printf(\"及格\"); } else{ printf(\"不及格\"); } } if这类的语句（包括我们下面还要介绍的三种）都是支持嵌套使用的，比如我们现在希望低于60分的同学需要补习，0-30分需要补Java，30-60分需要补C++，这时我们就需要用到嵌套： #include int main() { int score = 2; if(score 30) { //在内层再嵌套一个if语句进行进一步的判断 printf(\"学习C++\"); } else{ printf(\"学习Java\"); } } } 分支语句 - switch 前面我们介绍了if语句，我们可以通过一个if语句轻松地进行条件判断，然后根据对应的条件，来执行不同的逻辑，当然除了这种方式之外，我们也可以使用switch语句来实现，它更适用于多分支的情况： switch (目标) { //我们需要传入一个目标，比如变量，或是计算表达式等 case 匹配值: //如果目标的值等于我们这里给定的匹配值，那么就执行case后面的代码 代码... break; //代码执行结束后需要使用break来结束，否则会继续溜到下一个case继续执行代码 } 比如现在我们要根据学生的等级进行分班，学生有ABC三个等级： #include int main() { char c = 'A'; switch (c) { //这里目标就是变量c case 'A': //分别指定ABC三个匹配值，并且执行不同的代码 printf(\"去尖子班！准备冲刺985大学！\"); break; //执行完之后一定记得break，否则会继续向下执行下一个case中的代码 case 'B': printf(\"去平行班！准备冲刺一本！\"); break; case 'C': printf(\"去职高深造。\"); break; } } switch可以精准匹配某个值，但是它不能进行范围判断，比如我们要判断分数段，这时用switch就很鸡肋了。 当然除了精准匹配之外，其他的情况我们可以用default来表示： switch (目标) { case: ... default: 其他情况下执行的代码 } 比如： #include int main() { char c = 'A'; switch (c) { case 'A': printf(\"去尖子班！\"); break; case 'B': printf(\"去平行班！\"); break; case 'C': printf(\"去差生班！\"); break; default: //其他情况一律就是下面的代码了 printf(\"去读职高，分流\"); } } 当然switch中可以继续嵌套其他的流程控制语句，比如if： #include int main() { char c = 'A'; switch (c) { case 'A': if(c == 'A') { //嵌套一个if语句 printf(\"去尖子班！\"); } break; case 'B': printf(\"去平行班！\"); break; } } 循环语句 - for 通过前面的学习，我们了解了如何使用分支语句来根据不同的条件执行不同的代码，我们接着来看第二种重要的流程控制语句，循环语句。 我们在某些时候，可能需要批量执行某些代码： #include int main() { printf(\"伞兵一号卢本伟准备就绪！\"); //把这句话给我打印三遍 printf(\"伞兵一号卢本伟准备就绪！\"); printf(\"伞兵一号卢本伟准备就绪！\"); } 遇到这种情况，我们由于还没学习循环语句，那么就只能写N次来实现这样的多次执行。现在我们可以使用for循环语句来多次执行： for (表达式1表达式2;表达式3) { 循环体 } 我们来介绍一下： 表达式1：在循环开始时仅执行一次。 表达式2：每次循环开始前会执行一次，要求为判断语句，用于判断是否可以结束循环，若结果为真，那么继续循环，否则结束循环。 表达式3：每次循环完成后会执行一次。 循环体：每次循环都会执行循环体里面的内容，直到循环结束。 一个标准的for循环语句写法如下： //比如现在我们希望循环4次 for (int i = 0; i 我们来看看按顺序打印的结果： #include int main() { //比如现在我们希望循环4次 for (int i = 0; i 这样，利用循环我们就可以批量执行各种操作了。 注意，如果表达式2我们什么都不写，那么会默认判定为真： #include int main() { for (int i = 0; ; ++i) { //表达式2不编写任何内容，默认为真，这样的话循环永远都不会结束 printf(\"%d, \", i); } } 所以，如果我们想要编写一个无限循环，其实什么都不用写就行了： #include int main() { for (;;) { //什么都不写直接无限循环，但是注意，两个分号还是要写的 printf(\"Hello World!\\n\"); //这里用到了\\n表示换行 } } 当然，我们也可以在循环过程中提前终止或是加速循环的进行，这里我们需要认识两个新的关键字： for (int i = 0; i 可以看到，当满足条件时，会直接通过break跳出循环，循环不再继续下去，直接结束掉。 我们也可以加速循环： for (int i = 0; i 虽然使用break和continue关键字能够更方便的控制循环，但是注意在多重循环嵌套下，它只对离它最近的循环生效（就近原则）： for (int i = 1; i 可以看到，continue仅仅加速的是内层循环，而对外层循环没有任何效果，同样的，break也只会终结离它最近的： for (int i = 1; i 循环语句 - while 前面我们介绍了for循环语句，我们接着来看第二种while循环，for循环要求我们填写三个表达式，而while相当于是一个简化版本，它只需要我们填写循环的维持条件即可，比如： #include int main() { while (1) { //每次循环开始之前都会判断括号内的内容是否为真，如果是就继续循环 printf(\"Hello World!\\n\"); //这里会无限循环 } } 相比for循环，while循环更多的用在不明确具体的结束时机的情况下，而for循环更多用于明确知道循环的情况，比如我们现在明确要进行循环10次，此时用for循环会更加合适一些，又比如我们现在只知道当i大于10时需要结束循环，但是i在循环多少次之后才不满足循环条件我们并不知道，此时使用while就比较合适了。 #include int main() { int i = 100; //比如现在我们想看看i不断除以2得到的结果会是什么，但是循环次数我们并不明确 while (i > 0) { //现在唯一知道的是循环条件，只要大于0那么就可以继续除 printf(\"%d, \", i); i /= 2; //每次循环都除以2 } } while也支持使用break和continue来进行循环的控制： int i = 100; while (i > 0) { if(i 我们可以反转循环判断的位置，可以先执行循环内容，然后再做循环条件判断，这里要用到do-while语句： #include int main() { do { //无论满不满足循环条件，先执行循环体里面的内容 printf(\"Hello World!\"); } while (0); //再做判断，如果判断成功，开启下一轮循环，否则结束 } 实战：寻找水仙花数 “水仙花数（Narcissistic number）也被称为超完全数字不变数（pluperfect digital invariant, PPDI）、自恋数、自幂数、阿姆斯壮数或阿姆斯特朗数（Armstrong number），水仙花数是指一个 3 位数，它的每个位上的数字的 3次幂之和等于它本身。例如：1^3 + 5^3+ 3^3 = 153。” 现在请你设计一个C语言程序，打印出所有1000以内的水仙花数。 实战：打印九九乘法表 现在我们要做的是在我们的程序中，也打印出这样的一个乘法表出来，请你设计一个C语言程序来实现它。 实战：斐波那契数列解法其一 斐波那契数列（Fibonacci sequence），又称黄金分割数列，因数学家莱昂纳多·斐波那契（Leonardo Fibonacci）以兔子繁殖为例子而引入，故又称为“兔子数列”，指的是这样一个数列：1、1、2、3、5、8、13、21、34、……在数学上，斐波那契数列以如下被以递推的方法定义：F(0)=0，F(1)=1, F(n)=F(n - 1)+F(n - 2)（n ≥ 2，n ∈ N*）在现代物理、准晶体结构、化学等领域，斐波纳契数列都有直接的应用，为此，美国数学会从 1963 年起出版了以《斐波纳契数列季刊》为名的一份数学杂志，用于专门刊载这方面的研究成果。 斐波那契数列：1，1，2，3，5，8，13，21，34，55，89...，不难发现一个规律，实际上从第三个数开始，每个数字的值都是前两个数字的和，现在请你设计一个C语言程序，可以获取斐波那契数列上任意一位的数字，比如获取第5个数，那么就是5。 #include int main() { int target = 7, result; //target是要获取的数，result是结果 //请在这里实现算法 printf(\"%d\", result); } 数组 现在我们有一个新的需求，我们需要存储2022年每个月都天数，那么此时，为了保存这12个月的天数，我们就得创建12个变量： #include int main() { int january = 31, february = 28, march = 31 ... } 这样是不是太累了点？万一我们想保存100个商品的售价，那岂不是得创建100个变量？这肯定不行啊。 数组的创建和使用 为了解决这种问题，我们可以使用数组，什么是数组呢？简单来说，就是存放数据的一个组，所有的数据都统一存放在这一个组中，一个数组可以同时存放多个数据。比如现在我们想保存12个月的天数，那么我们只需要创建一个int类型的数组就可以了，它可以保存很多个int类型的数据，这些保存在数组中的数据，称为“元素”： int arr[12] = {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}; //12个月的数据全部保存在了一起 可以看到，数组的定义方式也比较简单： 类型 数组名称[数组大小] = {数据1, 数据2...}; //后面的数据可以在一开始的时候不赋值，并且数组大小必须是整数 注意数组只能存放指定类型的数据，一旦确定是不能更改的，因为数组声明后，会在内存中开辟一块连续的区域，来存放这些数据，所以类型和长度必须在一开始就明确。 创建数组的方式有很多种： int a[10]; //直接声明int类型数组，容量为10 int b[10] = {1, 2, 4}; //声明后，可以赋值初始值，使用{}囊括，不一定需要让10个位置都有初始值，比如这里仅仅是为前三个设定了初始值，注意，跟变量一样，如果不设定初始值，数组内的数据并不一定都是0 int c[10] = {1, 2, [4] = 777, [9] = 666}; //我们也可以通过 [下标] = 的形式来指定某一位的初始值，注意下标是从0开始的，第一个元素就是第0个下标位置，比如这里数组容量为10，那么最多到9 int c[] = {1, 2, 3}; //也可以根据后面的赋值来决定数组长度 基本类型都可以声明数组： #include int main() { char str[] = {'A', 'B', 'C'}; //多个字符 char str2[] = \"ABC\"; //实际上字符串就是多个字符的数组形式，有关字符串我们会在下一节进行讲解 } 那么数组定义好了，如何去使用它呢？比如我们现在需要打印12个月的天数： #include int main() { int arr[12] = {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}; for (int i = 0; i 当然我们也可以对数组中的值进行修改： #include int main() { int arr[] = {666, 777, 888}; arr[1] = 999; //比如我们现在想要让第二个元素的值变成999 printf(\"%d\", arr[1]); //打印一下看看是不是变成了999 } 注意，和变量一样，如果只是创建数组但是不赋初始值的话，因为是在内存中随机申请的一块空间，有可能之前其他地方使用过，保存了一些数据，所以数组内部的元素值并不一定都是0： #include int main() { int arr[10]; for (int i = 0; i 不要尝试去访问超出数组长度位置的数据，虽然可以编译通过，但是会给警告，这些数据是毫无意义的： #include int main() { int arr[] = {111, 222, 333}; printf(\"%d\", arr[3]); //不能去访问超出数组长度的元素，很明显这里根本就没有第四个元素 } 多维数组 数组不仅仅只可以有一个维度，我们可以创建二维甚至多维的数组，简单来说就是，存放数组的数组（套娃了属于是）： int arr[][2] = { {20, 10}, {18, 9} }; //可以看到，数组里面存放的居然是数组 //存放的内层数组的长度是需要确定的，存放数组的数组和之前一样，可以根据后面的值决定 比如现在我们要存放2020-2022年每个月的天数，那么此时用一维数组肯定是不方便了，我们就可以使用二维数组来处理： int arr[3][12] = { {31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}, //2020年是闰年，2月有29天 {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}, {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31} }; 这样，我们就通过二维数组将这三年每个月的天数都保存下来了。 那么二维数组又该如何去访问呢？ #include int main() { int arr[3][12] = { {31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}, //2020年是闰年，2月有29天 {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}, {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31} }; printf(\"%d\", arr[0][1]); //比如现在我们想要获取2020年2月的天数，首先第一个是[0]表示存放的第一个数组，第二个[1]表示数组中的第二个元素 } 当然除了二维还可以上升到三维、四维： int arr[2][2][2] = { { {1, 2}, {1, 2}}, { {1, 2}, {1, 2} } }; 有关多维数组，暂时先介绍到这里。 实战：冒泡排序算法 现在有一个int数组，但是数组内的数据是打乱的，现在请你通过C语言，实现将数组中的数据按从小到大的顺序进行排列： #include int main() { int arr[10] = {3, 5, 7, 2, 9, 0, 6, 1, 8, 4}; //乱序的 //请编写代码对以上数组进行排序 } 这里我们使用冒泡排序算法来实现，此算法的核心思想是： 假设数组长度为N 进行N轮循环，每轮循环都选出一个最大的数放到后面。 每次循环中，从第一个数开始，让其与后面的数两两比较，如果更大，就交换位置，如果更小，就不动。 动画演示：https://visualgo.net/zh/sorting?slide=2-2 实战：斐波那契数列解法其二 学习了数组，我们来看看如何利用数组来计算斐波那契数列，这里采用动态规划的思想。 动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。 我们可以在一开始创建一个数组，然后从最开始的条件不断向后推导，从斐波那契数列的规律我们可以得知： fib[i] = fib[i - 1] + fib[i - 2]（这里fib代表斐波那契数列） 得到这样的一个关系（递推方程）就好办了，我们要求解数列第i个位置上的数，只需要知道i - 1和i - 2的值即可，这样，一个大问题，就分成了两个小问题，比如现在我们要求解斐波那契数列的第5个元素： fib[4] = fib[3] + fib[2]现在我们只需要知道fib[3]和fib[2]即可，那么我们接着来看： fib[3] = fib[2] + fib[1]以及fib[2] = fib[1] + fib[0] 由于fib[0]和fib[1]我们已经明确知道是1了，那么现在问题其实已经有结果了，把这些小问题的结果组合起来不就能得到原来大问题的结果了吗？ 现在请你设计一个C语言程序，利用动态规划的思想解决斐波那契数列问题。 实战：打家劫舍 我们继续通过一道简单的算法题来强化动态规划思想。 来源：力扣（LeetCode）No.198 打家劫舍：https://leetcode.cn/problems/house-robber/ 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。 给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。 示例 1： 输入：[1,2,3,1] 输出：4 解释：偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。 偷窃到的最高金额 = 1 + 3 = 4 。 示例 2： 输入：[2,7,9,3,1] 输出：12 解释：偷窃 1 号房屋 (金额 = 2), 偷窃 3 号房屋 (金额 = 9)，接着偷窃 5 号房屋 (金额 = 1)。 偷窃到的最高金额 = 2 + 9 + 1 = 12 。 这道题我们也可以很轻松地按照上面的动态规划思路来处理，首先我们可以将问题分为子问题，比如现在有[2,7,9,3,1]五个房屋，这个问题看起来比较复杂，我们不妨先将大问题先简化成小问题，我们来看看只有N个房屋的情况： 假设现在只有[2]这一个房屋，那么很明显，我可以直接去偷一号房，得到2块钱，所以当有一个房子时最大能偷到2块钱。 假设现在有[2, 7]这两个房屋，那么很明显，我可以直接去偷二号房，得到7块钱，所以当有两个房子时最大能偷到7块钱。 假设现在只有[2, 7, 9]这三个房屋，我们就要来看看了，是先偷一号房再偷三号房好，还是只偷二号房好，根据前面的结论，如果我们偷了一号房，那么就可以继续偷三号房，并且得到的钱就是从一号房过来的钱+三号房的钱，也就是2+9块钱，但是如果只偷二号房的话，那么就只能得到7块钱，所以，三号房能够偷到的最大金额有以下关系（dp是我们求出的第i个房屋的最大偷钱数量，value表示房屋价值，max表示取括号中取最大的一个）： dp[i] = max(dp[i - 1], dp[i - 2] + value[i]) -> 递推方程已得到 这样就不难求出：dp[2] = max(dp[1], dp[0] + value[i]) = dp[2] = max(7, 2 + 9) = dp[2] = 11，所以有三个房屋时最大的金额是11块钱。 所以，实际上我们只需要关心前面计算出来的盗窃最大值即可，而不需要关心前面到底是怎么在偷。 我们以同样的方式来计算四个房屋[2, 7, 9, 3]的情况： dp[3] = max(dp[2], dp[1] + value[3]) = dp[3] = max(11, 7 + 3) = dp[3] = 11 所以，当有四个房屋时，我们依然采用先偷一后偷三的方案，不去偷四号，得到最大价值11块钱。 好了，现在思路已经出来了，我们直接上算法吧，现在请你实现下面的C语言程序： #include int main() { int arr[] = {2,7,9,3,1}, size = 5, result; //请补充程序 printf(\"%d\", result); } 力扣提交，建议各位小伙伴学习了函数和指针之后再回来看看，这里暂时可以跳过。 int max(int a, int b) { return a > b ? a : b; } int rob(int* nums, int numsSize){ if(numsSize == 0) return 0; if(numsSize == 1) return nums[0]; if(numsSize == 2) return max(nums[1], nums[0]); int dp[numsSize]; dp[0] = nums[0]; dp[1] = max(nums[1], nums[0]); for (int i = 2; i 字符串 前面我们学习了数组，而对于字符类型的数组，比较特殊，它实际上可以作为一个字符串（String）表示，字符串就是一个或多个字符的序列，比如我们在一开始认识的\"Hello World!\"，像这样的多个字符形成的一连串数据，就是一个字符串，而printf函数接受的第一个参数也是字符串。 那么，我们就来认识一下字符串。 字符串的创建和使用 在C语言中并没有直接提供存储字符串的类型，我们熟知的能够存储字符的只有char类型，但是它只能存储单个字符，而一连串的字符想要通过变量进行保存，那么就只能依靠数组了，char类型的数组允许我们存放多个字符，这样的话就可以表示字符串了。 比如我们现在想要存储Hello这一连串字符： char str[] = {'H', 'e', 'l', 'l', 'o', '\\0'}; //直接保存单个字符，但是注意，无论内容是什么，字符串末尾必须添加一个‘\\0’字符（ASCII码为0）表示结束。 printf(\"%s\", str); //用%s来作为一个字符串输出 不过这样写起来实在是太麻烦了，我们可以使用更加简便的写法： char str[] = \"Hello\"; //直接使用双引号将所有的内容囊括起来，并且也不需要补充\\0（但是本质上是和上面一样的字符数组） //也可以添加 const char str[] = \"Hello World!\"; 双引号囊括的字符串实际上就是一个const char数组类型的值 printf(\"%s\", str); 这下终于明白了，原来我们一直在写的双引号，其实表示的就是一个字符串。 那么现在请各位小伙伴看看下面的写法有什么不同： \"c\" 'c' 我们发现一个问题，char类型只能保存ASCII编码表中的字符，但是我们发现实际上中文也是可以正常打印的： printf(\"你这瓜保熟吗\"); 这是什么情况？那么多中文字符（差不多有6000多个），用ASCII编码表那128个肯定是没办法全部表示的，但是我们现在需要在电脑中使用中文。这时，我们就需要扩展字符集了。 我们可以使用两个甚至多个字节来表示一个中文字符，这样我们能够表示的数量就大大增加了，GB2132方案规定当连续出现两个大于127的字节时（注意不考虑符号位，此时相当于是第一个bit位一直为1了），表示这是一个中文字符（所以为什么常常有人说一个英文字符占一字节，一个中文字符占两个字节），这样我们就可以表示出超过7000种字符了，不仅仅是中文，甚至中文标点、数学符号等，都可以被正确的表示出来。 10000011 10000110 //这就是一个连续出现都大于127的字节（注意这里是不考虑符号位的） 不过这样能够表示的内容还是不太够，除了那些常见的汉字之外，还有很多的生僻字，比如龘、錕、釿、拷这类的汉字，后来干脆直接只要第一个字节大于127，就表示这是一个汉字的开始，无论下一个字节是什么内容（甚至原来的128个字符也被编到新的表中），这就是Windows至今一直在使用的默认GBK编码格式。 虽然这种编码方式能够很好的解决中文无法表示的问题，但是由于全球还有很多很多的国家以及很多很多种语言，所以我们的最终目标是能够创造一种可以表示全球所有字符的编码方式，整个世界都使用同一种编码格式，这样就可以同时表示全球的语言了。所以这时就出现了一个叫做ISO的（国际标准化组织）组织，来定义一套编码方案来解决所有国家的编码问题，这个新的编码方案就叫做Unicode，规定每个字符必须使用俩个字节，即用16个bit位来表示所有的字符（也就是说原来的那128个字符也要强行用两位来表示） 但是这样的话实际上是很浪费资源的，因为这样很多字符都不会用到两字节来保存，但是又得这样去表示，这就导致某些字符浪费了很多空间。所以最后就有了UTF-8编码格式，区分每个字符的开始是根据字符的高位字节来区分的，比如用一个字节表示的字符，第一个字节高位以“0”开头；用两个字节表示的字符，第一个字节的高位为以“110”开头，后面一个字节以“10开头”；用三个字节表示的字符，第一个字节以“1110”开头，后面俩字节以“10”开头；用四个字节表示的字符，第一个字节以“11110”开头，后面的三个字节以“10”开头： Unicode符号范围（十六进制） UTF-8编码方式(二进制) 0000 0000 ~ 0000 007F 0xxxxxxx 0000 0080 ~ 0000 07FF 110xxxxx 10xxxxxx 0000 0800 ~ 0000 FFFF 1110xxxx 10xxxxxx 10xxxxxx 0001 0000 ~ 0010 FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 所以如果我们的程序需要表示多种语言，最好采用UTF-8编码格式。 简而言之，我们的中文实际上是依靠多个char来进行表示的。 这样，我们就了解了字符串的使用。 scanf、gets、puts函数 函数我们会在下一章详细介绍，不过这里还是要再提到一个比较重要的函数。 前面我们认识了printf函数，实际上这个函数就是用于打印字符串到控制台，我们只需要填入一个字符串和后续的参数即可。 #include int main() { const char str[] = \"Hello World!\"; //注意printf需要填写一个const char数组进去，也就是字符串 printf(str); } 现在我们知道该如何输出，那么输入该如何实现呢，比如我们现在希望将我们想要说的话告诉程序，让程序从控制台读取我们输入的内容，这时我们就需要使用到scanf函数了： #include int main() { char str[10]; scanf(\"%s\", str); //使用scanf函数来接受控制台输入，并将输入的结果按照格式，分配给后续的变量 //比如这里我们想要输入一个字符串，那么依然是使用%s（和输出是一样的占位符），后面跟上我们要赋值的数组（存放输入的内容） printf(\"输入的内容为：%s\", str); } 可以看到，成功接收到用户输入： 当然除了能够扫描成字符串之外，我们也可以直接扫描为一个数字： #include int main() { int a, b; scanf(\"%d\", &a); //连续扫描两个int数字 scanf(\"%d\", &b); //注意，如果不是数组类型，那么这里在填写变量时一定要在前面添加一个&符号（至于为什么，下一章在指针小节中会详细介绍）这里的&不是做与运算，而是取地址操作。 printf(\"a + b = %d\", a + b); //扫描成功后，我们来计算a + b的结果 } 除了使用scanf之外，我们也可以使用字符串专用的函数来接受字符串类型的输入和输出： #include int main() { char str[10]; gets(str); //gets也是接收控制台输入，然后将结果丢给str数组中 puts(str); //puts其实就是直接打印字符串到控制台 } 当然也有专门用于字符输入输出的函数： #include int main() { int c = getchar(); putchar(c); } 由于我们目前还没有学习函数，所以这里稍微提及一下即可。 实战：回文串判断 “回文串”是一个正读和反读都一样的字符串，请你实现一个C语言程序，判断用户输入的字符串（仅出现英文字符）是否为“回文”串。 ABCBA 就是一个回文串，因为正读反读都是一样的 ABCA 就不是一个回文串，因为反着读不一样 实战：字符串匹配KMP算法 现在有两个字符串： str1 = \"abcdabbc\" str2 = \"cda\" 现在请你设计一个C语言程序，判断第一个字符串中是否包含了第二个字符串，比如上面的例子中，很明显第一个字符串包含了第二个字符串。 暴力解法 KMP算法 有关C语言的基础部分内容，我们就讲解到这里，从下一章开始，难度将会有一定的提升，所以请各位小伙伴务必将本章知识点梳理清楚，牢记心中。 window.onload = function() {gitbook.events.on(\"page.change\", function() {var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/C语言程序设计/C语言（二）.html\"});gitalk.render(\"gitalk-container\");});};var gitalk = new Gitalk({\"clientID\":\"f0da19fb826f620b26d6\",\"clientSecret\":\"666fa5dabfb7913cf38b23fd348cf75d6f673820\",\"repo\":\".docs\",\"owner\":\"april-projects\",\"admin\":[\"mobaijun\"],\"id\":\"/other/C语言程序设计/C语言（二）.html\"});gitalk.render(\"gitalk-container\"); Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2023-04-22 03:46:12 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}